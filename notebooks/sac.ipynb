{
 "cells": [
  {
   "cell_type": "code",
   "id": "ba8c59a3eba2f172",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-02T01:45:23.958687Z",
     "start_time": "2024-11-02T01:45:23.862914Z"
    }
   },
   "source": [
    "\n",
    "import time\n",
    "from typing import Any\n",
    "\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import torch\n",
    "import tqdm\n",
    "from torch import optim, nn\n",
    "\n",
    "from src.experiment_logging.experiment_log import ExperimentLogItem\n",
    "from src.experiment_logging.experiment_logger import ExperimentLogger, log_experiment\n",
    "from src.module_analysis import count_parameters\n",
    "from src.reinforcement_learning.algorithms.sac.sac import SAC, SACInfoStashConfig\n",
    "from src.reinforcement_learning.algorithms.sac.sac_policy import SACPolicy\n",
    "from src.reinforcement_learning.core.action_selectors.predicted_std_action_selector import PredictedStdActionSelector\n",
    "from src.reinforcement_learning.core.callback import Callback\n",
    "from src.reinforcement_learning.core.loss_config import LossInfoStashConfig\n",
    "from src.reinforcement_learning.core.policies.components.actor import Actor\n",
    "from src.reinforcement_learning.core.policies.components.q_critic import QCritic\n",
    "from src.reinforcement_learning.gym.parallelize_env import parallelize_env_async\n",
    "from src.stopwatch import Stopwatch\n",
    "from src.summary_statistics import maybe_compute_summary_statistics\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "execution_count": 44
  },
  {
   "cell_type": "code",
   "source": [
    "def get_setup() -> dict[str, str]:\n",
    "    return {\n",
    "        'notebook': _ih[1] + '\\n\\n' + _ih[-1], # first and last cell input (imports and this cell)\n",
    "    }\n",
    "\n",
    "step_stopwatch = Stopwatch()\n",
    "total_stopwatch = Stopwatch()\n",
    "best_iteration_score = -1e6\n",
    "\n",
    "def save_experiment_state():\n",
    "    experiment_id = logger.experiment_log['experiment_id']\n",
    "    algo.save(\n",
    "        folder_location=f'models/{env_name}/{experiment_id}', \n",
    "        name=experiment_id, \n",
    "        latest_log_item=logger.get_latest_log_item()\n",
    "    )\n",
    "    \n",
    "\n",
    "def on_rollout_done(rl: SAC, step: int, info: dict[str, Any], scheduler_values: dict[str, Any]):\n",
    "    if step % 1000 != 0:\n",
    "        return\n",
    "    \n",
    "    episode_scores = rl.buffer.compute_most_recent_episode_scores(rl.num_envs, consider_truncated_as_done=True)\n",
    "    \n",
    "    if len(episode_scores) > 0:\n",
    "    \n",
    "        global best_iteration_score\n",
    "        iteration_score = episode_scores.mean()\n",
    "        if iteration_score >= best_iteration_score:\n",
    "            pass\n",
    "    \n",
    "    info['episode_scores'] = episode_scores\n",
    "        \n",
    "def on_optimization_done(rl: SAC, step: int, info: dict[str, Any], scheduler_values: dict[str, Any]):    \n",
    "    if step % 1000 != 0:\n",
    "        return\n",
    "    \n",
    "    num_env_steps = step * rl.num_envs\n",
    "    \n",
    "    step_time = step_stopwatch.reset()\n",
    "    total_time = total_stopwatch.time_passed()\n",
    "    \n",
    "    tail_indices = rl.buffer.tail_indices(1000)\n",
    "    \n",
    "    episode_scores = info.get('episode_scores')\n",
    "    \n",
    "    log_item: ExperimentLogItem = {\n",
    "        'step': step,\n",
    "        'num_env_steps': num_env_steps,\n",
    "        'scores': maybe_compute_summary_statistics(episode_scores),\n",
    "        'actor_loss': maybe_compute_summary_statistics(info['final_actor_loss']),\n",
    "        'critic_loss': maybe_compute_summary_statistics(info['final_critic_loss']),\n",
    "        'entropy_coef_loss': maybe_compute_summary_statistics(info.get('final_entropy_coef_loss')),\n",
    "        'entropy_coef': maybe_compute_summary_statistics(info['entropy_coef']),\n",
    "        'action_stds': maybe_compute_summary_statistics(info['rollout'].get('action_stds')),\n",
    "        'action_magnitude': maybe_compute_summary_statistics(np.abs(rl.buffer.actions[tail_indices])),\n",
    "        'num_gradient_steps': rl.gradient_steps_performed,\n",
    "        'step_time': step_time,\n",
    "        'total_time': total_time\n",
    "    }\n",
    "    print(logger.format_log_item(\n",
    "        log_item, \n",
    "        mean_format='5.3f', \n",
    "        std_format='5.3f', \n",
    "        step_time='.2f', \n",
    "        total_time='.2f',\n",
    "        scores={\n",
    "            'mean_format': '5.3f',\n",
    "            'n_format': 'd',\n",
    "        }\n",
    "    ), end='\\n\\n')\n",
    "    logger.add_item(log_item)\n",
    "    if step % 10000 == 0:\n",
    "        experiment_id = logger.save_experiment_log()[\"experiment_id\"]\n",
    "        \n",
    "        if step % 100_000 == 0:\n",
    "            rl.policy.save(f'saved_models/{env_name}/sac/{experiment_id}.pth')\n",
    "            \n",
    "        print()\n",
    "    print()\n",
    "\n",
    "device = torch.device(\"cuda:0\") if True else torch.device('cpu')\n",
    "print(f'using device {device}')\n",
    "\n",
    "env_name = 'HalfCheetah-v4'\n",
    "# env_kwargs = {'forward_reward_weight': 1.25, 'healthy_reward': 0.5, 'ctrl_cost_weight': 0.001 }\n",
    "env_kwargs = {}\n",
    "num_envs = 1\n",
    "\n",
    "def create_env(render_mode: str | None):\n",
    "    make_single_env = lambda: gym.make(env_name, render_mode=render_mode, **env_kwargs)\n",
    "    \n",
    "    if num_envs == 1:\n",
    "        return make_single_env()\n",
    "        \n",
    "    return parallelize_env_async(make_single_env, num_envs)\n",
    "\n",
    "\n",
    "def create_policy():\n",
    "    in_size = 17\n",
    "    action_size = 6\n",
    "    \n",
    "    actor_net = nn.Sequential(\n",
    "        nn.Linear(in_size, 256),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(256, 256),\n",
    "        nn.ReLU(),\n",
    "    )\n",
    "\n",
    "    critic = QCritic(\n",
    "        n_critics=2,\n",
    "        create_q_network=lambda: nn.Sequential(\n",
    "            nn.Linear(in_size + action_size, 256),\n",
    "            nn.ReLU(),\n",
    "            # BatchRenorm(256),\n",
    "            nn.Linear(256, 256),\n",
    "            nn.ReLU(),\n",
    "            # BatchRenorm(256),\n",
    "            nn.Linear(256, 1)\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return SACPolicy(\n",
    "        actor=Actor(actor_net, PredictedStdActionSelector(\n",
    "            latent_dim=256,\n",
    "            action_dim=action_size,\n",
    "            base_std=1.0,\n",
    "            squash_output=True,\n",
    "        )),\n",
    "        critic=critic\n",
    "    )\n",
    "\n",
    "\n",
    "env = create_env(render_mode=None)\n",
    "policy = create_policy()\n",
    "logger = ExperimentLogger(f'experiment_logs/{env_name}/sac/')\n",
    "\n",
    "try:\n",
    "    print(f'{count_parameters(policy) = }')\n",
    "    print(f'{env = }, {num_envs = }')\n",
    "        \n",
    "    with ((torch.autograd.set_detect_anomaly(False))):\n",
    "        algo = SAC(\n",
    "            env=env,\n",
    "            policy=policy,\n",
    "            actor_optimizer_provider=lambda params: optim.Adam(params, lr=3e-4),  # (params, lr=3e-4, betas=(0.5, 0.999)),\n",
    "            critic_optimizer_provider=lambda params: optim.Adam(params, lr=3e-4),  # (params, lr=3e-4, betas=(0.5, 0.999)),\n",
    "            buffer_size=1_000_000,\n",
    "            reward_scale=1,\n",
    "            gamma=0.99,\n",
    "            tau=0.005,\n",
    "            entropy_coef_optimizer_provider=lambda params: optim.Adam(params, lr=3e-4),\n",
    "            entropy_coef=1.0,\n",
    "            rollout_steps=1,\n",
    "            gradient_steps=1,\n",
    "            warmup_steps=10_000,\n",
    "            optimization_batch_size=256,\n",
    "            target_update_interval=1,\n",
    "            callback=Callback(\n",
    "                on_rollout_done=on_rollout_done,\n",
    "                rollout_schedulers={},\n",
    "                on_optimization_done=on_optimization_done,\n",
    "                optimization_schedulers={},\n",
    "            ),\n",
    "            stash_config=SACInfoStashConfig(stash_rollout_infos=True, stash_rollout_action_stds=True,\n",
    "                                            stash_entropy_coef=True,\n",
    "                                            entropy_coef_loss=LossInfoStashConfig(stash_final=True),\n",
    "                                            actor_loss=LossInfoStashConfig(stash_final=True),\n",
    "                                            critic_loss=LossInfoStashConfig(stash_final=True)),\n",
    "            torch_device=device,\n",
    "        )\n",
    "        total_stopwatch.reset()\n",
    "        with log_experiment(\n",
    "            logger,\n",
    "            experiment_tags=algo.collect_tags(),\n",
    "            hyper_parameters=algo.collect_hyper_parameters(),\n",
    "            setup=get_setup(),\n",
    "        ) as x:\n",
    "            logger.save_experiment_log()\n",
    "            print('\\nStarting Training\\n\\n')\n",
    "            # import cProfile\n",
    "            # pr = cProfile.Profile()\n",
    "            # pr.enable()\n",
    "            algo.learn(5_000_000)\n",
    "            # pr.disable()  \n",
    "            # pr.dump_stats('profile_stats.pstat')\n",
    "except KeyboardInterrupt as ki:\n",
    "    print('keyboard interrupt')\n",
    "    raise ki\n",
    "finally:\n",
    "    print('closing envs')\n",
    "    time.sleep(0.5)\n",
    "    env.close()\n",
    "    print('envs closed')\n",
    "    \n",
    "\n",
    "print('done')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-21T09:42:19.278055Z",
     "start_time": "2024-10-21T09:39:58.845590Z"
    }
   },
   "id": "f71efe062771e81b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device cuda:0\n",
      "count_parameters(policy) = 217870\n",
      "env = <TimeLimit<OrderEnforcing<PassiveEnvChecker<HalfCheetahEnv<HalfCheetah-v4>>>>>, num_envs = 1\n",
      "Grabbing system information... done!\n",
      "saved experiment log 2024-10-21_09-39-59_555014~4J6lFW at experiment_logs/HalfCheetah-v4/sac/2024-10-21_09-39-59_555014~4J6lFW.json\n",
      "\n",
      "Starting Training\n",
      "\n",
      "\n",
      "self.log_ent_coef = tensor([-0.3001], device='cuda:0', requires_grad=True)\n",
      "actions_pi_log_prob = tensor([[-4.3998],\n",
      "        [-3.9373],\n",
      "        [-3.4147],\n",
      "        [-4.3203],\n",
      "        [-4.1546],\n",
      "        [-3.9914],\n",
      "        [-4.9038],\n",
      "        [-3.5747],\n",
      "        [-4.5029],\n",
      "        [-4.3757],\n",
      "        [-4.1280],\n",
      "        [-4.8241],\n",
      "        [-4.3853],\n",
      "        [-4.6347],\n",
      "        [-3.9751],\n",
      "        [-3.9438],\n",
      "        [-4.3633],\n",
      "        [-4.4005],\n",
      "        [-5.4730],\n",
      "        [-3.9581],\n",
      "        [-4.6724],\n",
      "        [-4.7304],\n",
      "        [-4.3266],\n",
      "        [-3.8694],\n",
      "        [-4.4207],\n",
      "        [-3.8882],\n",
      "        [-4.3190],\n",
      "        [-3.4612],\n",
      "        [-4.2863],\n",
      "        [-3.9118],\n",
      "        [-4.3574],\n",
      "        [-3.1914],\n",
      "        [-3.9225],\n",
      "        [-4.8033],\n",
      "        [-4.5535],\n",
      "        [-3.0936],\n",
      "        [-4.0089],\n",
      "        [-4.6532],\n",
      "        [-3.9015],\n",
      "        [-3.1615],\n",
      "        [-4.0730],\n",
      "        [-4.0092],\n",
      "        [-3.6929],\n",
      "        [-4.2648],\n",
      "        [-3.9301],\n",
      "        [-3.8174],\n",
      "        [-3.6351],\n",
      "        [-3.0329],\n",
      "        [-4.8855],\n",
      "        [-4.0501],\n",
      "        [-4.2616],\n",
      "        [-3.9765],\n",
      "        [-4.1852],\n",
      "        [-3.4276],\n",
      "        [-4.3256],\n",
      "        [-4.0282],\n",
      "        [-4.3448],\n",
      "        [-3.9224],\n",
      "        [-4.0944],\n",
      "        [-3.1787],\n",
      "        [-4.1814],\n",
      "        [-5.1829],\n",
      "        [-3.6619],\n",
      "        [-4.1120],\n",
      "        [-3.9127],\n",
      "        [-4.3130],\n",
      "        [-4.3541],\n",
      "        [-4.2386],\n",
      "        [-4.2544],\n",
      "        [-4.7055],\n",
      "        [-3.5558],\n",
      "        [-2.9979],\n",
      "        [-4.1987],\n",
      "        [-4.0578],\n",
      "        [-3.9421],\n",
      "        [-4.1283],\n",
      "        [-5.1119],\n",
      "        [-4.2174],\n",
      "        [-4.2714],\n",
      "        [-4.1649],\n",
      "        [-3.3295],\n",
      "        [-3.3130],\n",
      "        [-4.4219],\n",
      "        [-4.1464],\n",
      "        [-3.7699],\n",
      "        [-3.5628],\n",
      "        [-3.1998],\n",
      "        [-4.0674],\n",
      "        [-4.6214],\n",
      "        [-3.5131],\n",
      "        [-4.1398],\n",
      "        [-4.1395],\n",
      "        [-3.7110],\n",
      "        [-3.0622],\n",
      "        [-3.8877],\n",
      "        [-4.5154],\n",
      "        [-4.0403],\n",
      "        [-3.9459],\n",
      "        [-3.8136],\n",
      "        [-3.2628],\n",
      "        [-3.1146],\n",
      "        [-3.9356],\n",
      "        [-4.3811],\n",
      "        [-4.0928],\n",
      "        [-3.7168],\n",
      "        [-4.8944],\n",
      "        [-3.6892],\n",
      "        [-4.0823],\n",
      "        [-4.4681],\n",
      "        [-3.8389],\n",
      "        [-4.2615],\n",
      "        [-3.6810],\n",
      "        [-3.4623],\n",
      "        [-3.6664],\n",
      "        [-3.5195],\n",
      "        [-4.0636],\n",
      "        [-3.8156],\n",
      "        [-3.9229],\n",
      "        [-3.8635],\n",
      "        [-4.2144],\n",
      "        [-3.9009],\n",
      "        [-4.1840],\n",
      "        [-3.5695],\n",
      "        [-4.1704],\n",
      "        [-3.3531],\n",
      "        [-4.0833],\n",
      "        [-4.1739],\n",
      "        [-3.3101],\n",
      "        [-3.7578],\n",
      "        [-3.8021],\n",
      "        [-4.2937],\n",
      "        [-3.4825],\n",
      "        [-3.0235],\n",
      "        [-3.8429],\n",
      "        [-4.5215],\n",
      "        [-4.0750],\n",
      "        [-4.1317],\n",
      "        [-3.7806],\n",
      "        [-4.0473],\n",
      "        [-4.0303],\n",
      "        [-4.5321],\n",
      "        [-2.9133],\n",
      "        [-4.1841],\n",
      "        [-3.7722],\n",
      "        [-3.6562],\n",
      "        [-4.3684],\n",
      "        [-4.7389],\n",
      "        [-3.6257],\n",
      "        [-3.6654],\n",
      "        [-4.6968],\n",
      "        [-3.1055],\n",
      "        [-4.6477],\n",
      "        [-4.1194],\n",
      "        [-4.4566],\n",
      "        [-3.4406],\n",
      "        [-3.4515],\n",
      "        [-3.5819],\n",
      "        [-3.9877],\n",
      "        [-4.8069],\n",
      "        [-3.9710],\n",
      "        [-4.4786],\n",
      "        [-4.1696],\n",
      "        [-4.3845],\n",
      "        [-3.3784],\n",
      "        [-4.0111],\n",
      "        [-4.3397],\n",
      "        [-4.2069],\n",
      "        [-4.6781],\n",
      "        [-4.4939],\n",
      "        [-3.4579],\n",
      "        [-3.5271],\n",
      "        [-4.1058],\n",
      "        [-4.3371],\n",
      "        [-4.1189],\n",
      "        [-4.2197],\n",
      "        [-4.1897],\n",
      "        [-3.3011],\n",
      "        [-3.7382],\n",
      "        [-3.5143],\n",
      "        [-3.9398],\n",
      "        [-3.8531],\n",
      "        [-3.3815],\n",
      "        [-3.4862],\n",
      "        [-3.8778],\n",
      "        [-4.7110],\n",
      "        [-4.6284],\n",
      "        [-4.1887],\n",
      "        [-4.0191],\n",
      "        [-4.4778],\n",
      "        [-3.8793],\n",
      "        [-4.0245],\n",
      "        [-4.4234],\n",
      "        [-3.8538],\n",
      "        [-3.9921],\n",
      "        [-3.4944],\n",
      "        [-4.2397],\n",
      "        [-3.8508],\n",
      "        [-4.1952],\n",
      "        [-4.2193],\n",
      "        [-3.8249],\n",
      "        [-4.0336],\n",
      "        [-4.1000],\n",
      "        [-4.0805],\n",
      "        [-3.9439],\n",
      "        [-4.1941],\n",
      "        [-2.7905],\n",
      "        [-4.0218],\n",
      "        [-3.9377],\n",
      "        [-4.2812],\n",
      "        [-4.0798],\n",
      "        [-3.4780],\n",
      "        [-3.5882],\n",
      "        [-4.2141],\n",
      "        [-4.2786],\n",
      "        [-4.5031],\n",
      "        [-3.5720],\n",
      "        [-4.5562],\n",
      "        [-3.7332],\n",
      "        [-4.0470],\n",
      "        [-4.4555],\n",
      "        [-4.5332],\n",
      "        [-3.8635],\n",
      "        [-3.2268],\n",
      "        [-4.6055],\n",
      "        [-4.3009],\n",
      "        [-4.9044],\n",
      "        [-4.2729],\n",
      "        [-2.2976],\n",
      "        [-4.3149],\n",
      "        [-4.0584],\n",
      "        [-4.0529],\n",
      "        [-4.0900],\n",
      "        [-3.5281],\n",
      "        [-3.6999],\n",
      "        [-3.4123],\n",
      "        [-4.1408],\n",
      "        [-4.9527],\n",
      "        [-3.7832],\n",
      "        [-3.3156],\n",
      "        [-3.0010],\n",
      "        [-4.5319],\n",
      "        [-3.7202],\n",
      "        [-3.6711],\n",
      "        [-3.9920],\n",
      "        [-4.0389],\n",
      "        [-2.9517],\n",
      "        [-5.6403],\n",
      "        [-3.4762],\n",
      "        [-2.7155],\n",
      "        [-2.7735],\n",
      "        [-3.5743],\n",
      "        [-3.9842],\n",
      "        [-4.6897],\n",
      "        [-4.3769],\n",
      "        [-4.9142],\n",
      "        [-4.3282]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "step = 11000, num_env_steps = 11000, scores = -262.135 (n=1), actor_loss = -18.051, critic_loss = 0.962, entropy_coef_loss = -3.003, entropy_coef = 0.741, action_stds = 0.860 ± 0.049, action_magnitude = 0.529 ± 0.287, num_gradient_steps = 1000, step_time = 10.71, total_time = 10.06\n",
      "\n",
      "\n",
      "self.log_ent_coef = tensor([-0.5995], device='cuda:0', requires_grad=True)\n",
      "actions_pi_log_prob = tensor([[-3.5875],\n",
      "        [-4.2454],\n",
      "        [-4.6229],\n",
      "        [-3.2468],\n",
      "        [-4.7667],\n",
      "        [-4.3270],\n",
      "        [-4.4681],\n",
      "        [-4.6440],\n",
      "        [-4.4491],\n",
      "        [-4.8900],\n",
      "        [-3.3983],\n",
      "        [-3.7000],\n",
      "        [-3.5714],\n",
      "        [-4.2697],\n",
      "        [-3.9796],\n",
      "        [-3.6022],\n",
      "        [-2.2914],\n",
      "        [-5.0078],\n",
      "        [-3.8878],\n",
      "        [-3.5946],\n",
      "        [-2.9996],\n",
      "        [-4.4518],\n",
      "        [-4.2733],\n",
      "        [-3.5406],\n",
      "        [-2.4363],\n",
      "        [-2.9495],\n",
      "        [-3.6114],\n",
      "        [-4.6136],\n",
      "        [-4.6886],\n",
      "        [-4.7255],\n",
      "        [-3.7258],\n",
      "        [-4.4292],\n",
      "        [-3.4770],\n",
      "        [-2.5836],\n",
      "        [-3.4929],\n",
      "        [-4.5655],\n",
      "        [-3.7668],\n",
      "        [-4.1325],\n",
      "        [-3.8714],\n",
      "        [-4.3127],\n",
      "        [-4.5270],\n",
      "        [-3.5112],\n",
      "        [-4.0442],\n",
      "        [-3.8957],\n",
      "        [-3.5294],\n",
      "        [-2.1421],\n",
      "        [-4.0384],\n",
      "        [-4.3430],\n",
      "        [-3.2728],\n",
      "        [-3.4024],\n",
      "        [-4.3818],\n",
      "        [-4.4163],\n",
      "        [-4.0515],\n",
      "        [-3.5833],\n",
      "        [-5.1842],\n",
      "        [-4.3323],\n",
      "        [-4.0640],\n",
      "        [-4.0988],\n",
      "        [-4.0730],\n",
      "        [-3.6087],\n",
      "        [-3.9504],\n",
      "        [-4.8400],\n",
      "        [-3.8048],\n",
      "        [-4.8976],\n",
      "        [-3.7759],\n",
      "        [-4.0786],\n",
      "        [-3.0409],\n",
      "        [-3.4976],\n",
      "        [-3.7554],\n",
      "        [-2.1917],\n",
      "        [-3.4786],\n",
      "        [-3.7591],\n",
      "        [-3.1547],\n",
      "        [-3.4298],\n",
      "        [-4.8186],\n",
      "        [-3.6547],\n",
      "        [-3.7939],\n",
      "        [-1.7633],\n",
      "        [-4.5844],\n",
      "        [-4.0183],\n",
      "        [-4.2091],\n",
      "        [-4.1180],\n",
      "        [-4.6250],\n",
      "        [-4.4183],\n",
      "        [-3.8996],\n",
      "        [-4.6517],\n",
      "        [-4.5546],\n",
      "        [-3.4696],\n",
      "        [-3.9515],\n",
      "        [-4.1677],\n",
      "        [-3.8351],\n",
      "        [-4.2885],\n",
      "        [-3.9335],\n",
      "        [-4.0539],\n",
      "        [-4.0736],\n",
      "        [-4.6595],\n",
      "        [-3.9388],\n",
      "        [-2.8785],\n",
      "        [-4.8686],\n",
      "        [-4.3256],\n",
      "        [-3.4276],\n",
      "        [-4.0695],\n",
      "        [-3.6028],\n",
      "        [-4.5629],\n",
      "        [-3.5961],\n",
      "        [-3.2980],\n",
      "        [-4.2365],\n",
      "        [-3.8333],\n",
      "        [-3.5068],\n",
      "        [-4.3675],\n",
      "        [-5.0027],\n",
      "        [-4.2629],\n",
      "        [-3.8061],\n",
      "        [-4.7017],\n",
      "        [-4.4687],\n",
      "        [-4.2745],\n",
      "        [-4.6890],\n",
      "        [-4.6590],\n",
      "        [-4.1932],\n",
      "        [-3.4603],\n",
      "        [-3.5462],\n",
      "        [-3.4638],\n",
      "        [-4.7248],\n",
      "        [-3.7072],\n",
      "        [-3.5691],\n",
      "        [-3.8131],\n",
      "        [-4.3073],\n",
      "        [-3.5480],\n",
      "        [-3.1803],\n",
      "        [-3.3855],\n",
      "        [-3.6210],\n",
      "        [-4.2709],\n",
      "        [-4.6129],\n",
      "        [-2.7802],\n",
      "        [-4.8358],\n",
      "        [-4.2966],\n",
      "        [-3.8778],\n",
      "        [-3.7642],\n",
      "        [-4.4090],\n",
      "        [-4.2335],\n",
      "        [-3.1872],\n",
      "        [-3.2374],\n",
      "        [-3.6216],\n",
      "        [-4.1890],\n",
      "        [-4.2977],\n",
      "        [-3.3144],\n",
      "        [-3.5198],\n",
      "        [-4.7732],\n",
      "        [-3.9882],\n",
      "        [-4.5403],\n",
      "        [-3.3775],\n",
      "        [-3.7450],\n",
      "        [-3.4719],\n",
      "        [-4.5327],\n",
      "        [-3.8781],\n",
      "        [-2.8949],\n",
      "        [-4.1981],\n",
      "        [-3.2722],\n",
      "        [-4.1810],\n",
      "        [-4.3946],\n",
      "        [-2.6534],\n",
      "        [-2.3540],\n",
      "        [-5.1279],\n",
      "        [-4.7088],\n",
      "        [-4.2062],\n",
      "        [-4.3898],\n",
      "        [-3.0603],\n",
      "        [-4.5527],\n",
      "        [-4.7152],\n",
      "        [-4.9402],\n",
      "        [-4.8886],\n",
      "        [-3.8179],\n",
      "        [-4.5940],\n",
      "        [-4.3663],\n",
      "        [-4.2365],\n",
      "        [-4.8974],\n",
      "        [-4.4249],\n",
      "        [-3.4191],\n",
      "        [-3.1259],\n",
      "        [-5.5844],\n",
      "        [-3.6464],\n",
      "        [-4.5135],\n",
      "        [-3.7943],\n",
      "        [-3.0580],\n",
      "        [-3.2094],\n",
      "        [-4.2815],\n",
      "        [-4.8367],\n",
      "        [-3.1396],\n",
      "        [-4.8114],\n",
      "        [-4.4610],\n",
      "        [-4.1427],\n",
      "        [-3.9603],\n",
      "        [-3.4100],\n",
      "        [-3.7775],\n",
      "        [-5.2980],\n",
      "        [-2.9114],\n",
      "        [-3.0920],\n",
      "        [-3.4630],\n",
      "        [-4.7219],\n",
      "        [-3.6247],\n",
      "        [-3.5915],\n",
      "        [-3.0323],\n",
      "        [-3.5850],\n",
      "        [-3.7872],\n",
      "        [-4.3760],\n",
      "        [-3.6478],\n",
      "        [-4.0724],\n",
      "        [-4.6505],\n",
      "        [-4.5133],\n",
      "        [-4.2931],\n",
      "        [-4.7316],\n",
      "        [-3.6545],\n",
      "        [-4.5720],\n",
      "        [-5.0481],\n",
      "        [-3.6815],\n",
      "        [-4.1610],\n",
      "        [-4.0223],\n",
      "        [-4.5577],\n",
      "        [-4.9285],\n",
      "        [-4.3565],\n",
      "        [-3.4722],\n",
      "        [-3.7135],\n",
      "        [-3.7547],\n",
      "        [-2.9751],\n",
      "        [-3.9747],\n",
      "        [-3.8337],\n",
      "        [-3.3358],\n",
      "        [-3.3199],\n",
      "        [-4.5355],\n",
      "        [-1.8697],\n",
      "        [-4.6868],\n",
      "        [-3.5077],\n",
      "        [-4.4621],\n",
      "        [-3.7172],\n",
      "        [-4.3132],\n",
      "        [-4.5385],\n",
      "        [-3.9228],\n",
      "        [-3.9896],\n",
      "        [-4.2116],\n",
      "        [-3.7392],\n",
      "        [-3.5208],\n",
      "        [-4.3361],\n",
      "        [-4.1029],\n",
      "        [-4.3030],\n",
      "        [-3.9617],\n",
      "        [-4.3443],\n",
      "        [-3.8404],\n",
      "        [-3.6322],\n",
      "        [-5.3257],\n",
      "        [-4.4549],\n",
      "        [-4.9418],\n",
      "        [-3.7303],\n",
      "        [-4.2675],\n",
      "        [-4.2974],\n",
      "        [-3.7859],\n",
      "        [-3.8020]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "step = 12000, num_env_steps = 12000, scores = -209.470 (n=1), actor_loss = -25.713, critic_loss = 1.118, entropy_coef_loss = -5.980, entropy_coef = 0.549, action_stds = 0.891 ± 0.019, action_magnitude = 0.532 ± 0.288, num_gradient_steps = 2000, step_time = 7.37, total_time = 17.43\n",
      "\n",
      "\n",
      "self.log_ent_coef = tensor([-0.8984], device='cuda:0', requires_grad=True)\n",
      "actions_pi_log_prob = tensor([[-3.5266],\n",
      "        [-3.7895],\n",
      "        [-3.0174],\n",
      "        [-3.2664],\n",
      "        [-4.8096],\n",
      "        [-3.7346],\n",
      "        [-4.4041],\n",
      "        [-3.8835],\n",
      "        [-3.2624],\n",
      "        [-4.1594],\n",
      "        [-4.1146],\n",
      "        [-3.6776],\n",
      "        [-3.0439],\n",
      "        [-3.4319],\n",
      "        [-3.3719],\n",
      "        [-4.5585],\n",
      "        [-4.5166],\n",
      "        [-4.2398],\n",
      "        [-3.7205],\n",
      "        [-4.1919],\n",
      "        [-2.8451],\n",
      "        [-3.6465],\n",
      "        [-4.1522],\n",
      "        [-3.1022],\n",
      "        [-4.3542],\n",
      "        [-3.7175],\n",
      "        [-4.6652],\n",
      "        [-3.9359],\n",
      "        [-4.3242],\n",
      "        [-3.4578],\n",
      "        [-5.2257],\n",
      "        [-4.1619],\n",
      "        [-3.3938],\n",
      "        [-3.9018],\n",
      "        [-5.2297],\n",
      "        [-3.9554],\n",
      "        [-5.1460],\n",
      "        [-3.7259],\n",
      "        [-3.4755],\n",
      "        [-4.5360],\n",
      "        [-3.2558],\n",
      "        [-3.4677],\n",
      "        [-3.0016],\n",
      "        [-4.2169],\n",
      "        [-4.9278],\n",
      "        [-4.4915],\n",
      "        [-2.7615],\n",
      "        [-4.6385],\n",
      "        [-3.5172],\n",
      "        [-3.5987],\n",
      "        [-3.1168],\n",
      "        [-3.1436],\n",
      "        [-4.4633],\n",
      "        [-3.7182],\n",
      "        [-2.5934],\n",
      "        [-4.5276],\n",
      "        [-4.0739],\n",
      "        [-4.0247],\n",
      "        [-4.6783],\n",
      "        [-4.2767],\n",
      "        [-4.5332],\n",
      "        [-4.0232],\n",
      "        [-4.3662],\n",
      "        [-2.8842],\n",
      "        [-4.1391],\n",
      "        [-3.2242],\n",
      "        [-4.3743],\n",
      "        [-2.9703],\n",
      "        [-4.3162],\n",
      "        [-3.5938],\n",
      "        [-4.4952],\n",
      "        [-3.6006],\n",
      "        [-3.7516],\n",
      "        [-2.7736],\n",
      "        [-3.8077],\n",
      "        [-4.0952],\n",
      "        [-2.9558],\n",
      "        [-4.6527],\n",
      "        [-4.3450],\n",
      "        [-4.6121],\n",
      "        [-3.0389],\n",
      "        [-2.8652],\n",
      "        [-3.2093],\n",
      "        [-4.9649],\n",
      "        [-3.2683],\n",
      "        [-4.0062],\n",
      "        [-3.5906],\n",
      "        [-4.0736],\n",
      "        [-4.1326],\n",
      "        [-4.0190],\n",
      "        [-3.0569],\n",
      "        [-3.0129],\n",
      "        [-4.9187],\n",
      "        [-3.6542],\n",
      "        [-4.0463],\n",
      "        [-4.2599],\n",
      "        [-3.3707],\n",
      "        [-5.1557],\n",
      "        [-3.4111],\n",
      "        [-4.7927],\n",
      "        [-2.2363],\n",
      "        [-3.9419],\n",
      "        [-3.4072],\n",
      "        [-4.2070],\n",
      "        [-3.2649],\n",
      "        [-4.0567],\n",
      "        [-3.1814],\n",
      "        [-3.1874],\n",
      "        [-4.8573],\n",
      "        [-2.1242],\n",
      "        [-3.2267],\n",
      "        [-4.1123],\n",
      "        [-4.7468],\n",
      "        [-4.3849],\n",
      "        [-4.4384],\n",
      "        [-3.9840],\n",
      "        [-4.3629],\n",
      "        [-5.3977],\n",
      "        [-4.0159],\n",
      "        [-2.5601],\n",
      "        [-4.2386],\n",
      "        [-3.4844],\n",
      "        [-3.0109],\n",
      "        [-3.6904],\n",
      "        [-3.8443],\n",
      "        [-4.3169],\n",
      "        [-3.7574],\n",
      "        [-3.0697],\n",
      "        [-4.0741],\n",
      "        [-4.2816],\n",
      "        [-2.9764],\n",
      "        [-3.0258],\n",
      "        [-5.2419],\n",
      "        [-5.3999],\n",
      "        [-2.5504],\n",
      "        [-3.6712],\n",
      "        [-5.0485],\n",
      "        [-1.8039],\n",
      "        [-2.9811],\n",
      "        [-4.1920],\n",
      "        [-3.9891],\n",
      "        [-4.0721],\n",
      "        [-4.5147],\n",
      "        [-3.5699],\n",
      "        [-4.4021],\n",
      "        [-5.2567],\n",
      "        [-4.1839],\n",
      "        [-4.1335],\n",
      "        [-3.3858],\n",
      "        [-3.3467],\n",
      "        [-2.5136],\n",
      "        [-4.4101],\n",
      "        [-4.1633],\n",
      "        [-3.3082],\n",
      "        [-4.6723],\n",
      "        [-3.8934],\n",
      "        [-4.2951],\n",
      "        [-4.0743],\n",
      "        [-2.0088],\n",
      "        [-4.0676],\n",
      "        [-5.3689],\n",
      "        [-4.9337],\n",
      "        [-4.6802],\n",
      "        [-1.6765],\n",
      "        [-3.7102],\n",
      "        [-4.6023],\n",
      "        [-3.4499],\n",
      "        [-4.3133],\n",
      "        [-3.4754],\n",
      "        [-4.2464],\n",
      "        [-4.3740],\n",
      "        [-3.8883],\n",
      "        [-4.2598],\n",
      "        [-5.5000],\n",
      "        [-4.9222],\n",
      "        [-4.1422],\n",
      "        [-4.5461],\n",
      "        [-2.9083],\n",
      "        [-5.0204],\n",
      "        [-3.0021],\n",
      "        [-2.6132],\n",
      "        [-4.1550],\n",
      "        [-3.3629],\n",
      "        [-3.7996],\n",
      "        [-3.2004],\n",
      "        [-3.9306],\n",
      "        [-3.7385],\n",
      "        [-2.1574],\n",
      "        [-4.3413],\n",
      "        [-3.8187],\n",
      "        [-3.6530],\n",
      "        [-4.9460],\n",
      "        [-3.7839],\n",
      "        [-3.2749],\n",
      "        [-3.9674],\n",
      "        [-4.6812],\n",
      "        [-3.2774],\n",
      "        [-1.4527],\n",
      "        [-4.6469],\n",
      "        [-3.4059],\n",
      "        [-5.1020],\n",
      "        [-4.2631],\n",
      "        [-3.7164],\n",
      "        [-3.6844],\n",
      "        [-4.1961],\n",
      "        [-4.9865],\n",
      "        [-3.7078],\n",
      "        [-4.2094],\n",
      "        [-4.4272],\n",
      "        [-3.0606],\n",
      "        [-4.4017],\n",
      "        [-3.9367],\n",
      "        [-3.2725],\n",
      "        [-4.0277],\n",
      "        [-2.7197],\n",
      "        [-3.9662],\n",
      "        [-3.3030],\n",
      "        [-4.6000],\n",
      "        [-3.9736],\n",
      "        [-3.3439],\n",
      "        [-2.9883],\n",
      "        [-3.8360],\n",
      "        [-4.0853],\n",
      "        [-4.1139],\n",
      "        [-4.0474],\n",
      "        [-3.7459],\n",
      "        [-5.4191],\n",
      "        [-3.7726],\n",
      "        [-3.2452],\n",
      "        [-4.5419],\n",
      "        [-3.2268],\n",
      "        [-4.0886],\n",
      "        [-4.0752],\n",
      "        [-4.1698],\n",
      "        [-2.7049],\n",
      "        [-3.9410],\n",
      "        [-3.2450],\n",
      "        [-4.3122],\n",
      "        [-3.9135],\n",
      "        [-2.8625],\n",
      "        [-3.3335],\n",
      "        [-4.5213],\n",
      "        [-4.7733],\n",
      "        [-2.5045],\n",
      "        [-3.7901],\n",
      "        [-4.3255],\n",
      "        [-3.3552],\n",
      "        [-3.5179],\n",
      "        [-3.0644],\n",
      "        [-3.3356],\n",
      "        [-4.0440],\n",
      "        [-4.2761],\n",
      "        [-1.1951],\n",
      "        [-4.0230],\n",
      "        [-5.0926],\n",
      "        [-3.2392]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "step = 13000, num_env_steps = 13000, scores = -276.700 (n=1), actor_loss = -30.292, critic_loss = 1.517, entropy_coef_loss = -8.850, entropy_coef = 0.407, action_stds = 0.885 ± 0.021, action_magnitude = 0.536 ± 0.290, num_gradient_steps = 3000, step_time = 7.45, total_time = 24.88\n",
      "\n",
      "\n",
      "self.log_ent_coef = tensor([-1.1953], device='cuda:0', requires_grad=True)\n",
      "actions_pi_log_prob = tensor([[-3.4129],\n",
      "        [-6.0135],\n",
      "        [-4.1072],\n",
      "        [-4.6487],\n",
      "        [-6.0921],\n",
      "        [-4.3541],\n",
      "        [-4.3694],\n",
      "        [-3.4749],\n",
      "        [-2.8925],\n",
      "        [-4.1854],\n",
      "        [-1.6962],\n",
      "        [-3.2180],\n",
      "        [-2.8016],\n",
      "        [-3.4819],\n",
      "        [-4.5955],\n",
      "        [-2.4905],\n",
      "        [-4.0771],\n",
      "        [-3.0085],\n",
      "        [-2.1940],\n",
      "        [-3.4054],\n",
      "        [-4.6814],\n",
      "        [-3.4141],\n",
      "        [-3.9808],\n",
      "        [-4.2996],\n",
      "        [-3.6804],\n",
      "        [-4.7959],\n",
      "        [-3.1737],\n",
      "        [-3.1813],\n",
      "        [-3.4464],\n",
      "        [-3.6171],\n",
      "        [-3.3485],\n",
      "        [-4.0831],\n",
      "        [-4.0261],\n",
      "        [-2.6324],\n",
      "        [-5.0696],\n",
      "        [-4.2219],\n",
      "        [-2.2074],\n",
      "        [-1.2714],\n",
      "        [-4.7023],\n",
      "        [-3.8788],\n",
      "        [-4.4310],\n",
      "        [-3.9446],\n",
      "        [-4.0673],\n",
      "        [-3.6698],\n",
      "        [-3.5530],\n",
      "        [-4.4002],\n",
      "        [-4.6752],\n",
      "        [-3.3530],\n",
      "        [-4.0015],\n",
      "        [-2.5746],\n",
      "        [-4.1523],\n",
      "        [-3.6595],\n",
      "        [-3.3884],\n",
      "        [-3.5709],\n",
      "        [-3.9019],\n",
      "        [-3.4677],\n",
      "        [-4.2962],\n",
      "        [-3.1150],\n",
      "        [-2.3910],\n",
      "        [-4.3714],\n",
      "        [-3.3558],\n",
      "        [-2.0684],\n",
      "        [-4.1717],\n",
      "        [-3.7023],\n",
      "        [-3.2997],\n",
      "        [-1.7706],\n",
      "        [-3.8646],\n",
      "        [-2.8669],\n",
      "        [-2.9703],\n",
      "        [-3.5837],\n",
      "        [-1.5303],\n",
      "        [-4.2291],\n",
      "        [-3.2095],\n",
      "        [-2.4543],\n",
      "        [-2.9033],\n",
      "        [-2.2934],\n",
      "        [-4.6410],\n",
      "        [-5.5408],\n",
      "        [-4.5100],\n",
      "        [-3.2339],\n",
      "        [-3.2428],\n",
      "        [-4.1288],\n",
      "        [-4.1265],\n",
      "        [-3.6979],\n",
      "        [-3.2736],\n",
      "        [-3.7043],\n",
      "        [-5.1786],\n",
      "        [-4.6833],\n",
      "        [-1.9475],\n",
      "        [-4.5420],\n",
      "        [-1.9535],\n",
      "        [-2.3770],\n",
      "        [-4.3685],\n",
      "        [-3.3102],\n",
      "        [-3.1704],\n",
      "        [-3.6382],\n",
      "        [-1.7023],\n",
      "        [-3.0513],\n",
      "        [-2.6391],\n",
      "        [-4.1484],\n",
      "        [-5.1864],\n",
      "        [-2.4170],\n",
      "        [-3.3626],\n",
      "        [-3.9917],\n",
      "        [-4.6181],\n",
      "        [-4.7287],\n",
      "        [-3.4301],\n",
      "        [-2.3364],\n",
      "        [-4.0011],\n",
      "        [-2.0403],\n",
      "        [-4.1982],\n",
      "        [-5.4875],\n",
      "        [-3.4884],\n",
      "        [-4.8146],\n",
      "        [-4.1497],\n",
      "        [-4.1347],\n",
      "        [-2.2869],\n",
      "        [-3.6423],\n",
      "        [-6.1388],\n",
      "        [-2.5973],\n",
      "        [-2.8346],\n",
      "        [-4.0771],\n",
      "        [-4.5292],\n",
      "        [-3.3461],\n",
      "        [-3.3528],\n",
      "        [-3.2415],\n",
      "        [-3.1098],\n",
      "        [-1.9294],\n",
      "        [-2.6293],\n",
      "        [-2.2340],\n",
      "        [-4.7382],\n",
      "        [-2.9689],\n",
      "        [-3.4062],\n",
      "        [-3.8500],\n",
      "        [-2.5901],\n",
      "        [-0.1644],\n",
      "        [-3.9084],\n",
      "        [-2.8344],\n",
      "        [-4.1185],\n",
      "        [-3.2877],\n",
      "        [-5.4609],\n",
      "        [-2.8030],\n",
      "        [-3.0917],\n",
      "        [-4.4155],\n",
      "        [-4.7086],\n",
      "        [-4.5361],\n",
      "        [-2.3080],\n",
      "        [-4.1123],\n",
      "        [-4.5379],\n",
      "        [-1.7834],\n",
      "        [-4.2055],\n",
      "        [-4.8147],\n",
      "        [-3.7465],\n",
      "        [-3.8554],\n",
      "        [-3.7016],\n",
      "        [-4.7910],\n",
      "        [-3.9570],\n",
      "        [-3.8537],\n",
      "        [-3.9825],\n",
      "        [-2.3796],\n",
      "        [-2.3020],\n",
      "        [-4.1130],\n",
      "        [-4.5135],\n",
      "        [-2.9184],\n",
      "        [-4.5621],\n",
      "        [-3.3337],\n",
      "        [-0.9479],\n",
      "        [-2.8520],\n",
      "        [-4.6716],\n",
      "        [-2.3388],\n",
      "        [-3.1970],\n",
      "        [-4.4844],\n",
      "        [-3.0492],\n",
      "        [-4.0804],\n",
      "        [-4.2836],\n",
      "        [-2.2865],\n",
      "        [-2.8541],\n",
      "        [-4.0891],\n",
      "        [-2.4674],\n",
      "        [-4.3144],\n",
      "        [-3.8577],\n",
      "        [-5.6411],\n",
      "        [-5.1327],\n",
      "        [-4.3852],\n",
      "        [-3.0682],\n",
      "        [-2.4721],\n",
      "        [-3.3030],\n",
      "        [-4.1980],\n",
      "        [-1.5502],\n",
      "        [-3.7094],\n",
      "        [-2.4123],\n",
      "        [-3.3622],\n",
      "        [-4.4348],\n",
      "        [-3.6486],\n",
      "        [-3.9944],\n",
      "        [-2.8660],\n",
      "        [-3.0520],\n",
      "        [-4.0121],\n",
      "        [-3.2900],\n",
      "        [-3.2020],\n",
      "        [-4.1776],\n",
      "        [-4.4582],\n",
      "        [-4.1331],\n",
      "        [-4.2551],\n",
      "        [-4.2346],\n",
      "        [-4.5705],\n",
      "        [-4.2703],\n",
      "        [-4.2930],\n",
      "        [-2.8076],\n",
      "        [-4.0972],\n",
      "        [-4.3159],\n",
      "        [-3.2471],\n",
      "        [-3.6708],\n",
      "        [-5.0135],\n",
      "        [-0.5494],\n",
      "        [-4.1700],\n",
      "        [-3.8387],\n",
      "        [-3.8355],\n",
      "        [-4.2172],\n",
      "        [-3.1107],\n",
      "        [-4.7893],\n",
      "        [-1.6636],\n",
      "        [-3.8500],\n",
      "        [-2.6279],\n",
      "        [-3.1759],\n",
      "        [-5.2732],\n",
      "        [-4.2328],\n",
      "        [-4.6930],\n",
      "        [-1.6003],\n",
      "        [-4.1760],\n",
      "        [-5.1610],\n",
      "        [-4.5283],\n",
      "        [-3.1628],\n",
      "        [-3.8846],\n",
      "        [-3.1505],\n",
      "        [-2.0834],\n",
      "        [-3.3979],\n",
      "        [-3.8094],\n",
      "        [-3.7425],\n",
      "        [-3.2247],\n",
      "        [-3.2984],\n",
      "        [-3.6204],\n",
      "        [-2.1241],\n",
      "        [-4.7905],\n",
      "        [-3.6630],\n",
      "        [-3.3701],\n",
      "        [ 1.7847],\n",
      "        [-4.5538],\n",
      "        [-4.2027],\n",
      "        [-4.8062],\n",
      "        [-1.8069],\n",
      "        [-3.0315],\n",
      "        [-3.2517],\n",
      "        [-2.8872],\n",
      "        [-3.8888],\n",
      "        [-4.9237]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "step = 14000, num_env_steps = 14000, scores = -97.508 (n=1), actor_loss = -32.838, critic_loss = 1.389, entropy_coef_loss = -11.452, entropy_coef = 0.303, action_stds = 0.915 ± 0.059, action_magnitude = 0.547 ± 0.288, num_gradient_steps = 4000, step_time = 7.00, total_time = 31.88\n",
      "\n",
      "\n",
      "self.log_ent_coef = tensor([-1.4874], device='cuda:0', requires_grad=True)\n",
      "actions_pi_log_prob = tensor([[-2.7230e+00],\n",
      "        [-3.3434e+00],\n",
      "        [-1.7171e+00],\n",
      "        [-3.2266e+00],\n",
      "        [-3.8653e+00],\n",
      "        [-5.3012e+00],\n",
      "        [-2.5992e+00],\n",
      "        [-3.1946e+00],\n",
      "        [-4.0909e+00],\n",
      "        [-2.0734e+00],\n",
      "        [-5.9286e+00],\n",
      "        [-1.5723e+00],\n",
      "        [-1.0427e+00],\n",
      "        [-5.4622e+00],\n",
      "        [-1.7607e+00],\n",
      "        [-1.4907e+00],\n",
      "        [-3.9563e+00],\n",
      "        [-4.2248e+00],\n",
      "        [-4.2448e+00],\n",
      "        [-1.2158e+00],\n",
      "        [-3.3979e+00],\n",
      "        [-5.5633e+00],\n",
      "        [-1.0520e+00],\n",
      "        [-6.2306e+00],\n",
      "        [-3.8957e+00],\n",
      "        [-5.2275e+00],\n",
      "        [-4.3479e+00],\n",
      "        [-3.1328e+00],\n",
      "        [-3.7223e+00],\n",
      "        [-3.4509e+00],\n",
      "        [-3.8715e+00],\n",
      "        [-1.9149e+00],\n",
      "        [-3.3150e+00],\n",
      "        [-3.0245e-01],\n",
      "        [-4.2927e+00],\n",
      "        [-2.3869e+00],\n",
      "        [-3.6676e+00],\n",
      "        [-3.2448e+00],\n",
      "        [-3.7125e+00],\n",
      "        [-5.1101e+00],\n",
      "        [-4.5079e+00],\n",
      "        [-3.8454e+00],\n",
      "        [-4.5197e+00],\n",
      "        [-2.0381e-01],\n",
      "        [-3.2128e+00],\n",
      "        [-6.5384e-03],\n",
      "        [-4.2473e+00],\n",
      "        [-1.7936e+00],\n",
      "        [-1.2426e+00],\n",
      "        [-3.0775e+00],\n",
      "        [-1.0387e-01],\n",
      "        [-2.5230e+00],\n",
      "        [-1.2036e+00],\n",
      "        [-1.4990e+00],\n",
      "        [-2.6897e+00],\n",
      "        [-2.2623e+00],\n",
      "        [-5.8431e+00],\n",
      "        [-3.2511e+00],\n",
      "        [-7.2552e+00],\n",
      "        [-2.6911e+00],\n",
      "        [-2.8082e+00],\n",
      "        [-3.3135e+00],\n",
      "        [-4.8575e+00],\n",
      "        [-1.0642e+00],\n",
      "        [-3.8995e+00],\n",
      "        [-3.2188e+00],\n",
      "        [-2.7681e+00],\n",
      "        [-3.5638e+00],\n",
      "        [-2.5662e+00],\n",
      "        [-1.1879e+00],\n",
      "        [-3.9026e+00],\n",
      "        [-2.8263e+00],\n",
      "        [-2.6859e+00],\n",
      "        [-1.9761e+00],\n",
      "        [-4.1237e+00],\n",
      "        [-1.8813e+00],\n",
      "        [-3.1484e+00],\n",
      "        [-4.3300e+00],\n",
      "        [-2.7273e+00],\n",
      "        [-4.6148e+00],\n",
      "        [-1.8062e+00],\n",
      "        [-2.1947e+00],\n",
      "        [-3.9825e-01],\n",
      "        [-3.1023e+00],\n",
      "        [-2.5575e+00],\n",
      "        [-4.0246e+00],\n",
      "        [-2.9127e+00],\n",
      "        [-4.8429e+00],\n",
      "        [-1.0269e+00],\n",
      "        [-4.0444e+00],\n",
      "        [-3.7807e+00],\n",
      "        [-3.6017e+00],\n",
      "        [-5.2333e+00],\n",
      "        [-3.7083e+00],\n",
      "        [-4.4782e+00],\n",
      "        [-4.2116e+00],\n",
      "        [-4.5680e-01],\n",
      "        [-2.5498e+00],\n",
      "        [-1.3555e+00],\n",
      "        [-2.2620e+00],\n",
      "        [-8.2909e-01],\n",
      "        [-2.7270e+00],\n",
      "        [-3.7500e+00],\n",
      "        [-2.2244e+00],\n",
      "        [ 7.5881e-01],\n",
      "        [-6.1037e+00],\n",
      "        [-3.6329e+00],\n",
      "        [-2.4306e+00],\n",
      "        [-4.2023e+00],\n",
      "        [-4.2758e+00],\n",
      "        [-3.3600e+00],\n",
      "        [-4.2071e+00],\n",
      "        [-2.4246e+00],\n",
      "        [-9.1068e-01],\n",
      "        [-3.8522e+00],\n",
      "        [-2.2590e+00],\n",
      "        [-1.5347e+00],\n",
      "        [-2.9581e+00],\n",
      "        [-5.1816e+00],\n",
      "        [-1.2935e-01],\n",
      "        [-4.8167e+00],\n",
      "        [-4.0356e+00],\n",
      "        [-2.8407e+00],\n",
      "        [-3.5750e+00],\n",
      "        [-6.1593e+00],\n",
      "        [-3.5035e+00],\n",
      "        [-3.5113e+00],\n",
      "        [-5.1500e+00],\n",
      "        [ 1.7462e+00],\n",
      "        [-2.1759e+00],\n",
      "        [-2.9837e+00],\n",
      "        [-2.7222e+00],\n",
      "        [-5.3909e+00],\n",
      "        [-5.1979e+00],\n",
      "        [-3.5545e+00],\n",
      "        [-2.3019e+00],\n",
      "        [-3.6928e+00],\n",
      "        [-4.0031e+00],\n",
      "        [-4.8490e+00],\n",
      "        [-6.4776e+00],\n",
      "        [-1.5445e+00],\n",
      "        [-6.5680e+00],\n",
      "        [-4.2147e+00],\n",
      "        [-3.3664e+00],\n",
      "        [-3.7893e+00],\n",
      "        [-2.5335e+00],\n",
      "        [-3.9749e+00],\n",
      "        [ 9.3914e-01],\n",
      "        [-4.0932e+00],\n",
      "        [-2.6242e+00],\n",
      "        [-2.6652e+00],\n",
      "        [-4.8734e+00],\n",
      "        [-5.0160e+00],\n",
      "        [-5.4398e+00],\n",
      "        [-6.2178e-02],\n",
      "        [-1.3167e+00],\n",
      "        [-4.0313e+00],\n",
      "        [-3.9430e+00],\n",
      "        [-3.6570e+00],\n",
      "        [-2.2752e+00],\n",
      "        [-3.8755e+00],\n",
      "        [-3.6520e+00],\n",
      "        [-4.9192e+00],\n",
      "        [-2.8994e+00],\n",
      "        [-2.0025e+00],\n",
      "        [-1.7426e+00],\n",
      "        [-4.2379e+00],\n",
      "        [-3.8062e+00],\n",
      "        [-3.6596e+00],\n",
      "        [-7.0345e-01],\n",
      "        [-3.5706e+00],\n",
      "        [-4.5365e+00],\n",
      "        [-4.2427e+00],\n",
      "        [-2.5972e+00],\n",
      "        [-2.8942e+00],\n",
      "        [-2.7955e+00],\n",
      "        [-2.5815e+00],\n",
      "        [-3.5299e-02],\n",
      "        [-3.5888e+00],\n",
      "        [-5.3860e-01],\n",
      "        [-2.1862e+00],\n",
      "        [-8.6847e-01],\n",
      "        [-3.8582e+00],\n",
      "        [-3.8998e+00],\n",
      "        [-3.2514e+00],\n",
      "        [-3.5351e+00],\n",
      "        [-3.0791e+00],\n",
      "        [-5.0599e+00],\n",
      "        [-1.3266e+00],\n",
      "        [-3.6821e+00],\n",
      "        [-2.8312e+00],\n",
      "        [-3.7095e+00],\n",
      "        [-4.1529e+00],\n",
      "        [-4.0182e+00],\n",
      "        [-5.4455e+00],\n",
      "        [-7.2539e+00],\n",
      "        [-4.9978e+00],\n",
      "        [-2.7478e+00],\n",
      "        [-6.5151e-01],\n",
      "        [-1.4381e+00],\n",
      "        [-1.8907e+00],\n",
      "        [-6.8263e+00],\n",
      "        [-1.7333e+00],\n",
      "        [-3.1238e+00],\n",
      "        [-2.3208e+00],\n",
      "        [-3.3525e+00],\n",
      "        [-2.1391e+00],\n",
      "        [-4.8194e+00],\n",
      "        [-4.1649e+00],\n",
      "        [-4.7829e+00],\n",
      "        [ 2.0277e-01],\n",
      "        [ 2.1662e+00],\n",
      "        [-4.4619e+00],\n",
      "        [-1.9819e+00],\n",
      "        [-3.0419e+00],\n",
      "        [-5.2751e+00],\n",
      "        [-4.2470e+00],\n",
      "        [-3.4305e+00],\n",
      "        [-3.3448e+00],\n",
      "        [-3.3863e+00],\n",
      "        [-4.3675e+00],\n",
      "        [-2.3828e+00],\n",
      "        [ 6.2998e-02],\n",
      "        [-1.8988e+00],\n",
      "        [-3.6944e+00],\n",
      "        [-2.1886e+00],\n",
      "        [-3.2602e+00],\n",
      "        [-1.4162e+00],\n",
      "        [-2.3910e+00],\n",
      "        [-2.7452e+00],\n",
      "        [-9.1666e-01],\n",
      "        [-4.5612e+00],\n",
      "        [-4.7781e+00],\n",
      "        [-3.2338e+00],\n",
      "        [ 3.4824e+00],\n",
      "        [-3.1295e+00],\n",
      "        [-4.6581e+00],\n",
      "        [-3.0533e+00],\n",
      "        [-4.7723e+00],\n",
      "        [-2.7339e+00],\n",
      "        [-2.5857e+00],\n",
      "        [-1.1115e+00],\n",
      "        [-2.9354e+00],\n",
      "        [-4.3356e+00],\n",
      "        [-3.0394e+00],\n",
      "        [-3.7786e+00],\n",
      "        [-3.6801e+00],\n",
      "        [-2.5743e+00],\n",
      "        [-2.2847e+00],\n",
      "        [-3.6215e+00],\n",
      "        [-4.1108e+00],\n",
      "        [-3.4881e+00],\n",
      "        [-2.7175e+00],\n",
      "        [-9.2431e-01],\n",
      "        [-2.8607e+00],\n",
      "        [-4.5961e+00]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "step = 15000, num_env_steps = 15000, scores = -281.379 (n=1), actor_loss = -34.418, critic_loss = 1.806, entropy_coef_loss = -13.558, entropy_coef = 0.226, action_stds = 0.828 ± 0.047, action_magnitude = 0.549 ± 0.289, num_gradient_steps = 5000, step_time = 7.01, total_time = 38.89\n",
      "\n",
      "\n",
      "self.log_ent_coef = tensor([-1.7713], device='cuda:0', requires_grad=True)\n",
      "actions_pi_log_prob = tensor([[-1.7801e+00],\n",
      "        [-2.8330e+00],\n",
      "        [-2.2188e+00],\n",
      "        [-3.2186e+00],\n",
      "        [-1.9231e+00],\n",
      "        [-3.6164e+00],\n",
      "        [ 1.3639e+00],\n",
      "        [-2.2692e+00],\n",
      "        [-5.4436e+00],\n",
      "        [-2.3990e+00],\n",
      "        [-3.3155e+00],\n",
      "        [-3.5035e+00],\n",
      "        [-1.6696e-01],\n",
      "        [-4.1968e+00],\n",
      "        [-1.4987e+00],\n",
      "        [-6.0911e-01],\n",
      "        [-4.0331e+00],\n",
      "        [ 1.2739e+00],\n",
      "        [-1.8823e+00],\n",
      "        [ 4.2990e+00],\n",
      "        [-2.1825e+00],\n",
      "        [-3.2604e+00],\n",
      "        [-1.0284e+00],\n",
      "        [-2.0914e+00],\n",
      "        [-2.3012e+00],\n",
      "        [-2.6904e+00],\n",
      "        [ 1.7963e-01],\n",
      "        [-1.3123e+00],\n",
      "        [ 1.9859e+00],\n",
      "        [-1.5896e+00],\n",
      "        [-2.1605e+00],\n",
      "        [ 1.7674e+00],\n",
      "        [-4.3289e+00],\n",
      "        [-4.8101e+00],\n",
      "        [-1.7543e+00],\n",
      "        [-1.5653e-01],\n",
      "        [-4.4988e+00],\n",
      "        [-1.5963e+00],\n",
      "        [-3.5517e+00],\n",
      "        [-3.5761e+00],\n",
      "        [-3.1211e+00],\n",
      "        [-1.4555e+00],\n",
      "        [-2.2698e+00],\n",
      "        [-3.2648e+00],\n",
      "        [-3.2223e+00],\n",
      "        [-2.9268e+00],\n",
      "        [ 6.6490e-03],\n",
      "        [-3.1214e+00],\n",
      "        [-1.4735e+00],\n",
      "        [-3.9874e+00],\n",
      "        [-3.5074e+00],\n",
      "        [-4.1091e-01],\n",
      "        [-5.0229e+00],\n",
      "        [-2.3446e+00],\n",
      "        [-2.6664e+00],\n",
      "        [-1.8911e+00],\n",
      "        [-4.2599e+00],\n",
      "        [-5.6285e+00],\n",
      "        [-4.4845e+00],\n",
      "        [-4.5254e+00],\n",
      "        [-1.7692e+00],\n",
      "        [ 5.1228e+00],\n",
      "        [-1.3380e+00],\n",
      "        [ 1.3031e+00],\n",
      "        [ 4.6129e-01],\n",
      "        [-4.2767e+00],\n",
      "        [-2.4792e+00],\n",
      "        [-5.8265e+00],\n",
      "        [-3.6211e+00],\n",
      "        [-1.3024e+00],\n",
      "        [ 2.3308e-01],\n",
      "        [-2.3962e+00],\n",
      "        [-2.3212e+00],\n",
      "        [-1.8038e+00],\n",
      "        [-4.2068e+00],\n",
      "        [-4.2056e+00],\n",
      "        [-4.1174e+00],\n",
      "        [-3.1738e+00],\n",
      "        [-2.7775e+00],\n",
      "        [-3.6100e+00],\n",
      "        [-1.5551e+00],\n",
      "        [-5.0515e-02],\n",
      "        [-2.3142e+00],\n",
      "        [-6.0034e+00],\n",
      "        [-8.9366e-01],\n",
      "        [-2.8758e+00],\n",
      "        [-2.9686e+00],\n",
      "        [-2.2323e+00],\n",
      "        [-7.4608e+00],\n",
      "        [-5.9169e+00],\n",
      "        [-3.2230e-01],\n",
      "        [-3.2940e+00],\n",
      "        [ 9.5500e-01],\n",
      "        [-2.6440e+00],\n",
      "        [-5.7383e+00],\n",
      "        [-2.1006e+00],\n",
      "        [-2.9117e+00],\n",
      "        [-3.6578e+00],\n",
      "        [ 2.0468e+00],\n",
      "        [-2.8353e+00],\n",
      "        [-1.3753e+00],\n",
      "        [-3.7822e+00],\n",
      "        [-4.8162e+00],\n",
      "        [-7.1995e-01],\n",
      "        [-4.1588e+00],\n",
      "        [-5.9387e+00],\n",
      "        [-1.1822e-01],\n",
      "        [-2.0062e+00],\n",
      "        [-3.3180e-01],\n",
      "        [-2.0599e+00],\n",
      "        [-3.1797e+00],\n",
      "        [-3.4036e+00],\n",
      "        [-1.2623e+00],\n",
      "        [-4.4446e+00],\n",
      "        [-3.3149e+00],\n",
      "        [-3.0247e+00],\n",
      "        [-4.2257e+00],\n",
      "        [-3.7590e+00],\n",
      "        [-4.8126e+00],\n",
      "        [-1.9749e+00],\n",
      "        [-1.6525e+00],\n",
      "        [-9.8408e-01],\n",
      "        [-1.7989e+00],\n",
      "        [-1.4011e+00],\n",
      "        [-2.2375e+00],\n",
      "        [-4.0182e+00],\n",
      "        [ 4.6059e-01],\n",
      "        [-2.7151e+00],\n",
      "        [-3.5917e+00],\n",
      "        [-3.8137e+00],\n",
      "        [-2.5331e+00],\n",
      "        [-1.9017e+00],\n",
      "        [-4.5099e+00],\n",
      "        [-3.7556e+00],\n",
      "        [-3.4310e+00],\n",
      "        [-1.4790e-01],\n",
      "        [ 1.6238e+00],\n",
      "        [-4.3115e+00],\n",
      "        [-1.2026e+00],\n",
      "        [-9.3778e-01],\n",
      "        [-2.0172e+00],\n",
      "        [-8.0180e+00],\n",
      "        [ 6.6174e-01],\n",
      "        [-2.2298e+00],\n",
      "        [-3.2504e+00],\n",
      "        [-1.3065e+00],\n",
      "        [-5.4135e-01],\n",
      "        [-2.5938e+00],\n",
      "        [ 1.9955e+00],\n",
      "        [-4.0008e+00],\n",
      "        [-1.9237e+00],\n",
      "        [-2.8972e+00],\n",
      "        [-4.5647e+00],\n",
      "        [ 2.3932e+00],\n",
      "        [-1.0153e+00],\n",
      "        [-7.5331e-01],\n",
      "        [ 2.1133e+00],\n",
      "        [-4.5378e+00],\n",
      "        [-4.3269e+00],\n",
      "        [-3.3481e+00],\n",
      "        [ 1.4480e+00],\n",
      "        [ 2.6393e+00],\n",
      "        [-2.0087e+00],\n",
      "        [-2.7055e+00],\n",
      "        [-2.2330e+00],\n",
      "        [-6.2650e+00],\n",
      "        [-4.3867e+00],\n",
      "        [-2.7430e+00],\n",
      "        [-2.2159e+00],\n",
      "        [-2.1958e+00],\n",
      "        [-3.3338e+00],\n",
      "        [-2.0587e+00],\n",
      "        [-1.8399e+00],\n",
      "        [-1.0410e+00],\n",
      "        [-3.5123e+00],\n",
      "        [ 1.7553e-01],\n",
      "        [-1.2228e+00],\n",
      "        [-4.1861e+00],\n",
      "        [-1.7318e+00],\n",
      "        [-4.3732e+00],\n",
      "        [-2.1212e+00],\n",
      "        [-7.3477e-02],\n",
      "        [-3.5825e+00],\n",
      "        [-1.7296e+00],\n",
      "        [-1.3730e+00],\n",
      "        [-5.8230e+00],\n",
      "        [-3.1363e+00],\n",
      "        [-1.5208e+00],\n",
      "        [-4.3970e+00],\n",
      "        [-7.1029e-01],\n",
      "        [-4.7950e+00],\n",
      "        [-2.1112e+00],\n",
      "        [-3.4105e+00],\n",
      "        [-4.2978e+00],\n",
      "        [-5.4830e+00],\n",
      "        [-5.5725e+00],\n",
      "        [ 6.2178e-01],\n",
      "        [-2.4973e-02],\n",
      "        [-3.5563e+00],\n",
      "        [-2.2005e+00],\n",
      "        [-1.8560e+00],\n",
      "        [-2.2790e-01],\n",
      "        [-1.4409e+00],\n",
      "        [ 2.3634e-01],\n",
      "        [-6.4646e-01],\n",
      "        [-1.7418e+00],\n",
      "        [-4.0914e+00],\n",
      "        [-1.7884e+00],\n",
      "        [-3.2014e+00],\n",
      "        [ 7.9982e-01],\n",
      "        [-3.6409e+00],\n",
      "        [ 8.3099e-02],\n",
      "        [-2.9638e+00],\n",
      "        [-4.4154e+00],\n",
      "        [-7.2036e-01],\n",
      "        [-2.1238e+00],\n",
      "        [-2.5712e-01],\n",
      "        [-1.4089e+00],\n",
      "        [-2.4931e-01],\n",
      "        [-2.2486e+00],\n",
      "        [-4.0488e+00],\n",
      "        [-3.0333e+00],\n",
      "        [ 1.9478e+00],\n",
      "        [-3.5511e+00],\n",
      "        [-4.1651e+00],\n",
      "        [-9.2977e-01],\n",
      "        [ 2.6263e+00],\n",
      "        [-3.8212e+00],\n",
      "        [-2.2301e+00],\n",
      "        [-2.2069e+00],\n",
      "        [-3.3945e+00],\n",
      "        [-3.0958e+00],\n",
      "        [-3.9788e+00],\n",
      "        [-7.7819e-01],\n",
      "        [-2.9064e+00],\n",
      "        [-4.4009e+00],\n",
      "        [-7.4012e-01],\n",
      "        [-1.5332e+00],\n",
      "        [-1.6319e-01],\n",
      "        [-2.5733e+00],\n",
      "        [-2.1648e+00],\n",
      "        [-1.9453e+00],\n",
      "        [-6.5706e-01],\n",
      "        [-3.9021e+00],\n",
      "        [-2.6440e+00],\n",
      "        [-4.0223e+00],\n",
      "        [-1.5815e+00],\n",
      "        [-2.3190e+00],\n",
      "        [-3.8899e+00],\n",
      "        [-3.1484e+00],\n",
      "        [-1.4411e+00],\n",
      "        [-3.2547e+00],\n",
      "        [-1.3363e+00],\n",
      "        [-3.0970e+00],\n",
      "        [-1.9127e+00],\n",
      "        [-5.4233e-01]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "step = 16000, num_env_steps = 16000, scores = -206.498 (n=1), actor_loss = -34.543, critic_loss = 1.977, entropy_coef_loss = -14.675, entropy_coef = 0.170, action_stds = 0.850 ± 0.059, action_magnitude = 0.553 ± 0.295, num_gradient_steps = 6000, step_time = 6.98, total_time = 45.87\n",
      "\n",
      "\n",
      "self.log_ent_coef = tensor([-2.0461], device='cuda:0', requires_grad=True)\n",
      "actions_pi_log_prob = tensor([[-0.4636],\n",
      "        [ 2.0167],\n",
      "        [-1.9119],\n",
      "        [-1.9362],\n",
      "        [ 1.5442],\n",
      "        [-4.9278],\n",
      "        [ 0.7865],\n",
      "        [-1.0260],\n",
      "        [-2.1234],\n",
      "        [-3.5827],\n",
      "        [ 0.2861],\n",
      "        [-0.5871],\n",
      "        [ 2.9546],\n",
      "        [-5.2414],\n",
      "        [-3.8492],\n",
      "        [-3.1307],\n",
      "        [-3.2994],\n",
      "        [-1.2689],\n",
      "        [-3.2256],\n",
      "        [-1.4125],\n",
      "        [-0.7402],\n",
      "        [-3.2971],\n",
      "        [-2.9400],\n",
      "        [-1.2984],\n",
      "        [-0.0203],\n",
      "        [-1.7079],\n",
      "        [-1.9259],\n",
      "        [-3.5849],\n",
      "        [-4.1863],\n",
      "        [-3.2103],\n",
      "        [ 3.2691],\n",
      "        [-2.0844],\n",
      "        [-4.9066],\n",
      "        [-1.4627],\n",
      "        [-0.5175],\n",
      "        [ 2.6180],\n",
      "        [-1.0669],\n",
      "        [ 2.6116],\n",
      "        [-4.3598],\n",
      "        [-8.9756],\n",
      "        [ 2.3149],\n",
      "        [-1.3987],\n",
      "        [-1.5263],\n",
      "        [ 2.6278],\n",
      "        [ 0.8777],\n",
      "        [-1.5123],\n",
      "        [-1.9126],\n",
      "        [-0.3292],\n",
      "        [-1.5458],\n",
      "        [-3.1526],\n",
      "        [-0.2848],\n",
      "        [-3.5464],\n",
      "        [-4.0719],\n",
      "        [-2.3237],\n",
      "        [ 0.7565],\n",
      "        [-1.9277],\n",
      "        [ 2.8967],\n",
      "        [-1.5827],\n",
      "        [ 2.9167],\n",
      "        [-1.5704],\n",
      "        [-3.8364],\n",
      "        [-2.5578],\n",
      "        [-2.9859],\n",
      "        [-3.4588],\n",
      "        [-3.9043],\n",
      "        [-0.2287],\n",
      "        [-3.7001],\n",
      "        [-2.8014],\n",
      "        [-3.9162],\n",
      "        [-3.2985],\n",
      "        [-2.8306],\n",
      "        [-1.7861],\n",
      "        [-4.6984],\n",
      "        [-1.8496],\n",
      "        [-2.6569],\n",
      "        [-5.1428],\n",
      "        [ 0.8535],\n",
      "        [-2.7383],\n",
      "        [-3.0396],\n",
      "        [-3.5003],\n",
      "        [-0.9226],\n",
      "        [ 1.6453],\n",
      "        [-5.1613],\n",
      "        [-4.8646],\n",
      "        [-2.1278],\n",
      "        [-1.8585],\n",
      "        [-1.0240],\n",
      "        [-3.1832],\n",
      "        [-2.2085],\n",
      "        [-2.9759],\n",
      "        [-4.3665],\n",
      "        [-2.7241],\n",
      "        [ 2.6628],\n",
      "        [-1.8567],\n",
      "        [-3.6640],\n",
      "        [-3.0322],\n",
      "        [-0.4820],\n",
      "        [-2.6487],\n",
      "        [-5.6287],\n",
      "        [-6.1243],\n",
      "        [-5.4468],\n",
      "        [-2.6148],\n",
      "        [ 0.1570],\n",
      "        [-0.1713],\n",
      "        [-0.5679],\n",
      "        [ 1.1538],\n",
      "        [-1.1222],\n",
      "        [-4.1725],\n",
      "        [-2.4368],\n",
      "        [-1.3349],\n",
      "        [ 1.0744],\n",
      "        [-2.2812],\n",
      "        [ 8.0493],\n",
      "        [ 0.8074],\n",
      "        [-3.5647],\n",
      "        [-4.7923],\n",
      "        [ 0.5378],\n",
      "        [ 2.8079],\n",
      "        [-0.7052],\n",
      "        [-0.9348],\n",
      "        [-2.6763],\n",
      "        [-3.2846],\n",
      "        [-2.2244],\n",
      "        [ 1.6249],\n",
      "        [-1.0437],\n",
      "        [-1.4191],\n",
      "        [ 0.0106],\n",
      "        [ 5.5267],\n",
      "        [-0.5949],\n",
      "        [-3.2754],\n",
      "        [ 0.8241],\n",
      "        [-3.2901],\n",
      "        [-2.6520],\n",
      "        [-3.2032],\n",
      "        [ 4.5153],\n",
      "        [-1.1638],\n",
      "        [ 1.6869],\n",
      "        [-1.3783],\n",
      "        [-3.1398],\n",
      "        [-3.9054],\n",
      "        [-3.6062],\n",
      "        [-1.6586],\n",
      "        [-4.7496],\n",
      "        [-1.8530],\n",
      "        [-4.3435],\n",
      "        [-2.8742],\n",
      "        [-1.6540],\n",
      "        [-4.1108],\n",
      "        [-1.9475],\n",
      "        [ 0.2147],\n",
      "        [-0.8649],\n",
      "        [-0.0475],\n",
      "        [-1.2680],\n",
      "        [ 2.3135],\n",
      "        [-3.3705],\n",
      "        [-2.5931],\n",
      "        [-2.4910],\n",
      "        [-1.6167],\n",
      "        [-5.3428],\n",
      "        [-0.7454],\n",
      "        [ 0.9379],\n",
      "        [ 5.4543],\n",
      "        [ 1.3663],\n",
      "        [-2.9387],\n",
      "        [ 9.2195],\n",
      "        [-2.6210],\n",
      "        [ 1.1577],\n",
      "        [-2.7165],\n",
      "        [ 2.4729],\n",
      "        [ 0.0122],\n",
      "        [-1.8534],\n",
      "        [-0.9560],\n",
      "        [-0.6812],\n",
      "        [-1.4788],\n",
      "        [-2.8712],\n",
      "        [-1.4505],\n",
      "        [-2.8822],\n",
      "        [ 1.6595],\n",
      "        [-4.1066],\n",
      "        [-3.8045],\n",
      "        [-2.3279],\n",
      "        [-0.6867],\n",
      "        [-1.3007],\n",
      "        [-4.0318],\n",
      "        [-4.1155],\n",
      "        [ 0.2850],\n",
      "        [-2.6303],\n",
      "        [-2.8267],\n",
      "        [-1.8240],\n",
      "        [-4.2945],\n",
      "        [-2.2255],\n",
      "        [-0.0298],\n",
      "        [-2.2493],\n",
      "        [-1.8165],\n",
      "        [ 3.8715],\n",
      "        [-4.5957],\n",
      "        [-1.2527],\n",
      "        [-2.5163],\n",
      "        [ 2.7678],\n",
      "        [-1.6305],\n",
      "        [ 3.1949],\n",
      "        [ 1.7953],\n",
      "        [ 0.7352],\n",
      "        [-4.2731],\n",
      "        [-2.2575],\n",
      "        [ 1.8047],\n",
      "        [-1.1676],\n",
      "        [-5.9363],\n",
      "        [-2.8357],\n",
      "        [-3.6924],\n",
      "        [-3.2884],\n",
      "        [-0.0971],\n",
      "        [-2.3979],\n",
      "        [ 0.7152],\n",
      "        [-6.0719],\n",
      "        [-2.5704],\n",
      "        [-3.8090],\n",
      "        [ 0.3511],\n",
      "        [ 0.1428],\n",
      "        [-3.6603],\n",
      "        [-3.4973],\n",
      "        [-1.2780],\n",
      "        [-2.7679],\n",
      "        [-1.6884],\n",
      "        [-0.4165],\n",
      "        [ 1.6512],\n",
      "        [-3.8347],\n",
      "        [ 0.4706],\n",
      "        [-2.7645],\n",
      "        [-0.5234],\n",
      "        [-2.8124],\n",
      "        [-1.8894],\n",
      "        [-2.4080],\n",
      "        [ 1.4455],\n",
      "        [ 4.1852],\n",
      "        [ 2.2872],\n",
      "        [-4.7992],\n",
      "        [-2.6350],\n",
      "        [-1.0051],\n",
      "        [-4.5395],\n",
      "        [-2.0317],\n",
      "        [-1.8742],\n",
      "        [-1.9638],\n",
      "        [-1.2728],\n",
      "        [-3.6602],\n",
      "        [-4.3109],\n",
      "        [-2.9248],\n",
      "        [-5.2447],\n",
      "        [-0.8861],\n",
      "        [-2.1337],\n",
      "        [ 2.7231],\n",
      "        [-2.7378],\n",
      "        [ 1.4049],\n",
      "        [ 1.8986],\n",
      "        [-3.3161],\n",
      "        [-4.0383]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "step = 17000, num_env_steps = 17000, scores = -229.870 (n=1), actor_loss = -35.182, critic_loss = 1.787, entropy_coef_loss = -15.460, entropy_coef = 0.129, action_stds = 0.905 ± 0.044, action_magnitude = 0.565 ± 0.297, num_gradient_steps = 7000, step_time = 6.98, total_time = 52.85\n",
      "\n",
      "\n",
      "self.log_ent_coef = tensor([-2.3179], device='cuda:0', requires_grad=True)\n",
      "actions_pi_log_prob = tensor([[-1.9065e+00],\n",
      "        [-5.4246e+00],\n",
      "        [ 6.8963e-01],\n",
      "        [-2.9299e+00],\n",
      "        [-5.5441e-01],\n",
      "        [-4.2712e+00],\n",
      "        [ 3.6412e+00],\n",
      "        [-3.0745e+00],\n",
      "        [-5.3872e-01],\n",
      "        [-3.0623e+00],\n",
      "        [-4.0357e+00],\n",
      "        [-9.9005e-01],\n",
      "        [-7.5776e-01],\n",
      "        [-1.3605e+00],\n",
      "        [ 5.6565e-01],\n",
      "        [-5.9691e+00],\n",
      "        [-1.3180e-01],\n",
      "        [ 2.5789e+00],\n",
      "        [-1.0770e+01],\n",
      "        [-5.3502e+00],\n",
      "        [-8.9266e-01],\n",
      "        [ 3.9407e-01],\n",
      "        [ 1.7715e+00],\n",
      "        [ 1.2413e+00],\n",
      "        [ 2.6756e-01],\n",
      "        [-2.3948e+00],\n",
      "        [-2.6361e+00],\n",
      "        [-4.5599e+00],\n",
      "        [ 2.8841e+00],\n",
      "        [-2.7738e+00],\n",
      "        [ 3.3324e+00],\n",
      "        [-4.6535e+00],\n",
      "        [ 1.8897e+00],\n",
      "        [-1.0954e-01],\n",
      "        [ 1.5857e+00],\n",
      "        [-2.9182e+00],\n",
      "        [-2.5019e-01],\n",
      "        [-4.1142e+00],\n",
      "        [-4.5146e-01],\n",
      "        [ 1.0267e+00],\n",
      "        [-4.1687e-01],\n",
      "        [-3.6167e+00],\n",
      "        [-2.2043e+00],\n",
      "        [-3.3409e+00],\n",
      "        [-1.7536e+00],\n",
      "        [-5.5750e+00],\n",
      "        [-4.3576e-02],\n",
      "        [ 5.2080e-01],\n",
      "        [-6.8636e-01],\n",
      "        [-5.4648e+00],\n",
      "        [-3.5366e+00],\n",
      "        [-1.2207e+00],\n",
      "        [-2.8538e+00],\n",
      "        [-2.5738e+00],\n",
      "        [-7.8582e-01],\n",
      "        [-1.5789e+00],\n",
      "        [-1.5754e+00],\n",
      "        [-5.2202e+00],\n",
      "        [ 1.5877e+00],\n",
      "        [ 2.9432e+00],\n",
      "        [ 7.5416e-01],\n",
      "        [-3.9286e+00],\n",
      "        [-1.7798e+00],\n",
      "        [ 1.5023e+00],\n",
      "        [ 5.4883e-01],\n",
      "        [-2.8340e+00],\n",
      "        [ 3.3804e-01],\n",
      "        [ 1.0537e+00],\n",
      "        [-3.2010e+00],\n",
      "        [-6.3181e-01],\n",
      "        [-3.7212e+00],\n",
      "        [-4.6314e+00],\n",
      "        [-1.7500e+00],\n",
      "        [ 4.7581e-01],\n",
      "        [-1.9440e+00],\n",
      "        [-2.9680e+00],\n",
      "        [-2.4739e+00],\n",
      "        [ 2.5042e+00],\n",
      "        [-2.2859e+00],\n",
      "        [-5.1188e+00],\n",
      "        [-4.5888e+00],\n",
      "        [-4.2975e+00],\n",
      "        [-5.3599e+00],\n",
      "        [-2.0750e+00],\n",
      "        [-1.8387e+00],\n",
      "        [ 3.8266e-03],\n",
      "        [-2.4350e+00],\n",
      "        [-4.1903e+00],\n",
      "        [-9.7217e-01],\n",
      "        [-2.2590e+00],\n",
      "        [ 8.5484e+00],\n",
      "        [-5.1559e+00],\n",
      "        [-3.4277e+00],\n",
      "        [ 9.5947e-01],\n",
      "        [-2.7088e+00],\n",
      "        [-3.2339e+00],\n",
      "        [-1.5263e+00],\n",
      "        [-3.1853e+00],\n",
      "        [ 3.3442e+00],\n",
      "        [-2.7164e+00],\n",
      "        [-2.1525e+00],\n",
      "        [-1.6217e+00],\n",
      "        [-1.7282e+00],\n",
      "        [ 3.3916e-01],\n",
      "        [-4.4791e+00],\n",
      "        [-5.8704e+00],\n",
      "        [-7.4700e-01],\n",
      "        [ 1.1019e+00],\n",
      "        [-3.2455e+00],\n",
      "        [-2.1302e+00],\n",
      "        [-1.8221e+00],\n",
      "        [ 1.1899e+00],\n",
      "        [-2.7216e+00],\n",
      "        [-5.7114e-01],\n",
      "        [-4.9544e+00],\n",
      "        [-1.4512e+00],\n",
      "        [ 4.0825e+00],\n",
      "        [-2.4719e+00],\n",
      "        [-1.0290e+00],\n",
      "        [-2.7115e+00],\n",
      "        [-4.7313e+00],\n",
      "        [-1.7145e-01],\n",
      "        [ 9.0888e-01],\n",
      "        [-5.1573e+00],\n",
      "        [-5.3561e+00],\n",
      "        [ 1.1701e+00],\n",
      "        [-5.0595e+00],\n",
      "        [-2.6538e+00],\n",
      "        [-3.5003e+00],\n",
      "        [-4.2407e+00],\n",
      "        [-3.6401e+00],\n",
      "        [-2.7302e+00],\n",
      "        [-6.0607e+00],\n",
      "        [ 1.4599e+00],\n",
      "        [-5.4523e-01],\n",
      "        [-9.2205e-01],\n",
      "        [-4.7104e+00],\n",
      "        [-6.3490e+00],\n",
      "        [-2.3345e-01],\n",
      "        [ 4.4023e-01],\n",
      "        [-3.4821e+00],\n",
      "        [-2.2485e+00],\n",
      "        [ 1.2488e+00],\n",
      "        [ 4.8233e+00],\n",
      "        [ 2.3589e+00],\n",
      "        [-5.4527e+00],\n",
      "        [-2.1906e+00],\n",
      "        [ 1.3757e+00],\n",
      "        [ 4.6193e+00],\n",
      "        [-2.4159e+00],\n",
      "        [ 8.5123e-01],\n",
      "        [-2.6329e+00],\n",
      "        [-8.1298e-01],\n",
      "        [ 2.9523e+00],\n",
      "        [-2.4129e-01],\n",
      "        [ 2.8482e+00],\n",
      "        [ 7.2205e-01],\n",
      "        [ 4.4329e+00],\n",
      "        [-3.9523e+00],\n",
      "        [ 2.3321e+00],\n",
      "        [-1.7610e+00],\n",
      "        [-1.5157e+00],\n",
      "        [-1.9018e+00],\n",
      "        [ 1.5751e+00],\n",
      "        [-2.5136e+00],\n",
      "        [ 7.5231e+00],\n",
      "        [ 1.6579e+00],\n",
      "        [-5.8173e+00],\n",
      "        [-1.9614e+00],\n",
      "        [-6.4985e-01],\n",
      "        [ 1.2216e+00],\n",
      "        [ 4.0760e+00],\n",
      "        [-3.1972e+00],\n",
      "        [-9.9711e-01],\n",
      "        [-8.4388e+00],\n",
      "        [-1.9654e+00],\n",
      "        [ 1.4836e+00],\n",
      "        [ 6.9271e-01],\n",
      "        [ 3.1367e+00],\n",
      "        [ 9.1363e-01],\n",
      "        [-1.9319e+00],\n",
      "        [-3.9314e+00],\n",
      "        [-3.9251e+00],\n",
      "        [-1.3417e+00],\n",
      "        [ 4.2973e+00],\n",
      "        [-2.7960e+00],\n",
      "        [ 1.3353e+00],\n",
      "        [ 1.0062e+01],\n",
      "        [-1.9118e+00],\n",
      "        [-3.6806e+00],\n",
      "        [-1.6486e+00],\n",
      "        [ 6.8390e+00],\n",
      "        [ 2.2060e+00],\n",
      "        [-1.2765e+00],\n",
      "        [ 2.1044e+00],\n",
      "        [ 2.4617e+00],\n",
      "        [ 2.1880e+00],\n",
      "        [ 7.4693e-01],\n",
      "        [-3.3892e+00],\n",
      "        [-4.5102e+00],\n",
      "        [-3.0055e+00],\n",
      "        [-4.7958e-01],\n",
      "        [ 1.8386e+00],\n",
      "        [-2.2071e+00],\n",
      "        [-4.8681e+00],\n",
      "        [-2.6341e+00],\n",
      "        [-5.2128e-01],\n",
      "        [ 1.8857e-01],\n",
      "        [-2.9616e+00],\n",
      "        [-4.5685e+00],\n",
      "        [ 3.9197e+00],\n",
      "        [ 2.2514e+00],\n",
      "        [-2.6400e+00],\n",
      "        [-2.7495e+00],\n",
      "        [ 3.8891e+00],\n",
      "        [-3.7202e+00],\n",
      "        [-3.0080e+00],\n",
      "        [-3.7606e+00],\n",
      "        [ 1.8722e+00],\n",
      "        [-3.3406e+00],\n",
      "        [ 3.7508e+00],\n",
      "        [-2.6129e-01],\n",
      "        [-4.9288e+00],\n",
      "        [-1.6198e-01],\n",
      "        [-2.0048e+00],\n",
      "        [-1.7293e+00],\n",
      "        [-8.2055e-01],\n",
      "        [-1.6580e+00],\n",
      "        [-5.8405e+00],\n",
      "        [-4.8002e-02],\n",
      "        [ 3.1502e+00],\n",
      "        [-3.6337e+00],\n",
      "        [ 1.3258e+00],\n",
      "        [ 2.8517e+00],\n",
      "        [ 1.7125e-01],\n",
      "        [-2.5510e+00],\n",
      "        [-5.2522e+00],\n",
      "        [-5.1654e+00],\n",
      "        [ 4.3049e+00],\n",
      "        [ 1.2663e-01],\n",
      "        [ 1.7581e+00],\n",
      "        [ 6.4568e+00],\n",
      "        [-1.7770e+00],\n",
      "        [-3.4573e+00],\n",
      "        [ 2.6946e+00],\n",
      "        [-3.2922e+00],\n",
      "        [ 1.2862e+00],\n",
      "        [-3.1724e+00],\n",
      "        [ 2.0751e+00],\n",
      "        [-1.9413e+00],\n",
      "        [-1.9492e+00],\n",
      "        [-1.9697e+00],\n",
      "        [-2.7153e+00],\n",
      "        [-6.3700e+00],\n",
      "        [-2.2412e+00],\n",
      "        [-1.7525e+00]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "step = 18000, num_env_steps = 18000, scores = -508.028 (n=1), actor_loss = -34.939, critic_loss = 2.319, entropy_coef_loss = -16.690, entropy_coef = 0.098, action_stds = 0.785 ± 0.048, action_magnitude = 0.586 ± 0.296, num_gradient_steps = 8000, step_time = 7.50, total_time = 60.36\n",
      "\n",
      "\n",
      "self.log_ent_coef = tensor([-2.5910], device='cuda:0', requires_grad=True)\n",
      "actions_pi_log_prob = tensor([[-3.4970],\n",
      "        [-2.1326],\n",
      "        [-3.6599],\n",
      "        [ 0.8755],\n",
      "        [-2.3906],\n",
      "        [-3.0500],\n",
      "        [ 1.6562],\n",
      "        [-2.9558],\n",
      "        [-4.0831],\n",
      "        [-0.7470],\n",
      "        [-0.7637],\n",
      "        [ 3.1859],\n",
      "        [ 2.7450],\n",
      "        [ 5.0313],\n",
      "        [-0.7727],\n",
      "        [-2.5408],\n",
      "        [ 1.3539],\n",
      "        [ 3.3579],\n",
      "        [ 1.9501],\n",
      "        [ 1.2203],\n",
      "        [-3.2369],\n",
      "        [-7.4592],\n",
      "        [ 1.6547],\n",
      "        [ 7.3656],\n",
      "        [-2.6473],\n",
      "        [-3.2409],\n",
      "        [-0.8251],\n",
      "        [-2.0617],\n",
      "        [-0.4648],\n",
      "        [-3.1319],\n",
      "        [ 5.9777],\n",
      "        [ 2.7376],\n",
      "        [ 1.7183],\n",
      "        [-0.5734],\n",
      "        [-2.4279],\n",
      "        [ 0.3759],\n",
      "        [ 4.3529],\n",
      "        [-2.9044],\n",
      "        [-3.3029],\n",
      "        [ 3.2417],\n",
      "        [-0.9610],\n",
      "        [ 4.7914],\n",
      "        [-3.8205],\n",
      "        [-1.0349],\n",
      "        [ 0.9380],\n",
      "        [ 3.1187],\n",
      "        [ 3.4689],\n",
      "        [-4.4688],\n",
      "        [-1.1953],\n",
      "        [-2.6573],\n",
      "        [-0.0694],\n",
      "        [-0.6108],\n",
      "        [ 0.1460],\n",
      "        [-3.1282],\n",
      "        [-1.5000],\n",
      "        [ 5.4157],\n",
      "        [-3.5282],\n",
      "        [ 0.6826],\n",
      "        [-2.7639],\n",
      "        [ 7.8664],\n",
      "        [ 1.4011],\n",
      "        [ 0.2517],\n",
      "        [ 0.6286],\n",
      "        [ 3.5788],\n",
      "        [-0.3522],\n",
      "        [ 6.4985],\n",
      "        [ 1.3625],\n",
      "        [ 0.9914],\n",
      "        [-4.3189],\n",
      "        [ 2.8101],\n",
      "        [-1.1977],\n",
      "        [ 3.8753],\n",
      "        [-1.0762],\n",
      "        [-0.2838],\n",
      "        [-1.9717],\n",
      "        [ 2.4765],\n",
      "        [-1.8863],\n",
      "        [ 0.3938],\n",
      "        [ 3.5392],\n",
      "        [-1.5641],\n",
      "        [-2.4283],\n",
      "        [ 1.8013],\n",
      "        [-0.5651],\n",
      "        [-2.9142],\n",
      "        [-2.6347],\n",
      "        [ 3.7603],\n",
      "        [-4.9388],\n",
      "        [ 0.2402],\n",
      "        [ 8.9994],\n",
      "        [ 3.6289],\n",
      "        [-0.3309],\n",
      "        [-1.4811],\n",
      "        [ 0.8454],\n",
      "        [ 1.2814],\n",
      "        [-2.6383],\n",
      "        [-2.1688],\n",
      "        [-2.5216],\n",
      "        [ 0.7392],\n",
      "        [-2.2009],\n",
      "        [ 1.0927],\n",
      "        [-3.1089],\n",
      "        [-4.0645],\n",
      "        [-2.2318],\n",
      "        [-1.3881],\n",
      "        [ 5.2283],\n",
      "        [-4.2793],\n",
      "        [-1.5349],\n",
      "        [ 2.6265],\n",
      "        [-0.9926],\n",
      "        [ 2.0680],\n",
      "        [-0.1188],\n",
      "        [-6.0614],\n",
      "        [ 0.1145],\n",
      "        [-2.7646],\n",
      "        [ 0.7995],\n",
      "        [-4.8019],\n",
      "        [ 2.0408],\n",
      "        [-3.3109],\n",
      "        [ 0.6351],\n",
      "        [-5.1024],\n",
      "        [-4.9981],\n",
      "        [-2.7948],\n",
      "        [-3.6556],\n",
      "        [ 7.7966],\n",
      "        [-3.7925],\n",
      "        [-2.9308],\n",
      "        [-2.9294],\n",
      "        [ 3.5221],\n",
      "        [-2.8232],\n",
      "        [-1.5486],\n",
      "        [-0.1433],\n",
      "        [-3.7721],\n",
      "        [ 1.3130],\n",
      "        [-2.8910],\n",
      "        [ 2.7741],\n",
      "        [-4.8592],\n",
      "        [-0.4929],\n",
      "        [ 0.2035],\n",
      "        [-1.1693],\n",
      "        [-3.6670],\n",
      "        [-2.9996],\n",
      "        [ 4.0823],\n",
      "        [ 0.3953],\n",
      "        [ 3.1519],\n",
      "        [-4.4534],\n",
      "        [ 1.5200],\n",
      "        [-2.0679],\n",
      "        [-1.9803],\n",
      "        [ 3.9274],\n",
      "        [-0.5982],\n",
      "        [-1.4278],\n",
      "        [-0.6386],\n",
      "        [ 2.1845],\n",
      "        [ 0.8682],\n",
      "        [-0.8481],\n",
      "        [-1.9978],\n",
      "        [-4.6969],\n",
      "        [ 1.9189],\n",
      "        [-5.1237],\n",
      "        [ 4.4447],\n",
      "        [-1.0041],\n",
      "        [-0.8660],\n",
      "        [-1.9613],\n",
      "        [-3.7535],\n",
      "        [-1.9019],\n",
      "        [-0.3274],\n",
      "        [-3.1706],\n",
      "        [ 0.8146],\n",
      "        [ 0.0982],\n",
      "        [-3.3687],\n",
      "        [-2.3998],\n",
      "        [-1.6387],\n",
      "        [-2.7896],\n",
      "        [-2.5486],\n",
      "        [ 3.3135],\n",
      "        [-2.3728],\n",
      "        [ 4.0139],\n",
      "        [ 0.6589],\n",
      "        [ 0.6258],\n",
      "        [ 2.1585],\n",
      "        [ 0.0486],\n",
      "        [ 4.4341],\n",
      "        [-3.6252],\n",
      "        [ 1.9904],\n",
      "        [-1.4859],\n",
      "        [-2.0482],\n",
      "        [-3.2822],\n",
      "        [-4.1314],\n",
      "        [ 1.4144],\n",
      "        [ 2.5587],\n",
      "        [ 0.1399],\n",
      "        [-0.5596],\n",
      "        [ 2.6540],\n",
      "        [ 4.4017],\n",
      "        [-2.1244],\n",
      "        [-1.3007],\n",
      "        [-1.9059],\n",
      "        [-1.0831],\n",
      "        [-6.1942],\n",
      "        [-3.5405],\n",
      "        [ 1.3541],\n",
      "        [-0.9309],\n",
      "        [-0.1007],\n",
      "        [ 0.1432],\n",
      "        [-0.9455],\n",
      "        [-3.6553],\n",
      "        [-3.0220],\n",
      "        [ 2.2456],\n",
      "        [-1.3055],\n",
      "        [-2.4449],\n",
      "        [ 1.7821],\n",
      "        [ 1.3073],\n",
      "        [-2.7522],\n",
      "        [ 1.5867],\n",
      "        [-0.1490],\n",
      "        [-0.8109],\n",
      "        [-0.0459],\n",
      "        [ 5.3901],\n",
      "        [-2.2433],\n",
      "        [ 3.1358],\n",
      "        [-1.6974],\n",
      "        [ 1.5069],\n",
      "        [ 3.0209],\n",
      "        [-2.1620],\n",
      "        [-1.3123],\n",
      "        [-3.5086],\n",
      "        [ 3.5974],\n",
      "        [-1.1931],\n",
      "        [-4.8292],\n",
      "        [ 1.1443],\n",
      "        [-2.2382],\n",
      "        [ 3.6159],\n",
      "        [-2.2836],\n",
      "        [-1.3910],\n",
      "        [ 7.0601],\n",
      "        [-9.0699],\n",
      "        [ 0.7683],\n",
      "        [-1.2254],\n",
      "        [ 2.9518],\n",
      "        [-2.9207],\n",
      "        [-3.4380],\n",
      "        [-3.9146],\n",
      "        [-0.5097],\n",
      "        [-4.7416],\n",
      "        [-1.5631],\n",
      "        [-2.0328],\n",
      "        [-3.0473],\n",
      "        [-3.8683],\n",
      "        [ 0.2120],\n",
      "        [-1.7306],\n",
      "        [ 0.9278],\n",
      "        [ 2.3434],\n",
      "        [ 0.5775],\n",
      "        [-1.7925],\n",
      "        [ 0.3663],\n",
      "        [ 2.7491]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "step = 19000, num_env_steps = 19000, scores = -241.059 (n=1), actor_loss = -33.821, critic_loss = 1.972, entropy_coef_loss = -16.713, entropy_coef = 0.075, action_stds = 0.782 ± 0.046, action_magnitude = 0.608 ± 0.296, num_gradient_steps = 9000, step_time = 7.00, total_time = 67.36\n",
      "\n",
      "\n",
      "self.log_ent_coef = tensor([-2.8600], device='cuda:0', requires_grad=True)\n",
      "actions_pi_log_prob = tensor([[-3.4227],\n",
      "        [-0.1757],\n",
      "        [-1.2672],\n",
      "        [-2.4194],\n",
      "        [-1.2865],\n",
      "        [ 5.3995],\n",
      "        [-1.1243],\n",
      "        [-1.4624],\n",
      "        [ 1.4146],\n",
      "        [ 0.6544],\n",
      "        [-2.0517],\n",
      "        [-4.0201],\n",
      "        [ 3.8408],\n",
      "        [ 4.7451],\n",
      "        [ 2.7072],\n",
      "        [ 7.4907],\n",
      "        [ 4.9102],\n",
      "        [-4.1103],\n",
      "        [ 0.0212],\n",
      "        [-3.9004],\n",
      "        [ 2.5786],\n",
      "        [ 1.4262],\n",
      "        [-3.5643],\n",
      "        [ 3.6087],\n",
      "        [ 2.3424],\n",
      "        [-2.9945],\n",
      "        [ 1.5269],\n",
      "        [-0.6551],\n",
      "        [-2.1306],\n",
      "        [ 4.4701],\n",
      "        [ 1.8090],\n",
      "        [-2.0562],\n",
      "        [-2.8243],\n",
      "        [-0.6176],\n",
      "        [ 1.6538],\n",
      "        [-2.3811],\n",
      "        [-2.9771],\n",
      "        [-0.2227],\n",
      "        [-1.4859],\n",
      "        [ 1.8040],\n",
      "        [-3.1762],\n",
      "        [-1.2983],\n",
      "        [-4.1221],\n",
      "        [-0.9683],\n",
      "        [-1.6483],\n",
      "        [-0.5865],\n",
      "        [ 3.3546],\n",
      "        [ 0.0598],\n",
      "        [ 2.7416],\n",
      "        [ 1.7202],\n",
      "        [-3.6099],\n",
      "        [-0.6214],\n",
      "        [-2.9652],\n",
      "        [ 2.4738],\n",
      "        [-0.9369],\n",
      "        [ 8.2143],\n",
      "        [ 1.0036],\n",
      "        [-3.0264],\n",
      "        [ 4.4992],\n",
      "        [ 0.4616],\n",
      "        [-2.4013],\n",
      "        [ 3.2072],\n",
      "        [-1.6314],\n",
      "        [ 2.7718],\n",
      "        [ 0.7548],\n",
      "        [ 5.3063],\n",
      "        [ 1.8957],\n",
      "        [-5.1419],\n",
      "        [ 2.5220],\n",
      "        [-4.1769],\n",
      "        [ 2.2724],\n",
      "        [-5.0746],\n",
      "        [-1.8745],\n",
      "        [10.2206],\n",
      "        [-4.2734],\n",
      "        [-0.1289],\n",
      "        [-0.4750],\n",
      "        [-0.5450],\n",
      "        [ 2.6215],\n",
      "        [ 2.3883],\n",
      "        [ 2.1622],\n",
      "        [-3.3902],\n",
      "        [ 0.4295],\n",
      "        [ 0.1728],\n",
      "        [-0.7709],\n",
      "        [-0.2633],\n",
      "        [ 4.0639],\n",
      "        [-2.2903],\n",
      "        [ 0.5387],\n",
      "        [-2.5554],\n",
      "        [-3.0289],\n",
      "        [ 5.2748],\n",
      "        [ 2.7671],\n",
      "        [-5.3640],\n",
      "        [-4.0909],\n",
      "        [-0.0909],\n",
      "        [ 0.1690],\n",
      "        [-1.2895],\n",
      "        [ 0.7954],\n",
      "        [ 0.4969],\n",
      "        [-0.1519],\n",
      "        [ 1.7066],\n",
      "        [ 6.6207],\n",
      "        [ 3.5018],\n",
      "        [-5.7017],\n",
      "        [-1.8605],\n",
      "        [ 4.3846],\n",
      "        [ 1.6931],\n",
      "        [ 2.4301],\n",
      "        [ 0.9839],\n",
      "        [-2.4386],\n",
      "        [-0.1938],\n",
      "        [ 3.8783],\n",
      "        [ 0.6696],\n",
      "        [-2.1614],\n",
      "        [ 0.6817],\n",
      "        [ 1.0866],\n",
      "        [-0.9003],\n",
      "        [ 4.1516],\n",
      "        [-2.5959],\n",
      "        [-0.7666],\n",
      "        [-0.0236],\n",
      "        [ 5.3173],\n",
      "        [-0.8151],\n",
      "        [ 4.2975],\n",
      "        [ 2.2824],\n",
      "        [ 3.5103],\n",
      "        [-0.5181],\n",
      "        [ 1.8436],\n",
      "        [ 1.1268],\n",
      "        [-2.6359],\n",
      "        [ 4.6062],\n",
      "        [ 5.4797],\n",
      "        [-0.7592],\n",
      "        [ 0.7765],\n",
      "        [-4.2010],\n",
      "        [ 5.1683],\n",
      "        [ 3.7722],\n",
      "        [ 1.3087],\n",
      "        [ 0.5061],\n",
      "        [-1.1517],\n",
      "        [ 4.1854],\n",
      "        [ 1.7194],\n",
      "        [-5.2734],\n",
      "        [ 1.1529],\n",
      "        [ 0.3037],\n",
      "        [ 0.6801],\n",
      "        [-0.6812],\n",
      "        [ 1.3053],\n",
      "        [-3.8640],\n",
      "        [ 0.7164],\n",
      "        [-2.1764],\n",
      "        [-3.7375],\n",
      "        [ 0.4695],\n",
      "        [-3.3081],\n",
      "        [ 3.3609],\n",
      "        [-0.8045],\n",
      "        [ 2.2689],\n",
      "        [ 0.8585],\n",
      "        [ 4.5822],\n",
      "        [ 1.9469],\n",
      "        [ 1.1282],\n",
      "        [-3.5089],\n",
      "        [-2.4143],\n",
      "        [-1.9259],\n",
      "        [ 1.9352],\n",
      "        [-1.2019],\n",
      "        [ 3.0277],\n",
      "        [ 2.7242],\n",
      "        [-1.2068],\n",
      "        [ 1.0121],\n",
      "        [-3.4818],\n",
      "        [-4.8676],\n",
      "        [-0.3578],\n",
      "        [10.0205],\n",
      "        [-3.0189],\n",
      "        [-3.1733],\n",
      "        [-0.5229],\n",
      "        [-2.9728],\n",
      "        [-4.1492],\n",
      "        [ 2.4022],\n",
      "        [-1.2606],\n",
      "        [-1.0138],\n",
      "        [-1.5600],\n",
      "        [-2.3863],\n",
      "        [-0.2617],\n",
      "        [-4.3387],\n",
      "        [-0.7851],\n",
      "        [ 5.6379],\n",
      "        [ 2.1972],\n",
      "        [-2.6268],\n",
      "        [ 5.8117],\n",
      "        [-2.3520],\n",
      "        [ 0.4254],\n",
      "        [ 3.4290],\n",
      "        [-6.3091],\n",
      "        [-3.2942],\n",
      "        [ 1.4109],\n",
      "        [ 1.1014],\n",
      "        [-2.1815],\n",
      "        [-2.2195],\n",
      "        [ 1.2649],\n",
      "        [ 5.2281],\n",
      "        [ 0.1731],\n",
      "        [ 1.4172],\n",
      "        [ 0.2072],\n",
      "        [ 0.3965],\n",
      "        [-0.2682],\n",
      "        [ 2.7964],\n",
      "        [-5.2234],\n",
      "        [ 2.5082],\n",
      "        [ 1.2646],\n",
      "        [-2.2514],\n",
      "        [ 7.7938],\n",
      "        [ 4.7354],\n",
      "        [ 3.1164],\n",
      "        [-1.1699],\n",
      "        [-0.4823],\n",
      "        [-0.3231],\n",
      "        [ 4.1497],\n",
      "        [ 4.4617],\n",
      "        [-2.7923],\n",
      "        [ 4.2540],\n",
      "        [ 0.5591],\n",
      "        [ 1.3421],\n",
      "        [-0.9815],\n",
      "        [ 1.2429],\n",
      "        [-2.0348],\n",
      "        [ 0.6038],\n",
      "        [-2.0914],\n",
      "        [-2.5025],\n",
      "        [-3.5759],\n",
      "        [-0.2444],\n",
      "        [ 2.9578],\n",
      "        [-0.1520],\n",
      "        [ 0.6234],\n",
      "        [ 1.8223],\n",
      "        [-0.8483],\n",
      "        [ 2.3196],\n",
      "        [-0.2653],\n",
      "        [ 2.9994],\n",
      "        [ 1.9973],\n",
      "        [ 0.5896],\n",
      "        [-1.5785],\n",
      "        [ 2.1239],\n",
      "        [ 2.6716],\n",
      "        [-1.9346],\n",
      "        [ 1.6157],\n",
      "        [ 2.6215],\n",
      "        [ 3.1742],\n",
      "        [ 0.1103],\n",
      "        [ 0.3417],\n",
      "        [ 0.8792],\n",
      "        [-0.6084],\n",
      "        [-3.7745],\n",
      "        [-3.4405]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "step = 20000, num_env_steps = 20000, scores = -215.238 (n=1), actor_loss = -31.810, critic_loss = 1.880, entropy_coef_loss = -16.332, entropy_coef = 0.057, action_stds = 0.733 ± 0.094, action_magnitude = 0.592 ± 0.293, num_gradient_steps = 10000, step_time = 6.97, total_time = 74.33\n",
      "\n",
      "saved experiment log 2024-10-21_09-39-59_555014~4J6lFW at experiment_logs/HalfCheetah-v4/sac/2024-10-21_09-39-59_555014~4J6lFW.json\n",
      "\n",
      "\n",
      "self.log_ent_coef = tensor([-3.1219], device='cuda:0', requires_grad=True)\n",
      "actions_pi_log_prob = tensor([[-2.8449],\n",
      "        [ 5.9400],\n",
      "        [-1.3869],\n",
      "        [ 4.7623],\n",
      "        [-0.3309],\n",
      "        [ 2.9439],\n",
      "        [-2.6673],\n",
      "        [ 7.4484],\n",
      "        [ 0.6094],\n",
      "        [-1.2143],\n",
      "        [ 5.4336],\n",
      "        [ 2.6693],\n",
      "        [-1.5117],\n",
      "        [ 1.3393],\n",
      "        [-1.3147],\n",
      "        [-1.6779],\n",
      "        [ 7.3128],\n",
      "        [-0.0851],\n",
      "        [-0.4412],\n",
      "        [ 2.1769],\n",
      "        [-1.4071],\n",
      "        [ 5.4729],\n",
      "        [-0.7054],\n",
      "        [-2.4165],\n",
      "        [ 0.0584],\n",
      "        [ 2.1726],\n",
      "        [ 1.7011],\n",
      "        [ 6.6905],\n",
      "        [-3.0929],\n",
      "        [ 4.7854],\n",
      "        [-3.1495],\n",
      "        [-2.7349],\n",
      "        [ 1.3086],\n",
      "        [-5.7748],\n",
      "        [ 0.9616],\n",
      "        [-1.3970],\n",
      "        [ 0.7246],\n",
      "        [-0.8248],\n",
      "        [-0.7657],\n",
      "        [ 5.1045],\n",
      "        [-1.1384],\n",
      "        [ 4.4897],\n",
      "        [ 1.2253],\n",
      "        [ 0.3464],\n",
      "        [ 2.9553],\n",
      "        [-0.1302],\n",
      "        [ 4.5629],\n",
      "        [-1.0301],\n",
      "        [-1.3208],\n",
      "        [ 4.5122],\n",
      "        [ 6.6632],\n",
      "        [ 5.0551],\n",
      "        [ 1.1926],\n",
      "        [-1.9409],\n",
      "        [-0.6531],\n",
      "        [ 0.7458],\n",
      "        [-1.3748],\n",
      "        [-0.7495],\n",
      "        [-0.0428],\n",
      "        [-0.1664],\n",
      "        [ 5.9996],\n",
      "        [ 3.9244],\n",
      "        [ 1.2882],\n",
      "        [ 3.6292],\n",
      "        [-1.4896],\n",
      "        [ 3.3307],\n",
      "        [-2.0730],\n",
      "        [-1.2428],\n",
      "        [-1.8303],\n",
      "        [-1.2492],\n",
      "        [ 9.1625],\n",
      "        [ 4.8479],\n",
      "        [10.0479],\n",
      "        [ 3.2533],\n",
      "        [ 4.9825],\n",
      "        [ 0.0684],\n",
      "        [ 5.6879],\n",
      "        [ 4.3276],\n",
      "        [ 5.5142],\n",
      "        [-0.1445],\n",
      "        [-6.3303],\n",
      "        [-1.6086],\n",
      "        [-6.5835],\n",
      "        [-4.3159],\n",
      "        [ 0.6054],\n",
      "        [-0.1475],\n",
      "        [ 2.4449],\n",
      "        [-5.7541],\n",
      "        [ 1.5794],\n",
      "        [ 3.4143],\n",
      "        [ 6.5463],\n",
      "        [-0.9356],\n",
      "        [-1.8250],\n",
      "        [-2.6364],\n",
      "        [ 3.3740],\n",
      "        [-2.6087],\n",
      "        [ 3.6319],\n",
      "        [-4.0687],\n",
      "        [ 6.1203],\n",
      "        [ 2.0000],\n",
      "        [ 0.9569],\n",
      "        [ 2.6728],\n",
      "        [ 4.5675],\n",
      "        [ 5.5029],\n",
      "        [-2.2583],\n",
      "        [-1.4684],\n",
      "        [ 2.9781],\n",
      "        [ 1.0399],\n",
      "        [ 3.1922],\n",
      "        [ 4.4273],\n",
      "        [ 4.3099],\n",
      "        [-3.2684],\n",
      "        [-2.1969],\n",
      "        [ 6.0871],\n",
      "        [-1.6594],\n",
      "        [ 5.2211],\n",
      "        [ 0.5727],\n",
      "        [-3.4446],\n",
      "        [-0.2508],\n",
      "        [ 4.9564],\n",
      "        [ 0.2212],\n",
      "        [ 2.4720],\n",
      "        [-2.9998],\n",
      "        [ 2.3065],\n",
      "        [-1.9805],\n",
      "        [-3.3515],\n",
      "        [10.8537],\n",
      "        [ 1.6706],\n",
      "        [ 0.3555],\n",
      "        [ 4.8766],\n",
      "        [-0.3640],\n",
      "        [-1.8183],\n",
      "        [-0.4403],\n",
      "        [ 0.8255],\n",
      "        [-1.7733],\n",
      "        [ 3.7645],\n",
      "        [ 3.9006],\n",
      "        [ 0.3513],\n",
      "        [ 0.3390],\n",
      "        [-0.7649],\n",
      "        [ 8.3174],\n",
      "        [ 1.5947],\n",
      "        [-3.6868],\n",
      "        [ 1.8469],\n",
      "        [ 0.0742],\n",
      "        [-2.0138],\n",
      "        [ 3.8575],\n",
      "        [ 6.8899],\n",
      "        [ 1.1876],\n",
      "        [ 6.4017],\n",
      "        [ 1.6228],\n",
      "        [-2.4677],\n",
      "        [-1.9223],\n",
      "        [-0.3984],\n",
      "        [-1.6965],\n",
      "        [ 0.1953],\n",
      "        [ 0.4865],\n",
      "        [ 0.0542],\n",
      "        [-0.6591],\n",
      "        [-2.6027],\n",
      "        [ 0.2662],\n",
      "        [ 2.0100],\n",
      "        [ 6.7358],\n",
      "        [-0.6026],\n",
      "        [ 1.1040],\n",
      "        [ 3.5362],\n",
      "        [-2.4078],\n",
      "        [ 3.0662],\n",
      "        [ 2.2994],\n",
      "        [ 1.1705],\n",
      "        [-2.6650],\n",
      "        [-0.2967],\n",
      "        [ 1.8853],\n",
      "        [-2.4093],\n",
      "        [ 6.1377],\n",
      "        [ 0.6874],\n",
      "        [-5.2863],\n",
      "        [ 2.9129],\n",
      "        [ 3.5786],\n",
      "        [-3.4305],\n",
      "        [-0.3430],\n",
      "        [ 0.9802],\n",
      "        [ 4.9536],\n",
      "        [ 2.0431],\n",
      "        [-5.2977],\n",
      "        [ 2.2468],\n",
      "        [-0.8301],\n",
      "        [-3.4213],\n",
      "        [ 0.3723],\n",
      "        [-0.6486],\n",
      "        [ 6.3820],\n",
      "        [-0.4086],\n",
      "        [-1.6617],\n",
      "        [ 4.5913],\n",
      "        [ 2.6686],\n",
      "        [-2.5749],\n",
      "        [ 2.9948],\n",
      "        [ 0.9592],\n",
      "        [ 0.0877],\n",
      "        [-0.7456],\n",
      "        [ 7.3318],\n",
      "        [-2.5819],\n",
      "        [-2.4062],\n",
      "        [ 3.3164],\n",
      "        [-2.6726],\n",
      "        [-2.6417],\n",
      "        [ 9.5719],\n",
      "        [-0.0925],\n",
      "        [ 1.2577],\n",
      "        [ 9.9934],\n",
      "        [ 0.9052],\n",
      "        [ 0.1792],\n",
      "        [ 0.7628],\n",
      "        [ 5.2119],\n",
      "        [-4.0838],\n",
      "        [-1.3094],\n",
      "        [-0.9129],\n",
      "        [ 2.2598],\n",
      "        [ 2.0866],\n",
      "        [-0.2236],\n",
      "        [ 3.5560],\n",
      "        [-2.4096],\n",
      "        [-3.5649],\n",
      "        [ 1.4702],\n",
      "        [ 2.7398],\n",
      "        [ 5.3932],\n",
      "        [-1.1714],\n",
      "        [ 1.7016],\n",
      "        [10.7324],\n",
      "        [-1.7540],\n",
      "        [ 1.5968],\n",
      "        [ 1.5020],\n",
      "        [-0.9810],\n",
      "        [-1.9600],\n",
      "        [ 2.8521],\n",
      "        [ 1.7832],\n",
      "        [-1.4382],\n",
      "        [-3.9997],\n",
      "        [ 6.0091],\n",
      "        [ 5.0992],\n",
      "        [ 5.3685],\n",
      "        [ 0.4963],\n",
      "        [-1.1042],\n",
      "        [-0.3490],\n",
      "        [ 2.1651],\n",
      "        [ 1.2945],\n",
      "        [ 5.4783],\n",
      "        [-3.2811],\n",
      "        [ 4.8843],\n",
      "        [ 6.4844],\n",
      "        [ 1.4708],\n",
      "        [-3.4553],\n",
      "        [-2.7249],\n",
      "        [ 4.5895],\n",
      "        [-0.8502],\n",
      "        [ 0.9409]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "step = 21000, num_env_steps = 21000, scores = -194.313 (n=1), actor_loss = -31.085, critic_loss = 1.643, entropy_coef_loss = -15.309, entropy_coef = 0.044, action_stds = 0.688 ± 0.074, action_magnitude = 0.608 ± 0.295, num_gradient_steps = 11000, step_time = 7.09, total_time = 81.42\n",
      "\n",
      "\n",
      "self.log_ent_coef = tensor([-3.3791], device='cuda:0', requires_grad=True)\n",
      "actions_pi_log_prob = tensor([[-3.3464e+00],\n",
      "        [ 4.8544e+00],\n",
      "        [-2.1105e+00],\n",
      "        [ 1.6143e+00],\n",
      "        [ 2.5876e+00],\n",
      "        [ 1.5825e-01],\n",
      "        [-6.1759e+00],\n",
      "        [ 3.6832e+00],\n",
      "        [ 2.0210e+00],\n",
      "        [ 1.0309e-01],\n",
      "        [-2.8100e+00],\n",
      "        [ 4.8737e-01],\n",
      "        [ 4.1331e+00],\n",
      "        [ 4.9499e+00],\n",
      "        [ 3.0349e+00],\n",
      "        [ 3.2538e+00],\n",
      "        [-1.5874e+00],\n",
      "        [ 2.9884e+00],\n",
      "        [ 5.8722e+00],\n",
      "        [-7.6963e-01],\n",
      "        [-3.2674e+00],\n",
      "        [ 3.4043e+00],\n",
      "        [ 8.4791e+00],\n",
      "        [-2.2560e-01],\n",
      "        [-1.6533e+00],\n",
      "        [ 7.1565e-02],\n",
      "        [ 5.3730e+00],\n",
      "        [ 2.0269e-02],\n",
      "        [-4.1680e+00],\n",
      "        [-2.9146e-01],\n",
      "        [-7.1731e-01],\n",
      "        [ 9.9123e-01],\n",
      "        [ 3.2471e-01],\n",
      "        [ 1.1154e+00],\n",
      "        [ 9.2761e+00],\n",
      "        [ 9.8364e-01],\n",
      "        [-1.1110e+00],\n",
      "        [-1.7535e+00],\n",
      "        [ 2.2629e+00],\n",
      "        [ 8.5641e-01],\n",
      "        [ 7.4936e-01],\n",
      "        [ 1.0965e+00],\n",
      "        [ 2.1867e+00],\n",
      "        [ 7.8258e+00],\n",
      "        [-2.2254e+00],\n",
      "        [ 5.1978e+00],\n",
      "        [ 1.2852e+00],\n",
      "        [ 4.4871e+00],\n",
      "        [ 1.7546e+00],\n",
      "        [-2.3854e-01],\n",
      "        [ 1.1262e+01],\n",
      "        [-2.5155e+00],\n",
      "        [-8.9590e-01],\n",
      "        [-1.9829e+00],\n",
      "        [ 2.6617e+00],\n",
      "        [-3.9628e+00],\n",
      "        [-1.6875e-02],\n",
      "        [-2.5814e+00],\n",
      "        [-1.8142e-01],\n",
      "        [-2.9692e-01],\n",
      "        [-2.0779e+00],\n",
      "        [-1.8266e+00],\n",
      "        [-2.2168e+00],\n",
      "        [ 3.4461e-01],\n",
      "        [-2.2583e+00],\n",
      "        [ 1.3126e+00],\n",
      "        [-2.1195e+00],\n",
      "        [ 4.1141e+00],\n",
      "        [ 1.1374e+01],\n",
      "        [ 5.9745e-01],\n",
      "        [-4.6314e+00],\n",
      "        [ 4.6603e+00],\n",
      "        [ 3.1354e+00],\n",
      "        [ 2.1664e+00],\n",
      "        [ 3.0463e+00],\n",
      "        [-1.2884e+00],\n",
      "        [ 2.2483e+00],\n",
      "        [-4.2678e+00],\n",
      "        [ 1.6433e+00],\n",
      "        [-1.5961e+00],\n",
      "        [ 4.8957e+00],\n",
      "        [-3.7571e+00],\n",
      "        [-7.4956e-01],\n",
      "        [ 3.5015e+00],\n",
      "        [ 2.1163e+00],\n",
      "        [ 5.6737e+00],\n",
      "        [-8.6329e-01],\n",
      "        [ 2.9628e+00],\n",
      "        [-7.2081e-01],\n",
      "        [ 3.2716e-01],\n",
      "        [-6.7510e+00],\n",
      "        [ 2.8953e-01],\n",
      "        [ 1.2832e+00],\n",
      "        [ 4.0196e+00],\n",
      "        [ 1.9346e+00],\n",
      "        [-1.1560e+00],\n",
      "        [-6.5857e-01],\n",
      "        [ 1.0300e+01],\n",
      "        [ 2.0893e+00],\n",
      "        [ 1.3460e+00],\n",
      "        [ 2.8790e+00],\n",
      "        [ 8.4759e+00],\n",
      "        [ 4.0120e+00],\n",
      "        [-2.8862e+00],\n",
      "        [ 4.7769e+00],\n",
      "        [ 1.6782e+00],\n",
      "        [-2.2683e+00],\n",
      "        [ 3.3757e+00],\n",
      "        [ 3.8365e+00],\n",
      "        [-1.9475e+00],\n",
      "        [ 3.4438e-01],\n",
      "        [-5.1063e-01],\n",
      "        [ 3.2471e+00],\n",
      "        [ 2.2991e+00],\n",
      "        [-1.8696e+00],\n",
      "        [ 4.6735e+00],\n",
      "        [ 2.7098e+00],\n",
      "        [ 2.5708e+00],\n",
      "        [-1.6279e+00],\n",
      "        [ 8.6623e+00],\n",
      "        [ 5.7719e-01],\n",
      "        [ 5.2880e-01],\n",
      "        [-5.9414e-01],\n",
      "        [ 6.0165e+00],\n",
      "        [-9.3682e-02],\n",
      "        [ 5.0697e+00],\n",
      "        [-1.3685e+00],\n",
      "        [-2.2382e+00],\n",
      "        [-7.8307e-01],\n",
      "        [-4.7686e-01],\n",
      "        [ 5.2516e+00],\n",
      "        [ 1.6276e+00],\n",
      "        [ 6.1774e+00],\n",
      "        [ 2.8660e-01],\n",
      "        [ 7.1273e+00],\n",
      "        [-6.0097e-02],\n",
      "        [ 1.0833e+00],\n",
      "        [ 6.0774e-01],\n",
      "        [ 1.9009e+00],\n",
      "        [ 8.2710e+00],\n",
      "        [ 4.7567e+00],\n",
      "        [-1.4872e+00],\n",
      "        [-6.0636e-01],\n",
      "        [ 5.6257e+00],\n",
      "        [-1.2914e+00],\n",
      "        [ 8.4270e+00],\n",
      "        [ 1.9379e+00],\n",
      "        [ 1.3281e+00],\n",
      "        [ 5.6417e+00],\n",
      "        [ 3.0136e+00],\n",
      "        [ 2.4141e+00],\n",
      "        [ 3.9746e+00],\n",
      "        [ 1.5498e+00],\n",
      "        [ 2.3889e+00],\n",
      "        [-4.4541e-01],\n",
      "        [ 9.1054e+00],\n",
      "        [ 5.9882e+00],\n",
      "        [ 2.4489e+00],\n",
      "        [ 6.5760e+00],\n",
      "        [-2.1982e+00],\n",
      "        [ 5.6901e+00],\n",
      "        [ 6.2516e+00],\n",
      "        [ 5.6001e+00],\n",
      "        [ 3.6045e+00],\n",
      "        [ 1.1279e+00],\n",
      "        [ 6.7278e+00],\n",
      "        [ 5.1549e+00],\n",
      "        [-2.9675e+00],\n",
      "        [-4.5620e+00],\n",
      "        [ 1.2219e+00],\n",
      "        [ 1.3176e+00],\n",
      "        [ 3.1073e+00],\n",
      "        [ 4.6117e+00],\n",
      "        [ 3.7917e-01],\n",
      "        [ 8.1582e+00],\n",
      "        [-4.9019e-03],\n",
      "        [ 2.5871e+00],\n",
      "        [-4.2196e+00],\n",
      "        [ 7.4135e+00],\n",
      "        [ 7.4876e+00],\n",
      "        [-9.7598e-01],\n",
      "        [ 6.8231e+00],\n",
      "        [ 6.0433e+00],\n",
      "        [ 2.3380e+00],\n",
      "        [ 2.0311e-01],\n",
      "        [ 6.6243e-01],\n",
      "        [ 7.3657e+00],\n",
      "        [ 3.5699e+00],\n",
      "        [-2.2598e+00],\n",
      "        [ 2.6213e+00],\n",
      "        [-8.3250e-01],\n",
      "        [ 1.2914e+00],\n",
      "        [-1.9987e-01],\n",
      "        [ 2.5363e+00],\n",
      "        [ 1.2060e+00],\n",
      "        [ 3.4074e+00],\n",
      "        [-4.7842e+00],\n",
      "        [ 8.4172e+00],\n",
      "        [ 4.1983e+00],\n",
      "        [ 6.0607e+00],\n",
      "        [ 5.7468e-03],\n",
      "        [ 1.1646e+00],\n",
      "        [-4.4195e+00],\n",
      "        [-2.6526e+00],\n",
      "        [-3.9910e+00],\n",
      "        [-2.9431e+00],\n",
      "        [ 1.9458e+00],\n",
      "        [-2.9436e+00],\n",
      "        [ 7.1884e+00],\n",
      "        [ 2.4985e+00],\n",
      "        [ 3.4160e+00],\n",
      "        [ 5.4240e+00],\n",
      "        [ 2.1223e+00],\n",
      "        [-2.6012e-01],\n",
      "        [-2.4739e+00],\n",
      "        [-1.8085e+00],\n",
      "        [ 1.4687e+00],\n",
      "        [-5.7703e+00],\n",
      "        [ 6.0627e+00],\n",
      "        [ 3.4702e+00],\n",
      "        [-4.1476e+00],\n",
      "        [ 1.2319e-01],\n",
      "        [-3.3112e-01],\n",
      "        [ 6.9518e+00],\n",
      "        [ 1.5563e-02],\n",
      "        [-4.3009e-01],\n",
      "        [-3.1543e+00],\n",
      "        [ 4.4309e+00],\n",
      "        [ 1.2429e+00],\n",
      "        [ 5.2077e+00],\n",
      "        [ 9.6455e-01],\n",
      "        [ 1.5866e+00],\n",
      "        [ 1.9605e+00],\n",
      "        [ 1.5309e+00],\n",
      "        [-2.9595e+00],\n",
      "        [-7.8992e-01],\n",
      "        [-1.8271e+00],\n",
      "        [ 8.1415e+00],\n",
      "        [ 4.8620e+00],\n",
      "        [-3.4381e+00],\n",
      "        [-2.8983e+00],\n",
      "        [-8.8348e-01],\n",
      "        [-6.3968e-01],\n",
      "        [ 1.1916e+00],\n",
      "        [ 3.3487e+00],\n",
      "        [ 2.9901e+00],\n",
      "        [-5.2554e-01],\n",
      "        [ 7.0408e-01],\n",
      "        [-2.7421e+00],\n",
      "        [ 4.8753e+00],\n",
      "        [ 1.0605e+00],\n",
      "        [ 1.7960e+00],\n",
      "        [ 2.9714e+00],\n",
      "        [ 1.9808e+00],\n",
      "        [-1.8123e+00],\n",
      "        [ 2.3994e-01]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "step = 22000, num_env_steps = 22000, scores = -111.296 (n=1), actor_loss = -29.298, critic_loss = 2.104, entropy_coef_loss = -15.114, entropy_coef = 0.034, action_stds = 0.569 ± 0.109, action_magnitude = 0.593 ± 0.294, num_gradient_steps = 12000, step_time = 7.00, total_time = 88.42\n",
      "\n",
      "\n",
      "self.log_ent_coef = tensor([-3.6232], device='cuda:0', requires_grad=True)\n",
      "actions_pi_log_prob = tensor([[ 2.9151],\n",
      "        [ 1.8629],\n",
      "        [ 1.4002],\n",
      "        [ 2.2177],\n",
      "        [ 5.3100],\n",
      "        [ 6.2461],\n",
      "        [ 0.7450],\n",
      "        [-4.2966],\n",
      "        [-0.7818],\n",
      "        [ 1.3420],\n",
      "        [ 2.7511],\n",
      "        [ 0.1080],\n",
      "        [13.5182],\n",
      "        [ 1.2898],\n",
      "        [ 4.9098],\n",
      "        [ 1.8305],\n",
      "        [ 3.9625],\n",
      "        [ 1.3721],\n",
      "        [ 2.2007],\n",
      "        [ 3.2976],\n",
      "        [ 4.6982],\n",
      "        [-2.2124],\n",
      "        [11.6615],\n",
      "        [-1.2538],\n",
      "        [ 3.7547],\n",
      "        [ 3.2392],\n",
      "        [10.0322],\n",
      "        [ 7.3795],\n",
      "        [-1.3562],\n",
      "        [ 0.6283],\n",
      "        [ 7.4357],\n",
      "        [-2.1179],\n",
      "        [-2.9880],\n",
      "        [-4.3995],\n",
      "        [ 2.2500],\n",
      "        [ 4.9341],\n",
      "        [ 2.0239],\n",
      "        [ 2.0678],\n",
      "        [-0.3842],\n",
      "        [-0.4260],\n",
      "        [ 4.3137],\n",
      "        [ 7.9603],\n",
      "        [ 5.1059],\n",
      "        [-1.8544],\n",
      "        [ 6.6904],\n",
      "        [ 3.9987],\n",
      "        [10.2036],\n",
      "        [-0.3531],\n",
      "        [ 3.1355],\n",
      "        [ 2.0639],\n",
      "        [ 9.6092],\n",
      "        [ 4.6535],\n",
      "        [ 5.4601],\n",
      "        [ 7.8476],\n",
      "        [-2.0070],\n",
      "        [ 9.3577],\n",
      "        [ 8.5818],\n",
      "        [ 1.3550],\n",
      "        [13.1564],\n",
      "        [-4.5570],\n",
      "        [ 2.4976],\n",
      "        [-4.5841],\n",
      "        [ 3.8920],\n",
      "        [ 2.3507],\n",
      "        [ 0.5717],\n",
      "        [ 1.9687],\n",
      "        [ 3.7482],\n",
      "        [ 7.9889],\n",
      "        [ 4.8698],\n",
      "        [ 0.7523],\n",
      "        [ 5.8392],\n",
      "        [ 2.4954],\n",
      "        [12.1903],\n",
      "        [-0.5557],\n",
      "        [ 3.4319],\n",
      "        [-0.8047],\n",
      "        [ 1.3914],\n",
      "        [ 1.7580],\n",
      "        [ 2.4335],\n",
      "        [ 1.7448],\n",
      "        [ 3.5651],\n",
      "        [ 2.7175],\n",
      "        [ 0.2695],\n",
      "        [ 6.7568],\n",
      "        [-1.2368],\n",
      "        [-1.0452],\n",
      "        [-1.9565],\n",
      "        [-0.8121],\n",
      "        [-1.8237],\n",
      "        [ 7.8786],\n",
      "        [ 1.5756],\n",
      "        [ 6.9685],\n",
      "        [-0.3086],\n",
      "        [ 0.3201],\n",
      "        [-0.2264],\n",
      "        [ 2.4922],\n",
      "        [-1.6493],\n",
      "        [ 9.4289],\n",
      "        [ 5.0558],\n",
      "        [-0.0346],\n",
      "        [ 5.9691],\n",
      "        [15.1036],\n",
      "        [ 8.9608],\n",
      "        [ 1.5958],\n",
      "        [-1.4089],\n",
      "        [ 2.0266],\n",
      "        [-0.8585],\n",
      "        [-0.4275],\n",
      "        [ 6.3400],\n",
      "        [11.3421],\n",
      "        [-0.4631],\n",
      "        [-1.5365],\n",
      "        [-1.7113],\n",
      "        [ 1.2601],\n",
      "        [ 0.8059],\n",
      "        [ 6.0589],\n",
      "        [ 0.4066],\n",
      "        [ 4.2937],\n",
      "        [ 5.4205],\n",
      "        [ 3.0940],\n",
      "        [ 1.8987],\n",
      "        [ 1.4478],\n",
      "        [-0.7453],\n",
      "        [ 8.0171],\n",
      "        [ 0.6159],\n",
      "        [ 1.4629],\n",
      "        [-1.6454],\n",
      "        [ 2.8574],\n",
      "        [17.8525],\n",
      "        [-6.3622],\n",
      "        [ 0.3607],\n",
      "        [ 2.0924],\n",
      "        [ 4.4605],\n",
      "        [ 5.4164],\n",
      "        [-0.2725],\n",
      "        [ 6.8092],\n",
      "        [ 6.3773],\n",
      "        [ 6.0373],\n",
      "        [ 2.9779],\n",
      "        [-2.3066],\n",
      "        [ 2.2649],\n",
      "        [ 2.9401],\n",
      "        [-1.9823],\n",
      "        [ 1.3552],\n",
      "        [ 5.3538],\n",
      "        [-1.1416],\n",
      "        [-0.6714],\n",
      "        [ 1.7569],\n",
      "        [ 1.9549],\n",
      "        [ 4.8680],\n",
      "        [ 4.8148],\n",
      "        [ 7.9673],\n",
      "        [ 1.8520],\n",
      "        [ 5.2380],\n",
      "        [14.9743],\n",
      "        [ 3.7715],\n",
      "        [ 7.0989],\n",
      "        [-1.4982],\n",
      "        [ 3.6105],\n",
      "        [ 2.6627],\n",
      "        [ 2.3504],\n",
      "        [ 7.2015],\n",
      "        [ 3.9786],\n",
      "        [ 9.1064],\n",
      "        [ 0.7047],\n",
      "        [ 0.6518],\n",
      "        [ 1.3629],\n",
      "        [ 2.5363],\n",
      "        [ 3.3632],\n",
      "        [ 4.1352],\n",
      "        [ 4.6037],\n",
      "        [ 0.0555],\n",
      "        [ 5.1366],\n",
      "        [ 0.9050],\n",
      "        [ 6.2648],\n",
      "        [ 2.9869],\n",
      "        [ 3.1158],\n",
      "        [ 1.4225],\n",
      "        [ 0.4932],\n",
      "        [ 2.8426],\n",
      "        [ 7.0190],\n",
      "        [ 4.8463],\n",
      "        [ 2.2486],\n",
      "        [ 0.3008],\n",
      "        [-2.0254],\n",
      "        [ 0.7866],\n",
      "        [ 3.4551],\n",
      "        [ 2.7412],\n",
      "        [ 3.4504],\n",
      "        [11.6902],\n",
      "        [ 3.8980],\n",
      "        [-0.6622],\n",
      "        [ 2.9586],\n",
      "        [ 7.3075],\n",
      "        [ 1.8773],\n",
      "        [ 0.6275],\n",
      "        [-0.4442],\n",
      "        [ 3.2106],\n",
      "        [-0.2341],\n",
      "        [ 6.7527],\n",
      "        [-0.9489],\n",
      "        [-1.6057],\n",
      "        [ 7.0761],\n",
      "        [ 1.4124],\n",
      "        [ 0.0198],\n",
      "        [ 8.2766],\n",
      "        [12.2644],\n",
      "        [ 0.4007],\n",
      "        [ 2.5171],\n",
      "        [-1.6609],\n",
      "        [ 3.8241],\n",
      "        [ 0.3306],\n",
      "        [ 0.6838],\n",
      "        [ 1.1956],\n",
      "        [ 7.5497],\n",
      "        [ 5.8531],\n",
      "        [ 0.2388],\n",
      "        [ 2.0781],\n",
      "        [ 3.0642],\n",
      "        [ 1.9957],\n",
      "        [ 1.5318],\n",
      "        [ 6.4362],\n",
      "        [ 6.7029],\n",
      "        [ 2.2467],\n",
      "        [-0.4777],\n",
      "        [10.5655],\n",
      "        [ 1.2442],\n",
      "        [-1.7378],\n",
      "        [ 2.1414],\n",
      "        [ 3.8156],\n",
      "        [ 2.6566],\n",
      "        [ 4.9443],\n",
      "        [ 1.0599],\n",
      "        [ 2.9696],\n",
      "        [ 2.6901],\n",
      "        [11.7688],\n",
      "        [ 2.4303],\n",
      "        [-1.3307],\n",
      "        [ 1.7118],\n",
      "        [ 6.0381],\n",
      "        [ 2.7700],\n",
      "        [ 1.1614],\n",
      "        [ 0.7779],\n",
      "        [ 3.7861],\n",
      "        [-6.3710],\n",
      "        [ 5.9739],\n",
      "        [-0.9917],\n",
      "        [ 2.6956],\n",
      "        [ 3.1429],\n",
      "        [-2.8283],\n",
      "        [ 1.6348],\n",
      "        [ 4.3455],\n",
      "        [ 5.5467],\n",
      "        [ 2.1779],\n",
      "        [-2.1131],\n",
      "        [-4.2852]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "step = 23000, num_env_steps = 23000, scores = 53.991 (n=1), actor_loss = -29.454, critic_loss = 2.232, entropy_coef_loss = -11.308, entropy_coef = 0.027, action_stds = 0.552 ± 0.099, action_magnitude = 0.654 ± 0.300, num_gradient_steps = 13000, step_time = 7.00, total_time = 95.41\n",
      "\n",
      "\n",
      "self.log_ent_coef = tensor([-3.8626], device='cuda:0', requires_grad=True)\n",
      "actions_pi_log_prob = tensor([[ 1.0182e+01],\n",
      "        [ 3.4709e+00],\n",
      "        [ 3.3506e+00],\n",
      "        [-1.7028e+00],\n",
      "        [ 9.0109e+00],\n",
      "        [ 2.3359e+00],\n",
      "        [ 5.4223e+00],\n",
      "        [ 9.2885e+00],\n",
      "        [ 3.7945e+00],\n",
      "        [ 1.8596e+00],\n",
      "        [ 5.0512e+00],\n",
      "        [ 1.1457e+01],\n",
      "        [-1.3325e+00],\n",
      "        [ 5.0276e+00],\n",
      "        [-6.4108e-01],\n",
      "        [ 7.8765e+00],\n",
      "        [-8.3429e-01],\n",
      "        [ 4.6780e+00],\n",
      "        [ 5.5150e+00],\n",
      "        [ 5.5168e+00],\n",
      "        [ 1.4714e+01],\n",
      "        [ 6.5459e+00],\n",
      "        [ 3.2216e+00],\n",
      "        [ 3.5633e-01],\n",
      "        [ 6.1691e+00],\n",
      "        [ 6.1282e-01],\n",
      "        [-3.0646e+00],\n",
      "        [ 8.2919e+00],\n",
      "        [ 6.4391e+00],\n",
      "        [ 6.2628e+00],\n",
      "        [-2.7970e+00],\n",
      "        [ 3.6102e-01],\n",
      "        [-1.1722e+00],\n",
      "        [ 2.2906e+00],\n",
      "        [ 2.5232e+00],\n",
      "        [ 1.7815e+00],\n",
      "        [ 1.9350e+00],\n",
      "        [-9.8908e-01],\n",
      "        [ 9.8782e-01],\n",
      "        [ 1.0889e+01],\n",
      "        [ 4.7671e-01],\n",
      "        [ 2.7063e+00],\n",
      "        [ 9.2348e+00],\n",
      "        [ 1.7804e+00],\n",
      "        [-4.5853e+00],\n",
      "        [ 1.0289e+00],\n",
      "        [ 2.3144e+00],\n",
      "        [ 6.0164e+00],\n",
      "        [ 8.8478e+00],\n",
      "        [ 1.9284e-01],\n",
      "        [ 1.6305e+00],\n",
      "        [ 4.8380e+00],\n",
      "        [ 7.2528e-02],\n",
      "        [ 7.8219e+00],\n",
      "        [-5.5977e-01],\n",
      "        [-4.4165e-01],\n",
      "        [ 2.7318e+00],\n",
      "        [ 1.3384e+01],\n",
      "        [ 7.3932e+00],\n",
      "        [ 4.0456e-01],\n",
      "        [ 4.5999e+00],\n",
      "        [ 8.0492e+00],\n",
      "        [ 1.2884e+01],\n",
      "        [ 1.9842e+01],\n",
      "        [ 8.0903e+00],\n",
      "        [-2.0074e+00],\n",
      "        [ 1.6110e+00],\n",
      "        [ 7.8397e+00],\n",
      "        [ 6.8624e+00],\n",
      "        [ 6.9292e-01],\n",
      "        [ 8.2437e+00],\n",
      "        [ 2.5638e+00],\n",
      "        [ 7.1247e+00],\n",
      "        [ 1.3533e+01],\n",
      "        [ 1.6065e+00],\n",
      "        [ 5.7873e-01],\n",
      "        [ 4.5355e+00],\n",
      "        [ 8.8063e+00],\n",
      "        [-2.3765e+00],\n",
      "        [ 8.7537e+00],\n",
      "        [ 5.3995e+00],\n",
      "        [-2.8609e+00],\n",
      "        [ 4.7130e-01],\n",
      "        [-1.3950e-01],\n",
      "        [ 4.9126e+00],\n",
      "        [-5.0573e+00],\n",
      "        [ 2.4067e+00],\n",
      "        [ 7.4513e+00],\n",
      "        [ 1.5201e+00],\n",
      "        [ 1.7891e+00],\n",
      "        [ 1.8140e+00],\n",
      "        [ 5.1494e+00],\n",
      "        [ 3.5115e+00],\n",
      "        [ 7.1139e+00],\n",
      "        [ 4.0302e-01],\n",
      "        [ 6.6673e-02],\n",
      "        [ 3.0636e+00],\n",
      "        [-1.7642e+00],\n",
      "        [ 3.8170e+00],\n",
      "        [-1.4568e+00],\n",
      "        [-9.8227e-02],\n",
      "        [-1.6329e-01],\n",
      "        [-2.4557e+00],\n",
      "        [-4.0319e-03],\n",
      "        [-2.4966e-01],\n",
      "        [ 2.3064e+00],\n",
      "        [-3.7981e+00],\n",
      "        [ 3.5121e+00],\n",
      "        [ 2.2245e-01],\n",
      "        [ 7.9522e+00],\n",
      "        [ 3.5588e+00],\n",
      "        [ 3.9823e+00],\n",
      "        [ 6.8400e+00],\n",
      "        [ 1.5119e+00],\n",
      "        [ 3.3157e+00],\n",
      "        [ 8.8412e+00],\n",
      "        [ 2.0099e+00],\n",
      "        [-3.2729e+00],\n",
      "        [ 7.1414e+00],\n",
      "        [-7.4004e-01],\n",
      "        [ 1.7436e+00],\n",
      "        [-2.2042e+00],\n",
      "        [ 6.8292e+00],\n",
      "        [-1.4955e+00],\n",
      "        [ 1.1384e+01],\n",
      "        [ 6.0400e+00],\n",
      "        [ 4.9961e-01],\n",
      "        [-1.0681e-01],\n",
      "        [ 1.3090e+00],\n",
      "        [-4.1548e-01],\n",
      "        [ 2.6166e+00],\n",
      "        [-2.6444e+00],\n",
      "        [ 2.0783e+00],\n",
      "        [ 1.4090e+01],\n",
      "        [ 9.0904e-01],\n",
      "        [ 4.1715e+00],\n",
      "        [ 6.1554e+00],\n",
      "        [ 2.6865e+00],\n",
      "        [ 8.8407e+00],\n",
      "        [ 3.5064e+00],\n",
      "        [-7.1937e-01],\n",
      "        [ 1.8035e+00],\n",
      "        [ 5.6585e+00],\n",
      "        [ 6.4974e+00],\n",
      "        [ 1.4339e+00],\n",
      "        [-3.0717e+00],\n",
      "        [ 4.3461e+00],\n",
      "        [-1.1381e+00],\n",
      "        [-2.5678e-01],\n",
      "        [ 1.1494e+01],\n",
      "        [-6.3329e-02],\n",
      "        [-1.9657e-01],\n",
      "        [ 1.5114e+00],\n",
      "        [ 4.9656e+00],\n",
      "        [ 5.9407e+00],\n",
      "        [-1.9536e+00],\n",
      "        [-2.9566e-01],\n",
      "        [ 6.9901e+00],\n",
      "        [ 4.7914e+00],\n",
      "        [ 9.3253e-01],\n",
      "        [ 5.9213e+00],\n",
      "        [ 7.8857e+00],\n",
      "        [-1.4073e-01],\n",
      "        [ 6.6747e-01],\n",
      "        [-1.4148e+00],\n",
      "        [ 2.3809e+00],\n",
      "        [ 2.9211e+00],\n",
      "        [ 5.6860e+00],\n",
      "        [ 5.1598e+00],\n",
      "        [ 5.3583e+00],\n",
      "        [-1.2725e+00],\n",
      "        [ 1.1144e+01],\n",
      "        [ 4.7418e+00],\n",
      "        [-3.1116e-01],\n",
      "        [-1.4505e+00],\n",
      "        [ 1.1734e+01],\n",
      "        [-1.1634e+00],\n",
      "        [-8.8114e-01],\n",
      "        [-9.5158e-03],\n",
      "        [ 8.7699e+00],\n",
      "        [ 1.8192e+00],\n",
      "        [ 1.8814e+00],\n",
      "        [ 4.9005e+00],\n",
      "        [ 2.0378e+00],\n",
      "        [ 4.4869e+00],\n",
      "        [ 3.9013e+00],\n",
      "        [ 7.9323e+00],\n",
      "        [ 3.5494e+00],\n",
      "        [-1.2395e+00],\n",
      "        [-1.0148e+00],\n",
      "        [ 1.0649e+01],\n",
      "        [ 1.7937e+00],\n",
      "        [-1.6469e+00],\n",
      "        [ 2.9100e+00],\n",
      "        [-5.6845e-01],\n",
      "        [ 2.1431e+00],\n",
      "        [ 2.4236e+00],\n",
      "        [ 5.7977e+00],\n",
      "        [-1.0618e-02],\n",
      "        [ 6.4282e+00],\n",
      "        [ 2.0005e+00],\n",
      "        [ 6.3845e+00],\n",
      "        [ 5.9602e+00],\n",
      "        [ 2.2093e+00],\n",
      "        [ 7.0499e+00],\n",
      "        [ 3.0530e+00],\n",
      "        [ 2.2511e+00],\n",
      "        [ 8.6619e+00],\n",
      "        [ 9.6690e-01],\n",
      "        [-3.3986e+00],\n",
      "        [-2.4503e+00],\n",
      "        [ 1.3293e+00],\n",
      "        [-4.5541e+00],\n",
      "        [ 5.5408e+00],\n",
      "        [ 1.6508e+00],\n",
      "        [ 2.2881e+00],\n",
      "        [-6.0578e-01],\n",
      "        [ 1.7627e+00],\n",
      "        [-5.2183e-01],\n",
      "        [ 6.2670e+00],\n",
      "        [ 6.0711e+00],\n",
      "        [ 2.9515e+00],\n",
      "        [ 9.1726e+00],\n",
      "        [ 4.9430e+00],\n",
      "        [ 1.0178e+00],\n",
      "        [ 9.3349e+00],\n",
      "        [ 9.7127e+00],\n",
      "        [ 3.1476e+00],\n",
      "        [ 6.1970e+00],\n",
      "        [-7.4203e-01],\n",
      "        [ 6.1006e+00],\n",
      "        [ 9.7465e+00],\n",
      "        [-2.9229e+00],\n",
      "        [ 2.8832e+00],\n",
      "        [ 3.7466e+00],\n",
      "        [ 3.8932e+00],\n",
      "        [ 4.6909e+00],\n",
      "        [ 4.4486e+00],\n",
      "        [ 5.1680e+00],\n",
      "        [ 5.5115e+00],\n",
      "        [ 1.8643e+00],\n",
      "        [ 4.7887e+00],\n",
      "        [ 7.3933e+00],\n",
      "        [ 9.5710e-01],\n",
      "        [ 4.8807e-01],\n",
      "        [ 6.6422e+00],\n",
      "        [ 6.4302e+00],\n",
      "        [-5.7017e+00],\n",
      "        [ 6.5232e+00],\n",
      "        [ 3.6870e+00],\n",
      "        [ 3.5211e-01],\n",
      "        [-1.3984e+00],\n",
      "        [-1.9876e-02],\n",
      "        [ 1.8878e+01],\n",
      "        [ 3.4795e+00],\n",
      "        [-2.1136e+00]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "step = 24000, num_env_steps = 24000, scores = 22.990 (n=1), actor_loss = -27.551, critic_loss = 1.659, entropy_coef_loss = -10.327, entropy_coef = 0.021, action_stds = 0.538 ± 0.077, action_magnitude = 0.633 ± 0.299, num_gradient_steps = 14000, step_time = 7.15, total_time = 102.57\n",
      "\n",
      "\n",
      "self.log_ent_coef = tensor([-4.0846], device='cuda:0', requires_grad=True)\n",
      "actions_pi_log_prob = tensor([[12.6792],\n",
      "        [-1.5508],\n",
      "        [ 0.8867],\n",
      "        [ 5.8858],\n",
      "        [ 3.7531],\n",
      "        [ 4.3362],\n",
      "        [ 6.5219],\n",
      "        [10.9741],\n",
      "        [-2.3891],\n",
      "        [ 0.0656],\n",
      "        [-2.1601],\n",
      "        [ 9.3703],\n",
      "        [ 5.1084],\n",
      "        [ 0.6895],\n",
      "        [ 2.3864],\n",
      "        [ 1.6454],\n",
      "        [12.4804],\n",
      "        [-1.7711],\n",
      "        [ 8.0781],\n",
      "        [ 5.1176],\n",
      "        [ 5.6598],\n",
      "        [ 7.6434],\n",
      "        [ 1.7976],\n",
      "        [ 5.7457],\n",
      "        [ 1.2782],\n",
      "        [ 3.3042],\n",
      "        [ 4.4694],\n",
      "        [ 3.8136],\n",
      "        [11.8803],\n",
      "        [ 1.2669],\n",
      "        [ 8.8075],\n",
      "        [ 0.1898],\n",
      "        [ 3.5890],\n",
      "        [ 4.0789],\n",
      "        [ 1.3650],\n",
      "        [ 5.5100],\n",
      "        [-4.9344],\n",
      "        [ 1.3257],\n",
      "        [ 1.3741],\n",
      "        [ 1.9033],\n",
      "        [ 1.4239],\n",
      "        [ 4.1786],\n",
      "        [ 7.1958],\n",
      "        [ 3.8427],\n",
      "        [ 2.2640],\n",
      "        [-0.4984],\n",
      "        [ 6.9812],\n",
      "        [-0.4476],\n",
      "        [ 5.0300],\n",
      "        [ 8.1708],\n",
      "        [ 5.7459],\n",
      "        [21.3423],\n",
      "        [-0.7975],\n",
      "        [ 3.4517],\n",
      "        [ 4.3019],\n",
      "        [ 5.4470],\n",
      "        [ 3.0981],\n",
      "        [ 5.3725],\n",
      "        [ 3.0729],\n",
      "        [ 5.8607],\n",
      "        [ 5.5081],\n",
      "        [ 3.4487],\n",
      "        [-2.9148],\n",
      "        [-1.2339],\n",
      "        [ 6.4355],\n",
      "        [-0.7504],\n",
      "        [-3.2274],\n",
      "        [ 8.7046],\n",
      "        [ 9.4884],\n",
      "        [-1.0118],\n",
      "        [ 7.9327],\n",
      "        [ 7.1595],\n",
      "        [ 6.1477],\n",
      "        [ 1.1776],\n",
      "        [ 4.6553],\n",
      "        [ 1.7159],\n",
      "        [ 2.7458],\n",
      "        [ 1.8028],\n",
      "        [ 4.2024],\n",
      "        [ 3.6744],\n",
      "        [ 3.2220],\n",
      "        [13.7998],\n",
      "        [ 1.2949],\n",
      "        [-2.1431],\n",
      "        [-1.6094],\n",
      "        [-0.3587],\n",
      "        [-0.5029],\n",
      "        [ 3.6110],\n",
      "        [ 9.5967],\n",
      "        [ 5.4053],\n",
      "        [10.5709],\n",
      "        [ 3.0368],\n",
      "        [-1.0027],\n",
      "        [ 9.2747],\n",
      "        [ 5.6904],\n",
      "        [ 0.1866],\n",
      "        [ 3.0332],\n",
      "        [ 8.8946],\n",
      "        [-1.9157],\n",
      "        [11.6770],\n",
      "        [ 1.3253],\n",
      "        [ 2.9320],\n",
      "        [10.3799],\n",
      "        [ 1.3021],\n",
      "        [-3.5512],\n",
      "        [ 8.3696],\n",
      "        [ 3.3458],\n",
      "        [ 3.2991],\n",
      "        [ 0.1761],\n",
      "        [ 0.0527],\n",
      "        [ 8.9164],\n",
      "        [ 7.1785],\n",
      "        [ 1.4067],\n",
      "        [-0.3167],\n",
      "        [ 2.0901],\n",
      "        [ 0.5542],\n",
      "        [ 0.1582],\n",
      "        [ 6.4103],\n",
      "        [ 2.4444],\n",
      "        [ 4.5307],\n",
      "        [ 4.7404],\n",
      "        [ 0.9376],\n",
      "        [-1.2809],\n",
      "        [ 1.0081],\n",
      "        [ 2.3431],\n",
      "        [ 6.3303],\n",
      "        [ 3.0772],\n",
      "        [-0.2850],\n",
      "        [ 5.3503],\n",
      "        [14.1352],\n",
      "        [ 1.4458],\n",
      "        [ 3.6420],\n",
      "        [ 3.0907],\n",
      "        [ 3.2462],\n",
      "        [ 0.9522],\n",
      "        [ 9.6541],\n",
      "        [ 2.5204],\n",
      "        [ 4.8253],\n",
      "        [ 9.3844],\n",
      "        [ 2.6085],\n",
      "        [ 8.1401],\n",
      "        [ 3.3425],\n",
      "        [17.3546],\n",
      "        [ 3.8632],\n",
      "        [ 5.2249],\n",
      "        [ 2.9434],\n",
      "        [ 5.4922],\n",
      "        [10.6267],\n",
      "        [ 3.7311],\n",
      "        [12.2834],\n",
      "        [-2.0877],\n",
      "        [ 1.3895],\n",
      "        [ 3.4031],\n",
      "        [ 1.6843],\n",
      "        [-1.1413],\n",
      "        [ 1.5939],\n",
      "        [ 4.5241],\n",
      "        [ 5.0213],\n",
      "        [ 0.1804],\n",
      "        [-6.0270],\n",
      "        [ 3.4540],\n",
      "        [ 3.7183],\n",
      "        [ 0.8042],\n",
      "        [ 3.6012],\n",
      "        [ 1.5572],\n",
      "        [ 2.3042],\n",
      "        [ 3.6180],\n",
      "        [ 2.2788],\n",
      "        [ 4.9882],\n",
      "        [15.3241],\n",
      "        [-0.3235],\n",
      "        [ 4.2987],\n",
      "        [ 3.3558],\n",
      "        [ 2.3437],\n",
      "        [ 3.1159],\n",
      "        [ 7.9287],\n",
      "        [ 7.8505],\n",
      "        [ 0.8934],\n",
      "        [ 2.0459],\n",
      "        [-0.8948],\n",
      "        [10.1839],\n",
      "        [ 2.9882],\n",
      "        [ 9.4302],\n",
      "        [21.4257],\n",
      "        [ 0.0720],\n",
      "        [ 6.7240],\n",
      "        [ 6.9574],\n",
      "        [ 2.0243],\n",
      "        [ 1.2764],\n",
      "        [ 0.5946],\n",
      "        [-0.7470],\n",
      "        [ 4.0856],\n",
      "        [ 5.9330],\n",
      "        [-3.6464],\n",
      "        [-1.6312],\n",
      "        [-1.7536],\n",
      "        [ 3.1393],\n",
      "        [-2.6255],\n",
      "        [ 9.2935],\n",
      "        [-0.7414],\n",
      "        [ 3.2971],\n",
      "        [-0.6942],\n",
      "        [-0.4504],\n",
      "        [11.4932],\n",
      "        [ 7.0100],\n",
      "        [11.1445],\n",
      "        [ 9.5497],\n",
      "        [ 0.4962],\n",
      "        [ 9.7517],\n",
      "        [ 5.6214],\n",
      "        [ 0.7176],\n",
      "        [-1.9781],\n",
      "        [15.1293],\n",
      "        [ 0.1788],\n",
      "        [ 1.3692],\n",
      "        [ 8.7019],\n",
      "        [ 7.4511],\n",
      "        [11.8665],\n",
      "        [-2.2483],\n",
      "        [ 7.7917],\n",
      "        [ 1.1714],\n",
      "        [-1.8099],\n",
      "        [ 5.2715],\n",
      "        [-0.9111],\n",
      "        [ 3.6825],\n",
      "        [ 3.3406],\n",
      "        [ 7.5065],\n",
      "        [ 2.4991],\n",
      "        [ 2.1836],\n",
      "        [ 5.2716],\n",
      "        [ 3.0329],\n",
      "        [ 7.2905],\n",
      "        [ 0.5235],\n",
      "        [ 1.2964],\n",
      "        [ 6.7701],\n",
      "        [-0.2170],\n",
      "        [ 5.5681],\n",
      "        [ 4.1057],\n",
      "        [ 1.6716],\n",
      "        [ 3.8974],\n",
      "        [ 0.7038],\n",
      "        [ 8.5412],\n",
      "        [ 4.9253],\n",
      "        [ 4.3281],\n",
      "        [ 7.2881],\n",
      "        [ 9.0315],\n",
      "        [13.0192],\n",
      "        [ 3.3095],\n",
      "        [ 1.0828],\n",
      "        [-3.1943],\n",
      "        [-0.5814],\n",
      "        [11.6098],\n",
      "        [ 9.7599],\n",
      "        [-2.2097],\n",
      "        [ 2.7747],\n",
      "        [ 2.5174]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "step = 25000, num_env_steps = 25000, scores = 730.845 (n=1), actor_loss = -28.143, critic_loss = 1.618, entropy_coef_loss = -8.530, entropy_coef = 0.017, action_stds = 0.377 ± 0.076, action_magnitude = 0.690 ± 0.302, num_gradient_steps = 15000, step_time = 7.16, total_time = 109.72\n",
      "\n",
      "\n",
      "self.log_ent_coef = tensor([-4.2688], device='cuda:0', requires_grad=True)\n",
      "actions_pi_log_prob = tensor([[12.2510],\n",
      "        [ 3.9437],\n",
      "        [ 9.0340],\n",
      "        [ 8.2572],\n",
      "        [ 2.8935],\n",
      "        [ 9.3240],\n",
      "        [ 8.6422],\n",
      "        [-2.2350],\n",
      "        [ 1.7710],\n",
      "        [ 6.5707],\n",
      "        [ 4.7672],\n",
      "        [ 2.9396],\n",
      "        [ 6.8088],\n",
      "        [-1.1042],\n",
      "        [ 6.6171],\n",
      "        [11.3833],\n",
      "        [ 5.7700],\n",
      "        [ 0.3138],\n",
      "        [-0.6335],\n",
      "        [ 1.3429],\n",
      "        [ 9.3182],\n",
      "        [ 7.2349],\n",
      "        [ 2.9223],\n",
      "        [ 4.8754],\n",
      "        [ 9.6819],\n",
      "        [-0.2645],\n",
      "        [ 2.8384],\n",
      "        [ 9.4201],\n",
      "        [ 5.0718],\n",
      "        [ 5.6075],\n",
      "        [ 3.8742],\n",
      "        [ 3.3929],\n",
      "        [ 5.7907],\n",
      "        [ 3.6178],\n",
      "        [ 5.5724],\n",
      "        [ 3.9810],\n",
      "        [ 3.7537],\n",
      "        [ 3.7012],\n",
      "        [ 3.2802],\n",
      "        [-1.0618],\n",
      "        [ 1.6845],\n",
      "        [ 0.3693],\n",
      "        [ 3.8647],\n",
      "        [-0.2036],\n",
      "        [ 0.7557],\n",
      "        [ 9.7606],\n",
      "        [ 1.8560],\n",
      "        [ 2.5830],\n",
      "        [ 0.7234],\n",
      "        [10.4092],\n",
      "        [ 4.6098],\n",
      "        [ 2.2230],\n",
      "        [-3.4173],\n",
      "        [ 8.0823],\n",
      "        [15.1332],\n",
      "        [-0.8437],\n",
      "        [12.5048],\n",
      "        [ 4.7508],\n",
      "        [ 6.8075],\n",
      "        [ 6.7926],\n",
      "        [ 1.4508],\n",
      "        [ 4.1031],\n",
      "        [11.1365],\n",
      "        [ 6.5497],\n",
      "        [ 2.2811],\n",
      "        [-1.8035],\n",
      "        [-0.4478],\n",
      "        [ 0.0383],\n",
      "        [ 7.9063],\n",
      "        [ 1.0755],\n",
      "        [ 4.8232],\n",
      "        [ 2.2470],\n",
      "        [ 3.7929],\n",
      "        [ 5.7522],\n",
      "        [ 0.7174],\n",
      "        [ 0.7009],\n",
      "        [ 7.5488],\n",
      "        [ 5.4649],\n",
      "        [ 6.1412],\n",
      "        [12.5005],\n",
      "        [11.0163],\n",
      "        [ 6.4072],\n",
      "        [-0.4160],\n",
      "        [ 3.1884],\n",
      "        [ 7.3932],\n",
      "        [ 4.0985],\n",
      "        [ 0.9941],\n",
      "        [ 7.0620],\n",
      "        [ 8.2811],\n",
      "        [ 2.1221],\n",
      "        [-1.4733],\n",
      "        [-0.5361],\n",
      "        [ 6.7822],\n",
      "        [ 8.6580],\n",
      "        [ 6.8701],\n",
      "        [ 5.5702],\n",
      "        [ 3.1170],\n",
      "        [ 7.5173],\n",
      "        [ 0.6457],\n",
      "        [ 8.0372],\n",
      "        [-0.5542],\n",
      "        [ 6.7818],\n",
      "        [ 0.7339],\n",
      "        [-3.8082],\n",
      "        [10.9253],\n",
      "        [ 2.7948],\n",
      "        [ 1.1362],\n",
      "        [ 6.6252],\n",
      "        [13.8796],\n",
      "        [ 4.8054],\n",
      "        [ 7.0525],\n",
      "        [ 8.0340],\n",
      "        [ 0.4135],\n",
      "        [ 3.8834],\n",
      "        [ 5.6266],\n",
      "        [ 5.9503],\n",
      "        [16.1005],\n",
      "        [ 0.3714],\n",
      "        [ 7.0821],\n",
      "        [ 4.3182],\n",
      "        [ 1.3927],\n",
      "        [14.0624],\n",
      "        [ 0.7240],\n",
      "        [ 6.0243],\n",
      "        [ 0.2072],\n",
      "        [ 9.0686],\n",
      "        [ 4.8516],\n",
      "        [ 9.7078],\n",
      "        [-2.0680],\n",
      "        [ 2.7500],\n",
      "        [ 2.4417],\n",
      "        [ 9.8207],\n",
      "        [11.3568],\n",
      "        [10.4866],\n",
      "        [10.6981],\n",
      "        [ 9.9995],\n",
      "        [-5.8500],\n",
      "        [ 5.6821],\n",
      "        [ 1.7177],\n",
      "        [ 1.4830],\n",
      "        [ 4.2597],\n",
      "        [ 7.9258],\n",
      "        [ 7.0642],\n",
      "        [12.1367],\n",
      "        [ 6.0465],\n",
      "        [ 0.8515],\n",
      "        [-1.1004],\n",
      "        [ 7.3263],\n",
      "        [ 3.9114],\n",
      "        [ 8.9495],\n",
      "        [ 2.7231],\n",
      "        [ 1.9361],\n",
      "        [ 2.8437],\n",
      "        [ 4.2781],\n",
      "        [ 8.6825],\n",
      "        [ 6.2123],\n",
      "        [ 2.1900],\n",
      "        [ 5.2234],\n",
      "        [ 8.9785],\n",
      "        [19.2876],\n",
      "        [ 6.4539],\n",
      "        [ 7.5104],\n",
      "        [ 7.3944],\n",
      "        [ 3.1998],\n",
      "        [ 2.6063],\n",
      "        [ 8.4277],\n",
      "        [ 6.6402],\n",
      "        [15.0799],\n",
      "        [ 5.1886],\n",
      "        [ 6.1606],\n",
      "        [ 6.0367],\n",
      "        [13.3201],\n",
      "        [ 3.5862],\n",
      "        [ 9.9097],\n",
      "        [ 2.8093],\n",
      "        [13.8813],\n",
      "        [ 8.5455],\n",
      "        [ 8.0133],\n",
      "        [ 2.5977],\n",
      "        [ 6.9805],\n",
      "        [13.4255],\n",
      "        [ 1.4398],\n",
      "        [ 4.6862],\n",
      "        [ 4.0063],\n",
      "        [ 7.9751],\n",
      "        [ 6.1206],\n",
      "        [12.4255],\n",
      "        [ 1.7380],\n",
      "        [-2.2661],\n",
      "        [ 8.4075],\n",
      "        [ 2.0401],\n",
      "        [ 6.1694],\n",
      "        [11.7671],\n",
      "        [ 0.6646],\n",
      "        [ 6.8842],\n",
      "        [ 1.0365],\n",
      "        [ 9.5599],\n",
      "        [ 7.9729],\n",
      "        [-1.5752],\n",
      "        [11.5103],\n",
      "        [ 9.1735],\n",
      "        [ 7.2269],\n",
      "        [ 2.6744],\n",
      "        [ 5.4456],\n",
      "        [ 5.4804],\n",
      "        [ 1.3908],\n",
      "        [ 9.0820],\n",
      "        [10.5732],\n",
      "        [ 0.7924],\n",
      "        [ 6.6879],\n",
      "        [ 7.4831],\n",
      "        [12.4911],\n",
      "        [ 3.3008],\n",
      "        [ 0.3978],\n",
      "        [ 1.5537],\n",
      "        [-2.1759],\n",
      "        [ 9.9275],\n",
      "        [ 5.1094],\n",
      "        [ 4.2912],\n",
      "        [10.5876],\n",
      "        [ 3.1080],\n",
      "        [ 1.7634],\n",
      "        [12.3635],\n",
      "        [ 6.4437],\n",
      "        [ 0.8651],\n",
      "        [ 2.6320],\n",
      "        [12.0400],\n",
      "        [ 0.4486],\n",
      "        [ 1.1177],\n",
      "        [ 3.8210],\n",
      "        [ 1.8069],\n",
      "        [ 3.7144],\n",
      "        [ 1.7868],\n",
      "        [ 6.9260],\n",
      "        [ 2.1320],\n",
      "        [ 9.4422],\n",
      "        [-3.3282],\n",
      "        [ 8.2341],\n",
      "        [ 0.7499],\n",
      "        [13.9110],\n",
      "        [13.0635],\n",
      "        [ 2.5751],\n",
      "        [ 8.5902],\n",
      "        [ 3.7823],\n",
      "        [ 8.5257],\n",
      "        [-0.7666],\n",
      "        [-2.2287],\n",
      "        [ 1.8995],\n",
      "        [ 8.5417],\n",
      "        [ 2.9299],\n",
      "        [ 6.3344],\n",
      "        [ 5.5044],\n",
      "        [ 0.6900],\n",
      "        [17.4569],\n",
      "        [ 4.6302],\n",
      "        [ 0.0495]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "step = 26000, num_env_steps = 26000, scores = -169.770 (n=1), actor_loss = -27.375, critic_loss = 1.983, entropy_coef_loss = -3.521, entropy_coef = 0.014, action_stds = 0.550 ± 0.166, action_magnitude = 0.637 ± 0.303, num_gradient_steps = 16000, step_time = 7.09, total_time = 116.81\n",
      "\n",
      "\n",
      "self.log_ent_coef = tensor([-4.3748], device='cuda:0', requires_grad=True)\n",
      "actions_pi_log_prob = tensor([[ 3.8182e+00],\n",
      "        [ 2.4450e+00],\n",
      "        [-8.2836e-01],\n",
      "        [ 8.9298e+00],\n",
      "        [ 2.4466e+00],\n",
      "        [ 3.6505e+00],\n",
      "        [ 3.8165e+00],\n",
      "        [ 8.3026e+00],\n",
      "        [ 3.8405e+00],\n",
      "        [ 1.0335e+00],\n",
      "        [ 4.5821e+00],\n",
      "        [-1.7237e+00],\n",
      "        [ 1.8051e+01],\n",
      "        [ 8.0989e+00],\n",
      "        [ 1.7504e+01],\n",
      "        [ 4.9785e+00],\n",
      "        [ 7.1787e+00],\n",
      "        [ 1.1056e+00],\n",
      "        [ 1.0488e+01],\n",
      "        [-3.6549e-01],\n",
      "        [ 9.3630e+00],\n",
      "        [ 5.4642e+00],\n",
      "        [ 2.5667e+00],\n",
      "        [ 1.1489e+01],\n",
      "        [ 7.1075e-01],\n",
      "        [ 2.8789e-01],\n",
      "        [ 4.8884e+00],\n",
      "        [ 9.6393e-01],\n",
      "        [ 7.8282e+00],\n",
      "        [ 1.0158e+01],\n",
      "        [ 1.1111e+01],\n",
      "        [ 3.3787e+00],\n",
      "        [ 1.2300e+01],\n",
      "        [ 8.4365e+00],\n",
      "        [ 3.4536e+00],\n",
      "        [ 5.7196e+00],\n",
      "        [ 8.1557e+00],\n",
      "        [ 8.5527e+00],\n",
      "        [ 2.2060e+00],\n",
      "        [ 5.8920e+00],\n",
      "        [ 3.7952e+00],\n",
      "        [ 7.0629e+00],\n",
      "        [ 1.6322e+00],\n",
      "        [ 3.9466e+00],\n",
      "        [-6.8442e-01],\n",
      "        [ 5.0567e+00],\n",
      "        [ 1.7196e+00],\n",
      "        [ 4.3145e+00],\n",
      "        [ 1.5453e+01],\n",
      "        [ 1.7399e+00],\n",
      "        [ 2.4284e+00],\n",
      "        [ 7.0677e+00],\n",
      "        [ 1.5301e+01],\n",
      "        [ 9.8537e+00],\n",
      "        [ 3.3156e+00],\n",
      "        [ 5.0270e+00],\n",
      "        [ 7.9841e+00],\n",
      "        [-8.9676e-01],\n",
      "        [ 2.8369e+00],\n",
      "        [ 3.2016e+00],\n",
      "        [-2.1415e+00],\n",
      "        [-3.2634e+00],\n",
      "        [ 2.2352e+01],\n",
      "        [ 1.6498e+00],\n",
      "        [ 1.4721e-01],\n",
      "        [ 5.2821e+00],\n",
      "        [ 5.8979e+00],\n",
      "        [ 6.4038e+00],\n",
      "        [-1.4266e+00],\n",
      "        [ 4.5274e+00],\n",
      "        [-2.2456e+00],\n",
      "        [ 4.6420e+00],\n",
      "        [ 3.0832e+00],\n",
      "        [ 3.5451e+00],\n",
      "        [ 1.0214e+01],\n",
      "        [-2.2452e+00],\n",
      "        [ 4.9698e+00],\n",
      "        [ 8.5241e+00],\n",
      "        [ 7.3111e+00],\n",
      "        [ 3.4842e+00],\n",
      "        [ 8.1261e+00],\n",
      "        [ 9.2970e-01],\n",
      "        [ 3.5752e+00],\n",
      "        [ 4.2417e+00],\n",
      "        [ 8.9170e-01],\n",
      "        [ 8.4193e+00],\n",
      "        [-4.5199e-03],\n",
      "        [ 5.6023e+00],\n",
      "        [ 1.2315e+01],\n",
      "        [ 2.3570e+00],\n",
      "        [ 1.2154e+01],\n",
      "        [ 3.9858e+00],\n",
      "        [ 5.1776e+00],\n",
      "        [ 3.1077e+00],\n",
      "        [ 3.5954e+00],\n",
      "        [-3.6380e+00],\n",
      "        [ 7.1770e-01],\n",
      "        [ 8.6094e+00],\n",
      "        [ 4.0799e+00],\n",
      "        [ 1.7574e+01],\n",
      "        [-3.0423e+00],\n",
      "        [ 5.5335e-01],\n",
      "        [-4.8714e-01],\n",
      "        [ 7.7125e+00],\n",
      "        [ 5.9498e-01],\n",
      "        [ 7.0765e+00],\n",
      "        [ 3.6407e+00],\n",
      "        [ 1.2250e+01],\n",
      "        [ 1.0235e+01],\n",
      "        [ 1.2245e+01],\n",
      "        [ 1.8283e+00],\n",
      "        [ 6.3420e+00],\n",
      "        [ 7.0388e+00],\n",
      "        [ 1.5572e+00],\n",
      "        [-5.8698e-01],\n",
      "        [ 1.2146e+01],\n",
      "        [ 4.7015e-01],\n",
      "        [ 2.7409e+00],\n",
      "        [ 5.0619e+00],\n",
      "        [ 6.5615e+00],\n",
      "        [ 6.3259e+00],\n",
      "        [ 6.6283e+00],\n",
      "        [ 3.6611e+00],\n",
      "        [ 8.8681e+00],\n",
      "        [ 7.3860e+00],\n",
      "        [ 4.5187e+00],\n",
      "        [ 1.2152e+00],\n",
      "        [ 7.1408e+00],\n",
      "        [ 2.1815e+00],\n",
      "        [ 1.0955e+01],\n",
      "        [-1.2784e+00],\n",
      "        [ 6.1595e+00],\n",
      "        [ 1.3116e+01],\n",
      "        [ 2.9232e+00],\n",
      "        [ 3.9532e+00],\n",
      "        [-1.9158e+00],\n",
      "        [ 2.5494e+00],\n",
      "        [ 3.4817e+00],\n",
      "        [ 7.7235e+00],\n",
      "        [ 8.4925e+00],\n",
      "        [ 9.6587e+00],\n",
      "        [ 1.0896e+01],\n",
      "        [ 4.1370e+00],\n",
      "        [ 6.5969e+00],\n",
      "        [ 7.3009e+00],\n",
      "        [ 4.7349e+00],\n",
      "        [ 3.1385e+00],\n",
      "        [ 9.2107e+00],\n",
      "        [ 8.0309e+00],\n",
      "        [ 5.8231e+00],\n",
      "        [ 5.1208e+00],\n",
      "        [ 5.3621e+00],\n",
      "        [ 1.5460e+00],\n",
      "        [ 2.8195e+00],\n",
      "        [ 7.3234e+00],\n",
      "        [ 9.0050e+00],\n",
      "        [ 1.4350e+01],\n",
      "        [ 5.8654e+00],\n",
      "        [ 1.0947e+01],\n",
      "        [-7.1226e-01],\n",
      "        [ 1.2717e+01],\n",
      "        [ 5.5871e+00],\n",
      "        [ 6.9359e+00],\n",
      "        [ 9.9747e+00],\n",
      "        [ 1.8246e+00],\n",
      "        [ 2.1162e+01],\n",
      "        [ 2.8476e+00],\n",
      "        [ 1.0704e+01],\n",
      "        [ 9.1045e+00],\n",
      "        [ 2.1505e+01],\n",
      "        [ 6.5614e+00],\n",
      "        [ 1.0253e+01],\n",
      "        [ 5.7544e+00],\n",
      "        [ 9.3660e+00],\n",
      "        [-4.9594e-01],\n",
      "        [ 4.9539e+00],\n",
      "        [ 6.7487e+00],\n",
      "        [ 1.2813e+00],\n",
      "        [ 1.4569e+01],\n",
      "        [-6.7380e-02],\n",
      "        [ 8.0433e+00],\n",
      "        [-9.7023e-01],\n",
      "        [ 5.3429e+00],\n",
      "        [ 1.5238e+01],\n",
      "        [ 6.4842e+00],\n",
      "        [ 1.0839e+01],\n",
      "        [ 1.6513e+00],\n",
      "        [ 1.0555e+01],\n",
      "        [ 5.9796e+00],\n",
      "        [ 1.1449e+01],\n",
      "        [ 6.3749e+00],\n",
      "        [ 6.1703e+00],\n",
      "        [ 1.2561e+01],\n",
      "        [-2.7884e-01],\n",
      "        [ 5.2139e+00],\n",
      "        [ 7.0499e+00],\n",
      "        [ 2.0707e+00],\n",
      "        [ 2.8875e+00],\n",
      "        [ 3.6258e+00],\n",
      "        [ 1.1462e+01],\n",
      "        [ 5.7005e+00],\n",
      "        [ 4.8887e+00],\n",
      "        [ 1.8726e+00],\n",
      "        [ 6.0535e-01],\n",
      "        [ 3.3739e+00],\n",
      "        [ 8.5555e-01],\n",
      "        [ 1.4914e+01],\n",
      "        [ 5.9117e+00],\n",
      "        [ 4.0841e+00],\n",
      "        [ 1.0936e+01],\n",
      "        [ 7.1030e+00],\n",
      "        [ 5.8768e+00],\n",
      "        [ 7.9916e+00],\n",
      "        [ 4.0357e+00],\n",
      "        [-1.2142e+00],\n",
      "        [ 8.2543e+00],\n",
      "        [ 7.6249e+00],\n",
      "        [ 6.2731e+00],\n",
      "        [ 9.8228e+00],\n",
      "        [ 2.9536e+00],\n",
      "        [ 8.5233e+00],\n",
      "        [ 8.9843e+00],\n",
      "        [ 4.5665e+00],\n",
      "        [ 7.5402e+00],\n",
      "        [ 4.2351e+00],\n",
      "        [ 1.1362e+01],\n",
      "        [ 8.0064e+00],\n",
      "        [ 1.9262e+01],\n",
      "        [ 7.0138e-01],\n",
      "        [ 4.2904e+00],\n",
      "        [ 2.1449e+00],\n",
      "        [ 8.1657e+00],\n",
      "        [-1.6430e+00],\n",
      "        [ 3.5203e+00],\n",
      "        [ 2.9023e+00],\n",
      "        [ 3.7905e+00],\n",
      "        [ 9.6683e+00],\n",
      "        [ 1.2241e+01],\n",
      "        [ 6.4395e+00],\n",
      "        [ 1.2723e+01],\n",
      "        [ 1.6794e+01],\n",
      "        [ 3.6708e+00],\n",
      "        [ 1.6736e+00],\n",
      "        [ 2.7568e+00],\n",
      "        [ 6.0853e+00],\n",
      "        [-5.1091e-01],\n",
      "        [ 3.1901e+00],\n",
      "        [ 3.0070e+00],\n",
      "        [ 5.8462e+00],\n",
      "        [ 7.3434e+00],\n",
      "        [ 9.5127e+00],\n",
      "        [ 3.7610e+00],\n",
      "        [ 1.0223e+01],\n",
      "        [ 5.6636e+00],\n",
      "        [ 5.7378e-01],\n",
      "        [ 1.5675e+01]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "step = 27000, num_env_steps = 27000, scores = 824.189 (n=1), actor_loss = -29.016, critic_loss = 1.922, entropy_coef_loss = -0.962, entropy_coef = 0.013, action_stds = 0.453 ± 0.074, action_magnitude = 0.703 ± 0.296, num_gradient_steps = 17000, step_time = 7.31, total_time = 124.13\n",
      "\n",
      "\n",
      "self.log_ent_coef = tensor([-4.3560], device='cuda:0', requires_grad=True)\n",
      "actions_pi_log_prob = tensor([[-5.4710],\n",
      "        [-2.9612],\n",
      "        [ 2.5516],\n",
      "        [11.5426],\n",
      "        [11.7757],\n",
      "        [11.9452],\n",
      "        [ 5.5269],\n",
      "        [ 6.1256],\n",
      "        [ 3.5623],\n",
      "        [ 3.0936],\n",
      "        [ 1.2483],\n",
      "        [18.7100],\n",
      "        [19.1950],\n",
      "        [ 1.2244],\n",
      "        [13.9842],\n",
      "        [10.3623],\n",
      "        [ 0.4810],\n",
      "        [ 7.0737],\n",
      "        [ 5.6013],\n",
      "        [ 0.7515],\n",
      "        [ 8.2889],\n",
      "        [ 9.7035],\n",
      "        [ 1.7413],\n",
      "        [ 0.5191],\n",
      "        [ 6.0171],\n",
      "        [ 7.6413],\n",
      "        [13.3049],\n",
      "        [ 2.8459],\n",
      "        [ 2.5358],\n",
      "        [ 4.3879],\n",
      "        [23.5061],\n",
      "        [11.4393],\n",
      "        [-0.5355],\n",
      "        [10.1130],\n",
      "        [-0.1090],\n",
      "        [ 4.9612],\n",
      "        [ 8.1614],\n",
      "        [ 4.8624],\n",
      "        [ 8.3779],\n",
      "        [10.8113],\n",
      "        [14.1728],\n",
      "        [ 3.7681],\n",
      "        [ 7.2517],\n",
      "        [ 4.3642],\n",
      "        [ 8.8692],\n",
      "        [18.4470],\n",
      "        [ 6.9538],\n",
      "        [ 7.0171],\n",
      "        [22.4189],\n",
      "        [ 3.0604],\n",
      "        [ 1.1716],\n",
      "        [ 2.8322],\n",
      "        [18.1278],\n",
      "        [-1.1336],\n",
      "        [ 4.5246],\n",
      "        [10.5270],\n",
      "        [ 5.9905],\n",
      "        [ 5.3927],\n",
      "        [ 2.0634],\n",
      "        [ 3.2014],\n",
      "        [ 1.8015],\n",
      "        [ 8.6157],\n",
      "        [ 8.6638],\n",
      "        [ 8.1933],\n",
      "        [ 2.8450],\n",
      "        [ 2.7649],\n",
      "        [23.5865],\n",
      "        [-1.7477],\n",
      "        [ 5.9044],\n",
      "        [ 3.9898],\n",
      "        [-0.2492],\n",
      "        [16.2266],\n",
      "        [-1.3613],\n",
      "        [-0.3884],\n",
      "        [ 9.4994],\n",
      "        [ 4.8723],\n",
      "        [ 1.8014],\n",
      "        [ 5.2832],\n",
      "        [ 9.2502],\n",
      "        [11.2688],\n",
      "        [ 3.1773],\n",
      "        [ 8.8233],\n",
      "        [-0.2336],\n",
      "        [21.7603],\n",
      "        [ 5.3935],\n",
      "        [ 9.4080],\n",
      "        [ 4.7106],\n",
      "        [ 9.5864],\n",
      "        [10.8684],\n",
      "        [ 9.3484],\n",
      "        [ 4.8391],\n",
      "        [15.2795],\n",
      "        [-0.6981],\n",
      "        [ 3.0732],\n",
      "        [11.9267],\n",
      "        [11.7716],\n",
      "        [17.6232],\n",
      "        [ 3.1759],\n",
      "        [ 6.1557],\n",
      "        [ 5.5532],\n",
      "        [ 3.0582],\n",
      "        [ 8.1734],\n",
      "        [ 3.1397],\n",
      "        [ 7.9161],\n",
      "        [14.6703],\n",
      "        [14.5682],\n",
      "        [11.7705],\n",
      "        [ 4.4244],\n",
      "        [-0.4522],\n",
      "        [ 9.7177],\n",
      "        [ 3.5291],\n",
      "        [ 9.8383],\n",
      "        [ 2.7567],\n",
      "        [ 2.0979],\n",
      "        [-0.8858],\n",
      "        [ 1.5416],\n",
      "        [11.9030],\n",
      "        [ 7.9275],\n",
      "        [ 1.1284],\n",
      "        [ 1.1237],\n",
      "        [ 0.9984],\n",
      "        [ 9.8482],\n",
      "        [ 6.0344],\n",
      "        [-0.5988],\n",
      "        [ 2.3162],\n",
      "        [ 4.2666],\n",
      "        [ 3.2982],\n",
      "        [-1.5423],\n",
      "        [10.0874],\n",
      "        [ 9.9146],\n",
      "        [ 3.9080],\n",
      "        [15.3370],\n",
      "        [ 0.8609],\n",
      "        [ 5.5640],\n",
      "        [ 6.1712],\n",
      "        [ 3.9748],\n",
      "        [ 8.0879],\n",
      "        [ 0.9591],\n",
      "        [15.0208],\n",
      "        [ 7.9275],\n",
      "        [ 1.1905],\n",
      "        [18.8602],\n",
      "        [ 8.0555],\n",
      "        [17.0004],\n",
      "        [ 5.9678],\n",
      "        [-2.3084],\n",
      "        [20.9101],\n",
      "        [ 1.1760],\n",
      "        [ 2.7047],\n",
      "        [ 3.1164],\n",
      "        [10.0484],\n",
      "        [13.7507],\n",
      "        [13.0353],\n",
      "        [17.3031],\n",
      "        [ 8.6744],\n",
      "        [16.5683],\n",
      "        [ 3.9264],\n",
      "        [ 3.0993],\n",
      "        [16.7036],\n",
      "        [ 3.7694],\n",
      "        [ 7.5148],\n",
      "        [ 8.3440],\n",
      "        [16.1987],\n",
      "        [ 2.4942],\n",
      "        [11.9664],\n",
      "        [ 8.3656],\n",
      "        [ 7.9914],\n",
      "        [ 0.9086],\n",
      "        [14.5497],\n",
      "        [15.2489],\n",
      "        [11.1972],\n",
      "        [ 2.0499],\n",
      "        [ 3.2215],\n",
      "        [11.3452],\n",
      "        [-0.3032],\n",
      "        [ 4.4776],\n",
      "        [ 1.1416],\n",
      "        [11.4069],\n",
      "        [ 2.8985],\n",
      "        [ 1.4567],\n",
      "        [ 2.1225],\n",
      "        [ 0.7989],\n",
      "        [ 6.2020],\n",
      "        [ 1.8743],\n",
      "        [11.5987],\n",
      "        [ 8.4781],\n",
      "        [29.4595],\n",
      "        [10.0502],\n",
      "        [13.5316],\n",
      "        [ 1.4440],\n",
      "        [ 9.1065],\n",
      "        [ 8.6606],\n",
      "        [ 7.4411],\n",
      "        [ 7.4887],\n",
      "        [-0.1484],\n",
      "        [10.4395],\n",
      "        [25.2542],\n",
      "        [-0.1179],\n",
      "        [ 7.9641],\n",
      "        [12.4469],\n",
      "        [ 6.7990],\n",
      "        [14.8351],\n",
      "        [ 0.8692],\n",
      "        [ 7.1279],\n",
      "        [ 1.7382],\n",
      "        [ 6.6223],\n",
      "        [-0.5025],\n",
      "        [ 4.3844],\n",
      "        [ 2.4423],\n",
      "        [ 8.0394],\n",
      "        [ 7.5148],\n",
      "        [ 4.7550],\n",
      "        [ 1.2136],\n",
      "        [ 9.2321],\n",
      "        [ 5.9744],\n",
      "        [ 6.7131],\n",
      "        [ 5.0200],\n",
      "        [ 3.0794],\n",
      "        [ 9.7216],\n",
      "        [12.1526],\n",
      "        [11.0177],\n",
      "        [ 2.7719],\n",
      "        [ 6.6380],\n",
      "        [ 5.5660],\n",
      "        [12.0040],\n",
      "        [ 2.8790],\n",
      "        [-0.0467],\n",
      "        [ 4.4670],\n",
      "        [ 9.5404],\n",
      "        [ 4.0863],\n",
      "        [12.4040],\n",
      "        [25.1918],\n",
      "        [-0.4291],\n",
      "        [ 6.2331],\n",
      "        [ 4.3943],\n",
      "        [13.2214],\n",
      "        [-1.4551],\n",
      "        [ 2.8400],\n",
      "        [ 8.6640],\n",
      "        [ 5.0275],\n",
      "        [ 0.8688],\n",
      "        [ 4.6314],\n",
      "        [12.7453],\n",
      "        [ 7.9642],\n",
      "        [15.6465],\n",
      "        [ 8.1328],\n",
      "        [ 9.1256],\n",
      "        [13.9526],\n",
      "        [-1.6375],\n",
      "        [ 3.5753],\n",
      "        [10.2300],\n",
      "        [ 0.2834],\n",
      "        [ 9.9860],\n",
      "        [15.1831],\n",
      "        [ 1.6703],\n",
      "        [ 3.9397]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "step = 28000, num_env_steps = 28000, scores = 1185.291 (n=1), actor_loss = -29.969, critic_loss = 2.351, entropy_coef_loss = 4.421, entropy_coef = 0.013, action_stds = 0.395 ± 0.115, action_magnitude = 0.775 ± 0.282, num_gradient_steps = 18000, step_time = 7.01, total_time = 131.14\n",
      "\n",
      "\n",
      "self.log_ent_coef = tensor([-4.2688], device='cuda:0', requires_grad=True)\n",
      "actions_pi_log_prob = tensor([[ 3.4979e+00],\n",
      "        [ 1.1909e+01],\n",
      "        [ 8.6572e+00],\n",
      "        [ 1.2151e+01],\n",
      "        [ 8.2203e+00],\n",
      "        [ 1.2132e+01],\n",
      "        [ 4.1503e+00],\n",
      "        [ 1.2877e+01],\n",
      "        [ 1.1999e+01],\n",
      "        [ 9.2184e+00],\n",
      "        [ 2.2412e-02],\n",
      "        [ 5.0852e+00],\n",
      "        [ 1.4958e+00],\n",
      "        [ 5.5630e+00],\n",
      "        [ 4.8572e+00],\n",
      "        [ 8.8722e+00],\n",
      "        [-1.0801e+00],\n",
      "        [ 9.9504e+00],\n",
      "        [ 3.3250e+00],\n",
      "        [-2.5898e-01],\n",
      "        [ 1.5453e+01],\n",
      "        [ 5.0899e+00],\n",
      "        [ 4.7198e+00],\n",
      "        [ 3.6949e+00],\n",
      "        [ 8.9324e+00],\n",
      "        [-5.5431e+00],\n",
      "        [ 1.2959e+00],\n",
      "        [ 4.8301e+00],\n",
      "        [ 6.0500e+00],\n",
      "        [ 1.1873e+00],\n",
      "        [ 1.8400e+00],\n",
      "        [ 9.1207e+00],\n",
      "        [-3.0503e+00],\n",
      "        [ 1.8810e+00],\n",
      "        [-1.1707e+00],\n",
      "        [ 2.6715e+00],\n",
      "        [ 6.6183e+00],\n",
      "        [ 2.9789e+00],\n",
      "        [ 7.7412e+00],\n",
      "        [-2.2344e+00],\n",
      "        [ 5.5425e+00],\n",
      "        [ 1.1710e+01],\n",
      "        [ 5.2578e+00],\n",
      "        [ 8.5405e+00],\n",
      "        [ 7.5968e+00],\n",
      "        [ 7.1368e+00],\n",
      "        [ 3.9595e+00],\n",
      "        [ 1.2929e-01],\n",
      "        [ 4.5796e+00],\n",
      "        [ 1.0281e+01],\n",
      "        [ 8.6395e-01],\n",
      "        [ 3.5376e+00],\n",
      "        [ 3.2174e+00],\n",
      "        [ 1.6802e+00],\n",
      "        [ 1.5689e+01],\n",
      "        [ 2.5221e+00],\n",
      "        [ 5.1596e+00],\n",
      "        [ 7.5765e+00],\n",
      "        [ 1.2751e+01],\n",
      "        [ 4.4953e+00],\n",
      "        [ 4.9595e+00],\n",
      "        [ 2.0466e+00],\n",
      "        [ 6.2075e+00],\n",
      "        [ 1.1237e+01],\n",
      "        [-1.4865e-01],\n",
      "        [ 8.7564e+00],\n",
      "        [ 3.9127e+00],\n",
      "        [ 1.6222e+00],\n",
      "        [ 1.4837e+01],\n",
      "        [ 1.1751e+00],\n",
      "        [ 4.1820e+00],\n",
      "        [ 4.6772e+00],\n",
      "        [ 7.8030e+00],\n",
      "        [ 8.6295e+00],\n",
      "        [ 2.1694e+00],\n",
      "        [-2.3050e-01],\n",
      "        [ 4.2971e-01],\n",
      "        [ 2.7629e+00],\n",
      "        [ 4.7328e+00],\n",
      "        [ 2.4645e+00],\n",
      "        [ 2.1880e+01],\n",
      "        [ 4.8137e+00],\n",
      "        [ 1.9689e+01],\n",
      "        [ 1.3076e+00],\n",
      "        [ 2.6809e+00],\n",
      "        [ 2.0824e+00],\n",
      "        [ 3.6447e+00],\n",
      "        [ 2.5298e+00],\n",
      "        [ 1.6129e+00],\n",
      "        [ 5.9764e+00],\n",
      "        [ 1.8679e+00],\n",
      "        [ 7.7572e+00],\n",
      "        [ 2.8648e+00],\n",
      "        [ 2.2497e+00],\n",
      "        [ 8.8349e+00],\n",
      "        [ 1.9799e+00],\n",
      "        [ 4.4307e+00],\n",
      "        [ 2.8371e+00],\n",
      "        [ 8.2216e+00],\n",
      "        [-8.6908e-01],\n",
      "        [ 2.7830e+01],\n",
      "        [ 9.9083e+00],\n",
      "        [ 3.2888e+00],\n",
      "        [ 5.1675e+00],\n",
      "        [ 3.2942e+00],\n",
      "        [ 5.7866e+00],\n",
      "        [ 1.3165e+01],\n",
      "        [ 2.5159e+00],\n",
      "        [ 3.0576e+00],\n",
      "        [ 2.7406e+01],\n",
      "        [ 2.1205e+00],\n",
      "        [ 1.0012e+01],\n",
      "        [ 4.1430e+00],\n",
      "        [ 1.4137e+00],\n",
      "        [ 1.9709e+00],\n",
      "        [ 7.3093e+00],\n",
      "        [ 1.6253e+01],\n",
      "        [ 5.5096e+00],\n",
      "        [ 1.3762e+01],\n",
      "        [-1.3545e+00],\n",
      "        [ 9.1391e+00],\n",
      "        [ 2.8415e+00],\n",
      "        [ 6.0762e+00],\n",
      "        [ 1.7776e+00],\n",
      "        [ 6.7628e-01],\n",
      "        [ 1.3447e-02],\n",
      "        [ 5.0582e+00],\n",
      "        [ 5.7639e+00],\n",
      "        [ 5.2060e+00],\n",
      "        [ 1.1076e+01],\n",
      "        [ 9.4006e+00],\n",
      "        [ 1.0456e+01],\n",
      "        [ 7.4991e+00],\n",
      "        [ 6.8105e+00],\n",
      "        [ 1.7034e+00],\n",
      "        [-2.3161e+00],\n",
      "        [ 8.3730e+00],\n",
      "        [ 8.6684e+00],\n",
      "        [ 8.1975e+00],\n",
      "        [-6.1186e-01],\n",
      "        [ 4.4730e+00],\n",
      "        [ 5.4438e+00],\n",
      "        [ 3.8543e-01],\n",
      "        [-4.4927e-01],\n",
      "        [ 6.1660e+00],\n",
      "        [ 2.6237e+00],\n",
      "        [ 1.6069e+01],\n",
      "        [-1.4315e+00],\n",
      "        [ 7.7810e+00],\n",
      "        [ 9.7451e-01],\n",
      "        [ 3.9732e+00],\n",
      "        [ 4.2463e+00],\n",
      "        [ 1.6753e+00],\n",
      "        [ 4.0904e+00],\n",
      "        [-1.7897e+00],\n",
      "        [ 2.8158e+00],\n",
      "        [ 5.7778e+00],\n",
      "        [ 5.5099e-01],\n",
      "        [ 6.2429e+00],\n",
      "        [ 7.9808e+00],\n",
      "        [ 5.8317e+00],\n",
      "        [ 3.5340e+00],\n",
      "        [ 3.8553e+00],\n",
      "        [ 1.4713e+01],\n",
      "        [ 1.5360e+01],\n",
      "        [ 1.0197e+00],\n",
      "        [ 3.9014e+00],\n",
      "        [ 1.0179e+01],\n",
      "        [ 3.0037e+00],\n",
      "        [ 1.2838e+01],\n",
      "        [ 1.7420e+01],\n",
      "        [ 1.6707e+01],\n",
      "        [ 9.4073e+00],\n",
      "        [ 1.6296e+00],\n",
      "        [ 7.4929e+00],\n",
      "        [ 1.2415e+01],\n",
      "        [-1.3093e+00],\n",
      "        [ 7.5336e+00],\n",
      "        [ 7.7760e+00],\n",
      "        [ 9.7698e-01],\n",
      "        [ 1.3112e+01],\n",
      "        [ 8.9200e+00],\n",
      "        [ 9.2211e+00],\n",
      "        [-3.1437e-01],\n",
      "        [ 4.5649e-01],\n",
      "        [ 1.0674e+01],\n",
      "        [ 4.6998e+00],\n",
      "        [ 4.4054e+00],\n",
      "        [ 4.6114e+00],\n",
      "        [ 1.4783e+01],\n",
      "        [ 1.6060e+01],\n",
      "        [-2.4517e-01],\n",
      "        [ 3.0696e+00],\n",
      "        [ 5.3959e+00],\n",
      "        [ 1.8515e+01],\n",
      "        [ 2.9064e+00],\n",
      "        [ 6.3644e+00],\n",
      "        [-3.3570e+00],\n",
      "        [ 7.9405e+00],\n",
      "        [ 1.4198e+00],\n",
      "        [ 4.5385e+00],\n",
      "        [ 7.6998e+00],\n",
      "        [ 4.6653e+00],\n",
      "        [ 1.0637e+01],\n",
      "        [ 8.5854e+00],\n",
      "        [ 1.7713e+01],\n",
      "        [ 1.7516e+00],\n",
      "        [ 3.2830e+00],\n",
      "        [ 2.1561e+01],\n",
      "        [ 2.6272e+00],\n",
      "        [ 7.6760e+00],\n",
      "        [ 2.8352e+00],\n",
      "        [ 4.3154e+00],\n",
      "        [ 5.9565e+00],\n",
      "        [ 5.1276e+00],\n",
      "        [ 4.8965e+00],\n",
      "        [ 7.9497e+00],\n",
      "        [ 2.7523e+00],\n",
      "        [ 2.0578e+01],\n",
      "        [ 2.8140e+00],\n",
      "        [ 2.0788e+01],\n",
      "        [ 6.7857e+00],\n",
      "        [ 6.6087e+00],\n",
      "        [-1.2228e+00],\n",
      "        [ 2.5926e-01],\n",
      "        [-1.2479e+00],\n",
      "        [ 4.6312e+00],\n",
      "        [ 6.5625e+00],\n",
      "        [ 4.4188e+00],\n",
      "        [ 5.7996e+00],\n",
      "        [ 1.2181e+00],\n",
      "        [ 4.1269e+01],\n",
      "        [ 7.0020e+00],\n",
      "        [ 7.0266e+00],\n",
      "        [-1.9893e-01],\n",
      "        [ 1.7708e+01],\n",
      "        [ 5.4896e+00],\n",
      "        [ 2.5865e+00],\n",
      "        [ 7.8807e+00],\n",
      "        [ 1.9836e+00],\n",
      "        [ 1.3073e+01],\n",
      "        [ 1.2940e+00],\n",
      "        [ 4.6942e+00],\n",
      "        [ 5.9623e+00],\n",
      "        [ 6.3974e+00],\n",
      "        [ 1.5304e+00],\n",
      "        [ 1.6992e+01],\n",
      "        [ 3.3146e+00],\n",
      "        [ 3.0411e+00],\n",
      "        [ 3.3410e+00],\n",
      "        [ 4.0477e+00],\n",
      "        [ 8.4944e+00],\n",
      "        [ 5.4692e+00],\n",
      "        [-2.2515e+00],\n",
      "        [ 2.8592e+00],\n",
      "        [ 9.8463e+00]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "step = 29000, num_env_steps = 29000, scores = 259.968 (n=1), actor_loss = -28.534, critic_loss = 2.320, entropy_coef_loss = -0.002, entropy_coef = 0.014, action_stds = 0.455 ± 0.095, action_magnitude = 0.696 ± 0.299, num_gradient_steps = 19000, step_time = 7.16, total_time = 138.30\n",
      "\n",
      "\n",
      "saved experiment log 2024-10-21_09-39-59_555014~4J6lFW at experiment_logs/HalfCheetah-v4/sac/2024-10-21_09-39-59_555014~4J6lFW.json\n",
      "keyboard interrupt\n",
      "closing envs\n",
      "envs closed\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[2], line 189\u001B[0m\n\u001B[0;32m    187\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyboardInterrupt\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m ki:\n\u001B[0;32m    188\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mkeyboard interrupt\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m--> 189\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m ki\n\u001B[0;32m    190\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m    191\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mclosing envs\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "Cell \u001B[1;32mIn[2], line 184\u001B[0m\n\u001B[0;32m    180\u001B[0m             \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mStarting Training\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m    181\u001B[0m             \u001B[38;5;66;03m# import cProfile\u001B[39;00m\n\u001B[0;32m    182\u001B[0m             \u001B[38;5;66;03m# pr = cProfile.Profile()\u001B[39;00m\n\u001B[0;32m    183\u001B[0m             \u001B[38;5;66;03m# pr.enable()\u001B[39;00m\n\u001B[1;32m--> 184\u001B[0m             \u001B[43malgo\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlearn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m5_000_000\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m    185\u001B[0m             \u001B[38;5;66;03m# pr.disable()  \u001B[39;00m\n\u001B[0;32m    186\u001B[0m             \u001B[38;5;66;03m# pr.dump_stats('profile_stats.pstat')\u001B[39;00m\n\u001B[0;32m    187\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyboardInterrupt\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m ki:\n",
      "File \u001B[1;32m~\\git\\pytorch-repository\\src\\reinforcement_learning\\algorithms\\base\\base_algorithm.py:141\u001B[0m, in \u001B[0;36mBaseAlgorithm.learn\u001B[1;34m(self, total_timesteps)\u001B[0m\n\u001B[0;32m    139\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpolicy\u001B[38;5;241m.\u001B[39mset_train_mode(\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[0;32m    140\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[1;32m--> 141\u001B[0m     obs, episode_starts \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mperform_rollout\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    142\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmax_steps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtotal_timesteps\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msteps_performed\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    143\u001B[0m \u001B[43m        \u001B[49m\u001B[43mobs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mobs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    144\u001B[0m \u001B[43m        \u001B[49m\u001B[43mepisode_starts\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mepisode_starts\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    145\u001B[0m \u001B[43m        \u001B[49m\u001B[43minfo\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minfo\u001B[49m\n\u001B[0;32m    146\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    147\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcallback\u001B[38;5;241m.\u001B[39mon_rollout_done(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msteps_performed, info)\n\u001B[0;32m    149\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_should_optimize():\n",
      "File \u001B[1;32m~\\git\\pytorch-repository\\src\\reinforcement_learning\\algorithms\\base\\off_policy_algorithm.py:154\u001B[0m, in \u001B[0;36mOffPolicyAlgorithm.perform_rollout\u001B[1;34m(self, max_steps, obs, episode_starts, info)\u001B[0m\n\u001B[0;32m    151\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msde_noise_sample_freq \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msteps_performed \u001B[38;5;241m%\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msde_noise_sample_freq \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m    152\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpolicy\u001B[38;5;241m.\u001B[39mreset_sde_noise(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_envs)\n\u001B[1;32m--> 154\u001B[0m obs, episode_starts, step_info \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrollout_step\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    155\u001B[0m rollout_infos\u001B[38;5;241m.\u001B[39mappend(step_info)\n\u001B[0;32m    157\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m np\u001B[38;5;241m.\u001B[39many(episode_starts) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39maction_noise \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[1;32m~\\git\\pytorch-repository\\src\\reinforcement_learning\\algorithms\\base\\off_policy_algorithm.py:106\u001B[0m, in \u001B[0;36mOffPolicyAlgorithm.rollout_step\u001B[1;34m(self, obs)\u001B[0m\n\u001B[0;32m    100\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mrollout_step\u001B[39m(\n\u001B[0;32m    101\u001B[0m         \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    102\u001B[0m         obs: np\u001B[38;5;241m.\u001B[39mndarray\n\u001B[0;32m    103\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28mtuple\u001B[39m[np\u001B[38;5;241m.\u001B[39mndarray, np\u001B[38;5;241m.\u001B[39mndarray, \u001B[38;5;28mdict\u001B[39m]:\n\u001B[0;32m    104\u001B[0m     info: InfoDict \u001B[38;5;241m=\u001B[39m {}\n\u001B[1;32m--> 106\u001B[0m     actions \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msample_actions\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minfo\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    108\u001B[0m     new_obs, rewards, terminated, truncated, step_info \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39menv\u001B[38;5;241m.\u001B[39mstep(actions)\n\u001B[0;32m    109\u001B[0m     info\u001B[38;5;241m.\u001B[39mupdate(step_info)\n",
      "File \u001B[1;32m~\\git\\pytorch-repository\\src\\reinforcement_learning\\algorithms\\base\\off_policy_algorithm.py:87\u001B[0m, in \u001B[0;36mOffPolicyAlgorithm.sample_actions\u001B[1;34m(self, obs, info)\u001B[0m\n\u001B[0;32m     85\u001B[0m     actions \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marray([\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39maction_space\u001B[38;5;241m.\u001B[39msample() \u001B[38;5;28;01mfor\u001B[39;00m _ \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_envs)])\n\u001B[0;32m     86\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m---> 87\u001B[0m     action_selector \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpolicy\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mact\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     88\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtensor\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtorch_device\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtorch_dtype\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     89\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     91\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstash_config\u001B[38;5;241m.\u001B[39mstash_rollout_action_stds:\n\u001B[0;32m     92\u001B[0m         info[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124maction_stds\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m action_selector\u001B[38;5;241m.\u001B[39mdistribution\u001B[38;5;241m.\u001B[39mstddev\n",
      "File \u001B[1;32m~\\git\\pytorch-repository\\src\\reinforcement_learning\\core\\policies\\base_policy.py:47\u001B[0m, in \u001B[0;36mBasePolicy.act\u001B[1;34m(self, obs)\u001B[0m\n\u001B[0;32m     45\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mact\u001B[39m(\u001B[38;5;28mself\u001B[39m, obs: TensorObs) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m ActionSelector:\n\u001B[0;32m     46\u001B[0m     obs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mshared_feature_extractor(obs)\n\u001B[1;32m---> 47\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mactor\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\git\\pytorch-repository\\src\\reinforcement_learning\\core\\policies\\components\\actor.py:43\u001B[0m, in \u001B[0;36mActor.forward\u001B[1;34m(self, obs)\u001B[0m\n\u001B[0;32m     41\u001B[0m obs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfeature_extractor(obs)\n\u001B[0;32m     42\u001B[0m latent_pi \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnetwork(obs)\n\u001B[1;32m---> 43\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_action_selector\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mupdate_latent_features\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlatent_pi\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\git\\pytorch-repository\\src\\reinforcement_learning\\core\\action_selectors\\predicted_std_action_selector.py:70\u001B[0m, in \u001B[0;36mPredictedStdActionSelector.update_latent_features\u001B[1;34m(self, latent_pi)\u001B[0m\n\u001B[0;32m     68\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbase_log_std \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m     69\u001B[0m     log_stds \u001B[38;5;241m=\u001B[39m log_stds \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbase_log_std\n\u001B[1;32m---> 70\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mupdate_distribution_params\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmean_actions\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlog_stds\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\git\\pytorch-repository\\src\\reinforcement_learning\\core\\action_selectors\\predicted_std_action_selector.py:78\u001B[0m, in \u001B[0;36mPredictedStdActionSelector.update_distribution_params\u001B[1;34m(self, mean_actions, log_stds)\u001B[0m\n\u001B[0;32m     72\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mupdate_distribution_params\u001B[39m(\n\u001B[0;32m     73\u001B[0m         \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m     74\u001B[0m         mean_actions: torch\u001B[38;5;241m.\u001B[39mTensor,\n\u001B[0;32m     75\u001B[0m         log_stds: torch\u001B[38;5;241m.\u001B[39mTensor,\n\u001B[0;32m     76\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Self:\n\u001B[0;32m     77\u001B[0m     log_stds \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mclamp(log_stds, \u001B[38;5;241m*\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlog_std_clamp_range)\n\u001B[1;32m---> 78\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdistribution \u001B[38;5;241m=\u001B[39m \u001B[43mtorchdist\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mNormal\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmean_actions\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlog_stds\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexp\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     79\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\distributions\\normal.py:56\u001B[0m, in \u001B[0;36mNormal.__init__\u001B[1;34m(self, loc, scale, validate_args)\u001B[0m\n\u001B[0;32m     54\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     55\u001B[0m     batch_shape \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mloc\u001B[38;5;241m.\u001B[39msize()\n\u001B[1;32m---> 56\u001B[0m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__init__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mbatch_shape\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalidate_args\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvalidate_args\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\distributions\\distribution.py:67\u001B[0m, in \u001B[0;36mDistribution.__init__\u001B[1;34m(self, batch_shape, event_shape, validate_args)\u001B[0m\n\u001B[0;32m     65\u001B[0m         value \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(\u001B[38;5;28mself\u001B[39m, param)\n\u001B[0;32m     66\u001B[0m         valid \u001B[38;5;241m=\u001B[39m constraint\u001B[38;5;241m.\u001B[39mcheck(value)\n\u001B[1;32m---> 67\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m valid\u001B[38;5;241m.\u001B[39mall():\n\u001B[0;32m     68\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m     69\u001B[0m                 \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mExpected parameter \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mparam\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     70\u001B[0m                 \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m(\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mtype\u001B[39m(value)\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m of shape \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mtuple\u001B[39m(value\u001B[38;5;241m.\u001B[39mshape)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m) \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     73\u001B[0m                 \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbut found invalid values:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00mvalue\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     74\u001B[0m             )\n\u001B[0;32m     75\u001B[0m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m()\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "'2024-11-02 23:58:50.056338'"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.datetime import get_current_timestamp\n",
    "\n",
    "get_current_timestamp()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-02T23:58:50.060395Z",
     "start_time": "2024-11-02T23:58:50.053344Z"
    }
   },
   "id": "402361ca8aebbba1",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "source": [
    "from src.reinforcement_learning.core.buffers.replay.ring_with_reservoir_replay_buffer import \\\n",
    "    RingWithReservoirReplayBuffer\n",
    "from src.reinforcement_learning.core.buffers.replay.reservoir_replay_buffer import ReservoirReplayBuffer\n",
    "from src.reinforcement_learning.core.buffers.replay.ring_replay_buffer import RingReplayBuffer\n",
    "from src.reinforcement_learning.gym.singleton_vector_env import SingletonVectorEnv\n",
    "from src.reinforcement_learning.gym.envs.test_env import TestEnv\n",
    "\n",
    "env_name = 'HalfCheetah-v4'\n",
    "# env_kwargs = {'forward_reward_weight': 1.25, 'healthy_reward': 0.5, 'ctrl_cost_weight': 0.001 }\n",
    "env_kwargs = {}\n",
    "num_envs = 1\n",
    "\n",
    "device = torch.device(\"cuda:0\") if False else torch.device('cpu')\n",
    "env = SingletonVectorEnv(TestEnv(3))\n",
    "obs, info = env.reset()\n",
    "\n",
    "rep: RingReplayBuffer = RingReplayBuffer.for_env(\n",
    "    env,\n",
    "    buffer_size=20_000,\n",
    "    reward_scale=10,\n",
    "    torch_device=device\n",
    ")\n",
    "res = RingWithReservoirReplayBuffer.for_env(\n",
    "    env,\n",
    "    buffer_size=20_000,\n",
    "    reward_scale=10,\n",
    "    torch_device=device\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "for i in tqdm.tqdm(range(1, 1_000_000)):    \n",
    "    next_obs, rew, term, trunc, info = env.step(np.array([[i, i*10]]))\n",
    "    \n",
    "    rep.add(\n",
    "        observations=obs,\n",
    "        next_observations=next_obs,\n",
    "        actions=np.array([[i, i*10]]),\n",
    "        rewards=rew,\n",
    "        terminated=term,\n",
    "        truncated=trunc,\n",
    "    )\n",
    "    res.add(\n",
    "        observations=obs,\n",
    "        next_observations=next_obs,\n",
    "        actions=np.array([[i, i*10]]),\n",
    "        rewards=rew,\n",
    "        terminated=term,\n",
    "        truncated=trunc,\n",
    "    )\n",
    "    obs = next_obs\n",
    "    \n",
    "    rep_sample = rep.sample(256)\n",
    "    res_sample = res.sample(256)\n",
    "    \n",
    "    # print(i)\n",
    "    # print(rep_sample.observations, res_sample.observations)\n",
    "    # print(res.observations[:10], rep.observations[:10])\n",
    "    \n",
    "    # assert np.all(rep_sample.observations.cpu().numpy() == res_sample.observations.cpu().numpy())\n",
    "    # assert np.all(rep_sample.next_observations.cpu().numpy() == res_sample.next_observations.cpu().numpy())\n",
    "    # assert np.all(rep_sample.actions.cpu().numpy() == res_sample.actions.cpu().numpy())\n",
    "    # assert np.all(rep_sample.rewards.cpu().numpy() == res_sample.rewards.cpu().numpy())\n",
    "    # assert np.all(rep_sample.dones.cpu().numpy() == res_sample.dones.cpu().numpy())\n",
    "    \n",
    "    assert rep_sample.observations.cpu().numpy().shape == res_sample.observations.cpu().numpy().shape\n",
    "    assert rep_sample.next_observations.cpu().numpy().shape == res_sample.next_observations.cpu().numpy().shape\n",
    "    assert rep_sample.actions.cpu().numpy().shape == res_sample.actions.cpu().numpy().shape\n",
    "    assert rep_sample.rewards.cpu().numpy().shape == res_sample.rewards.cpu().numpy().shape\n",
    "    assert rep_sample.dones.cpu().numpy().shape == res_sample.dones.cpu().numpy().shape\n",
    "    \n",
    "    \n",
    "    assert np.all(rep.observations.squeeze() == res.observations.squeeze())\n",
    "    assert np.all(rep.next_observations.squeeze() == res.next_observations.squeeze())\n",
    "    assert np.all(rep.actions.squeeze() == res.actions.squeeze())\n",
    "    assert np.all(rep.rewards.squeeze() == res.rewards.squeeze())\n",
    "    assert np.all(rep.terminated.squeeze() == res.terminated.squeeze())\n",
    "    assert np.all(rep.truncated.squeeze() == res.truncated.squeeze())\n",
    "        \n",
    "    \n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-02T02:07:51.077851Z",
     "start_time": "2024-11-02T02:07:44.786792Z"
    }
   },
   "id": "128e0218ec9cae23",
   "execution_count": 97,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 20000/999999 [00:06<05:02, 3239.38it/s]\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAssertionError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[97], line 73\u001B[0m\n\u001B[0;32m     69\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m rep_sample\u001B[38;5;241m.\u001B[39mrewards\u001B[38;5;241m.\u001B[39mcpu()\u001B[38;5;241m.\u001B[39mnumpy()\u001B[38;5;241m.\u001B[39mshape \u001B[38;5;241m==\u001B[39m res_sample\u001B[38;5;241m.\u001B[39mrewards\u001B[38;5;241m.\u001B[39mcpu()\u001B[38;5;241m.\u001B[39mnumpy()\u001B[38;5;241m.\u001B[39mshape\n\u001B[0;32m     70\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m rep_sample\u001B[38;5;241m.\u001B[39mdones\u001B[38;5;241m.\u001B[39mcpu()\u001B[38;5;241m.\u001B[39mnumpy()\u001B[38;5;241m.\u001B[39mshape \u001B[38;5;241m==\u001B[39m res_sample\u001B[38;5;241m.\u001B[39mdones\u001B[38;5;241m.\u001B[39mcpu()\u001B[38;5;241m.\u001B[39mnumpy()\u001B[38;5;241m.\u001B[39mshape\n\u001B[1;32m---> 73\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m np\u001B[38;5;241m.\u001B[39mall(rep\u001B[38;5;241m.\u001B[39mobservations\u001B[38;5;241m.\u001B[39msqueeze() \u001B[38;5;241m==\u001B[39m res\u001B[38;5;241m.\u001B[39mobservations\u001B[38;5;241m.\u001B[39msqueeze())\n\u001B[0;32m     74\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m np\u001B[38;5;241m.\u001B[39mall(rep\u001B[38;5;241m.\u001B[39mnext_observations\u001B[38;5;241m.\u001B[39msqueeze() \u001B[38;5;241m==\u001B[39m res\u001B[38;5;241m.\u001B[39mnext_observations\u001B[38;5;241m.\u001B[39msqueeze())\n\u001B[0;32m     75\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m np\u001B[38;5;241m.\u001B[39mall(rep\u001B[38;5;241m.\u001B[39mactions\u001B[38;5;241m.\u001B[39msqueeze() \u001B[38;5;241m==\u001B[39m res\u001B[38;5;241m.\u001B[39mactions\u001B[38;5;241m.\u001B[39msqueeze())\n",
      "\u001B[1;31mAssertionError\u001B[0m: "
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "(0.1, 0.1, 0.1, 0.1, tensor(0.0820), tensor(0.0938))"
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rep_sample = rep.sample(256)\n",
    "res_sample = res.sample(256)\n",
    "res.truncated.mean(), rep.truncated.mean(), res.terminated.mean(), rep.terminated.mean(), res_sample.dones.mean(), rep_sample.dones.mean()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-02T01:54:48.117170Z",
     "start_time": "2024-11-02T01:54:48.024647Z"
    }
   },
   "id": "d3922bd02021ff01",
   "execution_count": 95
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from src.reinforcement_learning.core.buffers.replay.replay_with_reservoir_buffer import ReplayWithReservoirBuffer\n",
    "\n",
    "env_name = 'HalfCheetah-v4'\n",
    "# env_kwargs = {'forward_reward_weight': 1.25, 'healthy_reward': 0.5, 'ctrl_cost_weight': 0.001 }\n",
    "env_kwargs = {}\n",
    "num_envs = 1\n",
    "\n",
    "def create_env(render_mode: str | None):\n",
    "    make_single_env = lambda: gym.make(env_name, render_mode=render_mode, **env_kwargs)\n",
    "    \n",
    "    if num_envs == 1:\n",
    "        return make_single_env()\n",
    "        \n",
    "    return parallelize_env_async(make_single_env, num_envs)\n",
    "\n",
    "def create_policy():\n",
    "    in_size = 17\n",
    "    action_size = 6\n",
    "    \n",
    "    actor_net = nn.Sequential(\n",
    "        nn.Linear(in_size, 256),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(256, 256),\n",
    "        nn.ReLU(),\n",
    "    )\n",
    "\n",
    "    critic = QCritic(\n",
    "        n_critics=2,\n",
    "        create_q_network=lambda: nn.Sequential(\n",
    "            nn.Linear(in_size + action_size, 256),\n",
    "            nn.ReLU(),\n",
    "            # BatchRenorm(256),\n",
    "            nn.Linear(256, 256),\n",
    "            nn.ReLU(),\n",
    "            # BatchRenorm(256),\n",
    "            nn.Linear(256, 1)\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return SACPolicy(\n",
    "        actor=Actor(actor_net, PredictedStdActionSelector(\n",
    "            latent_dim=256,\n",
    "            action_dim=action_size,\n",
    "            base_std=1.0,\n",
    "            squash_output=True,\n",
    "        )),\n",
    "        critic=critic\n",
    "    )\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\") if True else torch.device('cpu')\n",
    "env = create_env(render_mode=None)\n",
    "policy = create_policy()\n",
    "\n",
    "# noinspection PyTypeChecker\n",
    "buf: ReplayWithReservoirBuffer = SAC(\n",
    "            env=env,\n",
    "            policy=policy,\n",
    "            actor_optimizer_provider=lambda params: optim.Adam(params, lr=3e-4),  # (params, lr=3e-4, betas=(0.5, 0.999)),\n",
    "            critic_optimizer_provider=lambda params: optim.Adam(params, lr=3e-4),  # (params, lr=3e-4, betas=(0.5, 0.999)),\n",
    "            buffer_type=ReplayWithReservoirBuffer,\n",
    "            buffer_step_size=200_000,\n",
    "            buffer_kwargs={\n",
    "                'reservoir_total_size': 300_000,\n",
    "            },\n",
    "            reward_scale=10,\n",
    "            gamma=0.99,\n",
    "            tau=0.005,\n",
    "            entropy_coef_optimizer_provider=lambda params: optim.Adam(params, lr=3e-4),\n",
    "            entropy_coef_clamp_range=(0.001, 1.5),\n",
    "            # entropy_coef=0.1,\n",
    "            rollout_steps=1,\n",
    "            gradient_steps=1,\n",
    "            warmup_steps=10_000,\n",
    "            optimization_batch_size=256,\n",
    "            target_update_interval=1,\n",
    "            # callback=Callback(\n",
    "            #     on_rollout_done=on_rollout_done,\n",
    "            #     rollout_schedulers={},\n",
    "            #     on_optimization_done=on_optimization_done,\n",
    "            #     optimization_schedulers={},\n",
    "            # ),\n",
    "            # stash_config=SACInfoStashConfig(stash_rollout_infos=True, stash_rollout_action_stds=True,\n",
    "            #                                 stash_entropy_coef=True,\n",
    "            #                                 entropy_coef_loss=LossInfoStashConfig(stash_final=True),\n",
    "            #                                 actor_loss=LossInfoStashConfig(stash_final=True),\n",
    "            #                                 critic_loss=LossInfoStashConfig(stash_final=True)),\n",
    "            torch_device=device,\n",
    "        ).buffer\n",
    "\n",
    "for i in tqdm.tqdm(range(0, 1_000_000)):\n",
    "    buf.add(\n",
    "        observations=np.array([i]),\n",
    "        next_observations=np.array([i + 1]),\n",
    "        actions=np.array([i]),\n",
    "        rewards=np.array([i]),\n",
    "        terminated=np.array([False]),\n",
    "        truncated=np.array([False]),\n",
    "    )\n",
    "    \n",
    "    if i >= 200_000 and (i % 1000 == 0):\n",
    "        fig, ax = plt.subplots(1, figsize=(14, 14))\n",
    "        \n",
    "        sample_obs = np.concatenate(tuple(buf.sample(256).observations[:, 0].cpu().numpy() for _ in range(1000)))\n",
    "        \n",
    "        buf_obs = buf.observations[:, 0, 0]\n",
    "        res_obs = buf.reservoir.observations[:, 0]\n",
    "        \n",
    "        buf_obs = buf_obs[buf_obs != 0]\n",
    "        res_obs = res_obs[res_obs != 0]\n",
    "        \n",
    "        ax.hist(sample_obs, bins=100, label='samples', alpha=0.5)\n",
    "        ax.hist(buf_obs, bins=100, label='rep', alpha=0.5)\n",
    "        ax.hist(res_obs, bins=100, label='res', alpha=0.5)\n",
    "        fig.legend()\n",
    "        \n",
    "        print(i)\n",
    "        \n",
    "    \n",
    "    "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "90d29b8194c1ace6"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "array([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n         0.]],\n\n       [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n         1.]],\n\n       [[2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n         2.]],\n\n       [[3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.,\n         3.]],\n\n       [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n         0.]],\n\n       [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n         0.]],\n\n       [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n         0.]],\n\n       [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n         0.]],\n\n       [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n         0.]],\n\n       [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n         0.]],\n\n       [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n         0.]],\n\n       [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n         0.]],\n\n       [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n         0.]],\n\n       [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n         0.]],\n\n       [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n         0.]],\n\n       [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n         0.]],\n\n       [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n         0.]],\n\n       [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n         0.]],\n\n       [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n         0.]],\n\n       [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n         0.]]], dtype=float32)"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buf.observations[:20]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-31T22:01:05.300864Z",
     "start_time": "2024-10-31T22:01:05.210621Z"
    }
   },
   "id": "446e76e69e52ae29",
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "id": "d1ae8571d73535c6",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-01T20:54:33.472390Z",
     "start_time": "2024-11-01T20:54:31.482322Z"
    }
   },
   "source": [
    "buf.sample(2)\n"
   ],
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "ReplayBufferSamples(observations=tensor([[25725., 25725., 25725., 25725., 25725., 25725., 25725., 25725., 25725.,\n         25725., 25725., 25725., 25725., 25725., 25725., 25725., 25725.],\n        [98733., 98733., 98733., 98733., 98733., 98733., 98733., 98733., 98733.,\n         98733., 98733., 98733., 98733., 98733., 98733., 98733., 98733.]],\n       device='cuda:0'), actions=tensor([[25725., 25725., 25725., 25725., 25725., 25725.],\n        [98733., 98733., 98733., 98733., 98733., 98733.]], device='cuda:0'), next_observations=tensor([[25726., 25726., 25726., 25726., 25726., 25726., 25726., 25726., 25726.,\n         25726., 25726., 25726., 25726., 25726., 25726., 25726., 25726.],\n        [98734., 98734., 98734., 98734., 98734., 98734., 98734., 98734., 98734.,\n         98734., 98734., 98734., 98734., 98734., 98734., 98734., 98734.]],\n       device='cuda:0'), dones=tensor([[0.],\n        [0.]], device='cuda:0'), rewards=tensor([[257250.],\n        [987330.]], device='cuda:0'))"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba6ab51a61dd845",
   "metadata": {
    "collapsed": false
   },
   "source": [],
   "outputs": []
  }
 ],
 "metadata": {
  "autoscrollcelloutput": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
