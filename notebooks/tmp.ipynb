{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-17T16:16:59.862463Z",
     "start_time": "2024-05-17T16:16:59.846803Z"
    }
   },
   "source": [
    "from typing import SupportsFloat, Any\n",
    "\n",
    "from gymnasium.core import ActType, ObsType\n",
    "\n",
    "from tmp_mp import main"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "main()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-17T16:17:15.230794Z",
     "start_time": "2024-05-17T16:17:01.129793Z"
    }
   },
   "id": "83a784f8b65b74f8",
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "\n",
    "# Parallel environments\n",
    "vec_env = make_vec_env(\"HalfCheetah-v4\", n_envs=4)\n",
    "\n",
    "model = PPO(\"MlpPolicy\", vec_env, use_sde=True, sde_sample_freq=100, verbose=2)\n",
    "model.learn(total_timesteps=250000)\n",
    "model.save(\"ppo_cartpole\")\n",
    "\n",
    "del model # remove to demonstrate saving and loading\n",
    "\n",
    "model = PPO.load(\"ppo_cartpole\")\n",
    "\n",
    "obs = vec_env.reset()\n",
    "# while True:\n",
    "#     action, _states = model.predict(obs)\n",
    "#     obs, rewards, dones, info = vec_env.step(action)\n",
    "#     vec_env.render(\"human\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T22:15:54.226301Z",
     "start_time": "2024-05-23T22:14:18.948367Z"
    }
   },
   "id": "6d26ca5d3fba5ab7",
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "rollout_data = np.random.random((2500, 32, 17))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T22:42:33.450537Z",
     "start_time": "2024-05-23T22:42:33.437024Z"
    }
   },
   "id": "8f542b5b7a30c20d",
   "execution_count": 14,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "%%timeit\n",
    "for i in range(len(rollout_data)):\n",
    "    tensor = torch.tensor(rollout_data[i], device='cuda')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T22:42:46.607754Z",
     "start_time": "2024-05-23T22:42:33.589059Z"
    }
   },
   "id": "7e926ae1d8feae57",
   "execution_count": 15,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import types\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "class A(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(17, 17)\n",
    "        \n",
    "        self.forward = self.linear.forward\n",
    "        \n",
    "    # def forward(self, x):\n",
    "    #     return self.linear(x)\n",
    "    \n",
    "test_data = torch.tensor(np.random.random((2500, 1024, 17))).float()\n",
    "\n",
    "a = A()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-28T17:25:49.731860Z",
     "start_time": "2024-05-28T17:25:49.343973Z"
    }
   },
   "id": "18b462eb301c3290",
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "%%timeit\n",
    "\n",
    "for i in range(len(test_data)):\n",
    "    a(test_data[i])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-28T17:26:00.167853Z",
     "start_time": "2024-05-28T17:25:49.732855Z"
    }
   },
   "id": "25fc61df57f13567",
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "%%timeit\n",
    "\n",
    "for i in range(len(test_data)):\n",
    "    a(test_data[i]).detach()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-28T17:26:11.629808Z",
     "start_time": "2024-05-28T17:26:00.168853Z"
    }
   },
   "id": "3e64a75ffcb3f542",
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from src.torch_device import get_torch_device\n",
    "\n",
    "get_torch_device()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-29T19:20:16.958767Z",
     "start_time": "2024-05-29T19:20:11.568280Z"
    }
   },
   "id": "c22c1a2827faef5",
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import gymnasium\n",
    "\n",
    "gymnasium.make('Ant-v4',)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "11fe74cc94873a0b",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "TinyModelDB(self.base_path = 'E:/saved_models/rl/Ant-v4/mitosis-2024-06-10_19.43.13', self.db_file_name = '_model_db.json')\n",
      "{'model_id': '2024-06-10_21.54.15~n4cBNU', 'parent_model_id': '2024-06-10_21.44.40~9gXtNx', 'model_info': {'policy_id': '2024-06-10_21.54.15~n4cBNU', 'parent_policy_id': '2024-06-10_21.44.40~9gXtNx', 'score': 271.6161154407198, 'steps_trained': 500000, 'env_steps_trained': 8000000, 'optimizations_done': 160, 'initialization_info': {'init_action_selector_source_code': \"def init_action_selector(latent_dim: int, action_dim: int, hyper_parameters: dict[str, 'Any']) -> 'ActionSelector':\\n    from src.reinforcement_learning.core.action_selectors.predicted_std_action_selector \\\\\\n        import PredictedStdActionSelector\\n    from src.weight_initialization import orthogonal_initialization\\n\\n    return PredictedStdActionSelector(\\n        latent_dim=latent_dim,\\n        action_dim=action_dim,\\n        base_std=0.15,\\n        squash_output=True,\\n        action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\\n        log_std_net_initialization=lambda module: orthogonal_initialization(module, gain=0.1),\\n    )\\n\", 'init_policy_source_code': \"def init_policy(\\n        init_action_selector_: 'InitActionSelectorFunction',\\n        hyper_parameters: dict[str, 'Any']\\n) -> 'BasePolicy':\\n    import torch\\n    from torch import nn\\n\\n    from src.networks.core.seq_net import SeqNet\\n    from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\\n    from src.networks.core.net import Net\\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\\n\\n    in_size = 27\\n    action_size = 8\\n\\n    actor_layers = 7\\n    actor_features = 64\\n\\n    critic_layers = 4\\n    critic_features = 64\\n\\n    hidden_activation_function = nn.ELU\\n\\n    class A2CNetwork(nn.Module):\\n\\n        def __init__(self):\\n            super().__init__()\\n\\n            self.actor_embedding = nn.Sequential(\\n                nn.Linear(in_size, actor_features),\\n                hidden_activation_function()\\n            )\\n            self.actor = SeqNet.from_layer_provider(\\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features:\\n                    AdditiveSkipConnection(Net.seq_as_net(\\n                        nn.Linear(in_features, out_features),\\n                        nn.Tanh() if is_last_layer else hidden_activation_function()\\n                    )),\\n                num_features=actor_features,\\n                num_layers=actor_layers,\\n            )\\n\\n            self.critic_embedding = nn.Sequential(\\n                nn.Linear(in_size, critic_features),\\n                hidden_activation_function()\\n            )\\n            self.critic = SeqNet.from_layer_provider(\\n                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features:\\n                    AdditiveSkipConnection(Net.seq_as_net(\\n                        nn.Linear(in_features, out_features),\\n                        nn.Identity() if is_last_layer else hidden_activation_function()\\n                    )),\\n                num_features=critic_features,\\n                num_layers=critic_layers,\\n            )\\n            self.critic_regressor = nn.Linear(critic_features, 1)\\n\\n        def forward(self, x: torch.Tensor) -> tuple[torch.Tensor, torch.Tensor]:\\n            return (\\n                self.actor(self.actor_embedding(x)),\\n                self.critic_regressor(self.critic(self.critic_embedding(x)))\\n            )\\n\\n    return ActorCriticPolicy(\\n        (network := A2CNetwork()),\\n        init_action_selector_(\\n            latent_dim=network.actor.out_shape.get_definite_features(),\\n            action_dim=action_size,\\n            hyper_parameters=hyper_parameters,\\n        )\\n    )\\n\", 'init_optimizer_source_code': \"def init_optimizer(policy: 'BasePolicy', hyper_parameters: dict[str, 'Any']) -> 'torch.optim.Optimizer':\\n    import torch.optim\\n    return torch.optim.AdamW(policy.parameters(), lr=1e-5)\\n\", 'wrap_env_source_code': \"def wrap_env(env_: 'gymnasium.vector.VectorEnv', hyper_parameters: dict[str, 'Any']) -> 'gymnasium.Env':\\n    from src.reinforcement_learning.gym.transform_reward_wrapper import TransformRewardWrapper\\n    from gymnasium.wrappers import RescaleAction\\n\\n    env_ = TransformRewardWrapper(env_, lambda _reward: 0.01 * _reward)\\n    env_ = RescaleAction(env_, min_action=-1.0, max_action=1.0)\\n\\n    return env_\\n\", 'hyper_parameters': {}}}, 'last_update_time': '2024-06-10 22:03:50.306875'}\n",
      "2024-06-10_21.54.15~n4cBNU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 982/50000 [00:02<01:38, 497.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video C:\\Users\\domin\\Videos\\rl\\2024-06-10_23.30.43\\rl-video-episode-0.mp4.\n",
      "Moviepy - Writing video C:\\Users\\domin\\Videos\\rl\\2024-06-10_23.30.43\\rl-video-episode-0.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "t:   0%|          | 0/1002 [00:00<?, ?it/s, now=None]\u001B[A\n",
      "t:   2%|▏         | 19/1002 [00:00<00:05, 186.23it/s, now=None]\u001B[A\n",
      "t:   5%|▍         | 48/1002 [00:00<00:04, 225.67it/s, now=None]\u001B[A\n",
      "t:   8%|▊         | 78/1002 [00:00<00:03, 255.58it/s, now=None]\u001B[A\n",
      "t:  11%|█         | 108/1002 [00:00<00:03, 270.38it/s, now=None]\u001B[A\n",
      "t:  14%|█▎        | 137/1002 [00:00<00:03, 276.26it/s, now=None]\u001B[A\n",
      "t:  17%|█▋        | 166/1002 [00:00<00:02, 279.13it/s, now=None]\u001B[A\n",
      "t:  19%|█▉        | 195/1002 [00:00<00:02, 282.60it/s, now=None]\u001B[A\n",
      "t:  22%|██▏       | 224/1002 [00:00<00:02, 284.01it/s, now=None]\u001B[A\n",
      "t:  25%|██▌       | 253/1002 [00:00<00:02, 284.08it/s, now=None]\u001B[A\n",
      "t:  28%|██▊       | 282/1002 [00:01<00:02, 285.87it/s, now=None]\u001B[A\n",
      "t:  31%|███       | 311/1002 [00:01<00:02, 287.10it/s, now=None]\u001B[A\n",
      "t:  34%|███▍      | 340/1002 [00:01<00:02, 287.09it/s, now=None]\u001B[A\n",
      "t:  37%|███▋      | 369/1002 [00:01<00:02, 285.91it/s, now=None]\u001B[A\n",
      "t:  40%|███▉      | 398/1002 [00:01<00:02, 284.19it/s, now=None]\u001B[A\n",
      "t:  43%|████▎     | 427/1002 [00:01<00:02, 283.37it/s, now=None]\u001B[A\n",
      "t:  46%|████▌     | 456/1002 [00:01<00:01, 283.64it/s, now=None]\u001B[A\n",
      "t:  48%|████▊     | 485/1002 [00:01<00:01, 284.66it/s, now=None]\u001B[A\n",
      "t:  51%|█████▏    | 514/1002 [00:01<00:01, 285.38it/s, now=None]\u001B[A\n",
      "t:  54%|█████▍    | 543/1002 [00:01<00:01, 285.25it/s, now=None]\u001B[A\n",
      "t:  57%|█████▋    | 572/1002 [00:02<00:01, 284.11it/s, now=None]\u001B[A\n",
      "t:  60%|██████    | 602/1002 [00:02<00:01, 287.09it/s, now=None]\u001B[A\n",
      "t:  63%|██████▎   | 631/1002 [00:02<00:01, 287.08it/s, now=None]\u001B[A\n",
      "t:  66%|██████▌   | 660/1002 [00:02<00:01, 287.93it/s, now=None]\u001B[A\n",
      "t:  69%|██████▉   | 689/1002 [00:02<00:01, 288.53it/s, now=None]\u001B[A\n",
      "t:  72%|███████▏  | 718/1002 [00:02<00:00, 286.38it/s, now=None]\u001B[A\n",
      "t:  75%|███████▍  | 747/1002 [00:02<00:00, 287.44it/s, now=None]\u001B[A\n",
      "t:  77%|███████▋  | 776/1002 [00:02<00:00, 286.48it/s, now=None]\u001B[A\n",
      "t:  80%|████████  | 805/1002 [00:02<00:00, 286.65it/s, now=None]\u001B[A\n",
      "t:  83%|████████▎ | 834/1002 [00:02<00:00, 286.77it/s, now=None]\u001B[A\n",
      "t:  86%|████████▌ | 863/1002 [00:03<00:00, 287.72it/s, now=None]\u001B[A\n",
      "t:  89%|████████▉ | 892/1002 [00:03<00:00, 286.67it/s, now=None]\u001B[A\n",
      "t:  92%|█████████▏| 921/1002 [00:03<00:00, 285.09it/s, now=None]\u001B[A\n",
      "t:  95%|█████████▍| 950/1002 [00:03<00:00, 284.19it/s, now=None]\u001B[A\n",
      "t:  98%|█████████▊| 979/1002 [00:03<00:00, 284.75it/s, now=None]\u001B[A\n",
      "  2%|▏         | 1032/50000 [00:05<19:29, 41.87it/s]            \u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready C:\\Users\\domin\\Videos\\rl\\2024-06-10_23.30.43\\rl-video-episode-0.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1999/50000 [00:08<01:42, 467.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video C:\\Users\\domin\\Videos\\rl\\2024-06-10_23.30.43\\rl-video-episode-1.mp4.\n",
      "Moviepy - Writing video C:\\Users\\domin\\Videos\\rl\\2024-06-10_23.30.43\\rl-video-episode-1.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "t:   0%|          | 0/1002 [00:00<?, ?it/s, now=None]\u001B[A\n",
      "t:   2%|▏         | 18/1002 [00:00<00:05, 176.15it/s, now=None]\u001B[A\n",
      "t:   5%|▍         | 47/1002 [00:00<00:03, 241.08it/s, now=None]\u001B[A\n",
      "t:   7%|▋         | 72/1002 [00:00<00:03, 239.67it/s, now=None]\u001B[A\n",
      "t:  10%|▉         | 100/1002 [00:00<00:03, 255.27it/s, now=None]\u001B[A\n",
      "t:  13%|█▎        | 129/1002 [00:00<00:03, 267.63it/s, now=None]\u001B[A\n",
      "t:  16%|█▌        | 158/1002 [00:00<00:03, 275.15it/s, now=None]\u001B[A\n",
      "t:  19%|█▊        | 187/1002 [00:00<00:02, 279.78it/s, now=None]\u001B[A\n",
      "t:  22%|██▏       | 216/1002 [00:00<00:02, 282.11it/s, now=None]\u001B[A\n",
      "t:  24%|██▍       | 245/1002 [00:00<00:02, 284.54it/s, now=None]\u001B[A\n",
      "t:  27%|██▋       | 274/1002 [00:01<00:02, 286.20it/s, now=None]\u001B[A\n",
      "t:  30%|███       | 303/1002 [00:01<00:02, 286.47it/s, now=None]\u001B[A\n",
      "t:  33%|███▎      | 333/1002 [00:01<00:02, 287.26it/s, now=None]\u001B[A\n",
      "t:  36%|███▌      | 362/1002 [00:01<00:02, 286.34it/s, now=None]\u001B[A\n",
      "t:  39%|███▉      | 391/1002 [00:01<00:02, 286.56it/s, now=None]\u001B[A\n",
      "t:  42%|████▏     | 420/1002 [00:01<00:02, 285.02it/s, now=None]\u001B[A\n",
      "t:  45%|████▍     | 449/1002 [00:01<00:01, 283.69it/s, now=None]\u001B[A\n",
      "t:  48%|████▊     | 478/1002 [00:01<00:01, 282.24it/s, now=None]\u001B[A\n",
      "t:  51%|█████     | 507/1002 [00:01<00:01, 279.97it/s, now=None]\u001B[A\n",
      "t:  53%|█████▎    | 536/1002 [00:01<00:01, 275.62it/s, now=None]\u001B[A\n",
      "t:  56%|█████▋    | 564/1002 [00:02<00:01, 276.87it/s, now=None]\u001B[A\n",
      "t:  59%|█████▉    | 593/1002 [00:02<00:01, 279.87it/s, now=None]\u001B[A\n",
      "t:  62%|██████▏   | 622/1002 [00:02<00:01, 282.00it/s, now=None]\u001B[A\n",
      "t:  65%|██████▍   | 651/1002 [00:02<00:01, 282.68it/s, now=None]\u001B[A\n",
      "t:  68%|██████▊   | 680/1002 [00:02<00:01, 283.98it/s, now=None]\u001B[A\n",
      "t:  71%|███████   | 710/1002 [00:02<00:01, 285.46it/s, now=None]\u001B[A\n",
      "t:  74%|███████▍  | 739/1002 [00:02<00:00, 285.94it/s, now=None]\u001B[A\n",
      "t:  77%|███████▋  | 768/1002 [00:02<00:00, 285.43it/s, now=None]\u001B[A\n",
      "t:  80%|███████▉  | 797/1002 [00:02<00:00, 285.08it/s, now=None]\u001B[A\n",
      "t:  82%|████████▏ | 826/1002 [00:02<00:00, 286.32it/s, now=None]\u001B[A\n",
      "t:  85%|████████▌ | 855/1002 [00:03<00:00, 285.70it/s, now=None]\u001B[A\n",
      "t:  88%|████████▊ | 884/1002 [00:03<00:00, 284.42it/s, now=None]\u001B[A\n",
      "t:  91%|█████████ | 913/1002 [00:03<00:00, 285.05it/s, now=None]\u001B[A\n",
      "t:  94%|█████████▍| 942/1002 [00:03<00:00, 283.97it/s, now=None]\u001B[A\n",
      "t:  97%|█████████▋| 971/1002 [00:03<00:00, 283.22it/s, now=None]\u001B[A\n",
      "t: 100%|█████████▉| 1000/1002 [00:03<00:00, 282.70it/s, now=None]\u001B[A\n",
      "  4%|▍         | 2047/50000 [00:12<20:27, 39.07it/s]             \u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready C:\\Users\\domin\\Videos\\rl\\2024-06-10_23.30.43\\rl-video-episode-1.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 2972/50000 [00:14<01:50, 424.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video C:\\Users\\domin\\Videos\\rl\\2024-06-10_23.30.43\\rl-video-episode-2.mp4.\n",
      "Moviepy - Writing video C:\\Users\\domin\\Videos\\rl\\2024-06-10_23.30.43\\rl-video-episode-2.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "t:   0%|          | 0/1002 [00:00<?, ?it/s, now=None]\u001B[A\n",
      "t:   2%|▏         | 18/1002 [00:00<00:05, 179.96it/s, now=None]\u001B[A\n",
      "t:   5%|▍         | 48/1002 [00:00<00:04, 224.16it/s, now=None]\u001B[A\n",
      "t:   8%|▊         | 77/1002 [00:00<00:03, 250.24it/s, now=None]\u001B[A\n",
      "t:  10%|█         | 105/1002 [00:00<00:03, 259.51it/s, now=None]\u001B[A\n",
      "t:  13%|█▎        | 134/1002 [00:00<00:03, 269.19it/s, now=None]\u001B[A\n",
      "t:  16%|█▋        | 163/1002 [00:00<00:03, 275.16it/s, now=None]\u001B[A\n",
      "t:  19%|█▉        | 192/1002 [00:00<00:02, 279.90it/s, now=None]\u001B[A\n",
      "t:  22%|██▏       | 221/1002 [00:00<00:02, 283.05it/s, now=None]\u001B[A\n",
      "t:  25%|██▍       | 250/1002 [00:00<00:02, 284.31it/s, now=None]\u001B[A\n",
      "t:  28%|██▊       | 279/1002 [00:01<00:02, 284.29it/s, now=None]\u001B[A\n",
      "t:  31%|███       | 308/1002 [00:01<00:02, 283.42it/s, now=None]\u001B[A\n",
      "t:  34%|███▎      | 337/1002 [00:01<00:02, 285.38it/s, now=None]\u001B[A\n",
      "t:  37%|███▋      | 366/1002 [00:01<00:02, 284.19it/s, now=None]\u001B[A\n",
      "t:  39%|███▉      | 395/1002 [00:01<00:02, 283.36it/s, now=None]\u001B[A\n",
      "t:  42%|████▏     | 424/1002 [00:01<00:02, 280.81it/s, now=None]\u001B[A\n",
      "t:  45%|████▌     | 453/1002 [00:01<00:01, 275.21it/s, now=None]\u001B[A\n",
      "t:  48%|████▊     | 482/1002 [00:01<00:01, 279.43it/s, now=None]\u001B[A\n",
      "t:  51%|█████     | 510/1002 [00:01<00:01, 279.58it/s, now=None]\u001B[A\n",
      "t:  54%|█████▎    | 538/1002 [00:01<00:01, 278.86it/s, now=None]\u001B[A\n",
      "t:  56%|█████▋    | 566/1002 [00:02<00:01, 278.41it/s, now=None]\u001B[A\n",
      "t:  59%|█████▉    | 595/1002 [00:02<00:01, 280.15it/s, now=None]\u001B[A\n",
      "t:  62%|██████▏   | 625/1002 [00:02<00:01, 283.06it/s, now=None]\u001B[A\n",
      "t:  65%|██████▌   | 654/1002 [00:02<00:01, 283.83it/s, now=None]\u001B[A\n",
      "t:  68%|██████▊   | 683/1002 [00:02<00:01, 283.95it/s, now=None]\u001B[A\n",
      "t:  71%|███████   | 712/1002 [00:02<00:01, 285.73it/s, now=None]\u001B[A\n",
      "t:  74%|███████▍  | 741/1002 [00:02<00:00, 286.13it/s, now=None]\u001B[A\n",
      "t:  77%|███████▋  | 770/1002 [00:02<00:00, 285.56it/s, now=None]\u001B[A\n",
      "t:  80%|███████▉  | 799/1002 [00:02<00:00, 285.38it/s, now=None]\u001B[A\n",
      "t:  83%|████████▎ | 828/1002 [00:02<00:00, 285.89it/s, now=None]\u001B[A\n",
      "t:  86%|████████▌ | 857/1002 [00:03<00:00, 287.09it/s, now=None]\u001B[A\n",
      "t:  88%|████████▊ | 886/1002 [00:03<00:00, 287.08it/s, now=None]\u001B[A\n",
      "t:  91%|█████████▏| 915/1002 [00:03<00:00, 287.50it/s, now=None]\u001B[A\n",
      "t:  94%|█████████▍| 944/1002 [00:03<00:00, 286.51it/s, now=None]\u001B[A\n",
      "t:  97%|█████████▋| 973/1002 [00:03<00:00, 286.32it/s, now=None]\u001B[A\n",
      "t: 100%|██████████| 1002/1002 [00:03<00:00, 286.54it/s, now=None]\u001B[A\n",
      "  6%|▌         | 3046/50000 [00:18<17:21, 45.08it/s]             \u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready C:\\Users\\domin\\Videos\\rl\\2024-06-10_23.30.43\\rl-video-episode-2.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 3994/50000 [00:21<01:47, 429.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video C:\\Users\\domin\\Videos\\rl\\2024-06-10_23.30.43\\rl-video-episode-3.mp4.\n",
      "Moviepy - Writing video C:\\Users\\domin\\Videos\\rl\\2024-06-10_23.30.43\\rl-video-episode-3.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "t:   0%|          | 0/1002 [00:00<?, ?it/s, now=None]\u001B[A\n",
      "t:   2%|▏         | 18/1002 [00:00<00:05, 176.43it/s, now=None]\u001B[A\n",
      "t:   5%|▍         | 47/1002 [00:00<00:04, 238.48it/s, now=None]\u001B[A\n",
      "t:   7%|▋         | 71/1002 [00:00<00:03, 236.89it/s, now=None]\u001B[A\n",
      "t:  10%|▉         | 99/1002 [00:00<00:03, 252.66it/s, now=None]\u001B[A\n",
      "t:  13%|█▎        | 129/1002 [00:00<00:03, 267.45it/s, now=None]\u001B[A\n",
      "t:  16%|█▌        | 158/1002 [00:00<00:03, 274.08it/s, now=None]\u001B[A\n",
      "t:  19%|█▊        | 187/1002 [00:00<00:02, 277.41it/s, now=None]\u001B[A\n",
      "t:  22%|██▏       | 216/1002 [00:00<00:02, 279.59it/s, now=None]\u001B[A\n",
      "t:  24%|██▍       | 245/1002 [00:00<00:02, 281.05it/s, now=None]\u001B[A\n",
      "t:  27%|██▋       | 274/1002 [00:01<00:02, 282.90it/s, now=None]\u001B[A\n",
      "t:  30%|███       | 303/1002 [00:01<00:02, 284.17it/s, now=None]\u001B[A\n",
      "t:  33%|███▎      | 332/1002 [00:01<00:02, 285.90it/s, now=None]\u001B[A\n",
      "t:  36%|███▌      | 361/1002 [00:01<00:02, 282.03it/s, now=None]\u001B[A\n",
      "t:  39%|███▉      | 390/1002 [00:01<00:02, 283.53it/s, now=None]\u001B[A\n",
      "t:  42%|████▏     | 419/1002 [00:01<00:02, 285.43it/s, now=None]\u001B[A\n",
      "t:  45%|████▍     | 448/1002 [00:01<00:01, 284.23it/s, now=None]\u001B[A\n",
      "t:  48%|████▊     | 477/1002 [00:01<00:01, 282.64it/s, now=None]\u001B[A\n",
      "t:  50%|█████     | 506/1002 [00:01<00:01, 280.59it/s, now=None]\u001B[A\n",
      "t:  53%|█████▎    | 535/1002 [00:01<00:01, 283.33it/s, now=None]\u001B[A\n",
      "t:  56%|█████▋    | 564/1002 [00:02<00:01, 284.63it/s, now=None]\u001B[A\n",
      "t:  59%|█████▉    | 593/1002 [00:02<00:01, 285.36it/s, now=None]\u001B[A\n",
      "t:  62%|██████▏   | 622/1002 [00:02<00:01, 285.02it/s, now=None]\u001B[A\n",
      "t:  65%|██████▍   | 651/1002 [00:02<00:01, 284.79it/s, now=None]\u001B[A\n",
      "t:  68%|██████▊   | 680/1002 [00:02<00:01, 286.32it/s, now=None]\u001B[A\n",
      "t:  71%|███████   | 709/1002 [00:02<00:01, 284.01it/s, now=None]\u001B[A\n",
      "t:  74%|███████▎  | 738/1002 [00:02<00:00, 284.08it/s, now=None]\u001B[A\n",
      "t:  77%|███████▋  | 767/1002 [00:02<00:00, 282.47it/s, now=None]\u001B[A\n",
      "t:  79%|███████▉  | 796/1002 [00:02<00:00, 284.67it/s, now=None]\u001B[A\n",
      "t:  82%|████████▏ | 825/1002 [00:02<00:00, 285.80it/s, now=None]\u001B[A\n",
      "t:  85%|████████▌ | 854/1002 [00:03<00:00, 285.32it/s, now=None]\u001B[A\n",
      "t:  88%|████████▊ | 883/1002 [00:03<00:00, 285.00it/s, now=None]\u001B[A\n",
      "t:  91%|█████████ | 912/1002 [00:03<00:00, 284.77it/s, now=None]\u001B[A\n",
      "t:  94%|█████████▍| 941/1002 [00:03<00:00, 283.78it/s, now=None]\u001B[A\n",
      "t:  97%|█████████▋| 970/1002 [00:03<00:00, 282.28it/s, now=None]\u001B[A\n",
      "t: 100%|█████████▉| 999/1002 [00:03<00:00, 274.82it/s, now=None]\u001B[A\n",
      "  8%|▊         | 4038/50000 [00:24<20:52, 36.69it/s]            \u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready C:\\Users\\domin\\Videos\\rl\\2024-06-10_23.30.43\\rl-video-episode-3.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 4564/50000 [00:26<02:09, 351.43it/s]"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "def record_video():\n",
    "    import torch\n",
    "    from tqdm import tqdm\n",
    "    from src.reinforcement_learning.gym.singleton_vector_env import as_vec_env\n",
    "    import gymnasium\n",
    "    from gymnasium.wrappers import AutoResetWrapper, RecordVideo    \n",
    "    from src.model_db.tiny_model_db import TinyModelDB\n",
    "    from src.reinforcement_learning.algorithms.policy_mitosis.mitosis_policy_info import MitosisPolicyInfo\n",
    "    from src.reinforcement_learning.core.policy_construction import PolicyConstruction\n",
    "    from src.datetime import get_current_timestamp\n",
    "\n",
    "    record_env, _ = as_vec_env(gymnasium.make('Ant-v4', render_mode='rgb_array'))\n",
    "\n",
    "    policy_db = TinyModelDB[MitosisPolicyInfo](base_path=f'E:/saved_models/rl/Ant-v4/mitosis-2024-06-10_19.43.13')\n",
    "    print(policy_db)\n",
    "    \n",
    "    policy_entry = list(sorted(policy_db.all_entries(), key=lambda entry: entry['model_info']['score']))[-2]\n",
    "    # policy_entry = policy_db.fetch_entry('2024-06-10_22.13.57~PJHPLG')\n",
    "    policy_info : MitosisPolicyInfo = policy_entry['model_info']\n",
    "    print(policy_entry)\n",
    "\n",
    "    policy, _, record_env = PolicyConstruction.init_from_info(policy_info['initialization_info'], record_env)\n",
    "\n",
    "    policy_db.load_model_state_dict(policy_entry['model_id'], policy)\n",
    "    \n",
    "    try:\n",
    "        record_env.metadata['render_fps'] = 30\n",
    "        record_env = AutoResetWrapper(\n",
    "            RecordVideo(record_env, video_folder=rf'C:\\Users\\domin\\Videos\\rl\\{get_current_timestamp()}', episode_trigger=lambda ep_nr: True)\n",
    "        )\n",
    "        \n",
    "        def record(max_steps: int):\n",
    "            with torch.no_grad():\n",
    "                obs, info = record_env.reset()\n",
    "                for step in tqdm(range(max_steps)):\n",
    "                    actions_dist, _ = policy.process_obs(torch.tensor(obs, device='cpu'))\n",
    "                    actions = actions_dist.get_actions(deterministic=True).cpu().numpy()\n",
    "                    obs, reward, terminated, truncated, info = record_env.step(actions)\n",
    "        \n",
    "        record(50_000)\n",
    "    except KeyboardInterrupt:\n",
    "        print('keyboard interrupt')\n",
    "    finally:\n",
    "        print('closing record_env')\n",
    "        record_env.close()\n",
    "        print('record_env closed')\n",
    "\n",
    "record_video()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-10T21:30:42.251803Z"
    }
   },
   "id": "9413fb35d2e62be7",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0; [0]; 0.0; [5.]; True\n",
      "1; [1]; 0.0; [5.]; False\n",
      "2; [2]; 0.0; [5.]; False\n",
      "3; [3]; 0.0; [5.]; False\n",
      "4; [4]; 0.0; [5.]; False\n",
      "5; [5]; 0.0; [5.]; False\n",
      "6; [6]; 0.0; [5.]; False\n",
      "7; [7]; 0.0; [5.]; False\n",
      "8; [8]; 0.0; [5.]; False\n",
      "9; [9]; 5.0; [5.]; False\n",
      "10; [0]; 0.0; [5.]; True\n",
      "11; [1]; 0.0; [5.]; False\n",
      "12; [2]; 0.0; [5.]; False\n",
      "13; [3]; 0.0; [5.]; False\n",
      "14; [4]; 0.0; [5.]; False\n",
      "15; [5]; 0.0; [5.]; False\n",
      "16; [6]; 0.0; [5.]; False\n",
      "17; [7]; 0.0; [5.]; False\n",
      "18; [8]; 0.0; [5.]; False\n",
      "19; [9]; 5.0; [5.]; False\n",
      "20; [0]; 0.0; [5.]; True\n",
      "21; [1]; 0.0; [5.]; False\n",
      "22; [2]; 0.0; [5.]; False\n",
      "23; [3]; 0.0; [5.]; False\n",
      "24; [4]; 0.0; [5.]; False\n",
      "25; [5]; 0.0; [5.]; False\n",
      "26; [6]; 0.0; [5.]; False\n",
      "27; [7]; 0.0; [5.]; False\n",
      "28; [8]; 0.0; [5.]; False\n",
      "29; [9]; 5.0; [5.]; False\n",
      "30; [0]; 0.0; [5.]; True\n",
      "31; [1]; 0.0; [5.]; False\n",
      "32; [2]; 0.0; [5.]; False\n",
      "33; [3]; 0.0; [5.]; False\n",
      "34; [4]; 0.0; [5.]; False\n",
      "35; [5]; 0.0; [5.]; False\n",
      "36; [6]; 0.0; [5.]; False\n",
      "37; [7]; 0.0; [5.]; False\n",
      "38; [8]; 0.0; [5.]; False\n",
      "39; [9]; 5.0; [5.]; False\n",
      "40; [0]; 0.0; [5.]; True\n",
      "41; [1]; 0.0; [5.]; False\n",
      "42; [2]; 0.0; [5.]; False\n",
      "43; [3]; 0.0; [5.]; False\n",
      "44; [4]; 0.0; [5.]; False\n",
      "45; [5]; 0.0; [5.]; False\n",
      "46; [6]; 0.0; [5.]; False\n",
      "47; [7]; 0.0; [5.]; False\n",
      "48; [8]; 0.0; [5.]; False\n",
      "49; [9]; 5.0; [5.]; False\n",
      "[0] True\n",
      "\n",
      "5 5.0 0.0\n"
     ]
    }
   ],
   "source": [
    "from gymnasium.wrappers import AutoResetWrapper, TimeLimit\n",
    "import torch\n",
    "import numpy as np\n",
    "import gymnasium\n",
    "from gymnasium.core import ActType, ObsType\n",
    "from typing import Any, SupportsFloat\n",
    "from src.reinforcement_learning.core.generalized_advantage_estimate import compute_episode_returns, compute_returns\n",
    "\n",
    "\n",
    "class TestEnv(gymnasium.Env):\n",
    "    \n",
    "    counter: int\n",
    "    \n",
    "    def reset(\n",
    "        self,\n",
    "        *,\n",
    "        seed: int | None = None,\n",
    "        options: dict[str, Any] | None = None,\n",
    "    ) -> tuple[ObsType, dict[str, Any]]:\n",
    "        self.counter = 0\n",
    "        return np.array([self.counter]), {}\n",
    "    \n",
    "    def step(\n",
    "        self, action: ActType\n",
    "    ) -> tuple[ObsType, SupportsFloat, bool, bool, dict[str, Any]]:\n",
    "        self.counter += 1\n",
    "        done_ = self.counter >= 10\n",
    "        \n",
    "        if done_:\n",
    "            reward_ = 5.0\n",
    "        else:\n",
    "            reward_ = 0.0\n",
    "        \n",
    "        return np.array([self.counter]), reward_, done_, False, {}\n",
    "\n",
    "\n",
    "\n",
    "env = AutoResetWrapper(TimeLimit(TestEnv(), 100))\n",
    "obs, _ = env.reset()\n",
    "episode_starts = True\n",
    "\n",
    "obs_l = []\n",
    "rewards = []\n",
    "dones = []\n",
    "\n",
    "for i in range(50):\n",
    "    next_obs, reward, terminated, truncated, _ = env.step(None)\n",
    "    obs_l.append(obs)\n",
    "    rewards.append(reward)\n",
    "    dones.append(episode_starts)\n",
    "    episode_starts = np.logical_or(terminated, truncated)\n",
    "    obs = next_obs\n",
    "    \n",
    "\n",
    "returns, episode_returns = compute_episode_returns(\n",
    "    rewards=np.array(rewards)[:, np.newaxis],\n",
    "    episode_starts=np.array(dones)[:, np.newaxis],\n",
    "    last_episode_starts=np.array([episode_starts]),\n",
    "    gamma=1.0,\n",
    "    gae_lambda=1.0,\n",
    "    normalize_rewards=None,\n",
    "    remove_unfinished_episodes=True\n",
    ")    \n",
    "\n",
    "for i, (obs_, reward_, return_, done) in enumerate(zip(obs_l, rewards, returns, dones)):\n",
    "    print(f'{i}; {obs_}; {reward_}; {return_}; {done}')\n",
    "print(obs, episode_starts)\n",
    "print()\n",
    "\n",
    "print(len(episode_returns), np.mean(episode_returns), np.std(episode_returns))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-14T18:37:33.198877Z",
     "start_time": "2024-06-14T18:37:33.185470Z"
    }
   },
   "id": "70f22b7cb50ff18a",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "232fbbf514e29e1d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
