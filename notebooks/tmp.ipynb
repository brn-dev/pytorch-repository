{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-17T16:16:59.862463Z",
     "start_time": "2024-05-17T16:16:59.846803Z"
    }
   },
   "source": [
    "from typing import SupportsFloat, Any\n",
    "\n",
    "from gymnasium.core import ActType, ObsType\n",
    "\n",
    "from tmp_mp import main"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "main()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-23T20:07:27.012896Z",
     "start_time": "2024-07-23T20:07:26.784305Z"
    }
   },
   "id": "83a784f8b65b74f8",
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "\n",
    "# Parallel environments\n",
    "vec_env = make_vec_env(\"HalfCheetah-v4\", n_envs=4)\n",
    "\n",
    "model = PPO(\"MlpPolicy\", vec_env, use_sde=True, sde_sample_freq=100, verbose=2)\n",
    "model.learn(total_timesteps=250000)\n",
    "model.save(\"ppo_cartpole\")\n",
    "\n",
    "del model  # remove to demonstrate saving and loading\n",
    "\n",
    "model = PPO.load(\"ppo_cartpole\")\n",
    "\n",
    "obs = vec_env.reset()\n",
    "# while True:\n",
    "#     action, _states = model.predict(obs)\n",
    "#     obs, rewards, dones, info = vec_env.step(action)\n",
    "#     vec_env.render(\"human\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T22:15:54.226301Z",
     "start_time": "2024-05-23T22:14:18.948367Z"
    }
   },
   "id": "6d26ca5d3fba5ab7",
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "rollout_data = np.random.random((2500, 32, 17))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T22:42:33.450537Z",
     "start_time": "2024-05-23T22:42:33.437024Z"
    }
   },
   "id": "8f542b5b7a30c20d",
   "execution_count": 14,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "%%timeit\n",
    "for i in range(len(rollout_data)):\n",
    "    tensor = torch.tensor(rollout_data[i], device='cuda')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T22:42:46.607754Z",
     "start_time": "2024-05-23T22:42:33.589059Z"
    }
   },
   "id": "7e926ae1d8feae57",
   "execution_count": 15,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import types\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "class A(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(17, 17)\n",
    "\n",
    "        self.forward = self.linear.forward\n",
    "\n",
    "    # def forward(self, x):\n",
    "    #     return self.linear(x)\n",
    "\n",
    "\n",
    "test_data = torch.tensor(np.random.random((2500, 1024, 17))).float()\n",
    "\n",
    "a = A()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-28T17:25:49.731860Z",
     "start_time": "2024-05-28T17:25:49.343973Z"
    }
   },
   "id": "18b462eb301c3290",
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "%%timeit\n",
    "\n",
    "for i in range(len(test_data)):\n",
    "    a(test_data[i])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-28T17:26:00.167853Z",
     "start_time": "2024-05-28T17:25:49.732855Z"
    }
   },
   "id": "25fc61df57f13567",
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "%%timeit\n",
    "\n",
    "for i in range(len(test_data)):\n",
    "    a(test_data[i]).detach()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-28T17:26:11.629808Z",
     "start_time": "2024-05-28T17:26:00.168853Z"
    }
   },
   "id": "3e64a75ffcb3f542",
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from src.torch_device import get_torch_device\n",
    "\n",
    "get_torch_device()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-29T19:20:16.958767Z",
     "start_time": "2024-05-29T19:20:11.568280Z"
    }
   },
   "id": "c22c1a2827faef5",
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import gymnasium\n",
    "\n",
    "gymnasium.make('Ant-v4', )"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "11fe74cc94873a0b",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "def record_video():\n",
    "    import torch\n",
    "    from tqdm import tqdm\n",
    "    from src.reinforcement_learning.gym.singleton_vector_env import as_vec_env\n",
    "    import gymnasium\n",
    "    from gymnasium.wrappers import AutoResetWrapper, RecordVideo\n",
    "    from src.model_db.tiny_model_db import TinyModelDB\n",
    "    from src.reinforcement_learning.algorithms.policy_mitosis.mitosis_policy_info import MitosisPolicyInfo\n",
    "    from src.reinforcement_learning.core.policy_construction import PolicyConstruction\n",
    "    from src.datetime import get_current_timestamp\n",
    "\n",
    "    record_env, _ = as_vec_env(gymnasium.make('Ant-v4', render_mode='rgb_array'))\n",
    "\n",
    "    policy_db = TinyModelDB[MitosisPolicyInfo](base_path=f'E:/saved_models/rl/Ant-v4/mitosis-2024-06-10_19.43.13')\n",
    "    print(policy_db)\n",
    "\n",
    "    policy_entry = list(sorted(policy_db.all_entries(), key=lambda entry: entry['model_info']['score']))[-2]\n",
    "    # policy_entry = policy_db.fetch_entry('2024-06-10_22.13.57~PJHPLG')\n",
    "    policy_info: MitosisPolicyInfo = policy_entry['model_info']\n",
    "    print(policy_entry)\n",
    "\n",
    "    policy, _, record_env = PolicyConstruction.init_from_info(policy_info['initialization_info'], record_env)\n",
    "\n",
    "    policy_db.load_model_state_dict(policy_entry['model_id'], policy)\n",
    "\n",
    "    try:\n",
    "        record_env.metadata['render_fps'] = 30\n",
    "        record_env = AutoResetWrapper(\n",
    "            RecordVideo(record_env, video_folder=rf'C:\\Users\\domin\\Videos\\rl\\{get_current_timestamp()}',\n",
    "                        episode_trigger=lambda ep_nr: True)\n",
    "        )\n",
    "\n",
    "        def record(max_steps: int):\n",
    "            with torch.no_grad():\n",
    "                obs, info = record_env.reset()\n",
    "                for step in tqdm(range(max_steps)):\n",
    "                    actions_dist, _ = policy.process_obs(torch.tensor(obs, device='cpu'))\n",
    "                    actions = actions_dist.get_actions(deterministic=True).cpu().numpy()\n",
    "                    obs, reward, terminated, truncated, info = record_env.step(actions)\n",
    "\n",
    "        record(50_000)\n",
    "    except KeyboardInterrupt:\n",
    "        print('keyboard interrupt')\n",
    "    finally:\n",
    "        print('closing record_env')\n",
    "        record_env.close()\n",
    "        print('record_env closed')\n",
    "\n",
    "\n",
    "record_video()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-10T21:30:42.251803Z"
    }
   },
   "id": "9413fb35d2e62be7",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from gymnasium.wrappers import AutoResetWrapper, TimeLimit\n",
    "import torch\n",
    "import numpy as np\n",
    "import gymnasium\n",
    "from gymnasium.core import ActType, ObsType\n",
    "from typing import Any, SupportsFloat\n",
    "from src.reinforcement_learning.core.generalized_advantage_estimate import compute_episode_returns, compute_returns\n",
    "\n",
    "\n",
    "class TestEnv(gymnasium.Env):\n",
    "    counter: int\n",
    "\n",
    "    def reset(\n",
    "            self,\n",
    "            *,\n",
    "            seed: int | None = None,\n",
    "            options: dict[str, Any] | None = None,\n",
    "    ) -> tuple[ObsType, dict[str, Any]]:\n",
    "        self.counter = 0\n",
    "        return np.array([self.counter]), {}\n",
    "\n",
    "    def step(\n",
    "            self, action: ActType\n",
    "    ) -> tuple[ObsType, SupportsFloat, bool, bool, dict[str, Any]]:\n",
    "        self.counter += 1\n",
    "        done_ = self.counter >= 10\n",
    "\n",
    "        if done_:\n",
    "            reward_ = 5.0\n",
    "        else:\n",
    "            reward_ = 0.0\n",
    "\n",
    "        return np.array([self.counter]), reward_, done_, False, {}\n",
    "\n",
    "\n",
    "env = AutoResetWrapper(TimeLimit(TestEnv(), 100))\n",
    "obs, _ = env.reset()\n",
    "episode_starts = True\n",
    "\n",
    "obs_l = []\n",
    "rewards = []\n",
    "dones = []\n",
    "\n",
    "for i in range(50):\n",
    "    next_obs, reward, terminated, truncated, _ = env.step(None)\n",
    "    obs_l.append(obs)\n",
    "    rewards.append(reward)\n",
    "    dones.append(episode_starts)\n",
    "    episode_starts = np.logical_or(terminated, truncated)\n",
    "    obs = next_obs\n",
    "\n",
    "returns, episode_returns = compute_episode_returns(\n",
    "    rewards=np.array(rewards)[:, np.newaxis],\n",
    "    episode_starts=np.array(dones)[:, np.newaxis],\n",
    "    last_episode_starts=np.array([episode_starts]),\n",
    "    gamma=1.0,\n",
    "    gae_lambda=1.0,\n",
    "    normalize_rewards=None,\n",
    "    remove_unfinished_episodes=True\n",
    ")\n",
    "\n",
    "for i, (obs_, reward_, return_, done) in enumerate(zip(obs_l, rewards, returns, dones)):\n",
    "    print(f'{i}; {obs_}; {reward_}; {return_}; {done}')\n",
    "print(obs, episode_starts)\n",
    "print()\n",
    "\n",
    "print(len(episode_returns), np.mean(episode_returns), np.std(episode_returns))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-14T18:37:33.198877Z",
     "start_time": "2024-06-14T18:37:33.185470Z"
    }
   },
   "id": "70f22b7cb50ff18a",
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "232fbbf514e29e1d",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from torch import nn\n",
    "\n",
    "from src.networks.core.net import Net\n",
    "from src.networks.multihead_self_attention import MultiheadSelfAttention\n",
    "from src.networks.core.seq_net import SeqNet\n",
    "from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n",
    "\n",
    "device = 'cuda:0'\n",
    "\n",
    "transformer_encoder_net = SeqNet.from_layer_provider(\n",
    "    layer_provider=lambda layer_nr, is_last_layer, in_features, out_features:\n",
    "    nn.Sequential(\n",
    "        AdditiveSkipConnection(MultiheadSelfAttention(\n",
    "            embed_dim=in_features,\n",
    "            num_heads=8,\n",
    "        )),\n",
    "        nn.LayerNorm(in_features),\n",
    "        AdditiveSkipConnection(Net.seq_as_net(\n",
    "            nn.Linear(in_features, 2048),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(2048, out_features),\n",
    "            nn.ReLU(),\n",
    "        )),\n",
    "        nn.LayerNorm(out_features),\n",
    "    ),\n",
    "    num_layers=6,\n",
    "    num_features=512,\n",
    ").to(device)\n",
    "\n",
    "transformer_encoder_net.out_shape\n",
    "transformer_encoder_net(torch.tensor(np.random.random((7, 5, 512))).to(device).float()).shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-15T15:33:07.121293Z",
     "start_time": "2024-07-15T15:33:06.915581Z"
    }
   },
   "id": "ca1327e49698c9da",
   "execution_count": 14,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "transformer_encoder = nn.TransformerEncoder(\n",
    "    nn.TransformerEncoderLayer(\n",
    "        d_model=512,\n",
    "        nhead=8,\n",
    "        dropout=0,\n",
    "    ),\n",
    "    num_layers=6\n",
    ").to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-05T23:53:19.747323Z",
     "start_time": "2024-07-05T23:53:19.693332Z"
    }
   },
   "id": "a6a3505b70768b0e",
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "data1 = torch.Tensor(np.random.random((100, 4, 512))).to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-05T23:53:19.753832Z",
     "start_time": "2024-07-05T23:53:19.748319Z"
    }
   },
   "id": "d74db2b4169c9712",
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "%%timeit -r 15 -n 500\n",
    "transformer_encoder_net(data1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-05T23:34:06.647640Z",
     "start_time": "2024-07-05T23:33:41.810146Z"
    }
   },
   "id": "6801cd3030143976",
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "%%timeit -r 15 -n 500\n",
    "transformer_encoder(data1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-05T23:34:31.399154Z",
     "start_time": "2024-07-05T23:34:06.648632Z"
    }
   },
   "id": "59acf00355898753",
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "6b0e27af3eb4c76d",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "data2 = torch.Tensor(np.random.random((100, 64, 512))).to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-05T23:35:49.613591Z",
     "start_time": "2024-07-05T23:35:49.577024Z"
    }
   },
   "id": "958cbae4fc1ed2dd",
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "%%timeit -r 15 -n 200\n",
    "transformer_encoder_net(data2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-05T23:37:24.849456Z",
     "start_time": "2024-07-05T23:35:49.737039Z"
    }
   },
   "id": "ba5c753fd48bb3e2",
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "%%timeit -r 15 -n 200\n",
    "transformer_encoder(data2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-05T23:38:59.007342Z",
     "start_time": "2024-07-05T23:37:24.850450Z"
    }
   },
   "id": "eccc331c444d129b",
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-05T23:38:59.009667Z",
     "start_time": "2024-07-05T23:38:59.007342Z"
    }
   },
   "id": "87ab683d0b8ca53f",
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "data3 = torch.Tensor(np.random.random((100, 512, 512))).to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-05T23:53:25.852521Z",
     "start_time": "2024-07-05T23:53:25.608954Z"
    }
   },
   "id": "2fcee7ab143e2a70",
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "%%timeit -r 5 -n 50\n",
    "transformer_encoder_net(data3)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-07-05T23:53:28.924077Z"
    }
   },
   "id": "395828e5ae3ee6c0",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "%%timeit -r 5 -n 50\n",
    "transformer_encoder(data3)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a753c9f1c37aee40",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "\n",
    "def relu(x):\n",
    "    return x * (x > 0)\n",
    "\n",
    "def elu(x, alpha=1.0):\n",
    "    return np.where(x > 0, x, alpha * (np.exp(x) - 1))\n",
    "\n",
    "def leaky_relu(x, alpha=0.1):\n",
    "    return np.where(x > 0, x, alpha * x)\n",
    "\n",
    "factors = np.array([1, 2, 5])\n",
    "num_iterations = 10000\n",
    "for d in np.concatenate((factors, factors * 10, factors * 100, factors * 1000, np.array([10_000]))):\n",
    "    sum_ = 0\n",
    "    for _ in range(num_iterations):\n",
    "        v1 = (np.random.rand(d) - 0.5) * 2\n",
    "        v2 = (np.random.rand(d) - 0.5) * 2\n",
    "        \n",
    "        v1 /= np.linalg.norm(v1)\n",
    "        v2 /= np.linalg.norm(v2)\n",
    "        \n",
    "        v1 = leaky_relu(v1)\n",
    "        v2 = leaky_relu(v2)\n",
    "        \n",
    "        sum_ += np.abs(np.inner(v1, v2))\n",
    "    \n",
    "    print(f'd={d:>5}: {sum_ / num_iterations}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-11T14:37:27.132969Z",
     "start_time": "2024-07-11T14:37:20.469439Z"
    }
   },
   "id": "fee8afbe385584e4",
   "execution_count": 20,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from src.networks.global_pooling import GlobalAveragePooling\n",
    "from src.networks.core.tensor_shape import TensorShape\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from src.networks.core.net import Net\n",
    "from src.networks.skip_nets.dense_skip_net import DenseSkipNet\n",
    "from torch import nn\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "    \n",
    "def make_dense_block(in_features: int, num_layers: int, growth_rate: int = 32):\n",
    "    return DenseSkipNet.from_layer_provider(\n",
    "        lambda layer_nr, is_last_layer, in_channels, out_channels:\n",
    "            Net.seq_as_net(\n",
    "                nn.BatchNorm2d(in_channels),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(in_channels, 4 * growth_rate, 1),\n",
    "                nn.BatchNorm2d(4 * growth_rate),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(4 * growth_rate, growth_rate, 3, padding='same')\n",
    "            ),\n",
    "        in_size=in_features,\n",
    "        out_sizes=[growth_rate] * num_layers,\n",
    "        feature_dim_index=1,\n",
    "    )\n",
    "\n",
    "def make_transition_layer(in_features: int):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_features, int(in_features / 2), 1),\n",
    "        nn.AvgPool2d(2, 2),\n",
    "    )\n",
    "\n",
    "dense_net_121 = Net.provider_seq_as_net(\n",
    "    3,\n",
    "    lambda in_f: nn.Conv2d(in_f, 64, 7, 2),\n",
    "    lambda in_f: nn.MaxPool2d(3, 2),\n",
    "    lambda in_f: make_dense_block(in_f, 6),\n",
    "    lambda in_f: make_transition_layer(in_f),\n",
    "    lambda in_f: make_dense_block(in_f, 12),\n",
    "    lambda in_f: make_transition_layer(in_f),\n",
    "    lambda in_f: make_dense_block(in_f, 24),\n",
    "    lambda in_f: make_transition_layer(in_f),\n",
    "    lambda in_f: make_dense_block(in_f, 16),\n",
    "    lambda in_f: GlobalAveragePooling((2, 3)),\n",
    "    lambda in_f: nn.Linear(in_f, 1000)\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-15T15:31:16.453011Z",
     "start_time": "2024-07-15T15:31:16.068139Z"
    }
   },
   "id": "610b336aab8028a7",
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "e9e4d76c618f7594"
  },
  {
   "cell_type": "code",
   "source": [
    "import sympy as sp\n",
    "expr = sp.Symbol('features') + 1\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-14T21:36:28.769379Z",
     "start_time": "2024-07-14T21:36:28.710794Z"
    }
   },
   "id": "6d302bfb3f5f6b25",
   "execution_count": 30,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "tuple((1, 2))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-15T14:58:25.471858Z",
     "start_time": "2024-07-15T14:58:25.464276Z"
    }
   },
   "id": "a489cb0ab6ba2f5a",
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-23T20:59:46.085099Z",
     "start_time": "2024-08-23T20:59:43.857177Z"
    }
   },
   "id": "a0f3b42a906982f0",
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "data = np.random.random((5000, 128, 255))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-23T20:59:47.112720Z",
     "start_time": "2024-08-23T20:59:46.086097Z"
    }
   },
   "id": "fd6b92e1c52e4cfe",
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "255 ms ± 12.8 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "torch_data = torch.tensor(data)\n",
    "results = []\n",
    "\n",
    "for i in range(0, 5000, 500):\n",
    "    result = torch_data[i:i+500].mean()\n",
    "    results.append(result)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-23T21:01:22.364063Z",
     "start_time": "2024-08-23T21:01:01.099721Z"
    }
   },
   "id": "3910fea46a825f63",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "208 ms ± 21.1 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "torch_data = torch.tensor(data)\n",
    "results = []\n",
    "\n",
    "for i in range(0, 5000, 500):\n",
    "    result = torch.as_tensor(torch_data[i:i+500])\n",
    "    results.append(result)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-23T21:01:24.432411Z",
     "start_time": "2024-08-23T21:01:22.365060Z"
    }
   },
   "id": "e35fda398ab06e6a",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164 ms ± 42.9 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "results = []\n",
    "\n",
    "for i in range(0, 5000, 500):\n",
    "    result = torch.tensor(data[i:i+500], device='cuda')\n",
    "    results.append(result)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-23T21:14:20.942675Z",
     "start_time": "2024-08-23T21:14:19.417696Z"
    }
   },
   "id": "bcedfc01858213f8",
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "torch_data = torch.tensor(data)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-23T21:09:07.168595Z",
     "start_time": "2024-08-23T21:09:07.006031Z"
    }
   },
   "id": "65b739364a9db817",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160 ms ± 28.2 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "results = []\n",
    "\n",
    "for i in range(0, 5000, 500):\n",
    "    result = torch_data[i:i+500].to('cuda').mean()\n",
    "    results.append(result)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-23T21:10:02.616972Z",
     "start_time": "2024-08-23T21:10:00.937085Z"
    }
   },
   "id": "1bab2d2703ac5a59",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -14.7    |\n",
      "| time/              |          |\n",
      "|    fps             | 424      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 4        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | -4.03       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 500         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 8           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008423874 |\n",
      "|    clip_fraction        | 0.0456      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.52       |\n",
      "|    explained_variance   | -0.0242     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 12.1        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.012      |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 24.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | -15.2       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 532         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 11          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006844442 |\n",
      "|    clip_fraction        | 0.0225      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.52       |\n",
      "|    explained_variance   | 0.00768     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 36.2        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.00887    |\n",
      "|    std                  | 0.999       |\n",
      "|    value_loss           | 64.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | -27.1       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 552         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 14          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009357647 |\n",
      "|    clip_fraction        | 0.049       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.51       |\n",
      "|    explained_variance   | 0.0242      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 10          |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0127     |\n",
      "|    std                  | 0.999       |\n",
      "|    value_loss           | 19.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | -47.9       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 576         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 17          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008894008 |\n",
      "|    clip_fraction        | 0.0417      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.51       |\n",
      "|    explained_variance   | 0.0115      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 17.5        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0127     |\n",
      "|    std                  | 0.998       |\n",
      "|    value_loss           | 35.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | -44.3       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 582         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 21          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008067158 |\n",
      "|    clip_fraction        | 0.0341      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.5        |\n",
      "|    explained_variance   | 0.00152     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 11.4        |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    std                  | 0.996       |\n",
      "|    value_loss           | 23.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | -48.2       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 590         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 24          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006665373 |\n",
      "|    clip_fraction        | 0.0232      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.48       |\n",
      "|    explained_variance   | 0.008       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 17.7        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0108     |\n",
      "|    std                  | 0.994       |\n",
      "|    value_loss           | 31.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1e+03        |\n",
      "|    ep_rew_mean          | -54.9        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 590          |\n",
      "|    iterations           | 8            |\n",
      "|    time_elapsed         | 27           |\n",
      "|    total_timesteps      | 16384        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045819553 |\n",
      "|    clip_fraction        | 0.00972      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.49        |\n",
      "|    explained_variance   | 0.0657       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 23.8         |\n",
      "|    n_updates            | 70           |\n",
      "|    policy_gradient_loss | -0.00801     |\n",
      "|    std                  | 0.997        |\n",
      "|    value_loss           | 51.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1e+03        |\n",
      "|    ep_rew_mean          | -57.6        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 593          |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 31           |\n",
      "|    total_timesteps      | 18432        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064609367 |\n",
      "|    clip_fraction        | 0.0211       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.49        |\n",
      "|    explained_variance   | 0.0404       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 14.5         |\n",
      "|    n_updates            | 80           |\n",
      "|    policy_gradient_loss | -0.00943     |\n",
      "|    std                  | 0.996        |\n",
      "|    value_loss           | 31.5         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[6], line 9\u001B[0m\n\u001B[0;32m      6\u001B[0m env \u001B[38;5;241m=\u001B[39m gym\u001B[38;5;241m.\u001B[39mmake(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mHalfCheetah-v4\u001B[39m\u001B[38;5;124m\"\u001B[39m, render_mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m{\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mforward_reward_weight\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;241m1.25\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mctrl_cost_weight\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;241m0.001\u001B[39m })\n\u001B[0;32m      8\u001B[0m model \u001B[38;5;241m=\u001B[39m PPO(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMlpPolicy\u001B[39m\u001B[38;5;124m\"\u001B[39m, env, verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m10\u001B[39m, target_kl\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.025\u001B[39m, batch_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m512\u001B[39m)\n\u001B[1;32m----> 9\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlearn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtotal_timesteps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m100_000\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\Program Files\\Python311\\Lib\\site-packages\\stable_baselines3\\ppo\\ppo.py:315\u001B[0m, in \u001B[0;36mPPO.learn\u001B[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001B[0m\n\u001B[0;32m    306\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mlearn\u001B[39m(\n\u001B[0;32m    307\u001B[0m     \u001B[38;5;28mself\u001B[39m: SelfPPO,\n\u001B[0;32m    308\u001B[0m     total_timesteps: \u001B[38;5;28mint\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    313\u001B[0m     progress_bar: \u001B[38;5;28mbool\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[0;32m    314\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m SelfPPO:\n\u001B[1;32m--> 315\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlearn\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    316\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtotal_timesteps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtotal_timesteps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    317\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcallback\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallback\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    318\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlog_interval\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlog_interval\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    319\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtb_log_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtb_log_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    320\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreset_num_timesteps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreset_num_timesteps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    321\u001B[0m \u001B[43m        \u001B[49m\u001B[43mprogress_bar\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mprogress_bar\u001B[49m\n\u001B[0;32m    322\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\Program Files\\Python311\\Lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:300\u001B[0m, in \u001B[0;36mOnPolicyAlgorithm.learn\u001B[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001B[0m\n\u001B[0;32m    297\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39menv \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    299\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_timesteps \u001B[38;5;241m<\u001B[39m total_timesteps:\n\u001B[1;32m--> 300\u001B[0m     continue_training \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcollect_rollouts\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43menv\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallback\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrollout_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_rollout_steps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mn_steps\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    302\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m continue_training:\n\u001B[0;32m    303\u001B[0m         \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "File \u001B[1;32mC:\\Program Files\\Python311\\Lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:179\u001B[0m, in \u001B[0;36mOnPolicyAlgorithm.collect_rollouts\u001B[1;34m(self, env, callback, rollout_buffer, n_rollout_steps)\u001B[0m\n\u001B[0;32m    176\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m th\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[0;32m    177\u001B[0m     \u001B[38;5;66;03m# Convert to pytorch tensor or to TensorDict\u001B[39;00m\n\u001B[0;32m    178\u001B[0m     obs_tensor \u001B[38;5;241m=\u001B[39m obs_as_tensor(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_last_obs, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice)\n\u001B[1;32m--> 179\u001B[0m     actions, values, log_probs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpolicy\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobs_tensor\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    180\u001B[0m actions \u001B[38;5;241m=\u001B[39m actions\u001B[38;5;241m.\u001B[39mcpu()\u001B[38;5;241m.\u001B[39mnumpy()\n\u001B[0;32m    182\u001B[0m \u001B[38;5;66;03m# Rescale and perform action\u001B[39;00m\n",
      "File \u001B[1;32mC:\\Program Files\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\Program Files\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32mC:\\Program Files\\Python311\\Lib\\site-packages\\stable_baselines3\\common\\policies.py:656\u001B[0m, in \u001B[0;36mActorCriticPolicy.forward\u001B[1;34m(self, obs, deterministic)\u001B[0m\n\u001B[0;32m    654\u001B[0m distribution \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_action_dist_from_latent(latent_pi)\n\u001B[0;32m    655\u001B[0m actions \u001B[38;5;241m=\u001B[39m distribution\u001B[38;5;241m.\u001B[39mget_actions(deterministic\u001B[38;5;241m=\u001B[39mdeterministic)\n\u001B[1;32m--> 656\u001B[0m log_prob \u001B[38;5;241m=\u001B[39m \u001B[43mdistribution\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlog_prob\u001B[49m\u001B[43m(\u001B[49m\u001B[43mactions\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    657\u001B[0m actions \u001B[38;5;241m=\u001B[39m actions\u001B[38;5;241m.\u001B[39mreshape((\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39maction_space\u001B[38;5;241m.\u001B[39mshape))  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m    658\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m actions, values, log_prob\n",
      "File \u001B[1;32mC:\\Program Files\\Python311\\Lib\\site-packages\\stable_baselines3\\common\\distributions.py:175\u001B[0m, in \u001B[0;36mDiagGaussianDistribution.log_prob\u001B[1;34m(self, actions)\u001B[0m\n\u001B[0;32m    167\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mlog_prob\u001B[39m(\u001B[38;5;28mself\u001B[39m, actions: th\u001B[38;5;241m.\u001B[39mTensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m th\u001B[38;5;241m.\u001B[39mTensor:\n\u001B[0;32m    168\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    169\u001B[0m \u001B[38;5;124;03m    Get the log probabilities of actions according to the distribution.\u001B[39;00m\n\u001B[0;32m    170\u001B[0m \u001B[38;5;124;03m    Note that you must first call the ``proba_distribution()`` method.\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    173\u001B[0m \u001B[38;5;124;03m    :return:\u001B[39;00m\n\u001B[0;32m    174\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 175\u001B[0m     log_prob \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdistribution\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlog_prob\u001B[49m\u001B[43m(\u001B[49m\u001B[43mactions\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    176\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m sum_independent_dims(log_prob)\n",
      "File \u001B[1;32mC:\\Program Files\\Python311\\Lib\\site-packages\\torch\\distributions\\normal.py:81\u001B[0m, in \u001B[0;36mNormal.log_prob\u001B[1;34m(self, value)\u001B[0m\n\u001B[0;32m     79\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_validate_sample(value)\n\u001B[0;32m     80\u001B[0m \u001B[38;5;66;03m# compute the variance\u001B[39;00m\n\u001B[1;32m---> 81\u001B[0m var \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mscale\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m2\u001B[39;49m\n\u001B[0;32m     82\u001B[0m log_scale \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m     83\u001B[0m     math\u001B[38;5;241m.\u001B[39mlog(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mscale) \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mscale, Real) \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mscale\u001B[38;5;241m.\u001B[39mlog()\n\u001B[0;32m     84\u001B[0m )\n\u001B[0;32m     85\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m (\n\u001B[0;32m     86\u001B[0m     \u001B[38;5;241m-\u001B[39m((value \u001B[38;5;241m-\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mloc) \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m \u001B[38;5;241m2\u001B[39m) \u001B[38;5;241m/\u001B[39m (\u001B[38;5;241m2\u001B[39m \u001B[38;5;241m*\u001B[39m var)\n\u001B[0;32m     87\u001B[0m     \u001B[38;5;241m-\u001B[39m log_scale\n\u001B[0;32m     88\u001B[0m     \u001B[38;5;241m-\u001B[39m math\u001B[38;5;241m.\u001B[39mlog(math\u001B[38;5;241m.\u001B[39msqrt(\u001B[38;5;241m2\u001B[39m \u001B[38;5;241m*\u001B[39m math\u001B[38;5;241m.\u001B[39mpi))\n\u001B[0;32m     89\u001B[0m )\n",
      "File \u001B[1;32mC:\\Program Files\\Python311\\Lib\\site-packages\\torch\\_tensor.py:34\u001B[0m, in \u001B[0;36m_handle_torch_function_and_wrap_type_error_to_not_implemented.<locals>.wrapped\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     31\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_handle_torch_function_and_wrap_type_error_to_not_implemented\u001B[39m(f):\n\u001B[0;32m     32\u001B[0m     assigned \u001B[38;5;241m=\u001B[39m functools\u001B[38;5;241m.\u001B[39mWRAPPER_ASSIGNMENTS\n\u001B[1;32m---> 34\u001B[0m     \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(f, assigned\u001B[38;5;241m=\u001B[39massigned)\n\u001B[0;32m     35\u001B[0m     \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrapped\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m     36\u001B[0m         \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     37\u001B[0m             \u001B[38;5;66;03m# See https://github.com/pytorch/pytorch/issues/75462\u001B[39;00m\n\u001B[0;32m     38\u001B[0m             \u001B[38;5;28;01mif\u001B[39;00m has_torch_function(args):\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from stable_baselines3.common.vec_env import SubprocVecEnv\n",
    "import gymnasium as gym\n",
    "\n",
    "from stable_baselines3 import PPO\n",
    "\n",
    "env = SubprocVecEnv([lambda: gym.make(\"HalfCheetah-v4\", render_mode=None, **{'forward_reward_weight': 1.25, 'ctrl_cost_weight': 0.001 })] * 16)\n",
    "\n",
    "model = PPO(\"MlpPolicy\", env, verbose=10, target_kl=0.025, batch_size=512)\n",
    "model.learn(total_timesteps=100_000)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-25T20:37:35.918916Z",
     "start_time": "2024-08-25T20:37:01.702040Z"
    }
   },
   "id": "cafc1b1cfd538e72",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "ff6d13d96bb2339a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
