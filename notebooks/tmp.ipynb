{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-17T16:16:59.862463Z",
     "start_time": "2024-05-17T16:16:59.846803Z"
    }
   },
   "source": [
    "from typing import SupportsFloat, Any\n",
    "\n",
    "from gymnasium.core import ActType, ObsType\n",
    "\n",
    "from src.reinforcement_learning.core.infos import InfoDict\n",
    "from tmp_mp import main"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "main()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-23T20:07:27.012896Z",
     "start_time": "2024-07-23T20:07:26.784305Z"
    }
   },
   "id": "83a784f8b65b74f8",
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "\n",
    "# Parallel environments\n",
    "vec_env = make_vec_env(\"HalfCheetah-v4\", n_envs=4)\n",
    "\n",
    "model = PPO(\"MlpPolicy\", vec_env, use_sde=True, sde_sample_freq=100, verbose=2)\n",
    "model.learn(total_timesteps=250000)\n",
    "model.save(\"ppo_cartpole\")\n",
    "\n",
    "del model  # remove to demonstrate saving and loading\n",
    "\n",
    "model = PPO.load(\"ppo_cartpole\")\n",
    "\n",
    "obs = vec_env.reset()\n",
    "# while True:\n",
    "#     action, _states = model.predict(obs)\n",
    "#     obs, rewards, dones, info = vec_env.step(action)\n",
    "#     vec_env.render(\"human\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T22:15:54.226301Z",
     "start_time": "2024-05-23T22:14:18.948367Z"
    }
   },
   "id": "6d26ca5d3fba5ab7",
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "model.target_entropy"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-22T19:27:57.633590Z",
     "start_time": "2024-09-22T19:27:57.630129Z"
    }
   },
   "id": "d806304b085dce6e",
   "execution_count": 16,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "rollout_data = np.random.random((2500, 32, 17))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T22:42:33.450537Z",
     "start_time": "2024-05-23T22:42:33.437024Z"
    }
   },
   "id": "8f542b5b7a30c20d",
   "execution_count": 14,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "%%timeit\n",
    "for i in range(len(rollout_data)):\n",
    "    tensor = torch.tensor(rollout_data[i], device='cuda')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T22:42:46.607754Z",
     "start_time": "2024-05-23T22:42:33.589059Z"
    }
   },
   "id": "7e926ae1d8feae57",
   "execution_count": 15,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import types\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "class A(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(17, 17)\n",
    "\n",
    "        self.forward = self.linear.forward\n",
    "\n",
    "    # def forward(self, x):\n",
    "    #     return self.linear(x)\n",
    "\n",
    "\n",
    "test_data = torch.tensor(np.random.random((2500, 1024, 17))).float()\n",
    "\n",
    "a = A()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-28T17:25:49.731860Z",
     "start_time": "2024-05-28T17:25:49.343973Z"
    }
   },
   "id": "18b462eb301c3290",
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "%%timeit\n",
    "\n",
    "for i in range(len(test_data)):\n",
    "    a(test_data[i])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-28T17:26:00.167853Z",
     "start_time": "2024-05-28T17:25:49.732855Z"
    }
   },
   "id": "25fc61df57f13567",
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "%%timeit\n",
    "\n",
    "for i in range(len(test_data)):\n",
    "    a(test_data[i]).detach()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-28T17:26:11.629808Z",
     "start_time": "2024-05-28T17:26:00.168853Z"
    }
   },
   "id": "3e64a75ffcb3f542",
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from src.torch_device import get_torch_device\n",
    "\n",
    "get_torch_device()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-29T19:20:16.958767Z",
     "start_time": "2024-05-29T19:20:11.568280Z"
    }
   },
   "id": "c22c1a2827faef5",
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import gymnasium\n",
    "\n",
    "gymnasium.make('Ant-v4', )"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "11fe74cc94873a0b",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "def record_video():\n",
    "    import torch\n",
    "    from tqdm import tqdm\n",
    "    from src.reinforcement_learning.gym.singleton_vector_env import as_vec_env\n",
    "    import gymnasium\n",
    "    from gymnasium.wrappers import AutoResetWrapper, RecordVideo\n",
    "    from src.model_db.tiny_model_db import TinyModelDB\n",
    "    from src.reinforcement_learning.algorithms.policy_mitosis.mitosis_policy_info import MitosisPolicyInfo\n",
    "    from src.reinforcement_learning.core.policy_construction import PolicyConstruction\n",
    "    from src.datetime import get_current_timestamp\n",
    "\n",
    "    record_env, _ = as_vec_env(gymnasium.make('Ant-v4', render_mode='rgb_array'))\n",
    "\n",
    "    policy_db = TinyModelDB[MitosisPolicyInfo](base_path=f'E:/saved_models/rl/Ant-v4/mitosis-2024-06-10_19.43.13')\n",
    "    print(policy_db)\n",
    "\n",
    "    policy_entry = list(sorted(policy_db.all_entries(), key=lambda entry: entry['model_info']['score']))[-2]\n",
    "    # policy_entry = policy_db.fetch_entry('2024-06-10_22.13.57~PJHPLG')\n",
    "    policy_info: MitosisPolicyInfo = policy_entry['model_info']\n",
    "    print(policy_entry)\n",
    "\n",
    "    policy, _, record_env = PolicyConstruction.init_from_info(policy_info['initialization_info'], record_env)\n",
    "\n",
    "    policy_db.load_model_state_dict(policy_entry['model_id'], policy)\n",
    "\n",
    "    try:\n",
    "        record_env.metadata['render_fps'] = 30\n",
    "        record_env = AutoResetWrapper(\n",
    "            RecordVideo(record_env, video_folder=rf'C:\\Users\\domin\\Videos\\rl\\{get_current_timestamp()}',\n",
    "                        episode_trigger=lambda ep_nr: True)\n",
    "        )\n",
    "\n",
    "        def record(max_steps: int):\n",
    "            with torch.no_grad():\n",
    "                obs, info = record_env.reset()\n",
    "                for step in tqdm(range(max_steps)):\n",
    "                    actions_dist, _ = policy.process_obs(torch.tensor(obs, device='cpu'))\n",
    "                    actions = actions_dist.get_actions(deterministic=True).cpu().numpy()\n",
    "                    obs, reward, terminated, truncated, info = record_env.step(actions)\n",
    "\n",
    "        record(50_000)\n",
    "    except KeyboardInterrupt:\n",
    "        print('keyboard interrupt')\n",
    "    finally:\n",
    "        print('closing record_env')\n",
    "        record_env.close()\n",
    "        print('record_env closed')\n",
    "\n",
    "\n",
    "record_video()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-10T21:30:42.251803Z"
    }
   },
   "id": "9413fb35d2e62be7",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "232fbbf514e29e1d",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from torch import nn\n",
    "\n",
    "from src.networks.core.net import Net\n",
    "from src.networks.multihead_self_attention import MultiheadSelfAttention\n",
    "from src.networks.core.seq_net import SeqNet\n",
    "from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n",
    "\n",
    "device = 'cuda:0'\n",
    "\n",
    "transformer_encoder_net = SeqNet.from_layer_provider(\n",
    "    layer_provider=lambda layer_nr, is_last_layer, in_features, out_features:\n",
    "    nn.Sequential(\n",
    "        AdditiveSkipConnection(MultiheadSelfAttention(\n",
    "            embed_dim=in_features,\n",
    "            num_heads=8,\n",
    "        )),\n",
    "        nn.LayerNorm(in_features),\n",
    "        AdditiveSkipConnection(Net.seq_as_net(\n",
    "            nn.Linear(in_features, 2048),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(2048, out_features),\n",
    "            nn.ReLU(),\n",
    "        )),\n",
    "        nn.LayerNorm(out_features),\n",
    "    ),\n",
    "    num_layers=6,\n",
    "    num_features=512,\n",
    ").to(device)\n",
    "\n",
    "transformer_encoder_net.out_shape\n",
    "transformer_encoder_net(torch.tensor(np.random.random((7, 5, 512))).to(device).float()).shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-15T15:33:07.121293Z",
     "start_time": "2024-07-15T15:33:06.915581Z"
    }
   },
   "id": "ca1327e49698c9da",
   "execution_count": 14,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "transformer_encoder = nn.TransformerEncoder(\n",
    "    nn.TransformerEncoderLayer(\n",
    "        d_model=512,\n",
    "        nhead=8,\n",
    "        dropout=0,\n",
    "    ),\n",
    "    num_layers=6\n",
    ").to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-05T23:53:19.747323Z",
     "start_time": "2024-07-05T23:53:19.693332Z"
    }
   },
   "id": "a6a3505b70768b0e",
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "data1 = torch.Tensor(np.random.random((100, 4, 512))).to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-05T23:53:19.753832Z",
     "start_time": "2024-07-05T23:53:19.748319Z"
    }
   },
   "id": "d74db2b4169c9712",
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "%%timeit -r 15 -n 500\n",
    "transformer_encoder_net(data1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-05T23:34:06.647640Z",
     "start_time": "2024-07-05T23:33:41.810146Z"
    }
   },
   "id": "6801cd3030143976",
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "%%timeit -r 15 -n 500\n",
    "transformer_encoder(data1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-05T23:34:31.399154Z",
     "start_time": "2024-07-05T23:34:06.648632Z"
    }
   },
   "id": "59acf00355898753",
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "6b0e27af3eb4c76d",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "data2 = torch.Tensor(np.random.random((100, 64, 512))).to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-05T23:35:49.613591Z",
     "start_time": "2024-07-05T23:35:49.577024Z"
    }
   },
   "id": "958cbae4fc1ed2dd",
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "%%timeit -r 15 -n 200\n",
    "transformer_encoder_net(data2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-05T23:37:24.849456Z",
     "start_time": "2024-07-05T23:35:49.737039Z"
    }
   },
   "id": "ba5c753fd48bb3e2",
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "%%timeit -r 15 -n 200\n",
    "transformer_encoder(data2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-05T23:38:59.007342Z",
     "start_time": "2024-07-05T23:37:24.850450Z"
    }
   },
   "id": "eccc331c444d129b",
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-05T23:38:59.009667Z",
     "start_time": "2024-07-05T23:38:59.007342Z"
    }
   },
   "id": "87ab683d0b8ca53f",
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "data3 = torch.Tensor(np.random.random((100, 512, 512))).to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-05T23:53:25.852521Z",
     "start_time": "2024-07-05T23:53:25.608954Z"
    }
   },
   "id": "2fcee7ab143e2a70",
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "%%timeit -r 5 -n 50\n",
    "transformer_encoder_net(data3)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-07-05T23:53:28.924077Z"
    }
   },
   "id": "395828e5ae3ee6c0",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "%%timeit -r 5 -n 50\n",
    "transformer_encoder(data3)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a753c9f1c37aee40",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "\n",
    "def relu(x):\n",
    "    return x * (x > 0)\n",
    "\n",
    "def elu(x, alpha=1.0):\n",
    "    return np.where(x > 0, x, alpha * (np.exp(x) - 1))\n",
    "\n",
    "def leaky_relu(x, alpha=0.1):\n",
    "    return np.where(x > 0, x, alpha * x)\n",
    "\n",
    "factors = np.array([1, 2, 5])\n",
    "num_iterations = 10000\n",
    "for d in np.concatenate((factors, factors * 10, factors * 100, factors * 1000, np.array([10_000]))):\n",
    "    sum_ = 0\n",
    "    for _ in range(num_iterations):\n",
    "        v1 = (np.random.rand(d) - 0.5) * 2\n",
    "        v2 = (np.random.rand(d) - 0.5) * 2\n",
    "        \n",
    "        v1 /= np.linalg.norm(v1)\n",
    "        v2 /= np.linalg.norm(v2)\n",
    "        \n",
    "        v1 = leaky_relu(v1)\n",
    "        v2 = leaky_relu(v2)\n",
    "        \n",
    "        sum_ += np.abs(np.inner(v1, v2))\n",
    "    \n",
    "    print(f'd={d:>5}: {sum_ / num_iterations}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-11T14:37:27.132969Z",
     "start_time": "2024-07-11T14:37:20.469439Z"
    }
   },
   "id": "fee8afbe385584e4",
   "execution_count": 20,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from src.networks.global_pooling import GlobalAveragePooling\n",
    "from src.networks.core.tensor_shape import TensorShape\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from src.networks.core.net import Net\n",
    "from src.networks.skip_nets.dense_skip_net import DenseSkipNet\n",
    "from torch import nn\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "    \n",
    "def make_dense_block(in_features: int, num_layers: int, growth_rate: int = 32):\n",
    "    return DenseSkipNet.from_layer_provider(\n",
    "        lambda layer_nr, is_last_layer, in_channels, out_channels:\n",
    "            Net.seq_as_net(\n",
    "                nn.BatchNorm2d(in_channels),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(in_channels, 4 * growth_rate, 1),\n",
    "                nn.BatchNorm2d(4 * growth_rate),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(4 * growth_rate, growth_rate, 3, padding='same')\n",
    "            ),\n",
    "        in_size=in_features,\n",
    "        out_sizes=[growth_rate] * num_layers,\n",
    "        feature_dim_index=1,\n",
    "    )\n",
    "\n",
    "def make_transition_layer(in_features: int):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_features, int(in_features / 2), 1),\n",
    "        nn.AvgPool2d(2, 2),\n",
    "    )\n",
    "\n",
    "dense_net_121 = Net.provider_seq_as_net(\n",
    "    3,\n",
    "    lambda in_f: nn.Conv2d(in_f, 64, 7, 2),\n",
    "    lambda in_f: nn.MaxPool2d(3, 2),\n",
    "    lambda in_f: make_dense_block(in_f, 6),\n",
    "    lambda in_f: make_transition_layer(in_f),\n",
    "    lambda in_f: make_dense_block(in_f, 12),\n",
    "    lambda in_f: make_transition_layer(in_f),\n",
    "    lambda in_f: make_dense_block(in_f, 24),\n",
    "    lambda in_f: make_transition_layer(in_f),\n",
    "    lambda in_f: make_dense_block(in_f, 16),\n",
    "    lambda in_f: GlobalAveragePooling((2, 3)),\n",
    "    lambda in_f: nn.Linear(in_f, 1000)\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-15T15:31:16.453011Z",
     "start_time": "2024-07-15T15:31:16.068139Z"
    }
   },
   "id": "610b336aab8028a7",
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "e9e4d76c618f7594"
  },
  {
   "cell_type": "code",
   "source": [
    "import sympy as sp\n",
    "expr = sp.Symbol('features') + 1\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-14T21:36:28.769379Z",
     "start_time": "2024-07-14T21:36:28.710794Z"
    }
   },
   "id": "6d302bfb3f5f6b25",
   "execution_count": 30,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "tuple((1, 2))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-15T14:58:25.471858Z",
     "start_time": "2024-07-15T14:58:25.464276Z"
    }
   },
   "id": "a489cb0ab6ba2f5a",
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-23T20:59:46.085099Z",
     "start_time": "2024-08-23T20:59:43.857177Z"
    }
   },
   "id": "a0f3b42a906982f0",
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "data = np.random.random((5000, 128, 255))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-23T20:59:47.112720Z",
     "start_time": "2024-08-23T20:59:46.086097Z"
    }
   },
   "id": "fd6b92e1c52e4cfe",
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "%%timeit\n",
    "\n",
    "torch_data = torch.tensor(data)\n",
    "results = []\n",
    "\n",
    "for i in range(0, 5000, 500):\n",
    "    result = torch_data[i:i+500].mean()\n",
    "    results.append(result)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-23T21:01:22.364063Z",
     "start_time": "2024-08-23T21:01:01.099721Z"
    }
   },
   "id": "3910fea46a825f63",
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "%%timeit\n",
    "\n",
    "torch_data = torch.tensor(data)\n",
    "results = []\n",
    "\n",
    "for i in range(0, 5000, 500):\n",
    "    result = torch.as_tensor(torch_data[i:i+500])\n",
    "    results.append(result)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-23T21:01:24.432411Z",
     "start_time": "2024-08-23T21:01:22.365060Z"
    }
   },
   "id": "e35fda398ab06e6a",
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "%%timeit\n",
    "\n",
    "results = []\n",
    "\n",
    "for i in range(0, 5000, 500):\n",
    "    result = torch.tensor(data[i:i+500], device='cuda')\n",
    "    results.append(result)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-23T21:14:20.942675Z",
     "start_time": "2024-08-23T21:14:19.417696Z"
    }
   },
   "id": "bcedfc01858213f8",
   "execution_count": 17,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "torch_data = torch.tensor(data)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-23T21:09:07.168595Z",
     "start_time": "2024-08-23T21:09:07.006031Z"
    }
   },
   "id": "65b739364a9db817",
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "%%timeit\n",
    "\n",
    "results = []\n",
    "\n",
    "for i in range(0, 5000, 500):\n",
    "    result = torch_data[i:i+500].to('cuda').mean()\n",
    "    results.append(result)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-23T21:10:02.616972Z",
     "start_time": "2024-08-23T21:10:00.937085Z"
    }
   },
   "id": "1bab2d2703ac5a59",
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from stable_baselines3.common.vec_env import SubprocVecEnv\n",
    "import gymnasium as gym\n",
    "\n",
    "from stable_baselines3 import PPO\n",
    "\n",
    "env = SubprocVecEnv([lambda: gym.make(\"HalfCheetah-v4\", render_mode=None, **{'forward_reward_weight': 1.25, 'ctrl_cost_weight': 0.001 })] * 16)\n",
    "\n",
    "model = PPO(\"MlpPolicy\", env, verbose=10, target_kl=0.025, batch_size=500, n_steps=2500)\n",
    "\n",
    "import cProfile\n",
    "\n",
    "pr = cProfile.Profile()\n",
    "pr.enable()\n",
    "model.learn(total_timesteps=10_000 * 16)\n",
    "pr.disable()\n",
    "pr.dump_stats('profile_stats_sb3.pstat')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-26T15:53:53.547753Z",
     "start_time": "2024-08-26T15:53:03.100735Z"
    }
   },
   "id": "cafc1b1cfd538e72",
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from src.module_analysis import count_parameters\n",
    "\n",
    "count_parameters(model.policy)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-26T15:48:38.639918Z",
     "start_time": "2024-08-26T15:48:38.636159Z"
    }
   },
   "id": "ff6d13d96bb2339a",
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from gymnasium.vector import AsyncVectorEnv, SyncVectorEnv\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "from src.reinforcement_learning.gym.envs.test_env import TestEnv\n",
    "\n",
    "\n",
    "env_fns = [\n",
    "    lambda: TestEnv(1, False, False, 2),\n",
    "    lambda: TestEnv(1, False, False, 3),\n",
    "    lambda: TestEnv(1, False, False, 5),\n",
    "    lambda: TestEnv(1, False, False, 7),\n",
    "    # lambda: TestEnv(1, False, True, 3),\n",
    "    # lambda: TestEnv(1, False, True, 3),\n",
    "    # lambda: TestEnv(1, False, True, 3),\n",
    "    # lambda: TestEnv(1, False, True, 3),\n",
    "]\n",
    "env = SyncVectorEnv(env_fns)\n",
    "\n",
    "# print(env.env_fns[0]().env.episode_length)\n",
    "\n",
    "env.reset()\n",
    "for _ in range(31):\n",
    "    obs, reward, term, trunc, info = env.step(np.zeros((len(env_fns), 2)))\n",
    "    print(obs)\n",
    "    print(np.logical_or(term, trunc))\n",
    "    print(info)\n",
    "    print()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-19T13:58:01.726046Z",
     "start_time": "2024-09-19T13:58:00.540687Z"
    }
   },
   "id": "9953628e12413f3d",
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from src.reinforcement_learning.core.policies.actor_policy import ActorPolicy\n",
    "from src.reinforcement_learning.core.action_noise import NormalActionNoise\n",
    "from src.reinforcement_learning.algorithms.base.logging_config import LoggingConfig\n",
    "from src.reinforcement_learning.core.callback import Callback\n",
    "from src.reinforcement_learning.core.buffers.replay.replay_buffer import ReplayBuffer\n",
    "from src.reinforcement_learning.core.action_selectors.diag_gaussian_action_selector import DiagGaussianActionSelector\n",
    "from src.reinforcement_learning.core.policies.components.actor import Actor\n",
    "from src.reinforcement_learning.core.policies.base_policy import BasePolicy\n",
    "from src.reinforcement_learning.algorithms.base.off_policy_algorithm import OffPolicyAlgorithm\n",
    "from torch import nn\n",
    "import torch\n",
    "\n",
    "\n",
    "class TestOffPolicyAlgo(OffPolicyAlgorithm):\n",
    "    def optimize(self, last_obs: np.ndarray, last_episode_starts: np.ndarray, info: dict) -> None:\n",
    "        print(self.buffer.observations)\n",
    "\n",
    "\n",
    "algo = TestOffPolicyAlgo(\n",
    "    env=env,\n",
    "    policy=ActorPolicy(Actor(nn.Linear(1, 8), DiagGaussianActionSelector(8, 2, 0.0001, False))),\n",
    "    buffer=ReplayBuffer.for_env(env, 10, 'cuda', optimize_memory_usage=False),\n",
    "    gamma=0.99,\n",
    "    tau=0.1,\n",
    "    rollout_steps=10,\n",
    "    gradient_steps=1,\n",
    "    optimization_batch_size=256,\n",
    "    action_noise=NormalActionNoise(np.array([[-5, 5], [5, -5], [0, 0], [-0.5, 0.5]]), np.array([0.1])),\n",
    "    warmup_steps=5,\n",
    "    learning_starts=0,\n",
    "    sde_noise_sample_freq=None,\n",
    "    callback=Callback(),\n",
    "    logging_config=LoggingConfig(),\n",
    "    torch_device='cuda',\n",
    "    torch_dtype=torch.float32,\n",
    ")\n",
    "algo.learn(10)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-19T13:59:11.920346Z",
     "start_time": "2024-09-19T13:59:11.705212Z"
    }
   },
   "id": "99abea17d47a8539",
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "np.concatenate((\n",
    "    algo.buffer.observations, \n",
    "    algo.buffer.next_observations, \n",
    "    algo.buffer.dones[:, :, np.newaxis],\n",
    "    algo.buffer.rewards[:, :, np.newaxis]\n",
    "), axis=-1)[:, 1, :]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-19T14:06:27.580942Z",
     "start_time": "2024-09-19T14:06:27.489992Z"
    }
   },
   "id": "1af12b6ce205d8a7",
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "indices = algo.buffer.sample(40)\n",
    "\n",
    "np.concatenate((\n",
    "    indices.observations.cpu().numpy(),\n",
    "    # samples.actions.cpu().numpy(),\n",
    "    indices.next_observations.cpu().numpy(),\n",
    "    indices.dones.cpu().numpy(),\n",
    "    indices.rewards.cpu().numpy()\n",
    "), axis=-1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-19T14:00:10.459137Z",
     "start_time": "2024-09-19T14:00:10.367940Z"
    }
   },
   "id": "3fbce7251c73ea82",
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "a = np.zeros((4,))\n",
    "b = np.ones((3, 4))\n",
    "\n",
    "b[1] = a\n",
    "\n",
    "a[0] = 2\n",
    "b[1, 1] = 3 \n",
    "\n",
    "print(a)\n",
    "print(b)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-09T22:11:32.839799Z",
     "start_time": "2024-09-09T22:11:32.748825Z"
    }
   },
   "id": "9da07e03064c2712",
   "execution_count": 48,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "bool_arr = np.array([1, 0, 0, 1] + [0] * (32 - 5) + [1], dtype=bool)\n",
    "print(bool_arr.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-13T15:57:01.439292Z",
     "start_time": "2024-09-13T15:57:01.435701Z"
    }
   },
   "id": "763335df698d7a0",
   "execution_count": 35,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "%%timeit\n",
    "s = 0\n",
    "\n",
    "for i, b in enumerate(bool_arr):\n",
    "    if b:\n",
    "        s += i"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-13T15:57:16.360641Z",
     "start_time": "2024-09-13T15:57:01.555043Z"
    }
   },
   "id": "3fcb32dddf37da80",
   "execution_count": 36,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "%%timeit\n",
    "\n",
    "s = 0\n",
    "\n",
    "for i in np.where(bool_arr)[0]:\n",
    "    s += i"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-13T15:57:30.947812Z",
     "start_time": "2024-09-13T15:57:16.361642Z"
    }
   },
   "id": "44acc9dfe6e31be0",
   "execution_count": 37,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "np.where(bool_arr[10:20])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-13T15:59:57.335073Z",
     "start_time": "2024-09-13T15:59:57.331352Z"
    }
   },
   "id": "ae89dfceceac491e",
   "execution_count": 41,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from typing import Any, ClassVar, Dict, List, Optional, Tuple, Type, TypeVar, Union\n",
    "\n",
    "import numpy as np\n",
    "import torch as th\n",
    "from gymnasium import spaces\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from stable_baselines3.common.buffers import ReplayBuffer\n",
    "from stable_baselines3.common.noise import ActionNoise\n",
    "from stable_baselines3.common.off_policy_algorithm import OffPolicyAlgorithm\n",
    "from stable_baselines3.common.policies import BasePolicy, ContinuousCritic\n",
    "from stable_baselines3.common.type_aliases import GymEnv, MaybeCallback, Schedule\n",
    "from stable_baselines3.common.utils import get_parameters_by_name, polyak_update\n",
    "from stable_baselines3.sac.policies import Actor, CnnPolicy, MlpPolicy, MultiInputPolicy, SACPolicy\n",
    "\n",
    "SelfSAC = TypeVar(\"SelfSAC\", bound=\"SAC\")\n",
    "\n",
    "\n",
    "class SAC(OffPolicyAlgorithm):\n",
    "    \"\"\"\n",
    "    Soft Actor-Critic (SAC)\n",
    "    Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor,\n",
    "    This implementation borrows code from original implementation (https://github.com/haarnoja/sac)\n",
    "    from OpenAI Spinning Up (https://github.com/openai/spinningup), from the softlearning repo\n",
    "    (https://github.com/rail-berkeley/softlearning/)\n",
    "    and from Stable Baselines (https://github.com/hill-a/stable-baselines)\n",
    "    Paper: https://arxiv.org/abs/1801.01290\n",
    "    Introduction to SAC: https://spinningup.openai.com/en/latest/algorithms/sac.html\n",
    "\n",
    "    Note: we use double q target and not value target as discussed\n",
    "    in https://github.com/hill-a/stable-baselines/issues/270\n",
    "\n",
    "    :param policy: The policy model to use (MlpPolicy, CnnPolicy, ...)\n",
    "    :param env: The environment to learn from (if registered in Gym, can be str)\n",
    "    :param learning_rate: learning rate for adam optimizer,\n",
    "        the same learning rate will be used for all networks (Q-Values, Actor and Value function)\n",
    "        it can be a function of the current progress remaining (from 1 to 0)\n",
    "    :param buffer_size: size of the replay buffer\n",
    "    :param learning_starts: how many steps of the model to collect transitions for before learning starts\n",
    "    :param batch_size: Minibatch size for each gradient update\n",
    "    :param tau: the soft update coefficient (\"Polyak update\", between 0 and 1)\n",
    "    :param gamma: the discount factor\n",
    "    :param train_freq: Update the model every ``train_freq`` steps. Alternatively pass a tuple of frequency and unit\n",
    "        like ``(5, \"step\")`` or ``(2, \"episode\")``.\n",
    "    :param gradient_steps: How many gradient steps to do after each rollout (see ``train_freq``)\n",
    "        Set to ``-1`` means to do as many gradient steps as steps done in the environment\n",
    "        during the rollout.\n",
    "    :param action_noise: the action noise type (None by default), this can help\n",
    "        for hard exploration problem. Cf common.noise for the different action noise type.\n",
    "    :param replay_buffer_class: Replay buffer class to use (for instance ``HerReplayBuffer``).\n",
    "        If ``None``, it will be automatically selected.\n",
    "    :param replay_buffer_kwargs: Keyword arguments to pass to the replay buffer on creation.\n",
    "    :param optimize_memory_usage: Enable a memory efficient variant of the replay buffer\n",
    "        at a cost of more complexity.\n",
    "        See https://github.com/DLR-RM/stable-baselines3/issues/37#issuecomment-637501195\n",
    "    :param ent_coef: Entropy regularization coefficient. (Equivalent to\n",
    "        inverse of reward scale in the original SAC paper.)  Controlling exploration/exploitation trade-off.\n",
    "        Set it to 'auto' to learn it automatically (and 'auto_0.1' for using 0.1 as initial value)\n",
    "    :param target_update_interval: update the target network every ``target_network_update_freq``\n",
    "        gradient steps.\n",
    "    :param target_entropy: target entropy when learning ``ent_coef`` (``ent_coef = 'auto'``)\n",
    "    :param use_sde: Whether to use generalized State Dependent Exploration (gSDE)\n",
    "        instead of action noise exploration (default: False)\n",
    "    :param sde_sample_freq: Sample a new noise matrix every n steps when using gSDE\n",
    "        Default: -1 (only sample at the beginning of the rollout)\n",
    "    :param use_sde_at_warmup: Whether to use gSDE instead of uniform sampling\n",
    "        during the warm up phase (before learning starts)\n",
    "    :param stats_window_size: Window size for the rollout logging, specifying the number of episodes to average\n",
    "        the reported success rate, mean episode length, and mean reward over\n",
    "    :param tensorboard_log: the log location for tensorboard (if None, no logging)\n",
    "    :param policy_kwargs: additional arguments to be passed to the policy on creation\n",
    "    :param verbose: Verbosity level: 0 for no output, 1 for info messages (such as device or wrappers used), 2 for\n",
    "        debug messages\n",
    "    :param seed: Seed for the pseudo random generators\n",
    "    :param device: Device (cpu, cuda, ...) on which the code should be run.\n",
    "        Setting it to auto, the code will be run on the GPU if possible.\n",
    "    :param _init_setup_model: Whether or not to build the network at the creation of the instance\n",
    "    \"\"\"\n",
    "\n",
    "    policy_aliases: ClassVar[Dict[str, Type[BasePolicy]]] = {\n",
    "        \"MlpPolicy\": MlpPolicy,\n",
    "        \"CnnPolicy\": CnnPolicy,\n",
    "        \"MultiInputPolicy\": MultiInputPolicy,\n",
    "    }\n",
    "    policy: SACPolicy\n",
    "    actor: Actor\n",
    "    critic: ContinuousCritic\n",
    "    critic_target: ContinuousCritic\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        policy: Union[str, Type[SACPolicy]],\n",
    "        env: Union[GymEnv, str],\n",
    "        learning_rate: Union[float, Schedule] = 3e-4,\n",
    "        buffer_size: int = 1_000_000,  # 1e6\n",
    "        learning_starts: int = 100,\n",
    "        batch_size: int = 256,\n",
    "        tau: float = 0.005,\n",
    "        gamma: float = 0.99,\n",
    "        train_freq: Union[int, Tuple[int, str]] = 1,\n",
    "        gradient_steps: int = 1,\n",
    "        action_noise: Optional[ActionNoise] = None,\n",
    "        replay_buffer_class: Optional[Type[ReplayBuffer]] = None,\n",
    "        replay_buffer_kwargs: Optional[Dict[str, Any]] = None,\n",
    "        optimize_memory_usage: bool = False,\n",
    "        ent_coef: Union[str, float] = \"auto\",\n",
    "        target_update_interval: int = 1,\n",
    "        target_entropy: Union[str, float] = \"auto\",\n",
    "        use_sde: bool = False,\n",
    "        sde_sample_freq: int = -1,\n",
    "        use_sde_at_warmup: bool = False,\n",
    "        stats_window_size: int = 100,\n",
    "        tensorboard_log: Optional[str] = None,\n",
    "        policy_kwargs: Optional[Dict[str, Any]] = None,\n",
    "        verbose: int = 0,\n",
    "        seed: Optional[int] = None,\n",
    "        device: Union[th.device, str] = \"auto\",\n",
    "        _init_setup_model: bool = True,\n",
    "    ):\n",
    "        super().__init__(\n",
    "            policy,\n",
    "            env,\n",
    "            learning_rate,\n",
    "            buffer_size,\n",
    "            learning_starts,\n",
    "            batch_size,\n",
    "            tau,\n",
    "            gamma,\n",
    "            train_freq,\n",
    "            gradient_steps,\n",
    "            action_noise,\n",
    "            replay_buffer_class=replay_buffer_class,\n",
    "            replay_buffer_kwargs=replay_buffer_kwargs,\n",
    "            policy_kwargs=policy_kwargs,\n",
    "            stats_window_size=stats_window_size,\n",
    "            tensorboard_log=tensorboard_log,\n",
    "            verbose=verbose,\n",
    "            device=device,\n",
    "            seed=seed,\n",
    "            use_sde=use_sde,\n",
    "            sde_sample_freq=sde_sample_freq,\n",
    "            use_sde_at_warmup=use_sde_at_warmup,\n",
    "            optimize_memory_usage=optimize_memory_usage,\n",
    "            supported_action_spaces=(spaces.Box,),\n",
    "            support_multi_env=True,\n",
    "        )\n",
    "\n",
    "        self.target_entropy = target_entropy\n",
    "        self.log_ent_coef = None  # type: Optional[th.Tensor]\n",
    "        # Entropy coefficient / Entropy temperature\n",
    "        # Inverse of the reward scale\n",
    "        self.ent_coef = ent_coef\n",
    "        self.target_update_interval = target_update_interval\n",
    "        self.ent_coef_optimizer: Optional[th.optim.Adam] = None\n",
    "\n",
    "        if _init_setup_model:\n",
    "            self._setup_model()\n",
    "\n",
    "    def _setup_model(self) -> None:\n",
    "        super()._setup_model()\n",
    "        self._create_aliases()\n",
    "        # Running mean and running var\n",
    "        self.batch_norm_stats = get_parameters_by_name(self.critic, [\"running_\"])\n",
    "        self.batch_norm_stats_target = get_parameters_by_name(self.critic_target, [\"running_\"])\n",
    "        # Target entropy is used when learning the entropy coefficient\n",
    "        if self.target_entropy == \"auto\":\n",
    "            # automatically set target entropy if needed\n",
    "            self.target_entropy = float(-np.prod(self.env.action_space.shape).astype(np.float32))  # type: ignore\n",
    "        else:\n",
    "            # Force conversion\n",
    "            # this will also throw an error for unexpected string\n",
    "            self.target_entropy = float(self.target_entropy)\n",
    "\n",
    "        # The entropy coefficient or entropy can be learned automatically\n",
    "        # see Automating Entropy Adjustment for Maximum Entropy RL section\n",
    "        # of https://arxiv.org/abs/1812.05905\n",
    "        if isinstance(self.ent_coef, str) and self.ent_coef.startswith(\"auto\"):\n",
    "            # Default initial value of ent_coef when learned\n",
    "            init_value = 1.0\n",
    "            if \"_\" in self.ent_coef:\n",
    "                init_value = float(self.ent_coef.split(\"_\")[1])\n",
    "                assert init_value > 0.0, \"The initial value of ent_coef must be greater than 0\"\n",
    "\n",
    "            # Note: we optimize the log of the entropy coeff which is slightly different from the paper\n",
    "            # as discussed in https://github.com/rail-berkeley/softlearning/issues/37\n",
    "            self.log_ent_coef = th.log(th.ones(1, device=self.device) * init_value).requires_grad_(True)\n",
    "            self.ent_coef_optimizer = th.optim.Adam([self.log_ent_coef], lr=self.lr_schedule(1))\n",
    "        else:\n",
    "            # Force conversion to float\n",
    "            # this will throw an error if a malformed string (different from 'auto')\n",
    "            # is passed\n",
    "            self.ent_coef_tensor = th.tensor(float(self.ent_coef), device=self.device)\n",
    "\n",
    "    def _create_aliases(self) -> None:\n",
    "        self.actor = self.policy.actor\n",
    "        self.critic = self.policy.critic\n",
    "        self.critic_target = self.policy.critic_target\n",
    "\n",
    "    def train(self, gradient_steps: int, batch_size: int = 64) -> None:\n",
    "        # Switch to train mode (this affects batch norm / dropout)\n",
    "        self.policy.set_training_mode(True)\n",
    "        # Update optimizers learning rate\n",
    "        optimizers = [self.actor.optimizer, self.critic.optimizer]\n",
    "        if self.ent_coef_optimizer is not None:\n",
    "            optimizers += [self.ent_coef_optimizer]\n",
    "\n",
    "        # Update learning rate according to lr schedule\n",
    "        self._update_learning_rate(optimizers)\n",
    "\n",
    "        ent_coef_losses, ent_coefs = [], []\n",
    "        actor_losses, critic_losses = [], []\n",
    "\n",
    "        for gradient_step in range(gradient_steps):\n",
    "            # Sample replay buffer\n",
    "            replay_data = self.replay_buffer.sample(batch_size, env=self._vec_normalize_env)  # type: ignore[union-attr]\n",
    "\n",
    "            # We need to sample because `log_std` may have changed between two gradient steps\n",
    "            if self.use_sde:\n",
    "                self.actor.reset_noise()\n",
    "\n",
    "            # Action by the current actor for the sampled state\n",
    "            actions_pi, log_prob = self.actor.action_log_prob(replay_data.observations)\n",
    "            log_prob = log_prob.reshape(-1, 1)\n",
    "\n",
    "            ent_coef_loss = None\n",
    "            if self.ent_coef_optimizer is not None and self.log_ent_coef is not None:\n",
    "                # Important: detach the variable from the graph\n",
    "                # so we don't change it with other losses\n",
    "                # see https://github.com/rail-berkeley/softlearning/issues/60\n",
    "                ent_coef = th.exp(self.log_ent_coef.detach())\n",
    "                ent_coef_loss = -(self.log_ent_coef * (log_prob + self.target_entropy).detach()).mean()\n",
    "                # print(f'{ent_coef.shape = }\\n{log_prob.shape = }\\n{(self.log_ent_coef * (log_prob + self.target_entropy)).shape = }')\n",
    "                ent_coef_losses.append(ent_coef_loss.item())\n",
    "            else:\n",
    "                ent_coef = self.ent_coef_tensor\n",
    "\n",
    "            ent_coefs.append(ent_coef.item())\n",
    "\n",
    "            # Optimize entropy coefficient, also called\n",
    "            # entropy temperature or alpha in the paper\n",
    "            if ent_coef_loss is not None and self.ent_coef_optimizer is not None:\n",
    "                self.ent_coef_optimizer.zero_grad()\n",
    "                ent_coef_loss.backward()\n",
    "                self.ent_coef_optimizer.step()\n",
    "\n",
    "            with th.no_grad():\n",
    "                # Select action according to policy\n",
    "                next_actions, next_log_prob = self.actor.action_log_prob(replay_data.next_observations)\n",
    "                # Compute the next Q values: min over all critics targets\n",
    "                next_q_values = th.cat(self.critic_target(replay_data.next_observations, next_actions), dim=1)\n",
    "                next_q_values, _ = th.min(next_q_values, dim=1, keepdim=True)\n",
    "                # add entropy term\n",
    "                next_q_values = next_q_values - ent_coef * next_log_prob.reshape(-1, 1)\n",
    "                # td error + entropy term\n",
    "                target_q_values = replay_data.rewards + (1 - replay_data.dones) * self.gamma * next_q_values\n",
    "\n",
    "            # Get current Q-values estimates for each critic network\n",
    "            # using action from the replay buffer\n",
    "            current_q_values = self.critic(replay_data.observations, replay_data.actions)\n",
    "\n",
    "            # Compute critic loss\n",
    "            critic_loss = 0.5 * sum(F.mse_loss(current_q, target_q_values) for current_q in current_q_values)\n",
    "            assert isinstance(critic_loss, th.Tensor)  # for type checker\n",
    "            critic_losses.append(critic_loss.item())  # type: ignore[union-attr]\n",
    "\n",
    "            # Optimize the critic\n",
    "            self.critic.optimizer.zero_grad()\n",
    "            critic_loss.backward()\n",
    "            self.critic.optimizer.step()\n",
    "\n",
    "            # Compute actor loss\n",
    "            # Alternative: actor_loss = th.mean(log_prob - qf1_pi)\n",
    "            # Min over all critic networks\n",
    "            q_values_pi = th.cat(self.critic(replay_data.observations, actions_pi), dim=1)\n",
    "            min_qf_pi, _ = th.min(q_values_pi, dim=1, keepdim=True)            \n",
    "            actor_loss = (ent_coef * log_prob - min_qf_pi).mean()\n",
    "            actor_losses.append(actor_loss.item())\n",
    "\n",
    "            # Optimize the actor\n",
    "            self.actor.optimizer.zero_grad()\n",
    "            actor_loss.backward()\n",
    "            self.actor.optimizer.step()\n",
    "\n",
    "            # Update target networks\n",
    "            if gradient_step % self.target_update_interval == 0:\n",
    "                polyak_update(self.critic.parameters(), self.critic_target.parameters(), self.tau)\n",
    "                # Copy running stats, see GH issue #996\n",
    "                polyak_update(self.batch_norm_stats, self.batch_norm_stats_target, 1.0)\n",
    "\n",
    "        self._n_updates += gradient_steps\n",
    "\n",
    "        self.logger.record(\"train/n_updates\", self._n_updates, exclude=\"tensorboard\")\n",
    "        self.logger.record(\"train/ent_coef\", np.mean(ent_coefs))\n",
    "        self.logger.record(\"train/actor_loss\", np.mean(actor_losses))\n",
    "        self.logger.record(\"train/critic_loss\", np.mean(critic_losses))\n",
    "        if len(ent_coef_losses) > 0:\n",
    "            self.logger.record(\"train/ent_coef_loss\", np.mean(ent_coef_losses))\n",
    "\n",
    "    def learn(\n",
    "        self: SelfSAC,\n",
    "        total_timesteps: int,\n",
    "        callback: MaybeCallback = None,\n",
    "        log_interval: int = 4,\n",
    "        tb_log_name: str = \"SAC\",\n",
    "        reset_num_timesteps: bool = True,\n",
    "        progress_bar: bool = False,\n",
    "    ) -> SelfSAC:\n",
    "        return super().learn(\n",
    "            total_timesteps=total_timesteps,\n",
    "            callback=callback,\n",
    "            log_interval=log_interval,\n",
    "            tb_log_name=tb_log_name,\n",
    "            reset_num_timesteps=reset_num_timesteps,\n",
    "            progress_bar=progress_bar,\n",
    "        )\n",
    "\n",
    "    def _excluded_save_params(self) -> List[str]:\n",
    "        return super()._excluded_save_params() + [\"actor\", \"critic\", \"critic_target\"]  # noqa: RUF005\n",
    "\n",
    "    def _get_torch_save_params(self) -> Tuple[List[str], List[str]]:\n",
    "        state_dicts = [\"policy\", \"actor.optimizer\", \"critic.optimizer\"]\n",
    "        if self.ent_coef_optimizer is not None:\n",
    "            saved_pytorch_variables = [\"log_ent_coef\"]\n",
    "            state_dicts.append(\"ent_coef_optimizer\")\n",
    "        else:\n",
    "            saved_pytorch_variables = [\"ent_coef_tensor\"]\n",
    "        return state_dicts, saved_pytorch_variables\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-25T15:36:53.253721Z",
     "start_time": "2024-09-25T15:36:42.395531Z"
    }
   },
   "id": "361d9f4836d8ea3d",
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from gymnasium.wrappers import TransformReward\n",
    "import gymnasium as gym\n",
    "\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.sac.sac import SAC\n",
    "\n",
    "# env = make_vec_env(lambda: TransformReward(gym.make(\"HalfCheetah-v4\"), lambda r: 5 * r), n_envs=1)\n",
    "env = TransformReward(gym.make(\"HalfCheetah-v4\"), lambda r: 5 * r)\n",
    "\n",
    "model = SAC(\"MlpPolicy\", env, verbose=10)\n",
    "model.learn(total_timesteps=3_000_000, log_interval=1)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-03T01:42:49.719952Z",
     "start_time": "2024-10-02T20:51:15.200060Z"
    }
   },
   "id": "27ae4b4f45e36c7a",
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "model.batch_norm_stats"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-24T17:48:35.900802Z",
     "start_time": "2024-09-24T17:48:35.897789Z"
    }
   },
   "id": "a983bb6240c616fe",
   "execution_count": 52,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "model.target_entropy"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-24T17:51:48.874115Z",
     "start_time": "2024-09-24T17:51:48.871062Z"
    }
   },
   "id": "624b708b89f7b115",
   "execution_count": 53,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "model.replay_buffer.sample(1000).rewards.max()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-24T17:30:29.292254Z",
     "start_time": "2024-09-24T17:30:29.285723Z"
    }
   },
   "id": "cd1ceffb8fc8c8a3",
   "execution_count": 49,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "for i in range(10):\n",
    "    print(np.mean(np.abs(model.replay_buffer.actions[12000 + 100 * i:12100 + 100*i])))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-22T15:33:43.775236Z",
     "start_time": "2024-09-22T15:33:43.771103Z"
    }
   },
   "id": "1a7bb0665ce56856",
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "inp1 = torch.rand((256, 32, 256))\n",
    "inp2 = torch.rand((256, 32, 256))\n",
    "\n",
    "mod = nn.Sequential(\n",
    "    nn.Linear(256, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(256, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(256, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(256, 256),\n",
    "    nn.ReLU(),\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-21T15:03:57.471271Z",
     "start_time": "2024-09-21T15:03:57.447267Z"
    }
   },
   "id": "2ff8fb4d21c41efb",
   "execution_count": 13,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "%%timeit\n",
    "\n",
    "out1, out2 = torch.chunk(mod(torch.cat((inp1, inp2), dim=0)), 2, dim=0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-21T15:04:28.776586Z",
     "start_time": "2024-09-21T15:04:24.165958Z"
    }
   },
   "id": "dfaaa46edea2080",
   "execution_count": 18,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "%%timeit\n",
    "\n",
    "with torch.no_grad():\n",
    "    out1 = mod(inp1)\n",
    "out2 = mod(inp2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-21T15:04:17.370229Z",
     "start_time": "2024-09-21T15:04:13.349628Z"
    }
   },
   "id": "470d58512eefc938",
   "execution_count": 17,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "inp1 = torch.rand((256, 32, 256))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-21T15:36:15.598610Z",
     "start_time": "2024-09-21T15:36:15.577459Z"
    }
   },
   "id": "c58c520c67cc175b",
   "execution_count": 19,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "%%timeit\n",
    "out = inp1\n",
    "for i in range(1):\n",
    "    out = out.detach()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-21T15:37:08.992508Z",
     "start_time": "2024-09-21T15:36:55.341899Z"
    }
   },
   "id": "fda270ae57735dd6",
   "execution_count": 20,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "%%timeit\n",
    "out = inp1\n",
    "for i in range(3):\n",
    "    out = out.detach()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-21T15:37:39.648509Z",
     "start_time": "2024-09-21T15:37:36.013809Z"
    }
   },
   "id": "f398b98b50d7ac45",
   "execution_count": 22,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "x = 1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-23T21:34:40.070062Z",
     "start_time": "2024-09-23T21:34:40.066061Z"
    }
   },
   "id": "8f60c823405c5b7b",
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "_ih[-2]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-23T21:35:29.470017Z",
     "start_time": "2024-09-23T21:35:29.467274Z"
    }
   },
   "id": "a6492020fcd1acfb",
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "data = np.random.random((256, 1024, 32))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-29T13:12:12.523319Z",
     "start_time": "2024-09-29T13:12:12.471964Z"
    }
   },
   "id": "8dcd2f32f89732af",
   "execution_count": 44,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "%%timeit\n",
    "\n",
    "y = data * 3.1209834"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-28T23:56:08.052194Z",
     "start_time": "2024-09-28T23:55:51.630547Z"
    }
   },
   "id": "99ff7a0bfbd90791",
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "data = torch.rand((256, 1024, 32)).cuda()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-29T13:08:18.272454Z",
     "start_time": "2024-09-29T13:08:18.216940Z"
    }
   },
   "id": "cc242828c18c4be7",
   "execution_count": 33,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "%%timeit\n",
    "\n",
    "y = data * 3.1234363"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-28T23:59:56.726318Z",
     "start_time": "2024-09-28T23:59:41.534121Z"
    }
   },
   "id": "81dfe2af588d68e1",
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "data = np.random.random((16,))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-29T00:13:05.264850Z",
     "start_time": "2024-09-29T00:13:05.261733Z"
    }
   },
   "id": "dc849e89df2e7b27",
   "execution_count": 20,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "%%timeit\n",
    "\n",
    "y = data * 3.1209834"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-29T00:13:15.075972Z",
     "start_time": "2024-09-29T00:13:05.470783Z"
    }
   },
   "id": "16dea77acabfdf84",
   "execution_count": 21,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "data = torch.rand((128,)).cuda()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-29T00:13:15.079984Z",
     "start_time": "2024-09-29T00:13:15.076968Z"
    }
   },
   "id": "5aca4b327f57badd",
   "execution_count": 22,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "%%timeit\n",
    "\n",
    "y = data * 3.1234363"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-29T00:14:16.967106Z",
     "start_time": "2024-09-29T00:14:09.244424Z"
    }
   },
   "id": "bb1497704532adc7",
   "execution_count": 24,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "data = np.random.random((32,))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-29T13:03:32.536256Z",
     "start_time": "2024-09-29T13:03:32.533630Z"
    }
   },
   "id": "a59df2b2af2d702f",
   "execution_count": 27,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "%%timeit\n",
    "\n",
    "y = data * 3.1209834"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-29T13:03:41.591890Z",
     "start_time": "2024-09-29T13:03:32.698382Z"
    }
   },
   "id": "2cbcb265c497adcb",
   "execution_count": 28,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "data = torch.rand((256,)).cuda()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-30T22:27:11.958860Z",
     "start_time": "2024-09-30T22:27:09.898091Z"
    }
   },
   "id": "1e6f7e94feb15ced",
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "%%timeit \n",
    "\n",
    "y = data - 2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-30T22:28:32.659101Z",
     "start_time": "2024-09-30T22:28:25.208345Z"
    }
   },
   "id": "587b178dad793a6",
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "%%timeit\n",
    "\n",
    "fac = 2\n",
    "if fac is None or fac == 1.0:\n",
    "    y = data\n",
    "else:\n",
    "    y = data - 1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-30T22:28:39.809569Z",
     "start_time": "2024-09-30T22:28:32.660097Z"
    }
   },
   "id": "edd0b650b406749f",
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "%%timeit\n",
    "y = data * 1.0"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-29T13:12:36.629792Z",
     "start_time": "2024-09-29T13:12:25.975179Z"
    }
   },
   "id": "3c5c90301dc90fdc",
   "execution_count": 46,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "%%timeit\n",
    "\n",
    "y = data * 3.1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-29T13:12:47.336440Z",
     "start_time": "2024-09-29T13:12:36.629792Z"
    }
   },
   "id": "753c30eafc8ffaa7",
   "execution_count": 47,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "e2c4c02e2479844c",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class A:\n",
    "    x = 1\n",
    "    def f(self):\n",
    "        self.x *= 0.99\n",
    "\n",
    "class B(A):\n",
    "    def f(self):\n",
    "        super().f()\n",
    "        \n",
    "a = A()\n",
    "b = B()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-29T13:02:48.902146Z",
     "start_time": "2024-09-29T13:02:48.899251Z"
    }
   },
   "id": "a23f2faa9a5c32f3",
   "execution_count": 23,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "%%timeit\n",
    "a.f()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-29T13:04:18.037085Z",
     "start_time": "2024-09-29T13:04:12.167450Z"
    }
   },
   "id": "31d999e407faeef8",
   "execution_count": 32,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "%%timeit\n",
    "b.f()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-29T13:14:54.415782Z",
     "start_time": "2024-09-29T13:14:36.835217Z"
    }
   },
   "id": "840e376d66666e1c",
   "execution_count": 48,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "a = 1.2"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f110054f5353abc6",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "%%timeit\n",
    "a == 1.0"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-29T13:15:17.618140Z",
     "start_time": "2024-09-29T13:15:14.841326Z"
    }
   },
   "id": "3979d3d4be54f7fa",
   "execution_count": 52,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "%%timeit\n",
    "a == None"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-29T13:15:14.840323Z",
     "start_time": "2024-09-29T13:15:12.605732Z"
    }
   },
   "id": "94d88b6b1c674ed3",
   "execution_count": 51,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "%%timeit\n",
    "a is None"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-29T13:17:06.072987Z",
     "start_time": "2024-09-29T13:16:53.651866Z"
    }
   },
   "id": "4d271db7bccdf8d1",
   "execution_count": 53,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-05T13:20:56.279557Z",
     "start_time": "2024-10-05T13:20:56.277552Z"
    }
   },
   "id": "ec928aa1271cf7e4",
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from collections import defaultdict\n",
    "from itertools import count\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "counts: dict[int, int] = defaultdict(lambda: 0)\n",
    "\n",
    "buf = np.zeros(20)\n",
    "\n",
    "for i in range(100):\n",
    "    buf[i % len(buf)] = i\n",
    "    \n",
    "    indices = np.random.choice(min(i + 1, len(buf)), size=10)\n",
    "    for idx in indices:\n",
    "        counts[buf[idx]] += 1\n",
    "    \n",
    "    if i % 10 == 0:\n",
    "        print(dict(counts))\n",
    "        print()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-05T13:29:19.148102Z",
     "start_time": "2024-10-05T13:29:08.350391Z"
    }
   },
   "id": "97260539b4519dcf",
   "execution_count": 14,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "x = plt.hist(counts.values(), bins=30)\n",
    "list(zip(*x[:2]))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-05T13:31:21.371995Z",
     "start_time": "2024-10-05T13:31:21.256020Z"
    }
   },
   "id": "fc96ec1b448f7172",
   "execution_count": 19,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-05T13:20:56.292529Z",
     "start_time": "2024-10-05T13:20:56.290573Z"
    }
   },
   "id": "72058c1b4d5300a7",
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-05T13:20:56.301353Z",
     "start_time": "2024-10-05T13:20:56.299533Z"
    }
   },
   "id": "8759b66e3eebcbed",
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-05T16:32:04.245112Z",
     "start_time": "2024-10-05T16:32:04.242597Z"
    }
   },
   "id": "b998c9a87ab54966",
   "execution_count": 19,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-05T16:32:04.527432Z",
     "start_time": "2024-10-05T16:32:04.525224Z"
    }
   },
   "id": "742c8e45e0f52a26",
   "execution_count": 19,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-05T16:32:04.699649Z",
     "start_time": "2024-10-05T16:32:04.697685Z"
    }
   },
   "id": "cb12f433355235f6",
   "execution_count": 19,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-05T16:32:04.861461Z",
     "start_time": "2024-10-05T16:32:04.858704Z"
    }
   },
   "id": "c807f88c4548c3d9",
   "execution_count": 19,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-05T16:32:05.002398Z",
     "start_time": "2024-10-05T16:32:04.999487Z"
    }
   },
   "id": "c8a10c27d4a0cb20",
   "execution_count": 19,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from src.reinforcement_learning.gym.parallelize_env import parallelize_env_sync\n",
    "from src.reinforcement_learning.core.buffers.resevoir.reservoir_buffer import ReservoirBuffer\n",
    "from src.reinforcement_learning.core.buffers.resevoir.replay_with_reservoir_buffer import ReplayWithReservoirBuffer\n",
    "from src.reinforcement_learning.gym.envs.test_env import TestEnv\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import tqdm\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "counts = defaultdict(lambda: 0)\n",
    "\n",
    "for _ in tqdm.tqdm(range(100)):\n",
    "    env = parallelize_env_sync(lambda: TestEnv(2, False,False, 100000), 1)\n",
    "    buf = ReplayWithReservoirBuffer(\n",
    "        ReservoirBuffer(\n",
    "            total_size=100,\n",
    "            num_envs=1,\n",
    "            obs_shape=(2,),\n",
    "            action_shape=(1,),\n",
    "            reward_scale=1,\n",
    "        ),\n",
    "        reservoir_ratio=0.5,\n",
    "        step_size=10,\n",
    "        num_envs=1,\n",
    "        obs_shape=(2,),\n",
    "        action_shape=(1,),\n",
    "        reward_scale=1,\n",
    "    )\n",
    "    \n",
    "    obs, _ = env.reset()\n",
    "    \n",
    "    for i in range(100):\n",
    "        action = np.ones((1,)) * i\n",
    "        next_obs, reward, term, trunc, _ = env.step(action)\n",
    "        buf.add(obs, next_obs, action, reward, np.logical_or(term, trunc))\n",
    "        obs = next_obs\n",
    "    \n",
    "    for i in range(10):\n",
    "        samples = buf.sample(100)\n",
    "        for obs in samples.observations[:, 0]:\n",
    "            counts[int(obs.item())] += 1 "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-06T01:44:01.342524Z",
     "start_time": "2024-10-06T01:44:00.347090Z"
    }
   },
   "id": "967a329b8f2bf11e",
   "execution_count": 98,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(counts.keys(), counts.values(), '.')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-06T01:44:01.502101Z",
     "start_time": "2024-10-06T01:44:01.343527Z"
    }
   },
   "id": "58353e77b66723d4",
   "execution_count": 99,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print(buf.sample(10))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-06T01:41:35.389992Z",
     "start_time": "2024-10-06T01:41:35.302188Z"
    }
   },
   "id": "5b1e1151b5244261",
   "execution_count": 80,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-10T23:10:52.986212Z",
     "start_time": "2024-10-10T23:10:52.983620Z"
    }
   },
   "id": "f2d0820e66c97c",
   "execution_count": 26,
   "outputs": []
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.46 ms ± 606 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "l = 100\n",
    "p = 1 + np.arange(l, dtype=float) ** 5\n",
    "p /= p.sum()\n",
    "x = np.random.choice(l, size=100_000, p=p)\n",
    "# plt.hist(x)\n",
    "# plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-10T23:16:18.763657Z",
     "start_time": "2024-10-10T23:16:15.212113Z"
    }
   },
   "id": "d4bde5bb1d649548",
   "execution_count": 37
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "l = 1_000_000\n",
    "a = np.arange(l, dtype=float)\n",
    "p = 1 + a * 5\n",
    "p /= p.sum()\n",
    "import tqdm"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-10T23:24:30.309169Z",
     "start_time": "2024-10-10T23:24:30.293153Z"
    }
   },
   "id": "e2fe4d4180b1176c",
   "execution_count": 54
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:07<00:00, 129.21it/s]\n"
     ]
    }
   ],
   "source": [
    "# %%timeit\n",
    "\n",
    "for _ in tqdm.tqdm(range(1000)):\n",
    "    x = np.random.choice(l, size=256, p=p)\n",
    "# plt.hist(x)\n",
    "# plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-10T23:24:38.190308Z",
     "start_time": "2024-10-10T23:24:30.436751Z"
    }
   },
   "id": "33d05ee8784c5d12",
   "execution_count": 55
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "b9e9d649d46e498e"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "547b77b627186853"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
