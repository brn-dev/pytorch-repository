{
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "from src.reinforcement_learning.core.action_selectors.predicted_std_action_selector import PredictedStdActionSelector\n",
    "from stable_baselines3.common.torch_layers import FlattenExtractor\n",
    "from dataclasses import dataclass\n",
    "from typing import Type, Optional, Any, Literal\n",
    "\n",
    "import gymnasium\n",
    "import numpy as np\n",
    "import stable_baselines3 as sb\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from stable_baselines3.common.policies import ContinuousCritic\n",
    "from torch import optim\n",
    "\n",
    "from src.function_types import TorchTensorFn\n",
    "from src.hyper_parameters import HyperParameters\n",
    "from src.reinforcement_learning.algorithms.base.base_algorithm import PolicyProvider\n",
    "from src.reinforcement_learning.algorithms.base.off_policy_algorithm import OffPolicyAlgorithm, ReplayBuf\n",
    "from src.reinforcement_learning.algorithms.sac.sac_crossq_policy import SACCrossQPolicy\n",
    "from src.reinforcement_learning.core.action_noise import ActionNoise\n",
    "from src.reinforcement_learning.core.buffers.replay.base_replay_buffer import BaseReplayBuffer, ReplayBufferSamples\n",
    "from src.reinforcement_learning.core.buffers.replay.replay_buffer import ReplayBuffer\n",
    "from src.reinforcement_learning.core.callback import Callback\n",
    "from src.reinforcement_learning.core.infos import InfoDict, concat_infos\n",
    "from src.reinforcement_learning.core.logging import LoggingConfig, log_if_enabled\n",
    "from src.reinforcement_learning.core.loss_config import LossLoggingConfig\n",
    "from src.reinforcement_learning.core.polyak_update import polyak_update\n",
    "from src.reinforcement_learning.core.type_aliases import OptimizerProvider, TensorObs, detach_obs\n",
    "from src.reinforcement_learning.gym.env_analysis import get_single_action_space\n",
    "from src.torch_device import TorchDevice\n",
    "from src.torch_functions import identity\n",
    "\n",
    "SAC_DEFAULT_OPTIMIZER_PROVIDER = lambda params: optim.AdamW(params, lr=3e-4, weight_decay=1e-4)\n",
    "AUTO_TARGET_ENTROPY = 'auto'\n",
    "\n",
    "from typing import Optional\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from src.hyper_parameters import HyperParameters\n",
    "from src.reinforcement_learning.core.action_selectors.action_selector import ActionSelector\n",
    "from src.reinforcement_learning.core.action_selectors.state_dependent_noise_action_selector import \\\n",
    "    StateDependentNoiseActionSelector\n",
    "from src.reinforcement_learning.core.policies.components.base_component import BasePolicyComponent\n",
    "from src.reinforcement_learning.core.policies.components.feature_extractors import FeatureExtractor, IdentityExtractor\n",
    "from src.reinforcement_learning.core.type_aliases import TensorObs\n",
    "\n",
    "\n",
    "class DebugActor(BasePolicyComponent):\n",
    "\n",
    "    action_selector: ActionSelector\n",
    "    uses_sde: bool\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            network: nn.Module,\n",
    "            action_selector: ActionSelector,\n",
    "            # feature_extractor: Optional[FeatureExtractor] = None\n",
    "    ):\n",
    "        assert isinstance(action_selector, PredictedStdActionSelector)\n",
    "        super().__init__(IdentityExtractor())\n",
    "        self.network = network\n",
    "        self.replace_action_selector(action_selector, copy_action_net_weights=False)\n",
    "\n",
    "    def collect_hyper_parameters(self) -> HyperParameters:\n",
    "        return self.update_hps(super().collect_hyper_parameters(), {\n",
    "            'network': self.get_hps_or_str(self.network),\n",
    "            'action_selector': self.get_hps_or_str(self.action_selector),\n",
    "        })\n",
    "\n",
    "    def forward(self, obs: TensorObs, deterministic: bool = False) -> torch.Tensor:\n",
    "        obs = self.feature_extractor(obs)\n",
    "        latent_pi = self.network(obs)\n",
    "        return self.action_selector.update_latent_features(latent_pi).get_actions(deterministic=debug_actor)\n",
    "\n",
    "    def get_actions_with_log_probs(\n",
    "            self,\n",
    "            obs: TensorObs,\n",
    "            deterministic: bool = False\n",
    "    ) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "        obs = self.feature_extractor(obs)\n",
    "        latent_pi = self.network(obs)\n",
    "        return self.action_selector.get_actions_with_log_probs(latent_pi, deterministic=deterministic)\n",
    "\n",
    "    def replace_action_selector(self, new_action_selector: ActionSelector, copy_action_net_weights: bool) -> None:\n",
    "        if copy_action_net_weights:\n",
    "            new_action_selector.action_net.load_state_dict(self.action_selector.action_net.state_dict())\n",
    "        self.action_selector = new_action_selector\n",
    "        self.uses_sde = isinstance(self.action_selector, StateDependentNoiseActionSelector)\n",
    "\n",
    "    def reset_sde_noise(self, batch_size: int = 1) -> None:\n",
    "        if self.uses_sde:\n",
    "            raise NotImplemented\n",
    "    \n",
    "    def set_training_mode(self, mode: bool):\n",
    "        self.set_train_mode(mode)\n",
    "\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class SACLoggingConfig(LoggingConfig):\n",
    "\n",
    "    log_entropy_coef: bool = False\n",
    "    entropy_coef_loss: LossLoggingConfig = None\n",
    "    actor_loss: LossLoggingConfig = None\n",
    "    critic_loss: LossLoggingConfig = None\n",
    "\n",
    "    def __post_init__(self):\n",
    "        if self.actor_loss is None:\n",
    "            self.actor_loss = LossLoggingConfig()\n",
    "        if self.entropy_coef_loss is None:\n",
    "            self.entropy_loss = LossLoggingConfig()\n",
    "        if self.critic_loss is None:\n",
    "            self.critic_loss = LossLoggingConfig()\n",
    "\n",
    "        super().__post_init__()\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "        Soft Actor-Critic:\n",
    "        Off-Policy Maximum Entropy Deep Reinforcement\n",
    "        Learning with a Stochastic Actor\n",
    "        https://arxiv.org/pdf/1801.01290\n",
    "\n",
    "\"\"\"\n",
    "class SACDebug(OffPolicyAlgorithm[sb.sac.sac.SACPolicy, ReplayBuf, SACLoggingConfig]):\n",
    "    \n",
    "    policy: sb.sac.sac.SACPolicy\n",
    "    actor: sb.sac.sac.Actor\n",
    "    critic: ContinuousCritic\n",
    "    buffer: BaseReplayBuffer\n",
    "    target_entropy: float\n",
    "    log_ent_coef: Optional[torch.Tensor]\n",
    "    entropy_coef_optimizer: Optional[optim.Optimizer]\n",
    "    entropy_coef_tensor: Optional[torch.Tensor]\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            env: gymnasium.Env,\n",
    "            policy: sb.sac.sac.SACPolicy | PolicyProvider[sb.sac.sac.SACPolicy],\n",
    "            actor_optimizer_provider: OptimizerProvider = SAC_DEFAULT_OPTIMIZER_PROVIDER,\n",
    "            critic_optimizer_provider: OptimizerProvider = SAC_DEFAULT_OPTIMIZER_PROVIDER,\n",
    "            weigh_and_reduce_actor_loss: TorchTensorFn = torch.mean,\n",
    "            weigh_critic_loss: TorchTensorFn = identity,\n",
    "            buffer_type: Type[ReplayBuf] = ReplayBuffer,\n",
    "            buffer_size: int = 100_000,\n",
    "            buffer_kwargs: dict[str, Any] = None,\n",
    "            gamma: float = 0.99,\n",
    "            tau: float = 0.005,\n",
    "            rollout_steps: int = 100,\n",
    "            gradient_steps: int = 1,\n",
    "            optimization_batch_size: int = 256,\n",
    "            target_update_interval: int = 1,\n",
    "            entropy_coef: float = 1.0,\n",
    "            target_entropy: float | Literal['auto'] = AUTO_TARGET_ENTROPY,\n",
    "            entropy_coef_optimizer_provider: Optional[OptimizerProvider] = None,\n",
    "            weigh_and_reduce_entropy_coef_loss: TorchTensorFn = torch.mean,\n",
    "            action_noise: Optional[ActionNoise] = None,\n",
    "            warmup_steps: int = 100,\n",
    "            learning_starts: int = 100,\n",
    "            sde_noise_sample_freq: Optional[int] = None,\n",
    "            callback: Callback['SAC'] = None,\n",
    "            logging_config: SACLoggingConfig = None,\n",
    "            torch_device: TorchDevice = 'auto',\n",
    "            torch_dtype: torch.dtype = torch.float32,\n",
    "    ):\n",
    "        super().__init__(\n",
    "            env=env,\n",
    "            policy=policy,\n",
    "            buffer=buffer_type.for_env(env, buffer_size, torch_device, torch_dtype, **(buffer_kwargs or {})),\n",
    "            gamma=gamma,\n",
    "            tau=tau,\n",
    "            rollout_steps=rollout_steps,\n",
    "            gradient_steps=gradient_steps,\n",
    "            optimization_batch_size=optimization_batch_size,\n",
    "            action_noise=action_noise,\n",
    "            warmup_steps=warmup_steps,\n",
    "            learning_starts=learning_starts,\n",
    "            sde_noise_sample_freq=sde_noise_sample_freq,\n",
    "            callback=callback or Callback(),\n",
    "            logging_config=logging_config or LoggingConfig(),\n",
    "            torch_device=torch_device,\n",
    "            torch_dtype=torch_dtype,\n",
    "        )\n",
    "\n",
    "        self.actor = self.policy.actor\n",
    "        self.critic = self.policy.critic\n",
    "        # self.shared_feature_extractor = self.policy.shared_feature_extractor\n",
    "\n",
    "        self.actor_optimizer = actor_optimizer_provider(\n",
    "            # self.chain_parameters(self.actor, self.shared_feature_extractor)\n",
    "            self.actor.parameters()\n",
    "        )\n",
    "        self.critic_optimizer = critic_optimizer_provider(self.critic.parameters())\n",
    "\n",
    "        self.weigh_and_reduce_entropy_coef_loss = weigh_and_reduce_entropy_coef_loss\n",
    "        self.weigh_and_reduce_actor_loss = weigh_and_reduce_actor_loss\n",
    "        self.weigh_critic_loss = weigh_critic_loss\n",
    "\n",
    "        self.target_update_interval = target_update_interval\n",
    "        self.gradient_steps_performed = 0\n",
    "\n",
    "        self._setup_entropy_optimization(entropy_coef, target_entropy, entropy_coef_optimizer_provider)\n",
    "\n",
    "        # CrossQ doesn't use a target critic\n",
    "        if isinstance(self.policy, SACCrossQPolicy):\n",
    "            self.tau = 0\n",
    "            self.target_update_interval = 0\n",
    "\n",
    "\n",
    "    def collect_hyper_parameters(self) -> HyperParameters:\n",
    "        return self.update_hps(super().collect_hyper_parameters(), {\n",
    "            'actor_optimizer': str(self.actor_optimizer),\n",
    "            'critic_optimizer': str(self.critic_optimizer),\n",
    "            'entropy_coef_optimizer': str(self.entropy_coef_optimizer),\n",
    "            'weigh_and_reduce_entropy_coef_loss': str(self.weigh_and_reduce_entropy_coef_loss),\n",
    "            'weigh_and_reduce_actor_loss': str(self.weigh_and_reduce_actor_loss),\n",
    "            'weigh_critic_loss': str(self.weigh_critic_loss),\n",
    "            'target_update_interval': self.target_update_interval,\n",
    "            'target_entropy': self.target_entropy,\n",
    "            'entropy_coef': self.entropy_coef_tensor.item() if self.entropy_coef_tensor is not None else 'dynamic',\n",
    "        })\n",
    "\n",
    "    def _setup_entropy_optimization(\n",
    "            self,\n",
    "            entropy_coef: float,\n",
    "            target_entropy: float | Literal['auto'],\n",
    "            entropy_coef_optimizer_provider: Optional[OptimizerProvider],\n",
    "    ):\n",
    "        if target_entropy == 'auto':\n",
    "            self.target_entropy = float(-np.prod(get_single_action_space(self.env).shape).astype(np.float32))\n",
    "        else:\n",
    "            self.target_entropy = float(target_entropy)\n",
    "\n",
    "        if entropy_coef_optimizer_provider is not None:\n",
    "            self.log_ent_coef = torch.log(\n",
    "                torch.tensor([entropy_coef], device=self.torch_device, dtype=self.torch_dtype)\n",
    "            ).requires_grad_(True)\n",
    "            self.entropy_coef_optimizer = entropy_coef_optimizer_provider([self.log_ent_coef])\n",
    "            self.entropy_coef_tensor = None\n",
    "        else:\n",
    "            self.log_ent_coef = None\n",
    "            self.entropy_coef_optimizer = None\n",
    "            self.entropy_coef_tensor = torch.tensor(entropy_coef, device=self.torch_device, dtype=self.torch_dtype)\n",
    "\n",
    "    def get_and_optimize_entropy_coef(\n",
    "            self,\n",
    "            actions_pi_log_prob: torch.Tensor,\n",
    "            info: InfoDict\n",
    "    ) -> torch.Tensor:\n",
    "        if self.entropy_coef_optimizer is not None:\n",
    "            entropy_coef = torch.exp(self.log_ent_coef.detach())\n",
    "\n",
    "            # TODO!\n",
    "            # entropy_coef_loss = weigh_and_reduce_loss(\n",
    "            #     raw_loss=-self.log_ent_coef * (actions_pi_log_prob + self.target_entropy).detach(),\n",
    "            #     weigh_and_reduce_function=self.weigh_and_reduce_entropy_coef_loss,\n",
    "            #     info=info,\n",
    "            #     loss_name='entropy_coef_loss',\n",
    "            #     logging_config=self.logging_config.entropy_coef_loss\n",
    "            # )\n",
    "\n",
    "            entropy_coef_loss = -(self.log_ent_coef * (actions_pi_log_prob + self.target_entropy).detach()).mean()\n",
    "            info['final_entropy_coef_loss'] = entropy_coef_loss.detach()\n",
    "\n",
    "            self.entropy_coef_optimizer.zero_grad()\n",
    "            entropy_coef_loss.backward()\n",
    "            self.entropy_coef_optimizer.step()\n",
    "\n",
    "            return entropy_coef\n",
    "        else:\n",
    "            return self.entropy_coef_tensor\n",
    "\n",
    "    def calculate_critic_loss(\n",
    "            self,\n",
    "            observation_features: TensorObs,\n",
    "            replay_samples: ReplayBufferSamples,\n",
    "            entropy_coef: torch.Tensor,\n",
    "            info: InfoDict,\n",
    "    ):\n",
    "        with torch.no_grad():\n",
    "                # Select action according to policy\n",
    "            next_actions, next_log_prob = self.actor.get_actions_with_log_probs(replay_samples.next_observations)\n",
    "            # Compute the next Q values: min over all critics targets\n",
    "            next_q_values = torch.cat(self.policy.critic_target(replay_samples.next_observations, next_actions), dim=1)\n",
    "            next_q_values, _ = torch.min(next_q_values, dim=1, keepdim=True)\n",
    "            # add entropy term\n",
    "            next_q_values = next_q_values - entropy_coef * next_log_prob.reshape(-1, 1)\n",
    "            # td error + entropy term\n",
    "            target_q_values = replay_samples.rewards + (1 - replay_samples.dones) * self.gamma * next_q_values\n",
    "\n",
    "        # target_q_values = self.policy.compute_target_values(\n",
    "        #     replay_samples=replay_samples,\n",
    "        #     entropy_coef=entropy_coef,\n",
    "        #     gamma=self.gamma,\n",
    "        # )\n",
    "        # critic loss should not influence shared feature extractor\n",
    "        current_q_values = self.critic(detach_obs(observation_features), replay_samples.actions)\n",
    "\n",
    "        # noinspection PyTypeChecker\n",
    "        critic_loss: torch.Tensor = 0.5 * sum(\n",
    "            F.mse_loss(current_q, target_q_values) for current_q in current_q_values\n",
    "        )\n",
    "        # TODO!\n",
    "        # critic_loss = weigh_and_reduce_loss(\n",
    "        #     raw_loss=critic_loss,\n",
    "        #     weigh_and_reduce_function=self.weigh_critic_loss,\n",
    "        #     info=info,\n",
    "        #     loss_name='critic_loss',\n",
    "        #     logging_config=self.logging_config.critic_loss,\n",
    "        # )\n",
    "\n",
    "        info['final_critic_loss'] = critic_loss.detach()\n",
    "        return critic_loss\n",
    "\n",
    "    def calculate_actor_loss(\n",
    "            self,\n",
    "            observation_features: TensorObs,\n",
    "            actions_pi: torch.Tensor,\n",
    "            actions_pi_log_prob: torch.Tensor,\n",
    "            entropy_coef: torch.Tensor,\n",
    "            info: InfoDict,\n",
    "    ) -> torch.Tensor:\n",
    "        q_values_pi = torch.cat(self.critic(observation_features, actions_pi), dim=-1)\n",
    "        min_q_values_pi, _ = torch.min(q_values_pi, dim=-1, keepdim=True)\n",
    "        actor_loss = (entropy_coef * actions_pi_log_prob - min_q_values_pi).mean()  # TODO!\n",
    "\n",
    "        # TODO!\n",
    "        # actor_loss = weigh_and_reduce_loss(\n",
    "        #     raw_loss=actor_loss,\n",
    "        #     weigh_and_reduce_function=self.weigh_and_reduce_actor_loss,\n",
    "        #     info=info,\n",
    "        #     loss_name='actor_loss',\n",
    "        #     logging_config=self.logging_config.actor_loss,\n",
    "        # )\n",
    "\n",
    "        info['final_actor_loss'] = actor_loss.detach()\n",
    "        return actor_loss\n",
    "\n",
    "    def optimize(self, last_obs: np.ndarray, last_episode_starts: np.ndarray, info: InfoDict) -> None:\n",
    "        gradient_step_infos: list[InfoDict] = []\n",
    "\n",
    "        for gradient_step in range(self.gradient_steps):\n",
    "            step_info: InfoDict = {}\n",
    "            replay_samples = self.buffer.sample(self.optimization_batch_size)\n",
    "\n",
    "            # self.actor.reset_sde_noise()  # TODO: set batch size?\n",
    "\n",
    "            # observation_features = self.shared_feature_extractor(replay_samples.observations)\n",
    "            # observation_features = replay_samples.observations\n",
    "            actions_pi, actions_pi_log_prob = self.actor.get_actions_with_log_probs(replay_samples.observations)\n",
    "            actions_pi_log_prob = actions_pi_log_prob.reshape(-1, 1)\n",
    "\n",
    "            entropy_coef = self.get_and_optimize_entropy_coef(actions_pi_log_prob, step_info)\n",
    "            log_if_enabled(step_info, 'entropy_coef', entropy_coef, self.logging_config.log_entropy_coef)\n",
    "\n",
    "            critic_loss = self.calculate_critic_loss(\n",
    "                observation_features=replay_samples.observations,\n",
    "                replay_samples=replay_samples,\n",
    "                entropy_coef=entropy_coef,\n",
    "                info=step_info\n",
    "            )\n",
    "\n",
    "            self.critic_optimizer.zero_grad()\n",
    "            critic_loss.backward()\n",
    "            self.critic_optimizer.step()\n",
    "\n",
    "            actor_loss = self.calculate_actor_loss(\n",
    "                observation_features=replay_samples.observations,\n",
    "                actions_pi=actions_pi,\n",
    "                actions_pi_log_prob=actions_pi_log_prob,\n",
    "                entropy_coef=entropy_coef,\n",
    "                info=step_info\n",
    "            )\n",
    "\n",
    "            self.actor_optimizer.zero_grad()\n",
    "            actor_loss.backward()\n",
    "            self.actor_optimizer.step()\n",
    "\n",
    "            self.gradient_steps_performed += 1\n",
    "            if self.target_update_interval > 0 and self.gradient_steps_performed % self.target_update_interval == 0:\n",
    "                # self.policy.perform_polyak_update(self.tau)\n",
    "                polyak_update(self.critic.parameters(), self.policy.critic_target.parameters(), self.tau)\n",
    "            gradient_step_infos.append(step_info)\n",
    "        info.update(concat_infos(gradient_step_infos))\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-08T13:36:30.871570Z",
     "start_time": "2024-10-08T13:36:27.542985Z"
    }
   },
   "id": "ff68171985aae759",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T13:36:31.631299Z",
     "start_time": "2024-10-08T13:36:30.872704Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "from sac import init_policy, init_action_selector\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "import stable_baselines3 as sb\n",
    "from src.reinforcement_learning.gym.parallelize_env import parallelize_env_async\n",
    "import gymnasium\n",
    "\n",
    "env_name = 'HalfCheetah-v4'\n",
    "# env_kwargs = {'forward_reward_weight': 1.25, 'healthy_reward': 0.5, 'ctrl_cost_weight': 0.001 }\n",
    "# env_kwargs = {'forward_reward_weight': 1.25, 'ctrl_cost_weight': 0.1 }\n",
    "# env_kwargs = {'forward_reward_weight': 1.25, 'ctrl_cost_weight': 0.05 }\n",
    "env_kwargs = {}\n",
    "num_envs = 1\n",
    "\n",
    "def create_env(render_mode: str | None):\n",
    "    return gymnasium.make(env_name, render_mode=render_mode, **env_kwargs)\n",
    "\n",
    "# env = parallelize_env_async(lambda: create_env(render_mode=None), num_envs)\n",
    "env = create_env(render_mode=None)\n",
    "\n",
    "from stable_baselines3.sac.sac import SAC\n",
    "\n",
    "sb_sac = SAC(\"MlpPolicy\", env, verbose=10, learning_starts=10000, stats_window_size=1) # , seed=594371)"
   ],
   "id": "47c2f325a8cba618",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T13:36:31.640485Z",
     "start_time": "2024-10-08T13:36:31.631299Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import copy\n",
    "from src.console import print_warning\n",
    "from src.tags import Tags\n",
    "from src.reinforcement_learning.core.policies.components.actor import Actor\n",
    "from src.reinforcement_learning.core.policies.components.q_critic import QCritic\n",
    "from src.reinforcement_learning.core.policies.base_policy import BasePolicy\n",
    "import stable_baselines3 as sb\n",
    "\n",
    "\n",
    "class DebugSACPolicy(BasePolicy):\n",
    "    \n",
    "    actor: sb.sac.policies.Actor\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            actor: Actor,\n",
    "            critic: QCritic,\n",
    "            shared_feature_extractor: Optional[FeatureExtractor] = None\n",
    "    ):\n",
    "        super().__init__(actor, shared_feature_extractor)\n",
    "        self.actor = sb.sac.policies.Actor(\n",
    "            env.observation_space,\n",
    "            env.action_space,\n",
    "            [256, 256],\n",
    "            FlattenExtractor(env.observation_space),\n",
    "            17\n",
    "        )\n",
    "\n",
    "        self.critic = critic\n",
    "\n",
    "        self._build_target()\n",
    "\n",
    "        self._check_action_selector()\n",
    "        \n",
    "    @property\n",
    "    def uses_sde(self):\n",
    "        return False\n",
    "        \n",
    "    def act(self, obs: TensorObs) -> torch.Tensor:\n",
    "        return self.actor(obs, False)\n",
    "    \n",
    "    def reset_sde_noise(self, batch_size: int) -> None:\n",
    "        pass\n",
    "        \n",
    "\n",
    "    def collect_hyper_parameters(self) -> HyperParameters:\n",
    "        return {}\n",
    "\n",
    "    def collect_tags(self) -> Tags:\n",
    "        return []\n",
    "\n",
    "    def _check_action_selector(self):\n",
    "        # if not isinstance(self.actor.action_selector, (PredictedStdActionSelector, StateDependentNoiseActionSelector)):\n",
    "        #     print_warning('SAC not being used with PredictedStdAction Selector or gSDE. LogStds should be clamped!')\n",
    "        pass\n",
    "\n",
    "    def _build_target(self):\n",
    "        self.target_critic = copy.deepcopy(self.critic)\n",
    "        self.target_critic.set_trainable(False)\n",
    "\n",
    "        self.target_shared_feature_extractor = copy.deepcopy(self.shared_feature_extractor)\n",
    "        self.target_shared_feature_extractor.set_trainable(False)\n",
    "\n",
    "    def forward(self):\n",
    "        raise NotImplementedError('forward is not used in SACPolicy')\n",
    "\n",
    "    def compute_target_values(\n",
    "            self,\n",
    "            replay_samples: ReplayBufferSamples,\n",
    "            entropy_coef: torch.Tensor,\n",
    "            gamma: float,\n",
    "    ):\n",
    "        with torch.no_grad():\n",
    "            next_observations = replay_samples.next_observations\n",
    "\n",
    "            next_actions, next_actions_log_prob = self.actor.action_log_prob(\n",
    "                self.shared_feature_extractor(next_observations)\n",
    "            )\n",
    "\n",
    "            next_q_values = torch.cat(\n",
    "                self.target_critic(self.target_shared_feature_extractor(next_observations), next_actions),\n",
    "                dim=-1\n",
    "            )\n",
    "            next_q_values, _ = torch.min(next_q_values, dim=-1, keepdim=True)\n",
    "            next_q_values = next_q_values - entropy_coef * next_actions_log_prob.reshape(-1, 1)\n",
    "\n",
    "            target_q_values = replay_samples.rewards + (1 - replay_samples.dones) * gamma * next_q_values\n",
    "\n",
    "            return target_q_values\n",
    "\n",
    "\n",
    "    def perform_polyak_update(self, tau: float):\n",
    "        polyak_update(self.critic.parameters(), self.target_critic.parameters(), tau)\n",
    "        polyak_update(\n",
    "            self.shared_feature_extractor.parameters(),\n",
    "            self.target_shared_feature_extractor.parameters(),\n",
    "            tau\n",
    "        )\n",
    "\n",
    "    def set_train_mode(self, mode: bool) -> None:\n",
    "        self.actor.set_training_mode(mode)\n",
    "        self.critic.set_train_mode(mode)\n",
    "        # Leaving target_critic on train_mode = False\n",
    "\n",
    "        self.shared_feature_extractor.set_train_mode(mode)\n",
    "        # Leaving target_shared_feature_extractor on train_mode = False\n",
    "\n",
    "        self.train_mode = mode\n"
   ],
   "id": "1948bbcf34ea601e",
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "source": [
    "import inspect\n",
    "import time\n",
    "\n",
    "from gymnasium import Env\n",
    "\n",
    "from sac import init_action_selector, init_policy, init_optimizer, wrap_env, policy_construction_hyper_parameter\n",
    "from src.datetime import get_current_timestamp\n",
    "from src.experiment_logging.experiment_logger import ExperimentLogger, log_experiment\n",
    "from src.model_db.dummy_model_db import DummyModelDB\n",
    "from src.reinforcement_learning.algorithms.policy_mitosis.mitosis_policy_info import MitosisPolicyInfo\n",
    "from src.module_analysis import count_parameters\n",
    "from src.moving_averages import ExponentialMovingAverage\n",
    "from src.reinforcement_learning.core.policies.base_policy import BasePolicy\n",
    "from src.reinforcement_learning.core.policy_construction import PolicyConstruction\n",
    "from src.stopwatch import Stopwatch\n",
    "from src.summary_statistics import format_summary_statics\n",
    "from typing import Any\n",
    "from src.reinforcement_learning.core.callback import Callback\n",
    "\n",
    "import torch\n",
    "from torch import optim\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-08T13:36:31.745527Z",
     "start_time": "2024-10-08T13:36:31.641513Z"
    }
   },
   "id": "2051c5de0ad8edfb",
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "source": [
    "from src.summary_statistics import maybe_compute_summary_statistics\n",
    "from src.reinforcement_learning.core.loss_config import LossLoggingConfig\n",
    "from src.reinforcement_learning.algorithms.sac.sac import SAC, SACLoggingConfig\n",
    "def get_setup() -> dict[str, str]:\n",
    "    import inspect\n",
    "    import sac\n",
    "    return {\n",
    "        'sac.py': inspect.getsource(sac),\n",
    "        'notebook': _ih[1] + '\\n\\n' + _ih[-4] + '\\n\\n' + _ih[-3] + '\\n\\n' + _ih[-2] + '\\n\\n' + _ih[-1], # first and last cell input (imports and this cell)\n",
    "    }\n",
    "\n",
    "policy_id: str\n",
    "policy: BasePolicy\n",
    "optimizer: optim.Optimizer\n",
    "wrapped_env: Env\n",
    "steps_trained: int\n",
    "def get_policy(create_new_if_exists: bool):\n",
    "    \n",
    "    global policy_id, policy, optimizer, wrapped_env, steps_trained\n",
    "    \n",
    "    policy_in_ram = 'policy' in globals()\n",
    "    if not policy_in_ram or create_new_if_exists:\n",
    "        if not policy_in_ram:\n",
    "            print('No policy in RAM, creating a new one')\n",
    "        \n",
    "        policy_id = get_current_timestamp()\n",
    "        policy, optimizer, wrapped_env = PolicyConstruction.init_from_info(\n",
    "            env=env,\n",
    "            info=PolicyConstruction.create_policy_initialization_info(\n",
    "                init_action_selector=init_action_selector,\n",
    "                init_policy=init_policy,\n",
    "                init_optimizer=init_optimizer,\n",
    "                wrap_env=wrap_env,\n",
    "                hyper_parameters=policy_construction_hyper_parameter,\n",
    "            ),\n",
    "        )\n",
    "        steps_trained = 0\n",
    "        print(f'New policy {policy_id} created')\n",
    "    \n",
    "    if parent_policy_id is not None:\n",
    "        model_entry = policy_db.load_model_state_dict(policy, parent_policy_id)\n",
    "        steps_trained = model_entry['model_info']['steps_trained']\n",
    "        print(f'Loading state dict from policy {parent_policy_id}')\n",
    "    \n",
    "    print(f'Using policy {policy_id} with parent policy {parent_policy_id}')\n",
    "    return policy_id, policy, optimizer, wrapped_env, steps_trained\n",
    "\n",
    "score_mean_ema = ExponentialMovingAverage(alpha=0.25)\n",
    "step_stopwatch = Stopwatch()\n",
    "total_stopwatch = Stopwatch()\n",
    "best_iteration_score = -1e6\n",
    "\n",
    "def on_rollout_done(rl: SAC, step: int, info: dict[str, Any], scheduler_values: dict[str, Any]):\n",
    "    \n",
    "    if step % 1000 != 0:\n",
    "        return\n",
    "    \n",
    "    # tail_indices = rl.buffer.tail_indices(1000)\n",
    "    \n",
    "    # rewards = rl.buffer.rewards[tail_indices]\n",
    "    # if 'raw_rewards' in info['rollout']:\n",
    "    #     rewards = info['rollout']['raw_rewards']\n",
    "    \n",
    "    # episode_scores = compute_episode_returns(\n",
    "    #     rewards=rewards,\n",
    "    #     episode_starts=np.repeat(np.arange(len(tail_indices)).reshape(-1, 1), num_envs, axis=1) % 1000 == 0,\n",
    "    #     last_episode_starts=info['last_episode_starts'],\n",
    "    #     gamma=1.0,\n",
    "    #     gae_lambda=1.0,\n",
    "    #     normalize_rewards=None,\n",
    "    #     remove_unfinished_episodes=True,\n",
    "    # )\n",
    "    \n",
    "    # episode_scores = rl.buffer.compute_most_recent_episode_scores(rl.num_envs)\n",
    "    # \n",
    "    # if len(episode_scores) > 0:\n",
    "    # \n",
    "    #     global best_iteration_score\n",
    "    #     iteration_score = episode_scores.mean()\n",
    "    #     score_moving_average = score_mean_ema.update(iteration_score)\n",
    "    #     if iteration_score >= best_iteration_score:\n",
    "    #         best_iteration_score = iteration_score\n",
    "    #         policy_db.save_model_state_dict(\n",
    "    #             model_id=policy_id,\n",
    "    #             parent_model_id=parent_policy_id,\n",
    "    #             model_info={\n",
    "    #                 'score': iteration_score.item(),\n",
    "    #                 'steps_trained': steps_trained,\n",
    "    #                 'wrap_env_source_code': wrap_env_source_code_source,\n",
    "    #                 'init_policy_source_code': init_policy_source\n",
    "    #             },\n",
    "    #             model=policy,\n",
    "    #             optimizer=optimizer,\n",
    "    #         )\n",
    "    #     info['score_moving_average'] = score_moving_average\n",
    "    # \n",
    "    # info['episode_scores'] = episode_scores\n",
    "        \n",
    "def on_optimization_done(rl: SAC, step: int, info: dict[str, Any], scheduler_values: dict[str, Any]):\n",
    "    # global steps_trained\n",
    "    # steps_trained += rl.buffer.pos\n",
    "    \n",
    "    if step % 1000 != 0:\n",
    "        return\n",
    "    num_env_steps = step * rl.num_envs\n",
    "    \n",
    "    step_time = step_stopwatch.reset()\n",
    "    total_time = total_stopwatch.time_passed()\n",
    "    \n",
    "    # TODO!!\n",
    "    # tail_indices = rl.buffer.tail_indices(1000)\n",
    "    \n",
    "    # episode_scores = info.get('episode_scores')\n",
    "    score_moving_average = info.get('score_moving_average') or 0.0\n",
    "    \n",
    "    tail_indices = np.arange(rl.buffer.pos - 1000, rl.buffer.pos)\n",
    "    episode_scores = rl.buffer.rewards[tail_indices].sum(axis=0)\n",
    "    \n",
    "    scores = format_summary_statics(\n",
    "        episode_scores, \n",
    "        mean_format=' 6.3f',\n",
    "        std_format='4.3f',\n",
    "        min_value_format=' 6.3f',\n",
    "        max_value_format='5.3f',\n",
    "        n_format='>2'\n",
    "    )\n",
    "    # scores2 = format_summary_statics(\n",
    "    #     rl.buffer.compute_most_recent_episode_scores(rl.num_envs, lambda r: 1 * r), \n",
    "    #     mean_format=' 6.3f',\n",
    "    #     std_format='4.3f',\n",
    "    #     min_value_format=' 6.3f',\n",
    "    #     max_value_format='5.3f',\n",
    "    #     n_format='>2'\n",
    "    # )\n",
    "    # advantages = format_summary_statics(\n",
    "    #     rl.buffer.advantages, \n",
    "    #     mean_format=' 6.3f',\n",
    "    #     std_format='.1f',\n",
    "    #     min_value_format=' 7.3f',\n",
    "    #     max_value_format='6.3f',\n",
    "    # )\n",
    "    actor_loss = format_summary_statics(\n",
    "        info['final_actor_loss'],  \n",
    "        mean_format=' 5.3f',\n",
    "        # std_format='5.3f',\n",
    "        std_format=None,\n",
    "        min_value_format=None,\n",
    "        max_value_format=None,\n",
    "    )\n",
    "    # actor_loss_raw = format_summary_statics(\n",
    "    #     info['raw_actor_loss'],  \n",
    "    #     mean_format=' 5.3f',\n",
    "    #     std_format='5.3f',\n",
    "    #     min_value_format=None,\n",
    "    #     max_value_format=None,\n",
    "    # )\n",
    "    entropy_coef_loss = None if 'final_entropy_coef_loss' not in info else format_summary_statics(\n",
    "        info['final_entropy_coef_loss'], \n",
    "        mean_format='5.3f',\n",
    "#         std_format='5.3f',\n",
    "        std_format=None,\n",
    "        min_value_format=None,\n",
    "        max_value_format=None,\n",
    "    )\n",
    "    critic_loss = format_summary_statics(\n",
    "        info['final_critic_loss'], \n",
    "        mean_format='5.3f',\n",
    "#         std_format='5.3f',\n",
    "        std_format=None,\n",
    "        min_value_format=None,\n",
    "        max_value_format=None,\n",
    "    )\n",
    "    entropy_coef = format_summary_statics(\n",
    "        info['entropy_coef'],\n",
    "        mean_format='5.3f',\n",
    "#         std_format='5.3f',\n",
    "        std_format=None,\n",
    "        min_value_format=None,\n",
    "        max_value_format=None,\n",
    "    )\n",
    "    # resets = format_summary_statics(\n",
    "    #     rl.buffer.dones.astype(int).sum(axis=0), \n",
    "    #     mean_format='.2f',\n",
    "    #     std_format=None,\n",
    "    #     min_value_format='1d',\n",
    "    #     max_value_format=None,\n",
    "    # )\n",
    "    # kl_div = info['actor_kl_divergence'][-1]\n",
    "    # grad_norm = format_summary_statics(\n",
    "    #     info['grad_norm'], \n",
    "    #     mean_format=' 6.3f',\n",
    "    #     std_format='.1f',\n",
    "    #     min_value_format=' 7.3f',\n",
    "    #     max_value_format='6.3f',\n",
    "    # )\n",
    "    action_stds = info['rollout'].get('action_stds')\n",
    "    if action_stds is not None:\n",
    "        rollout_action_stds = format_summary_statics(\n",
    "            action_stds,\n",
    "            mean_format='5.3f',\n",
    "            std_format='5.3f',\n",
    "            min_value_format=None,\n",
    "            max_value_format=None,\n",
    "        )\n",
    "    else:\n",
    "        rollout_action_stds = 'N/A'\n",
    "    action_magnitude = format_summary_statics(\n",
    "        np.abs(rl.buffer.actions[tail_indices]),\n",
    "        mean_format='5.3f',\n",
    "        std_format='5.3f',\n",
    "        min_value_format=None,\n",
    "        max_value_format=None,\n",
    "    )\n",
    "    # ppo_epochs = info['nr_ppo_epochs']\n",
    "    # ppo_updates = info['nr_ppo_updates']\n",
    "    # expl_var = rl.buffer.compute_critic_explained_variance()\n",
    "    print(f\"{step = : >7}, \"\n",
    "          f\"{num_env_steps = : >7}, \"\n",
    "          f\"{scores = :s}, \"\n",
    "          # f\"{scores2 = :s}, \"\n",
    "          f'score_ema = {score_moving_average: 6.3f}, '\n",
    "          # f\"{advantages = :s}, \"\n",
    "          f\"{actor_loss = :s}, \"\n",
    "          # f\"{actor_loss_raw = :s}, \"\n",
    "          f\"{critic_loss = :s}, \"\n",
    "          +(f\"{entropy_coef_loss = :s}, \" if entropy_coef_loss is not None else '')+\n",
    "          f\"{entropy_coef = :s}, \"\n",
    "          f\"rollout_stds = {rollout_action_stds:s}, \"\n",
    "          f\"{action_magnitude = :s}, \"\n",
    "          # f\"{expl_var = :.3f}, \"\n",
    "          # f\"{kl_div = :.4f}, \"\n",
    "          # f\"{ppo_epochs = }, \"\n",
    "          # f\"{ppo_updates = }, \"\n",
    "          # f\"{grad_norm = :s}, \"\n",
    "          f\"n_updates = {rl.gradient_steps_performed}, \"\n",
    "          # f\"{resets = :s}, \"\n",
    "          f\"time = {step_time:4.1f}, \"\n",
    "          f\"total_time = {total_time:4.1f} \\n\"\n",
    "          )\n",
    "    logger.add_item({\n",
    "        'step': step,\n",
    "        'num_env_steps': num_env_steps,\n",
    "        'scores': maybe_compute_summary_statistics(episode_scores),\n",
    "        'actor_loss': maybe_compute_summary_statistics(info['final_actor_loss']),\n",
    "        'entropy_coef_loss': maybe_compute_summary_statistics(info.get('final_entropy_coef_loss')),\n",
    "        'critic_loss': maybe_compute_summary_statistics(info['final_critic_loss']),\n",
    "        'entropy_coef': maybe_compute_summary_statistics(info['entropy_coef']),\n",
    "        'action_stds': maybe_compute_summary_statistics(action_stds),\n",
    "        'action_magnitude': maybe_compute_summary_statistics(np.abs(rl.buffer.actions[tail_indices])),\n",
    "        'num_gradient_steps': rl.gradient_steps_performed,\n",
    "        'step_time': step_time,\n",
    "        'total_time': total_time\n",
    "    })\n",
    "    if step % 10000 == 0:\n",
    "        logger.save_experiment_log()\n",
    "        print()\n",
    "    print()\n",
    "    \n",
    "    # if episode_scores is not None and len(episode_scores) > 0 and episode_scores.mean().item() < -500:\n",
    "    #     logger.save_experiment_log()\n",
    "    #     raise ValueError('Score too low, policy probably fucked :(')\n",
    "\n",
    "device = torch.device(\"cuda:0\") if True else torch.device('cpu')\n",
    "print(f'using device {device}')\n",
    "\n",
    "def create_env(render_mode: str | None):\n",
    "    return gym.make(env_name, render_mode=render_mode, **env_kwargs)\n",
    "\n",
    "wrap_env_source_code_source = inspect.getsource(wrap_env)\n",
    "init_policy_source = inspect.getsource(init_policy)\n",
    "\n",
    "env_name = 'HalfCheetah-v4'\n",
    "# env_kwargs = {'forward_reward_weight': 1.25, 'healthy_reward': 0.5, 'ctrl_cost_weight': 0.001 }\n",
    "# env_kwargs = {'forward_reward_weight': 1.25, 'ctrl_cost_weight': 0.1 }\n",
    "# env_kwargs = {'forward_reward_weight': 1.25, 'ctrl_cost_weight': 0.05 }\n",
    "env_kwargs = {}\n",
    "num_envs = 1\n",
    "    \n",
    "# policy_db = TinyModelDB[MitosisPolicyInfo](base_path=f'saved_models/rl/{env_name}')\n",
    "policy_db = DummyModelDB[MitosisPolicyInfo]()\n",
    "print(f'{policy_db = }')\n",
    "\n",
    "parent_policy_id=None  # '2024-04-28_20.57.23'\n",
    "\n",
    "# TODO\n",
    "# env = parallelize_env_async(lambda: create_env(render_mode=None), num_envs)\n",
    "env = create_env(render_mode=None)\n",
    "\n",
    "logger = ExperimentLogger(f'experiment_logs/{env_name}/sac/')\n",
    "\n",
    "try:\n",
    "    policy_id, policy, optimizer, wrapped_env, steps_trained = get_policy(create_new_if_exists=False)\n",
    "    print(f'{count_parameters(policy) = }')\n",
    "    print(f'{env = }, {num_envs = }')\n",
    "        \n",
    "    with ((torch.autograd.set_detect_anomaly(False))):\n",
    "        algo = SAC(\n",
    "            env=wrapped_env,\n",
    "            policy=DebugSACPolicy(policy.actor, policy.critic),\n",
    "            actor_optimizer_provider=lambda params: optim.Adam(params, lr=3e-4),  # (params, lr=3e-4, betas=(0.5, 0.999)),\n",
    "            critic_optimizer_provider=lambda params: optim.Adam(params, lr=3e-4),  # (params, lr=3e-4, betas=(0.5, 0.999)),\n",
    "            # weigh_and_reduce_actor_loss=lambda l: 1 * l.mean(),\n",
    "            # weigh_critic_loss=lambda l: 1 * l,\n",
    "            buffer_size=1_000_000,\n",
    "            reward_scale=1,\n",
    "            gamma=0.99,\n",
    "            tau=0.005,\n",
    "            entropy_coef_optimizer_provider=lambda params: optim.Adam(params, lr=3e-4),\n",
    "            entropy_coef=1.0,\n",
    "            rollout_steps=1,\n",
    "            gradient_steps=1,\n",
    "            warmup_steps=10_000,\n",
    "            optimization_batch_size=256,\n",
    "            target_update_interval=1,\n",
    "            # sde_noise_sample_freq=50,\n",
    "            callback=Callback(\n",
    "                on_rollout_done=on_rollout_done,\n",
    "                rollout_schedulers={},\n",
    "                on_optimization_done=on_optimization_done,\n",
    "                optimization_schedulers={},\n",
    "            ),\n",
    "            logging_config=SACLoggingConfig(log_rollout_infos=True, log_rollout_action_stds=True,\n",
    "                                            log_last_obs=True, log_entropy_coef=True,\n",
    "                                            entropy_coef_loss=LossLoggingConfig(log_final=True),\n",
    "                                            actor_loss=LossLoggingConfig(log_final=True, log_raw=True),\n",
    "                                            critic_loss=LossLoggingConfig(log_final=True)),\n",
    "            torch_device=device,\n",
    "        )\n",
    "        \n",
    "        # Todo!\n",
    "        algo.buffer = sb_sac.replay_buffer\n",
    "        algo.buffer.to_torch = lambda arr: torch.tensor(arr, device='cuda', dtype=torch.float32)\n",
    "        \n",
    "        total_stopwatch.reset()\n",
    "        with log_experiment(\n",
    "            logger,\n",
    "            experiment_tags=algo.collect_tags() + ['Debug'],\n",
    "            hyper_parameters=algo.collect_hyper_parameters(),\n",
    "            setup=get_setup(),\n",
    "        ) as x:\n",
    "            logger.save_experiment_log()\n",
    "            print('\\nStarting Training\\n\\n')\n",
    "            # import cProfile\n",
    "            # pr = cProfile.Profile()\n",
    "            # pr.enable()\n",
    "            algo.learn(5_000_000)\n",
    "            # pr.disable()  \n",
    "            # pr.dump_stats('profile_stats.pstat')\n",
    "except KeyboardInterrupt:\n",
    "    print('keyboard interrupt')\n",
    "finally:\n",
    "    print('closing envs')\n",
    "    time.sleep(0.5)\n",
    "    env.close()\n",
    "    print('envs closed')\n",
    "    policy_db.close()\n",
    "    print('model db closed')\n",
    "    \n",
    "\n",
    "print('done')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-08T14:58:40.880948Z",
     "start_time": "2024-10-08T13:43:48.085478Z"
    }
   },
   "id": "2bf98616d22b5cdc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device cuda:0\n",
      "policy_db = DummyModelDB()\n",
      "Using policy 2024-10-08 13:36:31.856491 with parent policy None\n",
      "count_parameters(policy) = 217870\n",
      "env = <TimeLimit<OrderEnforcing<PassiveEnvChecker<HalfCheetahEnv<HalfCheetah-v4>>>>>, num_envs = 1\n",
      "Grabbing system information... done!\n",
      "saved experiment log 2024-10-08_13-43-48_236302~fXPQM9 at experiment_logs/HalfCheetah-v4/sac/2024-10-08_13-43-48_236302~fXPQM9.json\n",
      "\n",
      "Starting Training\n",
      "\n",
      "\n",
      "step =   11000, num_env_steps =   11000, scores = -239.672 (n= 1), score_ema =  0.000, actor_loss = -59.483, critic_loss = 3.322, entropy_coef_loss = -3.001, entropy_coef = 0.741, rollout_stds = N/A, action_magnitude = 0.534 ± 0.286, n_updates = 1000, time = 12.8, total_time = 12.8 \n",
      "\n",
      "\n",
      "step =   12000, num_env_steps =   12000, scores = -239.406 (n= 1), score_ema =  0.000, actor_loss = -63.789, critic_loss = 3.120, entropy_coef_loss = -5.929, entropy_coef = 0.549, rollout_stds = N/A, action_magnitude = 0.536 ± 0.289, n_updates = 2000, time =  9.5, total_time = 22.3 \n",
      "\n",
      "\n",
      "step =   13000, num_env_steps =   13000, scores = -199.818 (n= 1), score_ema =  0.000, actor_loss = -66.719, critic_loss = 3.169, entropy_coef_loss = -8.631, entropy_coef = 0.409, rollout_stds = N/A, action_magnitude = 0.547 ± 0.292, n_updates = 3000, time =  9.4, total_time = 31.7 \n",
      "\n",
      "\n",
      "step =   14000, num_env_steps =   14000, scores = -257.730 (n= 1), score_ema =  0.000, actor_loss = -67.195, critic_loss = 2.804, entropy_coef_loss = -10.886, entropy_coef = 0.305, rollout_stds = N/A, action_magnitude = 0.559 ± 0.289, n_updates = 4000, time = 10.4, total_time = 42.0 \n",
      "\n",
      "\n",
      "step =   15000, num_env_steps =   15000, scores = -233.388 (n= 1), score_ema =  0.000, actor_loss = -67.021, critic_loss = 3.228, entropy_coef_loss = -12.485, entropy_coef = 0.230, rollout_stds = N/A, action_magnitude = 0.566 ± 0.292, n_updates = 5000, time = 10.2, total_time = 52.2 \n",
      "\n",
      "\n",
      "step =   16000, num_env_steps =   16000, scores = -252.401 (n= 1), score_ema =  0.000, actor_loss = -66.691, critic_loss = 2.212, entropy_coef_loss = -13.559, entropy_coef = 0.174, rollout_stds = N/A, action_magnitude = 0.583 ± 0.296, n_updates = 6000, time = 10.1, total_time = 62.3 \n",
      "\n",
      "\n",
      "step =   17000, num_env_steps =   17000, scores = -220.717 (n= 1), score_ema =  0.000, actor_loss = -65.136, critic_loss = 2.548, entropy_coef_loss = -13.985, entropy_coef = 0.133, rollout_stds = N/A, action_magnitude = 0.600 ± 0.296, n_updates = 7000, time = 10.7, total_time = 73.0 \n",
      "\n",
      "\n",
      "step =   18000, num_env_steps =   18000, scores = -201.286 (n= 1), score_ema =  0.000, actor_loss = -64.224, critic_loss = 16.004, entropy_coef_loss = -12.387, entropy_coef = 0.102, rollout_stds = N/A, action_magnitude = 0.614 ± 0.296, n_updates = 8000, time = 11.8, total_time = 84.8 \n",
      "\n",
      "\n",
      "step =   19000, num_env_steps =   19000, scores = -184.261 (n= 1), score_ema =  0.000, actor_loss = -63.569, critic_loss = 2.492, entropy_coef_loss = -11.539, entropy_coef = 0.080, rollout_stds = N/A, action_magnitude = 0.627 ± 0.298, n_updates = 9000, time =  9.7, total_time = 94.5 \n",
      "\n",
      "\n",
      "step =   20000, num_env_steps =   20000, scores = -119.719 (n= 1), score_ema =  0.000, actor_loss = -62.750, critic_loss = 2.364, entropy_coef_loss = -9.147, entropy_coef = 0.063, rollout_stds = N/A, action_magnitude = 0.645 ± 0.302, n_updates = 10000, time =  9.8, total_time = 104.3 \n",
      "\n",
      "saved experiment log 2024-10-08_13-43-48_236302~fXPQM9 at experiment_logs/HalfCheetah-v4/sac/2024-10-08_13-43-48_236302~fXPQM9.json\n",
      "\n",
      "\n",
      "step =   21000, num_env_steps =   21000, scores = -166.720 (n= 1), score_ema =  0.000, actor_loss = -60.280, critic_loss = 2.370, entropy_coef_loss = -9.067, entropy_coef = 0.050, rollout_stds = N/A, action_magnitude = 0.654 ± 0.297, n_updates = 11000, time =  9.6, total_time = 113.8 \n",
      "\n",
      "\n",
      "step =   22000, num_env_steps =   22000, scores = -754.090 (n= 1), score_ema =  0.000, actor_loss = -60.804, critic_loss = 2.317, entropy_coef_loss = -9.633, entropy_coef = 0.040, rollout_stds = N/A, action_magnitude = 0.731 ± 0.288, n_updates = 12000, time =  9.5, total_time = 123.3 \n",
      "\n",
      "\n",
      "step =   23000, num_env_steps =   23000, scores = -463.733 (n= 1), score_ema =  0.000, actor_loss = -61.033, critic_loss = 2.854, entropy_coef_loss = -7.492, entropy_coef = 0.031, rollout_stds = N/A, action_magnitude = 0.725 ± 0.291, n_updates = 13000, time =  9.6, total_time = 132.9 \n",
      "\n",
      "\n",
      "step =   24000, num_env_steps =   24000, scores = -284.556 (n= 1), score_ema =  0.000, actor_loss = -57.395, critic_loss = 19.526, entropy_coef_loss = -8.036, entropy_coef = 0.024, rollout_stds = N/A, action_magnitude = 0.706 ± 0.287, n_updates = 14000, time =  9.6, total_time = 142.5 \n",
      "\n",
      "\n",
      "step =   25000, num_env_steps =   25000, scores = -25.898 (n= 1), score_ema =  0.000, actor_loss = -57.877, critic_loss = 12.500, entropy_coef_loss = -0.209, entropy_coef = 0.019, rollout_stds = N/A, action_magnitude = 0.630 ± 0.299, n_updates = 15000, time =  9.4, total_time = 151.9 \n",
      "\n",
      "\n",
      "step =   26000, num_env_steps =   26000, scores =  713.222 (n= 1), score_ema =  0.000, actor_loss = -55.033, critic_loss = 2.397, entropy_coef_loss = 3.132, entropy_coef = 0.016, rollout_stds = N/A, action_magnitude = 0.710 ± 0.288, n_updates = 16000, time =  9.6, total_time = 161.5 \n",
      "\n",
      "\n",
      "step =   27000, num_env_steps =   27000, scores =  404.440 (n= 1), score_ema =  0.000, actor_loss = -54.281, critic_loss = 2.679, entropy_coef_loss = -1.191, entropy_coef = 0.014, rollout_stds = N/A, action_magnitude = 0.653 ± 0.306, n_updates = 17000, time =  9.9, total_time = 171.4 \n",
      "\n",
      "\n",
      "step =   28000, num_env_steps =   28000, scores =  1005.716 (n= 1), score_ema =  0.000, actor_loss = -51.835, critic_loss = 3.414, entropy_coef_loss = 3.184, entropy_coef = 0.013, rollout_stds = N/A, action_magnitude = 0.704 ± 0.297, n_updates = 18000, time =  9.5, total_time = 180.9 \n",
      "\n",
      "\n",
      "step =   29000, num_env_steps =   29000, scores =  1466.962 (n= 1), score_ema =  0.000, actor_loss = -55.083, critic_loss = 3.541, entropy_coef_loss = -0.635, entropy_coef = 0.013, rollout_stds = N/A, action_magnitude = 0.709 ± 0.292, n_updates = 19000, time =  9.3, total_time = 190.2 \n",
      "\n",
      "\n",
      "step =   30000, num_env_steps =   30000, scores =  1404.987 (n= 1), score_ema =  0.000, actor_loss = -53.514, critic_loss = 3.189, entropy_coef_loss = 0.404, entropy_coef = 0.013, rollout_stds = N/A, action_magnitude = 0.711 ± 0.294, n_updates = 20000, time =  9.5, total_time = 199.7 \n",
      "\n",
      "saved experiment log 2024-10-08_13-43-48_236302~fXPQM9 at experiment_logs/HalfCheetah-v4/sac/2024-10-08_13-43-48_236302~fXPQM9.json\n",
      "\n",
      "\n",
      "step =   31000, num_env_steps =   31000, scores =  1347.795 (n= 1), score_ema =  0.000, actor_loss = -52.654, critic_loss = 3.883, entropy_coef_loss = -0.993, entropy_coef = 0.014, rollout_stds = N/A, action_magnitude = 0.705 ± 0.296, n_updates = 21000, time = 10.7, total_time = 210.4 \n",
      "\n",
      "\n",
      "step =   32000, num_env_steps =   32000, scores =  1627.075 (n= 1), score_ema =  0.000, actor_loss = -55.527, critic_loss = 2.801, entropy_coef_loss = 1.291, entropy_coef = 0.015, rollout_stds = N/A, action_magnitude = 0.735 ± 0.288, n_updates = 22000, time = 11.3, total_time = 221.8 \n",
      "\n",
      "\n",
      "step =   33000, num_env_steps =   33000, scores =  1461.770 (n= 1), score_ema =  0.000, actor_loss = -52.940, critic_loss = 2.428, entropy_coef_loss = -0.541, entropy_coef = 0.016, rollout_stds = N/A, action_magnitude = 0.720 ± 0.288, n_updates = 23000, time = 11.1, total_time = 232.8 \n",
      "\n",
      "\n",
      "step =   34000, num_env_steps =   34000, scores =  1213.253 (n= 1), score_ema =  0.000, actor_loss = -54.999, critic_loss = 2.776, entropy_coef_loss = -1.013, entropy_coef = 0.017, rollout_stds = N/A, action_magnitude = 0.689 ± 0.297, n_updates = 24000, time = 10.4, total_time = 243.2 \n",
      "\n",
      "\n",
      "step =   35000, num_env_steps =   35000, scores =  1536.223 (n= 1), score_ema =  0.000, actor_loss = -55.768, critic_loss = 3.751, entropy_coef_loss = -0.886, entropy_coef = 0.018, rollout_stds = N/A, action_magnitude = 0.699 ± 0.294, n_updates = 25000, time =  9.8, total_time = 253.0 \n",
      "\n",
      "\n",
      "step =   36000, num_env_steps =   36000, scores =  1742.663 (n= 1), score_ema =  0.000, actor_loss = -57.635, critic_loss = 16.604, entropy_coef_loss = 2.937, entropy_coef = 0.020, rollout_stds = N/A, action_magnitude = 0.715 ± 0.291, n_updates = 26000, time = 10.2, total_time = 263.3 \n",
      "\n",
      "\n",
      "step =   37000, num_env_steps =   37000, scores =  1760.908 (n= 1), score_ema =  0.000, actor_loss = -56.507, critic_loss = 3.653, entropy_coef_loss = 2.330, entropy_coef = 0.020, rollout_stds = N/A, action_magnitude = 0.723 ± 0.290, n_updates = 27000, time = 11.0, total_time = 274.3 \n",
      "\n",
      "\n",
      "step =   38000, num_env_steps =   38000, scores =  1943.926 (n= 1), score_ema =  0.000, actor_loss = -59.099, critic_loss = 5.122, entropy_coef_loss = 1.733, entropy_coef = 0.021, rollout_stds = N/A, action_magnitude = 0.719 ± 0.288, n_updates = 28000, time = 10.1, total_time = 284.3 \n",
      "\n",
      "\n",
      "step =   39000, num_env_steps =   39000, scores =  2110.269 (n= 1), score_ema =  0.000, actor_loss = -63.083, critic_loss = 3.938, entropy_coef_loss = -1.719, entropy_coef = 0.023, rollout_stds = N/A, action_magnitude = 0.722 ± 0.289, n_updates = 29000, time = 10.0, total_time = 294.3 \n",
      "\n",
      "\n",
      "step =   40000, num_env_steps =   40000, scores =  1356.084 (n= 1), score_ema =  0.000, actor_loss = -64.991, critic_loss = 4.273, entropy_coef_loss = -0.658, entropy_coef = 0.024, rollout_stds = N/A, action_magnitude = 0.727 ± 0.289, n_updates = 30000, time = 10.8, total_time = 305.1 \n",
      "\n",
      "saved experiment log 2024-10-08_13-43-48_236302~fXPQM9 at experiment_logs/HalfCheetah-v4/sac/2024-10-08_13-43-48_236302~fXPQM9.json\n",
      "\n",
      "\n",
      "step =   41000, num_env_steps =   41000, scores =  2466.512 (n= 1), score_ema =  0.000, actor_loss = -66.695, critic_loss = 3.428, entropy_coef_loss = 0.246, entropy_coef = 0.025, rollout_stds = N/A, action_magnitude = 0.730 ± 0.283, n_updates = 31000, time = 12.9, total_time = 318.0 \n",
      "\n",
      "\n",
      "step =   42000, num_env_steps =   42000, scores =  1550.255 (n= 1), score_ema =  0.000, actor_loss = -65.672, critic_loss = 4.412, entropy_coef_loss = 4.121, entropy_coef = 0.026, rollout_stds = N/A, action_magnitude = 0.715 ± 0.292, n_updates = 32000, time = 10.2, total_time = 328.3 \n",
      "\n",
      "\n",
      "step =   43000, num_env_steps =   43000, scores =  1213.936 (n= 1), score_ema =  0.000, actor_loss = -69.057, critic_loss = 10.446, entropy_coef_loss = 0.927, entropy_coef = 0.027, rollout_stds = N/A, action_magnitude = 0.716 ± 0.291, n_updates = 33000, time = 10.6, total_time = 338.9 \n",
      "\n",
      "\n",
      "step =   44000, num_env_steps =   44000, scores =  2215.082 (n= 1), score_ema =  0.000, actor_loss = -74.698, critic_loss = 4.266, entropy_coef_loss = 1.305, entropy_coef = 0.027, rollout_stds = N/A, action_magnitude = 0.717 ± 0.294, n_updates = 34000, time = 10.4, total_time = 349.3 \n",
      "\n",
      "\n",
      "step =   45000, num_env_steps =   45000, scores =  2565.312 (n= 1), score_ema =  0.000, actor_loss = -74.637, critic_loss = 4.520, entropy_coef_loss = 0.550, entropy_coef = 0.027, rollout_stds = N/A, action_magnitude = 0.729 ± 0.292, n_updates = 35000, time = 12.0, total_time = 361.3 \n",
      "\n",
      "\n",
      "step =   46000, num_env_steps =   46000, scores =  2584.189 (n= 1), score_ema =  0.000, actor_loss = -71.808, critic_loss = 5.079, entropy_coef_loss = -0.162, entropy_coef = 0.028, rollout_stds = N/A, action_magnitude = 0.729 ± 0.290, n_updates = 36000, time = 16.7, total_time = 378.0 \n",
      "\n",
      "\n",
      "step =   47000, num_env_steps =   47000, scores =  2523.616 (n= 1), score_ema =  0.000, actor_loss = -75.786, critic_loss = 6.809, entropy_coef_loss = -0.585, entropy_coef = 0.029, rollout_stds = N/A, action_magnitude = 0.735 ± 0.291, n_updates = 37000, time = 12.1, total_time = 390.1 \n",
      "\n",
      "\n",
      "step =   48000, num_env_steps =   48000, scores =  2647.699 (n= 1), score_ema =  0.000, actor_loss = -79.781, critic_loss = 53.582, entropy_coef_loss = -0.382, entropy_coef = 0.029, rollout_stds = N/A, action_magnitude = 0.730 ± 0.291, n_updates = 38000, time = 10.3, total_time = 400.4 \n",
      "\n",
      "\n",
      "step =   49000, num_env_steps =   49000, scores =  2667.914 (n= 1), score_ema =  0.000, actor_loss = -83.796, critic_loss = 6.234, entropy_coef_loss = 2.239, entropy_coef = 0.029, rollout_stds = N/A, action_magnitude = 0.720 ± 0.291, n_updates = 39000, time = 10.8, total_time = 411.2 \n",
      "\n",
      "\n",
      "step =   50000, num_env_steps =   50000, scores =  2426.722 (n= 1), score_ema =  0.000, actor_loss = -87.148, critic_loss = 6.358, entropy_coef_loss = -0.094, entropy_coef = 0.031, rollout_stds = N/A, action_magnitude = 0.735 ± 0.286, n_updates = 40000, time = 12.3, total_time = 423.6 \n",
      "\n",
      "saved experiment log 2024-10-08_13-43-48_236302~fXPQM9 at experiment_logs/HalfCheetah-v4/sac/2024-10-08_13-43-48_236302~fXPQM9.json\n",
      "\n",
      "\n",
      "step =   51000, num_env_steps =   51000, scores =  2640.994 (n= 1), score_ema =  0.000, actor_loss = -81.265, critic_loss = 6.470, entropy_coef_loss = -1.056, entropy_coef = 0.031, rollout_stds = N/A, action_magnitude = 0.736 ± 0.288, n_updates = 41000, time = 10.4, total_time = 433.9 \n",
      "\n",
      "\n",
      "step =   52000, num_env_steps =   52000, scores =  2598.181 (n= 1), score_ema =  0.000, actor_loss = -90.066, critic_loss = 6.126, entropy_coef_loss = 1.365, entropy_coef = 0.033, rollout_stds = N/A, action_magnitude = 0.730 ± 0.292, n_updates = 42000, time = 10.2, total_time = 444.2 \n",
      "\n",
      "\n",
      "step =   53000, num_env_steps =   53000, scores =  2156.614 (n= 1), score_ema =  0.000, actor_loss = -91.112, critic_loss = 6.155, entropy_coef_loss = -1.449, entropy_coef = 0.033, rollout_stds = N/A, action_magnitude = 0.722 ± 0.289, n_updates = 43000, time = 11.5, total_time = 455.7 \n",
      "\n",
      "\n",
      "step =   54000, num_env_steps =   54000, scores =  2883.033 (n= 1), score_ema =  0.000, actor_loss = -94.804, critic_loss = 5.673, entropy_coef_loss = 0.297, entropy_coef = 0.034, rollout_stds = N/A, action_magnitude = 0.742 ± 0.284, n_updates = 44000, time = 11.2, total_time = 466.9 \n",
      "\n",
      "\n",
      "step =   55000, num_env_steps =   55000, scores =  2818.016 (n= 1), score_ema =  0.000, actor_loss = -88.694, critic_loss = 5.664, entropy_coef_loss = 0.253, entropy_coef = 0.034, rollout_stds = N/A, action_magnitude = 0.745 ± 0.283, n_updates = 45000, time = 11.4, total_time = 478.3 \n",
      "\n",
      "\n",
      "step =   56000, num_env_steps =   56000, scores =  2551.890 (n= 1), score_ema =  0.000, actor_loss = -100.086, critic_loss = 7.519, entropy_coef_loss = -0.667, entropy_coef = 0.034, rollout_stds = N/A, action_magnitude = 0.744 ± 0.283, n_updates = 46000, time = 13.4, total_time = 491.7 \n",
      "\n",
      "\n",
      "step =   57000, num_env_steps =   57000, scores =  2794.370 (n= 1), score_ema =  0.000, actor_loss = -104.141, critic_loss = 5.706, entropy_coef_loss = -0.113, entropy_coef = 0.034, rollout_stds = N/A, action_magnitude = 0.734 ± 0.286, n_updates = 47000, time = 10.7, total_time = 502.4 \n",
      "\n",
      "\n",
      "step =   58000, num_env_steps =   58000, scores =  74.862 (n= 1), score_ema =  0.000, actor_loss = -102.270, critic_loss = 5.817, entropy_coef_loss = 1.889, entropy_coef = 0.035, rollout_stds = N/A, action_magnitude = 0.680 ± 0.300, n_updates = 48000, time = 10.4, total_time = 512.8 \n",
      "\n",
      "\n",
      "step =   59000, num_env_steps =   59000, scores =  2779.402 (n= 1), score_ema =  0.000, actor_loss = -110.685, critic_loss = 35.688, entropy_coef_loss = 0.556, entropy_coef = 0.036, rollout_stds = N/A, action_magnitude = 0.739 ± 0.289, n_updates = 49000, time = 10.6, total_time = 523.4 \n",
      "\n",
      "\n",
      "step =   60000, num_env_steps =   60000, scores =  2956.673 (n= 1), score_ema =  0.000, actor_loss = -107.132, critic_loss = 5.541, entropy_coef_loss = 0.424, entropy_coef = 0.035, rollout_stds = N/A, action_magnitude = 0.730 ± 0.293, n_updates = 50000, time = 11.8, total_time = 535.2 \n",
      "\n",
      "saved experiment log 2024-10-08_13-43-48_236302~fXPQM9 at experiment_logs/HalfCheetah-v4/sac/2024-10-08_13-43-48_236302~fXPQM9.json\n",
      "\n",
      "\n",
      "step =   61000, num_env_steps =   61000, scores =  668.644 (n= 1), score_ema =  0.000, actor_loss = -102.603, critic_loss = 4.965, entropy_coef_loss = 0.654, entropy_coef = 0.034, rollout_stds = N/A, action_magnitude = 0.685 ± 0.297, n_updates = 51000, time = 12.0, total_time = 547.2 \n",
      "\n",
      "\n",
      "step =   62000, num_env_steps =   62000, scores =  2759.200 (n= 1), score_ema =  0.000, actor_loss = -111.093, critic_loss = 5.027, entropy_coef_loss = -2.418, entropy_coef = 0.034, rollout_stds = N/A, action_magnitude = 0.728 ± 0.292, n_updates = 52000, time = 10.5, total_time = 557.8 \n",
      "\n",
      "\n",
      "step =   63000, num_env_steps =   63000, scores =  3035.366 (n= 1), score_ema =  0.000, actor_loss = -110.527, critic_loss = 46.899, entropy_coef_loss = -0.642, entropy_coef = 0.034, rollout_stds = N/A, action_magnitude = 0.723 ± 0.292, n_updates = 53000, time = 10.4, total_time = 568.1 \n",
      "\n",
      "\n",
      "step =   64000, num_env_steps =   64000, scores =  3017.189 (n= 1), score_ema =  0.000, actor_loss = -107.964, critic_loss = 7.847, entropy_coef_loss = 0.644, entropy_coef = 0.035, rollout_stds = N/A, action_magnitude = 0.722 ± 0.294, n_updates = 54000, time =  9.8, total_time = 577.9 \n",
      "\n",
      "\n",
      "step =   65000, num_env_steps =   65000, scores =  3165.678 (n= 1), score_ema =  0.000, actor_loss = -116.299, critic_loss = 7.011, entropy_coef_loss = -0.915, entropy_coef = 0.035, rollout_stds = N/A, action_magnitude = 0.727 ± 0.292, n_updates = 55000, time =  9.9, total_time = 587.9 \n",
      "\n",
      "\n",
      "step =   66000, num_env_steps =   66000, scores =  2980.390 (n= 1), score_ema =  0.000, actor_loss = -115.964, critic_loss = 6.880, entropy_coef_loss = -2.376, entropy_coef = 0.037, rollout_stds = N/A, action_magnitude = 0.723 ± 0.293, n_updates = 56000, time = 11.3, total_time = 599.1 \n",
      "\n",
      "\n",
      "step =   67000, num_env_steps =   67000, scores =  3041.619 (n= 1), score_ema =  0.000, actor_loss = -120.191, critic_loss = 54.225, entropy_coef_loss = -0.346, entropy_coef = 0.037, rollout_stds = N/A, action_magnitude = 0.730 ± 0.287, n_updates = 57000, time = 13.9, total_time = 613.0 \n",
      "\n",
      "\n",
      "step =   68000, num_env_steps =   68000, scores =  3176.792 (n= 1), score_ema =  0.000, actor_loss = -121.281, critic_loss = 6.834, entropy_coef_loss = -1.028, entropy_coef = 0.037, rollout_stds = N/A, action_magnitude = 0.732 ± 0.290, n_updates = 58000, time =  9.9, total_time = 622.9 \n",
      "\n",
      "\n",
      "step =   69000, num_env_steps =   69000, scores =  2951.587 (n= 1), score_ema =  0.000, actor_loss = -123.437, critic_loss = 5.847, entropy_coef_loss = 1.120, entropy_coef = 0.038, rollout_stds = N/A, action_magnitude = 0.723 ± 0.294, n_updates = 59000, time =  9.7, total_time = 632.6 \n",
      "\n",
      "\n",
      "step =   70000, num_env_steps =   70000, scores =  3192.510 (n= 1), score_ema =  0.000, actor_loss = -132.823, critic_loss = 73.245, entropy_coef_loss = -0.184, entropy_coef = 0.039, rollout_stds = N/A, action_magnitude = 0.734 ± 0.288, n_updates = 60000, time =  9.7, total_time = 642.3 \n",
      "\n",
      "saved experiment log 2024-10-08_13-43-48_236302~fXPQM9 at experiment_logs/HalfCheetah-v4/sac/2024-10-08_13-43-48_236302~fXPQM9.json\n",
      "\n",
      "\n",
      "step =   71000, num_env_steps =   71000, scores =  3070.831 (n= 1), score_ema =  0.000, actor_loss = -126.674, critic_loss = 15.897, entropy_coef_loss = 1.166, entropy_coef = 0.040, rollout_stds = N/A, action_magnitude = 0.736 ± 0.286, n_updates = 61000, time =  9.7, total_time = 652.0 \n",
      "\n",
      "\n",
      "step =   72000, num_env_steps =   72000, scores =  3104.864 (n= 1), score_ema =  0.000, actor_loss = -132.954, critic_loss = 9.937, entropy_coef_loss = -1.596, entropy_coef = 0.041, rollout_stds = N/A, action_magnitude = 0.732 ± 0.287, n_updates = 62000, time = 10.4, total_time = 662.4 \n",
      "\n",
      "\n",
      "step =   73000, num_env_steps =   73000, scores =  3335.105 (n= 1), score_ema =  0.000, actor_loss = -132.247, critic_loss = 6.870, entropy_coef_loss = -0.736, entropy_coef = 0.040, rollout_stds = N/A, action_magnitude = 0.730 ± 0.291, n_updates = 63000, time =  9.9, total_time = 672.3 \n",
      "\n",
      "\n",
      "step =   74000, num_env_steps =   74000, scores =  3161.425 (n= 1), score_ema =  0.000, actor_loss = -134.004, critic_loss = 8.365, entropy_coef_loss = -0.788, entropy_coef = 0.040, rollout_stds = N/A, action_magnitude = 0.718 ± 0.291, n_updates = 64000, time = 12.0, total_time = 684.3 \n",
      "\n",
      "\n",
      "step =   75000, num_env_steps =   75000, scores =  3464.252 (n= 1), score_ema =  0.000, actor_loss = -138.055, critic_loss = 10.653, entropy_coef_loss = -0.419, entropy_coef = 0.041, rollout_stds = N/A, action_magnitude = 0.732 ± 0.286, n_updates = 65000, time = 10.3, total_time = 694.6 \n",
      "\n",
      "\n",
      "step =   76000, num_env_steps =   76000, scores =  3405.358 (n= 1), score_ema =  0.000, actor_loss = -136.481, critic_loss = 6.451, entropy_coef_loss = -1.609, entropy_coef = 0.042, rollout_stds = N/A, action_magnitude = 0.718 ± 0.291, n_updates = 66000, time = 10.3, total_time = 705.0 \n",
      "\n",
      "\n",
      "step =   77000, num_env_steps =   77000, scores =  3457.805 (n= 1), score_ema =  0.000, actor_loss = -141.269, critic_loss = 7.804, entropy_coef_loss = 0.996, entropy_coef = 0.042, rollout_stds = N/A, action_magnitude = 0.739 ± 0.285, n_updates = 67000, time = 10.7, total_time = 715.7 \n",
      "\n",
      "\n",
      "step =   78000, num_env_steps =   78000, scores =  3429.528 (n= 1), score_ema =  0.000, actor_loss = -138.266, critic_loss = 11.414, entropy_coef_loss = -0.904, entropy_coef = 0.042, rollout_stds = N/A, action_magnitude = 0.735 ± 0.285, n_updates = 68000, time = 11.2, total_time = 726.9 \n",
      "\n",
      "\n",
      "step =   79000, num_env_steps =   79000, scores =  3530.707 (n= 1), score_ema =  0.000, actor_loss = -145.088, critic_loss = 8.077, entropy_coef_loss = 0.175, entropy_coef = 0.043, rollout_stds = N/A, action_magnitude = 0.732 ± 0.288, n_updates = 69000, time = 14.9, total_time = 741.8 \n",
      "\n",
      "\n",
      "step =   80000, num_env_steps =   80000, scores =  3402.095 (n= 1), score_ema =  0.000, actor_loss = -153.115, critic_loss = 7.841, entropy_coef_loss = -1.056, entropy_coef = 0.042, rollout_stds = N/A, action_magnitude = 0.729 ± 0.288, n_updates = 70000, time = 13.1, total_time = 754.9 \n",
      "\n",
      "saved experiment log 2024-10-08_13-43-48_236302~fXPQM9 at experiment_logs/HalfCheetah-v4/sac/2024-10-08_13-43-48_236302~fXPQM9.json\n",
      "\n",
      "\n",
      "step =   81000, num_env_steps =   81000, scores =  3520.418 (n= 1), score_ema =  0.000, actor_loss = -140.046, critic_loss = 7.344, entropy_coef_loss = -2.421, entropy_coef = 0.044, rollout_stds = N/A, action_magnitude = 0.734 ± 0.287, n_updates = 71000, time = 11.7, total_time = 766.6 \n",
      "\n",
      "\n",
      "step =   82000, num_env_steps =   82000, scores =  3389.343 (n= 1), score_ema =  0.000, actor_loss = -150.686, critic_loss = 11.052, entropy_coef_loss = 0.975, entropy_coef = 0.044, rollout_stds = N/A, action_magnitude = 0.727 ± 0.291, n_updates = 72000, time = 11.8, total_time = 778.4 \n",
      "\n",
      "\n",
      "step =   83000, num_env_steps =   83000, scores =  3253.316 (n= 1), score_ema =  0.000, actor_loss = -156.385, critic_loss = 9.702, entropy_coef_loss = 0.288, entropy_coef = 0.045, rollout_stds = N/A, action_magnitude = 0.729 ± 0.291, n_updates = 73000, time = 12.0, total_time = 790.4 \n",
      "\n",
      "\n",
      "step =   84000, num_env_steps =   84000, scores =  3503.666 (n= 1), score_ema =  0.000, actor_loss = -157.712, critic_loss = 12.538, entropy_coef_loss = 2.604, entropy_coef = 0.046, rollout_stds = N/A, action_magnitude = 0.735 ± 0.287, n_updates = 74000, time = 12.2, total_time = 802.6 \n",
      "\n",
      "\n",
      "step =   85000, num_env_steps =   85000, scores =  3575.820 (n= 1), score_ema =  0.000, actor_loss = -157.118, critic_loss = 7.317, entropy_coef_loss = 1.064, entropy_coef = 0.046, rollout_stds = N/A, action_magnitude = 0.740 ± 0.285, n_updates = 75000, time = 11.1, total_time = 813.7 \n",
      "\n",
      "\n",
      "step =   86000, num_env_steps =   86000, scores =  3567.327 (n= 1), score_ema =  0.000, actor_loss = -157.950, critic_loss = 95.518, entropy_coef_loss = -0.757, entropy_coef = 0.048, rollout_stds = N/A, action_magnitude = 0.747 ± 0.284, n_updates = 76000, time = 11.9, total_time = 825.6 \n",
      "\n",
      "\n",
      "step =   87000, num_env_steps =   87000, scores =  3303.415 (n= 1), score_ema =  0.000, actor_loss = -153.433, critic_loss = 76.810, entropy_coef_loss = -0.835, entropy_coef = 0.047, rollout_stds = N/A, action_magnitude = 0.733 ± 0.291, n_updates = 77000, time = 10.9, total_time = 836.5 \n",
      "\n",
      "\n",
      "step =   88000, num_env_steps =   88000, scores =  3733.880 (n= 1), score_ema =  0.000, actor_loss = -156.183, critic_loss = 9.569, entropy_coef_loss = -0.732, entropy_coef = 0.047, rollout_stds = N/A, action_magnitude = 0.745 ± 0.282, n_updates = 78000, time = 10.2, total_time = 846.7 \n",
      "\n",
      "\n",
      "step =   89000, num_env_steps =   89000, scores =  3573.238 (n= 1), score_ema =  0.000, actor_loss = -162.010, critic_loss = 9.571, entropy_coef_loss = -0.043, entropy_coef = 0.048, rollout_stds = N/A, action_magnitude = 0.739 ± 0.285, n_updates = 79000, time =  9.7, total_time = 856.3 \n",
      "\n",
      "\n",
      "step =   90000, num_env_steps =   90000, scores =  3698.698 (n= 1), score_ema =  0.000, actor_loss = -162.343, critic_loss = 11.366, entropy_coef_loss = -0.524, entropy_coef = 0.049, rollout_stds = N/A, action_magnitude = 0.755 ± 0.280, n_updates = 80000, time = 12.7, total_time = 869.0 \n",
      "\n",
      "saved experiment log 2024-10-08_13-43-48_236302~fXPQM9 at experiment_logs/HalfCheetah-v4/sac/2024-10-08_13-43-48_236302~fXPQM9.json\n",
      "\n",
      "\n",
      "step =   91000, num_env_steps =   91000, scores =  3649.332 (n= 1), score_ema =  0.000, actor_loss = -167.814, critic_loss = 7.473, entropy_coef_loss = -1.092, entropy_coef = 0.048, rollout_stds = N/A, action_magnitude = 0.748 ± 0.282, n_updates = 81000, time = 12.1, total_time = 881.2 \n",
      "\n",
      "\n",
      "step =   92000, num_env_steps =   92000, scores =  3675.806 (n= 1), score_ema =  0.000, actor_loss = -172.066, critic_loss = 216.514, entropy_coef_loss = -0.081, entropy_coef = 0.048, rollout_stds = N/A, action_magnitude = 0.737 ± 0.289, n_updates = 82000, time =  9.5, total_time = 890.7 \n",
      "\n",
      "\n",
      "step =   93000, num_env_steps =   93000, scores =  3879.502 (n= 1), score_ema =  0.000, actor_loss = -164.323, critic_loss = 14.204, entropy_coef_loss = 0.108, entropy_coef = 0.050, rollout_stds = N/A, action_magnitude = 0.747 ± 0.285, n_updates = 83000, time = 10.6, total_time = 901.3 \n",
      "\n",
      "\n",
      "step =   94000, num_env_steps =   94000, scores =  3875.179 (n= 1), score_ema =  0.000, actor_loss = -167.655, critic_loss = 11.042, entropy_coef_loss = 0.353, entropy_coef = 0.049, rollout_stds = N/A, action_magnitude = 0.751 ± 0.282, n_updates = 84000, time = 10.0, total_time = 911.3 \n",
      "\n",
      "\n",
      "step =   95000, num_env_steps =   95000, scores =  3738.659 (n= 1), score_ema =  0.000, actor_loss = -170.823, critic_loss = 11.308, entropy_coef_loss = -0.531, entropy_coef = 0.050, rollout_stds = N/A, action_magnitude = 0.743 ± 0.285, n_updates = 85000, time = 10.5, total_time = 921.8 \n",
      "\n",
      "\n",
      "step =   96000, num_env_steps =   96000, scores =  3712.972 (n= 1), score_ema =  0.000, actor_loss = -160.615, critic_loss = 9.126, entropy_coef_loss = 0.078, entropy_coef = 0.051, rollout_stds = N/A, action_magnitude = 0.752 ± 0.283, n_updates = 86000, time =  9.2, total_time = 931.0 \n",
      "\n",
      "\n",
      "step =   97000, num_env_steps =   97000, scores =  3529.510 (n= 1), score_ema =  0.000, actor_loss = -164.356, critic_loss = 12.119, entropy_coef_loss = -0.135, entropy_coef = 0.051, rollout_stds = N/A, action_magnitude = 0.749 ± 0.284, n_updates = 87000, time =  8.9, total_time = 939.9 \n",
      "\n",
      "\n",
      "step =   98000, num_env_steps =   98000, scores =  3754.826 (n= 1), score_ema =  0.000, actor_loss = -177.407, critic_loss = 10.260, entropy_coef_loss = 1.375, entropy_coef = 0.050, rollout_stds = N/A, action_magnitude = 0.737 ± 0.288, n_updates = 88000, time =  9.8, total_time = 949.7 \n",
      "\n",
      "\n",
      "step =   99000, num_env_steps =   99000, scores =  3619.111 (n= 1), score_ema =  0.000, actor_loss = -182.434, critic_loss = 9.321, entropy_coef_loss = 2.459, entropy_coef = 0.052, rollout_stds = N/A, action_magnitude = 0.750 ± 0.285, n_updates = 89000, time = 10.5, total_time = 960.2 \n",
      "\n",
      "\n",
      "step =  100000, num_env_steps =  100000, scores =  3731.052 (n= 1), score_ema =  0.000, actor_loss = -177.356, critic_loss = 7.901, entropy_coef_loss = -0.384, entropy_coef = 0.052, rollout_stds = N/A, action_magnitude = 0.750 ± 0.285, n_updates = 90000, time = 10.5, total_time = 970.7 \n",
      "\n",
      "saved experiment log 2024-10-08_13-43-48_236302~fXPQM9 at experiment_logs/HalfCheetah-v4/sac/2024-10-08_13-43-48_236302~fXPQM9.json\n",
      "\n",
      "\n",
      "step =  101000, num_env_steps =  101000, scores =  4050.114 (n= 1), score_ema =  0.000, actor_loss = -175.266, critic_loss = 9.291, entropy_coef_loss = -0.592, entropy_coef = 0.053, rollout_stds = N/A, action_magnitude = 0.765 ± 0.272, n_updates = 91000, time = 10.2, total_time = 980.9 \n",
      "\n",
      "\n",
      "step =  102000, num_env_steps =  102000, scores =  3946.477 (n= 1), score_ema =  0.000, actor_loss = -184.256, critic_loss = 9.612, entropy_coef_loss = -0.261, entropy_coef = 0.054, rollout_stds = N/A, action_magnitude = 0.762 ± 0.278, n_updates = 92000, time =  9.3, total_time = 990.2 \n",
      "\n",
      "\n",
      "step =  103000, num_env_steps =  103000, scores =  3877.954 (n= 1), score_ema =  0.000, actor_loss = -192.916, critic_loss = 122.964, entropy_coef_loss = 1.052, entropy_coef = 0.056, rollout_stds = N/A, action_magnitude = 0.752 ± 0.280, n_updates = 93000, time =  9.2, total_time = 999.3 \n",
      "\n",
      "\n",
      "step =  104000, num_env_steps =  104000, scores =  3925.113 (n= 1), score_ema =  0.000, actor_loss = -187.306, critic_loss = 6.326, entropy_coef_loss = -0.283, entropy_coef = 0.056, rollout_stds = N/A, action_magnitude = 0.760 ± 0.280, n_updates = 94000, time =  9.1, total_time = 1008.4 \n",
      "\n",
      "\n",
      "step =  105000, num_env_steps =  105000, scores =  3892.624 (n= 1), score_ema =  0.000, actor_loss = -189.138, critic_loss = 128.005, entropy_coef_loss = -0.046, entropy_coef = 0.056, rollout_stds = N/A, action_magnitude = 0.752 ± 0.282, n_updates = 95000, time =  9.4, total_time = 1017.8 \n",
      "\n",
      "\n",
      "step =  106000, num_env_steps =  106000, scores =  3754.413 (n= 1), score_ema =  0.000, actor_loss = -188.480, critic_loss = 9.462, entropy_coef_loss = -0.356, entropy_coef = 0.056, rollout_stds = N/A, action_magnitude = 0.751 ± 0.281, n_updates = 96000, time = 10.0, total_time = 1027.9 \n",
      "\n",
      "\n",
      "step =  107000, num_env_steps =  107000, scores =  3998.056 (n= 1), score_ema =  0.000, actor_loss = -183.137, critic_loss = 7.331, entropy_coef_loss = -1.737, entropy_coef = 0.057, rollout_stds = N/A, action_magnitude = 0.757 ± 0.278, n_updates = 97000, time = 10.6, total_time = 1038.4 \n",
      "\n",
      "\n",
      "step =  108000, num_env_steps =  108000, scores =  3964.119 (n= 1), score_ema =  0.000, actor_loss = -189.960, critic_loss = 9.505, entropy_coef_loss = -1.896, entropy_coef = 0.057, rollout_stds = N/A, action_magnitude = 0.755 ± 0.281, n_updates = 98000, time = 10.6, total_time = 1049.1 \n",
      "\n",
      "\n",
      "step =  109000, num_env_steps =  109000, scores =  3853.066 (n= 1), score_ema =  0.000, actor_loss = -191.660, critic_loss = 9.185, entropy_coef_loss = 0.567, entropy_coef = 0.057, rollout_stds = N/A, action_magnitude = 0.750 ± 0.283, n_updates = 99000, time =  9.1, total_time = 1058.2 \n",
      "\n",
      "\n",
      "step =  110000, num_env_steps =  110000, scores =  4067.340 (n= 1), score_ema =  0.000, actor_loss = -201.002, critic_loss = 9.131, entropy_coef_loss = -0.543, entropy_coef = 0.059, rollout_stds = N/A, action_magnitude = 0.756 ± 0.279, n_updates = 100000, time =  9.7, total_time = 1067.8 \n",
      "\n",
      "saved experiment log 2024-10-08_13-43-48_236302~fXPQM9 at experiment_logs/HalfCheetah-v4/sac/2024-10-08_13-43-48_236302~fXPQM9.json\n",
      "\n",
      "\n",
      "step =  111000, num_env_steps =  111000, scores =  3999.854 (n= 1), score_ema =  0.000, actor_loss = -199.273, critic_loss = 8.319, entropy_coef_loss = 0.545, entropy_coef = 0.059, rollout_stds = N/A, action_magnitude = 0.768 ± 0.274, n_updates = 101000, time =  9.3, total_time = 1077.1 \n",
      "\n",
      "\n",
      "step =  112000, num_env_steps =  112000, scores =  3767.903 (n= 1), score_ema =  0.000, actor_loss = -185.362, critic_loss = 10.282, entropy_coef_loss = -0.459, entropy_coef = 0.057, rollout_stds = N/A, action_magnitude = 0.751 ± 0.280, n_updates = 102000, time = 10.0, total_time = 1087.1 \n",
      "\n",
      "\n",
      "step =  113000, num_env_steps =  113000, scores =  3814.173 (n= 1), score_ema =  0.000, actor_loss = -194.723, critic_loss = 143.751, entropy_coef_loss = 0.892, entropy_coef = 0.058, rollout_stds = N/A, action_magnitude = 0.757 ± 0.279, n_updates = 103000, time =  9.4, total_time = 1096.5 \n",
      "\n",
      "\n",
      "step =  114000, num_env_steps =  114000, scores =  3849.914 (n= 1), score_ema =  0.000, actor_loss = -196.255, critic_loss = 12.478, entropy_coef_loss = 1.241, entropy_coef = 0.060, rollout_stds = N/A, action_magnitude = 0.759 ± 0.274, n_updates = 104000, time =  9.3, total_time = 1105.8 \n",
      "\n",
      "\n",
      "step =  115000, num_env_steps =  115000, scores =  3994.881 (n= 1), score_ema =  0.000, actor_loss = -200.422, critic_loss = 9.793, entropy_coef_loss = -0.096, entropy_coef = 0.059, rollout_stds = N/A, action_magnitude = 0.763 ± 0.273, n_updates = 105000, time =  9.4, total_time = 1115.2 \n",
      "\n",
      "\n",
      "step =  116000, num_env_steps =  116000, scores =  3865.602 (n= 1), score_ema =  0.000, actor_loss = -194.693, critic_loss = 10.012, entropy_coef_loss = -1.589, entropy_coef = 0.061, rollout_stds = N/A, action_magnitude = 0.757 ± 0.278, n_updates = 106000, time = 10.0, total_time = 1125.2 \n",
      "\n",
      "\n",
      "step =  117000, num_env_steps =  117000, scores =  4081.357 (n= 1), score_ema =  0.000, actor_loss = -194.502, critic_loss = 10.762, entropy_coef_loss = -0.437, entropy_coef = 0.061, rollout_stds = N/A, action_magnitude = 0.764 ± 0.274, n_updates = 107000, time =  9.5, total_time = 1134.7 \n",
      "\n",
      "\n",
      "step =  118000, num_env_steps =  118000, scores =  4061.002 (n= 1), score_ema =  0.000, actor_loss = -199.128, critic_loss = 8.136, entropy_coef_loss = -2.364, entropy_coef = 0.063, rollout_stds = N/A, action_magnitude = 0.760 ± 0.276, n_updates = 108000, time = 10.0, total_time = 1144.7 \n",
      "\n",
      "\n",
      "step =  119000, num_env_steps =  119000, scores =  4076.563 (n= 1), score_ema =  0.000, actor_loss = -204.170, critic_loss = 213.566, entropy_coef_loss = 1.561, entropy_coef = 0.064, rollout_stds = N/A, action_magnitude = 0.761 ± 0.279, n_updates = 109000, time =  9.7, total_time = 1154.4 \n",
      "\n",
      "\n",
      "step =  120000, num_env_steps =  120000, scores =  4058.761 (n= 1), score_ema =  0.000, actor_loss = -204.630, critic_loss = 7.690, entropy_coef_loss = 0.203, entropy_coef = 0.063, rollout_stds = N/A, action_magnitude = 0.761 ± 0.275, n_updates = 110000, time =  9.2, total_time = 1163.6 \n",
      "\n",
      "saved experiment log 2024-10-08_13-43-48_236302~fXPQM9 at experiment_logs/HalfCheetah-v4/sac/2024-10-08_13-43-48_236302~fXPQM9.json\n",
      "\n",
      "\n",
      "step =  121000, num_env_steps =  121000, scores =  4334.472 (n= 1), score_ema =  0.000, actor_loss = -203.209, critic_loss = 30.177, entropy_coef_loss = 1.426, entropy_coef = 0.062, rollout_stds = N/A, action_magnitude = 0.765 ± 0.274, n_updates = 111000, time =  9.9, total_time = 1173.5 \n",
      "\n",
      "\n",
      "step =  122000, num_env_steps =  122000, scores =  3933.130 (n= 1), score_ema =  0.000, actor_loss = -217.235, critic_loss = 252.856, entropy_coef_loss = 3.091, entropy_coef = 0.062, rollout_stds = N/A, action_magnitude = 0.760 ± 0.274, n_updates = 112000, time =  9.5, total_time = 1183.0 \n",
      "\n",
      "\n",
      "step =  123000, num_env_steps =  123000, scores =  4046.269 (n= 1), score_ema =  0.000, actor_loss = -210.795, critic_loss = 11.608, entropy_coef_loss = 1.809, entropy_coef = 0.065, rollout_stds = N/A, action_magnitude = 0.761 ± 0.278, n_updates = 113000, time =  9.1, total_time = 1192.1 \n",
      "\n",
      "\n",
      "step =  124000, num_env_steps =  124000, scores =  4132.832 (n= 1), score_ema =  0.000, actor_loss = -210.135, critic_loss = 269.262, entropy_coef_loss = 1.553, entropy_coef = 0.066, rollout_stds = N/A, action_magnitude = 0.769 ± 0.273, n_updates = 114000, time =  9.4, total_time = 1201.5 \n",
      "\n",
      "\n",
      "step =  125000, num_env_steps =  125000, scores =  4157.625 (n= 1), score_ema =  0.000, actor_loss = -205.810, critic_loss = 256.736, entropy_coef_loss = -0.918, entropy_coef = 0.068, rollout_stds = N/A, action_magnitude = 0.774 ± 0.268, n_updates = 115000, time =  9.6, total_time = 1211.1 \n",
      "\n",
      "\n",
      "step =  126000, num_env_steps =  126000, scores =  4077.826 (n= 1), score_ema =  0.000, actor_loss = -206.770, critic_loss = 12.368, entropy_coef_loss = -1.076, entropy_coef = 0.063, rollout_stds = N/A, action_magnitude = 0.764 ± 0.272, n_updates = 116000, time =  9.9, total_time = 1221.0 \n",
      "\n",
      "\n",
      "step =  127000, num_env_steps =  127000, scores =  3934.888 (n= 1), score_ema =  0.000, actor_loss = -207.293, critic_loss = 10.732, entropy_coef_loss = 0.792, entropy_coef = 0.065, rollout_stds = N/A, action_magnitude = 0.761 ± 0.276, n_updates = 117000, time =  9.6, total_time = 1230.6 \n",
      "\n",
      "\n",
      "step =  128000, num_env_steps =  128000, scores =  4004.994 (n= 1), score_ema =  0.000, actor_loss = -212.931, critic_loss = 10.869, entropy_coef_loss = 0.655, entropy_coef = 0.067, rollout_stds = N/A, action_magnitude = 0.762 ± 0.274, n_updates = 118000, time =  9.2, total_time = 1239.8 \n",
      "\n",
      "\n",
      "step =  129000, num_env_steps =  129000, scores =  4047.068 (n= 1), score_ema =  0.000, actor_loss = -209.684, critic_loss = 11.282, entropy_coef_loss = 0.399, entropy_coef = 0.066, rollout_stds = N/A, action_magnitude = 0.758 ± 0.279, n_updates = 119000, time =  9.4, total_time = 1249.2 \n",
      "\n",
      "\n",
      "step =  130000, num_env_steps =  130000, scores =  4094.970 (n= 1), score_ema =  0.000, actor_loss = -212.367, critic_loss = 8.409, entropy_coef_loss = 0.002, entropy_coef = 0.069, rollout_stds = N/A, action_magnitude = 0.756 ± 0.278, n_updates = 120000, time =  8.7, total_time = 1257.9 \n",
      "\n",
      "saved experiment log 2024-10-08_13-43-48_236302~fXPQM9 at experiment_logs/HalfCheetah-v4/sac/2024-10-08_13-43-48_236302~fXPQM9.json\n",
      "\n",
      "\n",
      "step =  131000, num_env_steps =  131000, scores =  4002.694 (n= 1), score_ema =  0.000, actor_loss = -199.725, critic_loss = 14.142, entropy_coef_loss = 0.164, entropy_coef = 0.068, rollout_stds = N/A, action_magnitude = 0.766 ± 0.273, n_updates = 121000, time =  9.3, total_time = 1267.2 \n",
      "\n",
      "\n",
      "step =  132000, num_env_steps =  132000, scores =  3808.443 (n= 1), score_ema =  0.000, actor_loss = -215.240, critic_loss = 297.982, entropy_coef_loss = -0.075, entropy_coef = 0.070, rollout_stds = N/A, action_magnitude = 0.759 ± 0.276, n_updates = 122000, time =  9.8, total_time = 1277.0 \n",
      "\n",
      "\n",
      "step =  133000, num_env_steps =  133000, scores =  3986.059 (n= 1), score_ema =  0.000, actor_loss = -213.765, critic_loss = 300.981, entropy_coef_loss = -0.373, entropy_coef = 0.070, rollout_stds = N/A, action_magnitude = 0.753 ± 0.279, n_updates = 123000, time = 10.2, total_time = 1287.2 \n",
      "\n",
      "\n",
      "step =  134000, num_env_steps =  134000, scores =  4113.178 (n= 1), score_ema =  0.000, actor_loss = -217.283, critic_loss = 10.050, entropy_coef_loss = 0.547, entropy_coef = 0.069, rollout_stds = N/A, action_magnitude = 0.762 ± 0.274, n_updates = 124000, time =  9.9, total_time = 1297.1 \n",
      "\n",
      "\n",
      "step =  135000, num_env_steps =  135000, scores =  4131.466 (n= 1), score_ema =  0.000, actor_loss = -218.353, critic_loss = 11.703, entropy_coef_loss = 1.358, entropy_coef = 0.069, rollout_stds = N/A, action_magnitude = 0.764 ± 0.274, n_updates = 125000, time = 10.8, total_time = 1307.9 \n",
      "\n",
      "\n",
      "step =  136000, num_env_steps =  136000, scores =  4106.187 (n= 1), score_ema =  0.000, actor_loss = -200.984, critic_loss = 12.561, entropy_coef_loss = -0.129, entropy_coef = 0.071, rollout_stds = N/A, action_magnitude = 0.762 ± 0.274, n_updates = 126000, time = 11.8, total_time = 1319.7 \n",
      "\n",
      "\n",
      "step =  137000, num_env_steps =  137000, scores =  3932.365 (n= 1), score_ema =  0.000, actor_loss = -215.305, critic_loss = 10.954, entropy_coef_loss = 0.582, entropy_coef = 0.071, rollout_stds = N/A, action_magnitude = 0.761 ± 0.273, n_updates = 127000, time = 10.8, total_time = 1330.5 \n",
      "\n",
      "\n",
      "step =  138000, num_env_steps =  138000, scores =  3969.213 (n= 1), score_ema =  0.000, actor_loss = -225.765, critic_loss = 10.733, entropy_coef_loss = -0.143, entropy_coef = 0.070, rollout_stds = N/A, action_magnitude = 0.763 ± 0.274, n_updates = 128000, time = 11.0, total_time = 1341.5 \n",
      "\n",
      "\n",
      "step =  139000, num_env_steps =  139000, scores =  4042.640 (n= 1), score_ema =  0.000, actor_loss = -223.934, critic_loss = 11.440, entropy_coef_loss = 1.286, entropy_coef = 0.070, rollout_stds = N/A, action_magnitude = 0.757 ± 0.277, n_updates = 129000, time = 13.4, total_time = 1354.9 \n",
      "\n",
      "\n",
      "step =  140000, num_env_steps =  140000, scores =  4099.373 (n= 1), score_ema =  0.000, actor_loss = -214.979, critic_loss = 8.867, entropy_coef_loss = -1.247, entropy_coef = 0.069, rollout_stds = N/A, action_magnitude = 0.754 ± 0.280, n_updates = 130000, time = 12.6, total_time = 1367.4 \n",
      "\n",
      "saved experiment log 2024-10-08_13-43-48_236302~fXPQM9 at experiment_logs/HalfCheetah-v4/sac/2024-10-08_13-43-48_236302~fXPQM9.json\n",
      "\n",
      "\n",
      "step =  141000, num_env_steps =  141000, scores =  4137.636 (n= 1), score_ema =  0.000, actor_loss = -221.301, critic_loss = 9.322, entropy_coef_loss = -0.848, entropy_coef = 0.072, rollout_stds = N/A, action_magnitude = 0.760 ± 0.277, n_updates = 131000, time = 11.6, total_time = 1379.0 \n",
      "\n",
      "\n",
      "step =  142000, num_env_steps =  142000, scores =  3959.865 (n= 1), score_ema =  0.000, actor_loss = -221.914, critic_loss = 8.786, entropy_coef_loss = 0.387, entropy_coef = 0.072, rollout_stds = N/A, action_magnitude = 0.756 ± 0.278, n_updates = 132000, time =  9.6, total_time = 1388.6 \n",
      "\n",
      "\n",
      "step =  143000, num_env_steps =  143000, scores =  4145.305 (n= 1), score_ema =  0.000, actor_loss = -216.843, critic_loss = 282.669, entropy_coef_loss = -1.080, entropy_coef = 0.071, rollout_stds = N/A, action_magnitude = 0.754 ± 0.281, n_updates = 133000, time = 10.5, total_time = 1399.1 \n",
      "\n",
      "\n",
      "step =  144000, num_env_steps =  144000, scores =  4365.776 (n= 1), score_ema =  0.000, actor_loss = -224.423, critic_loss = 13.198, entropy_coef_loss = 0.302, entropy_coef = 0.071, rollout_stds = N/A, action_magnitude = 0.757 ± 0.279, n_updates = 134000, time = 11.7, total_time = 1410.9 \n",
      "\n",
      "\n",
      "step =  145000, num_env_steps =  145000, scores =  4071.311 (n= 1), score_ema =  0.000, actor_loss = -214.109, critic_loss = 11.637, entropy_coef_loss = 0.189, entropy_coef = 0.071, rollout_stds = N/A, action_magnitude = 0.764 ± 0.273, n_updates = 135000, time = 11.6, total_time = 1422.4 \n",
      "\n",
      "\n",
      "step =  146000, num_env_steps =  146000, scores =  4291.688 (n= 1), score_ema =  0.000, actor_loss = -230.042, critic_loss = 9.702, entropy_coef_loss = 0.189, entropy_coef = 0.072, rollout_stds = N/A, action_magnitude = 0.768 ± 0.273, n_updates = 136000, time =  9.5, total_time = 1431.9 \n",
      "\n",
      "\n",
      "step =  147000, num_env_steps =  147000, scores =  4110.520 (n= 1), score_ema =  0.000, actor_loss = -218.017, critic_loss = 237.744, entropy_coef_loss = -0.098, entropy_coef = 0.070, rollout_stds = N/A, action_magnitude = 0.762 ± 0.276, n_updates = 137000, time = 10.0, total_time = 1442.0 \n",
      "\n",
      "\n",
      "step =  148000, num_env_steps =  148000, scores =  4071.354 (n= 1), score_ema =  0.000, actor_loss = -226.684, critic_loss = 13.267, entropy_coef_loss = 0.618, entropy_coef = 0.071, rollout_stds = N/A, action_magnitude = 0.758 ± 0.278, n_updates = 138000, time = 10.0, total_time = 1452.0 \n",
      "\n",
      "\n",
      "step =  149000, num_env_steps =  149000, scores =  4221.166 (n= 1), score_ema =  0.000, actor_loss = -224.698, critic_loss = 9.247, entropy_coef_loss = 0.403, entropy_coef = 0.073, rollout_stds = N/A, action_magnitude = 0.776 ± 0.268, n_updates = 139000, time =  9.8, total_time = 1461.8 \n",
      "\n",
      "\n",
      "step =  150000, num_env_steps =  150000, scores =  3998.700 (n= 1), score_ema =  0.000, actor_loss = -225.631, critic_loss = 10.783, entropy_coef_loss = -1.215, entropy_coef = 0.074, rollout_stds = N/A, action_magnitude = 0.767 ± 0.272, n_updates = 140000, time = 10.2, total_time = 1472.0 \n",
      "\n",
      "saved experiment log 2024-10-08_13-43-48_236302~fXPQM9 at experiment_logs/HalfCheetah-v4/sac/2024-10-08_13-43-48_236302~fXPQM9.json\n",
      "\n",
      "\n",
      "step =  151000, num_env_steps =  151000, scores =  4177.629 (n= 1), score_ema =  0.000, actor_loss = -224.547, critic_loss = 14.860, entropy_coef_loss = -0.058, entropy_coef = 0.074, rollout_stds = N/A, action_magnitude = 0.768 ± 0.273, n_updates = 141000, time = 10.1, total_time = 1482.1 \n",
      "\n",
      "\n",
      "step =  152000, num_env_steps =  152000, scores =  4122.466 (n= 1), score_ema =  0.000, actor_loss = -223.475, critic_loss = 7.537, entropy_coef_loss = -0.646, entropy_coef = 0.074, rollout_stds = N/A, action_magnitude = 0.772 ± 0.275, n_updates = 142000, time = 12.3, total_time = 1494.4 \n",
      "\n",
      "\n",
      "step =  153000, num_env_steps =  153000, scores =  4213.092 (n= 1), score_ema =  0.000, actor_loss = -221.545, critic_loss = 135.516, entropy_coef_loss = 1.767, entropy_coef = 0.074, rollout_stds = N/A, action_magnitude = 0.777 ± 0.265, n_updates = 143000, time = 14.6, total_time = 1509.0 \n",
      "\n",
      "\n",
      "step =  154000, num_env_steps =  154000, scores =  3996.190 (n= 1), score_ema =  0.000, actor_loss = -224.756, critic_loss = 134.538, entropy_coef_loss = 0.714, entropy_coef = 0.075, rollout_stds = N/A, action_magnitude = 0.758 ± 0.276, n_updates = 144000, time = 13.2, total_time = 1522.1 \n",
      "\n",
      "\n",
      "step =  155000, num_env_steps =  155000, scores =  4218.564 (n= 1), score_ema =  0.000, actor_loss = -224.037, critic_loss = 9.794, entropy_coef_loss = -1.128, entropy_coef = 0.074, rollout_stds = N/A, action_magnitude = 0.762 ± 0.275, n_updates = 145000, time = 13.1, total_time = 1535.2 \n",
      "\n",
      "\n",
      "step =  156000, num_env_steps =  156000, scores =  3995.944 (n= 1), score_ema =  0.000, actor_loss = -228.587, critic_loss = 9.905, entropy_coef_loss = -0.892, entropy_coef = 0.074, rollout_stds = N/A, action_magnitude = 0.753 ± 0.278, n_updates = 146000, time = 13.2, total_time = 1548.4 \n",
      "\n",
      "\n",
      "step =  157000, num_env_steps =  157000, scores =  4244.848 (n= 1), score_ema =  0.000, actor_loss = -235.163, critic_loss = 9.831, entropy_coef_loss = 0.176, entropy_coef = 0.077, rollout_stds = N/A, action_magnitude = 0.763 ± 0.273, n_updates = 147000, time =  7.8, total_time = 1556.1 \n",
      "\n",
      "\n",
      "step =  158000, num_env_steps =  158000, scores =  4397.827 (n= 1), score_ema =  0.000, actor_loss = -234.849, critic_loss = 13.183, entropy_coef_loss = 0.045, entropy_coef = 0.075, rollout_stds = N/A, action_magnitude = 0.761 ± 0.277, n_updates = 148000, time =  6.8, total_time = 1562.9 \n",
      "\n",
      "\n",
      "step =  159000, num_env_steps =  159000, scores =  4234.649 (n= 1), score_ema =  0.000, actor_loss = -235.658, critic_loss = 13.408, entropy_coef_loss = -0.193, entropy_coef = 0.074, rollout_stds = N/A, action_magnitude = 0.756 ± 0.274, n_updates = 149000, time =  6.9, total_time = 1569.8 \n",
      "\n",
      "\n",
      "step =  160000, num_env_steps =  160000, scores =  4234.728 (n= 1), score_ema =  0.000, actor_loss = -237.635, critic_loss = 14.505, entropy_coef_loss = 0.578, entropy_coef = 0.073, rollout_stds = N/A, action_magnitude = 0.755 ± 0.280, n_updates = 150000, time =  6.5, total_time = 1576.4 \n",
      "\n",
      "saved experiment log 2024-10-08_13-43-48_236302~fXPQM9 at experiment_logs/HalfCheetah-v4/sac/2024-10-08_13-43-48_236302~fXPQM9.json\n",
      "\n",
      "\n",
      "step =  161000, num_env_steps =  161000, scores =  4137.863 (n= 1), score_ema =  0.000, actor_loss = -240.912, critic_loss = 14.136, entropy_coef_loss = 0.516, entropy_coef = 0.074, rollout_stds = N/A, action_magnitude = 0.754 ± 0.276, n_updates = 151000, time =  6.6, total_time = 1583.0 \n",
      "\n",
      "\n",
      "step =  162000, num_env_steps =  162000, scores =  4309.573 (n= 1), score_ema =  0.000, actor_loss = -240.174, critic_loss = 9.653, entropy_coef_loss = 0.214, entropy_coef = 0.075, rollout_stds = N/A, action_magnitude = 0.768 ± 0.269, n_updates = 152000, time =  6.6, total_time = 1589.6 \n",
      "\n",
      "\n",
      "step =  163000, num_env_steps =  163000, scores =  4393.559 (n= 1), score_ema =  0.000, actor_loss = -239.464, critic_loss = 160.182, entropy_coef_loss = 0.475, entropy_coef = 0.076, rollout_stds = N/A, action_magnitude = 0.762 ± 0.273, n_updates = 153000, time =  6.5, total_time = 1596.0 \n",
      "\n",
      "\n",
      "step =  164000, num_env_steps =  164000, scores =  4202.357 (n= 1), score_ema =  0.000, actor_loss = -236.457, critic_loss = 315.207, entropy_coef_loss = -0.135, entropy_coef = 0.076, rollout_stds = N/A, action_magnitude = 0.762 ± 0.273, n_updates = 154000, time =  6.7, total_time = 1602.8 \n",
      "\n",
      "\n",
      "step =  165000, num_env_steps =  165000, scores =  4316.499 (n= 1), score_ema =  0.000, actor_loss = -238.795, critic_loss = 10.607, entropy_coef_loss = 0.331, entropy_coef = 0.076, rollout_stds = N/A, action_magnitude = 0.759 ± 0.274, n_updates = 155000, time =  6.3, total_time = 1609.1 \n",
      "\n",
      "\n",
      "step =  166000, num_env_steps =  166000, scores =  4296.183 (n= 1), score_ema =  0.000, actor_loss = -231.765, critic_loss = 11.306, entropy_coef_loss = 0.703, entropy_coef = 0.075, rollout_stds = N/A, action_magnitude = 0.771 ± 0.271, n_updates = 156000, time =  7.1, total_time = 1616.2 \n",
      "\n",
      "\n",
      "step =  167000, num_env_steps =  167000, scores =  4160.548 (n= 1), score_ema =  0.000, actor_loss = -242.624, critic_loss = 240.952, entropy_coef_loss = 1.973, entropy_coef = 0.076, rollout_stds = N/A, action_magnitude = 0.753 ± 0.279, n_updates = 157000, time =  6.9, total_time = 1623.1 \n",
      "\n",
      "\n",
      "step =  168000, num_env_steps =  168000, scores =  3943.730 (n= 1), score_ema =  0.000, actor_loss = -239.782, critic_loss = 9.958, entropy_coef_loss = 0.793, entropy_coef = 0.077, rollout_stds = N/A, action_magnitude = 0.750 ± 0.281, n_updates = 158000, time =  7.1, total_time = 1630.2 \n",
      "\n",
      "\n",
      "step =  169000, num_env_steps =  169000, scores =  4476.967 (n= 1), score_ema =  0.000, actor_loss = -242.921, critic_loss = 106.661, entropy_coef_loss = 0.446, entropy_coef = 0.079, rollout_stds = N/A, action_magnitude = 0.763 ± 0.275, n_updates = 159000, time =  7.6, total_time = 1637.8 \n",
      "\n",
      "\n",
      "step =  170000, num_env_steps =  170000, scores =  4256.173 (n= 1), score_ema =  0.000, actor_loss = -241.257, critic_loss = 12.084, entropy_coef_loss = 0.081, entropy_coef = 0.079, rollout_stds = N/A, action_magnitude = 0.762 ± 0.275, n_updates = 160000, time =  7.6, total_time = 1645.4 \n",
      "\n",
      "saved experiment log 2024-10-08_13-43-48_236302~fXPQM9 at experiment_logs/HalfCheetah-v4/sac/2024-10-08_13-43-48_236302~fXPQM9.json\n",
      "\n",
      "\n",
      "step =  171000, num_env_steps =  171000, scores =  4349.669 (n= 1), score_ema =  0.000, actor_loss = -231.784, critic_loss = 10.842, entropy_coef_loss = 0.145, entropy_coef = 0.079, rollout_stds = N/A, action_magnitude = 0.763 ± 0.273, n_updates = 161000, time =  7.1, total_time = 1652.6 \n",
      "\n",
      "\n",
      "step =  172000, num_env_steps =  172000, scores =  4289.125 (n= 1), score_ema =  0.000, actor_loss = -240.381, critic_loss = 12.268, entropy_coef_loss = -0.564, entropy_coef = 0.078, rollout_stds = N/A, action_magnitude = 0.764 ± 0.270, n_updates = 162000, time =  7.9, total_time = 1660.5 \n",
      "\n",
      "\n",
      "step =  173000, num_env_steps =  173000, scores =  4241.128 (n= 1), score_ema =  0.000, actor_loss = -244.491, critic_loss = 11.232, entropy_coef_loss = 0.086, entropy_coef = 0.077, rollout_stds = N/A, action_magnitude = 0.754 ± 0.277, n_updates = 163000, time =  6.8, total_time = 1667.2 \n",
      "\n",
      "\n",
      "step =  174000, num_env_steps =  174000, scores =  4252.927 (n= 1), score_ema =  0.000, actor_loss = -238.003, critic_loss = 319.173, entropy_coef_loss = 0.541, entropy_coef = 0.079, rollout_stds = N/A, action_magnitude = 0.754 ± 0.280, n_updates = 164000, time =  6.9, total_time = 1674.1 \n",
      "\n",
      "\n",
      "step =  175000, num_env_steps =  175000, scores =  4457.203 (n= 1), score_ema =  0.000, actor_loss = -245.359, critic_loss = 175.462, entropy_coef_loss = 0.787, entropy_coef = 0.080, rollout_stds = N/A, action_magnitude = 0.756 ± 0.276, n_updates = 165000, time =  7.2, total_time = 1681.4 \n",
      "\n",
      "\n",
      "step =  176000, num_env_steps =  176000, scores =  4377.990 (n= 1), score_ema =  0.000, actor_loss = -241.106, critic_loss = 352.471, entropy_coef_loss = -0.407, entropy_coef = 0.080, rollout_stds = N/A, action_magnitude = 0.768 ± 0.271, n_updates = 166000, time =  8.0, total_time = 1689.4 \n",
      "\n",
      "\n",
      "step =  177000, num_env_steps =  177000, scores =  4487.084 (n= 1), score_ema =  0.000, actor_loss = -245.199, critic_loss = 339.144, entropy_coef_loss = 1.206, entropy_coef = 0.077, rollout_stds = N/A, action_magnitude = 0.771 ± 0.268, n_updates = 167000, time =  7.9, total_time = 1697.2 \n",
      "\n",
      "\n",
      "step =  178000, num_env_steps =  178000, scores =  4546.589 (n= 1), score_ema =  0.000, actor_loss = -248.000, critic_loss = 102.863, entropy_coef_loss = 1.949, entropy_coef = 0.083, rollout_stds = N/A, action_magnitude = 0.767 ± 0.271, n_updates = 168000, time =  7.0, total_time = 1704.2 \n",
      "\n",
      "\n",
      "step =  179000, num_env_steps =  179000, scores =  4344.097 (n= 1), score_ema =  0.000, actor_loss = -239.652, critic_loss = 10.410, entropy_coef_loss = -0.739, entropy_coef = 0.080, rollout_stds = N/A, action_magnitude = 0.758 ± 0.274, n_updates = 169000, time =  6.6, total_time = 1710.8 \n",
      "\n",
      "\n",
      "step =  180000, num_env_steps =  180000, scores =  4262.507 (n= 1), score_ema =  0.000, actor_loss = -240.010, critic_loss = 13.235, entropy_coef_loss = 0.020, entropy_coef = 0.078, rollout_stds = N/A, action_magnitude = 0.764 ± 0.275, n_updates = 170000, time =  6.6, total_time = 1717.5 \n",
      "\n",
      "saved experiment log 2024-10-08_13-43-48_236302~fXPQM9 at experiment_logs/HalfCheetah-v4/sac/2024-10-08_13-43-48_236302~fXPQM9.json\n",
      "\n",
      "\n",
      "step =  181000, num_env_steps =  181000, scores =  4356.761 (n= 1), score_ema =  0.000, actor_loss = -245.577, critic_loss = 9.723, entropy_coef_loss = -0.549, entropy_coef = 0.082, rollout_stds = N/A, action_magnitude = 0.768 ± 0.272, n_updates = 171000, time =  6.6, total_time = 1724.0 \n",
      "\n",
      "\n",
      "step =  182000, num_env_steps =  182000, scores =  4361.134 (n= 1), score_ema =  0.000, actor_loss = -246.072, critic_loss = 504.761, entropy_coef_loss = -1.197, entropy_coef = 0.082, rollout_stds = N/A, action_magnitude = 0.765 ± 0.271, n_updates = 172000, time =  6.7, total_time = 1730.8 \n",
      "\n",
      "\n",
      "step =  183000, num_env_steps =  183000, scores =  4320.991 (n= 1), score_ema =  0.000, actor_loss = -243.343, critic_loss = 143.480, entropy_coef_loss = 0.828, entropy_coef = 0.083, rollout_stds = N/A, action_magnitude = 0.763 ± 0.273, n_updates = 173000, time =  7.4, total_time = 1738.1 \n",
      "\n",
      "\n",
      "step =  184000, num_env_steps =  184000, scores =  4149.073 (n= 1), score_ema =  0.000, actor_loss = -246.208, critic_loss = 9.300, entropy_coef_loss = -0.072, entropy_coef = 0.081, rollout_stds = N/A, action_magnitude = 0.760 ± 0.273, n_updates = 174000, time =  6.8, total_time = 1744.9 \n",
      "\n",
      "\n",
      "step =  185000, num_env_steps =  185000, scores =  4516.547 (n= 1), score_ema =  0.000, actor_loss = -241.597, critic_loss = 11.484, entropy_coef_loss = 0.393, entropy_coef = 0.084, rollout_stds = N/A, action_magnitude = 0.771 ± 0.269, n_updates = 175000, time =  6.8, total_time = 1751.7 \n",
      "\n",
      "\n",
      "step =  186000, num_env_steps =  186000, scores =  4191.166 (n= 1), score_ema =  0.000, actor_loss = -248.689, critic_loss = 357.470, entropy_coef_loss = 0.479, entropy_coef = 0.083, rollout_stds = N/A, action_magnitude = 0.763 ± 0.272, n_updates = 176000, time =  7.0, total_time = 1758.7 \n",
      "\n",
      "\n",
      "step =  187000, num_env_steps =  187000, scores =  4523.868 (n= 1), score_ema =  0.000, actor_loss = -249.317, critic_loss = 13.834, entropy_coef_loss = 1.505, entropy_coef = 0.082, rollout_stds = N/A, action_magnitude = 0.765 ± 0.273, n_updates = 177000, time =  6.9, total_time = 1765.5 \n",
      "\n",
      "\n",
      "step =  188000, num_env_steps =  188000, scores =  4450.168 (n= 1), score_ema =  0.000, actor_loss = -249.926, critic_loss = 13.435, entropy_coef_loss = 0.987, entropy_coef = 0.083, rollout_stds = N/A, action_magnitude = 0.766 ± 0.273, n_updates = 178000, time =  7.0, total_time = 1772.5 \n",
      "\n",
      "\n",
      "step =  189000, num_env_steps =  189000, scores =  4531.710 (n= 1), score_ema =  0.000, actor_loss = -251.493, critic_loss = 8.526, entropy_coef_loss = 1.613, entropy_coef = 0.083, rollout_stds = N/A, action_magnitude = 0.771 ± 0.267, n_updates = 179000, time =  5.9, total_time = 1778.4 \n",
      "\n",
      "\n",
      "step =  190000, num_env_steps =  190000, scores =  4341.898 (n= 1), score_ema =  0.000, actor_loss = -240.717, critic_loss = 10.933, entropy_coef_loss = -2.122, entropy_coef = 0.085, rollout_stds = N/A, action_magnitude = 0.762 ± 0.272, n_updates = 180000, time =  6.1, total_time = 1784.5 \n",
      "\n",
      "saved experiment log 2024-10-08_13-43-48_236302~fXPQM9 at experiment_logs/HalfCheetah-v4/sac/2024-10-08_13-43-48_236302~fXPQM9.json\n",
      "\n",
      "\n",
      "step =  191000, num_env_steps =  191000, scores =  4179.583 (n= 1), score_ema =  0.000, actor_loss = -244.054, critic_loss = 13.856, entropy_coef_loss = -0.552, entropy_coef = 0.085, rollout_stds = N/A, action_magnitude = 0.756 ± 0.274, n_updates = 181000, time =  6.5, total_time = 1791.0 \n",
      "\n",
      "\n",
      "step =  192000, num_env_steps =  192000, scores =  4176.422 (n= 1), score_ema =  0.000, actor_loss = -246.598, critic_loss = 13.829, entropy_coef_loss = 1.030, entropy_coef = 0.086, rollout_stds = N/A, action_magnitude = 0.754 ± 0.277, n_updates = 182000, time =  8.3, total_time = 1799.3 \n",
      "\n",
      "\n",
      "step =  193000, num_env_steps =  193000, scores =  4480.895 (n= 1), score_ema =  0.000, actor_loss = -241.021, critic_loss = 387.922, entropy_coef_loss = -0.823, entropy_coef = 0.084, rollout_stds = N/A, action_magnitude = 0.758 ± 0.280, n_updates = 183000, time =  7.2, total_time = 1806.5 \n",
      "\n",
      "\n",
      "step =  194000, num_env_steps =  194000, scores =  4680.438 (n= 1), score_ema =  0.000, actor_loss = -242.728, critic_loss = 15.359, entropy_coef_loss = 1.797, entropy_coef = 0.085, rollout_stds = N/A, action_magnitude = 0.770 ± 0.270, n_updates = 184000, time =  6.8, total_time = 1813.3 \n",
      "\n",
      "\n",
      "step =  195000, num_env_steps =  195000, scores =  4231.077 (n= 1), score_ema =  0.000, actor_loss = -252.914, critic_loss = 10.468, entropy_coef_loss = 1.104, entropy_coef = 0.087, rollout_stds = N/A, action_magnitude = 0.763 ± 0.273, n_updates = 185000, time =  6.3, total_time = 1819.6 \n",
      "\n",
      "\n",
      "step =  196000, num_env_steps =  196000, scores =  4356.832 (n= 1), score_ema =  0.000, actor_loss = -251.582, critic_loss = 10.603, entropy_coef_loss = -0.937, entropy_coef = 0.086, rollout_stds = N/A, action_magnitude = 0.751 ± 0.281, n_updates = 186000, time =  7.0, total_time = 1826.6 \n",
      "\n",
      "\n",
      "step =  197000, num_env_steps =  197000, scores =  4413.475 (n= 1), score_ema =  0.000, actor_loss = -245.297, critic_loss = 11.923, entropy_coef_loss = 0.690, entropy_coef = 0.086, rollout_stds = N/A, action_magnitude = 0.759 ± 0.277, n_updates = 187000, time =  7.2, total_time = 1833.8 \n",
      "\n",
      "\n",
      "step =  198000, num_env_steps =  198000, scores =  4411.472 (n= 1), score_ema =  0.000, actor_loss = -249.268, critic_loss = 13.215, entropy_coef_loss = -1.013, entropy_coef = 0.086, rollout_stds = N/A, action_magnitude = 0.766 ± 0.271, n_updates = 188000, time =  7.8, total_time = 1841.6 \n",
      "\n",
      "\n",
      "step =  199000, num_env_steps =  199000, scores =  4513.264 (n= 1), score_ema =  0.000, actor_loss = -244.982, critic_loss = 110.384, entropy_coef_loss = -0.287, entropy_coef = 0.088, rollout_stds = N/A, action_magnitude = 0.763 ± 0.273, n_updates = 189000, time =  7.6, total_time = 1849.2 \n",
      "\n",
      "\n",
      "step =  200000, num_env_steps =  200000, scores =  4544.410 (n= 1), score_ema =  0.000, actor_loss = -247.799, critic_loss = 10.506, entropy_coef_loss = -0.872, entropy_coef = 0.086, rollout_stds = N/A, action_magnitude = 0.759 ± 0.276, n_updates = 190000, time =  6.1, total_time = 1855.3 \n",
      "\n",
      "saved experiment log 2024-10-08_13-43-48_236302~fXPQM9 at experiment_logs/HalfCheetah-v4/sac/2024-10-08_13-43-48_236302~fXPQM9.json\n",
      "\n",
      "\n",
      "step =  201000, num_env_steps =  201000, scores =  4417.355 (n= 1), score_ema =  0.000, actor_loss = -247.215, critic_loss = 13.293, entropy_coef_loss = -0.281, entropy_coef = 0.085, rollout_stds = N/A, action_magnitude = 0.757 ± 0.278, n_updates = 191000, time =  6.2, total_time = 1861.6 \n",
      "\n",
      "\n",
      "step =  202000, num_env_steps =  202000, scores =  4576.882 (n= 1), score_ema =  0.000, actor_loss = -248.170, critic_loss = 15.476, entropy_coef_loss = -0.726, entropy_coef = 0.086, rollout_stds = N/A, action_magnitude = 0.762 ± 0.277, n_updates = 192000, time =  6.9, total_time = 1868.5 \n",
      "\n",
      "\n",
      "step =  203000, num_env_steps =  203000, scores =  4358.841 (n= 1), score_ema =  0.000, actor_loss = -255.720, critic_loss = 9.806, entropy_coef_loss = 0.149, entropy_coef = 0.086, rollout_stds = N/A, action_magnitude = 0.757 ± 0.274, n_updates = 193000, time =  6.9, total_time = 1875.4 \n",
      "\n",
      "\n",
      "step =  204000, num_env_steps =  204000, scores =  4475.547 (n= 1), score_ema =  0.000, actor_loss = -249.986, critic_loss = 10.267, entropy_coef_loss = -0.777, entropy_coef = 0.090, rollout_stds = N/A, action_magnitude = 0.765 ± 0.274, n_updates = 194000, time =  7.7, total_time = 1883.1 \n",
      "\n",
      "\n",
      "step =  205000, num_env_steps =  205000, scores =  4368.044 (n= 1), score_ema =  0.000, actor_loss = -240.718, critic_loss = 320.559, entropy_coef_loss = -0.815, entropy_coef = 0.090, rollout_stds = N/A, action_magnitude = 0.755 ± 0.280, n_updates = 195000, time =  6.9, total_time = 1890.0 \n",
      "\n",
      "\n",
      "step =  206000, num_env_steps =  206000, scores =  4228.604 (n= 1), score_ema =  0.000, actor_loss = -253.980, critic_loss = 362.455, entropy_coef_loss = 0.166, entropy_coef = 0.089, rollout_stds = N/A, action_magnitude = 0.762 ± 0.272, n_updates = 196000, time =  6.3, total_time = 1896.3 \n",
      "\n",
      "\n",
      "step =  207000, num_env_steps =  207000, scores =  4548.644 (n= 1), score_ema =  0.000, actor_loss = -248.493, critic_loss = 13.802, entropy_coef_loss = -0.174, entropy_coef = 0.088, rollout_stds = N/A, action_magnitude = 0.767 ± 0.268, n_updates = 197000, time =  6.4, total_time = 1902.7 \n",
      "\n",
      "\n",
      "step =  208000, num_env_steps =  208000, scores =  4416.844 (n= 1), score_ema =  0.000, actor_loss = -260.086, critic_loss = 12.632, entropy_coef_loss = 0.455, entropy_coef = 0.089, rollout_stds = N/A, action_magnitude = 0.764 ± 0.273, n_updates = 198000, time =  6.7, total_time = 1909.4 \n",
      "\n",
      "\n",
      "step =  209000, num_env_steps =  209000, scores =  4489.513 (n= 1), score_ema =  0.000, actor_loss = -252.817, critic_loss = 10.808, entropy_coef_loss = -1.108, entropy_coef = 0.089, rollout_stds = N/A, action_magnitude = 0.758 ± 0.274, n_updates = 199000, time =  7.1, total_time = 1916.5 \n",
      "\n",
      "\n",
      "step =  210000, num_env_steps =  210000, scores =  4537.197 (n= 1), score_ema =  0.000, actor_loss = -254.802, critic_loss = 11.990, entropy_coef_loss = 0.119, entropy_coef = 0.087, rollout_stds = N/A, action_magnitude = 0.764 ± 0.274, n_updates = 200000, time =  7.1, total_time = 1923.6 \n",
      "\n",
      "saved experiment log 2024-10-08_13-43-48_236302~fXPQM9 at experiment_logs/HalfCheetah-v4/sac/2024-10-08_13-43-48_236302~fXPQM9.json\n",
      "\n",
      "\n",
      "step =  211000, num_env_steps =  211000, scores =  4577.329 (n= 1), score_ema =  0.000, actor_loss = -254.273, critic_loss = 11.446, entropy_coef_loss = -0.555, entropy_coef = 0.088, rollout_stds = N/A, action_magnitude = 0.762 ± 0.272, n_updates = 201000, time =  6.4, total_time = 1930.0 \n",
      "\n",
      "\n",
      "step =  212000, num_env_steps =  212000, scores =  4533.111 (n= 1), score_ema =  0.000, actor_loss = -247.306, critic_loss = 344.408, entropy_coef_loss = -0.737, entropy_coef = 0.088, rollout_stds = N/A, action_magnitude = 0.760 ± 0.276, n_updates = 202000, time =  6.6, total_time = 1936.6 \n",
      "\n",
      "\n",
      "step =  213000, num_env_steps =  213000, scores =  4551.661 (n= 1), score_ema =  0.000, actor_loss = -254.939, critic_loss = 12.717, entropy_coef_loss = 0.641, entropy_coef = 0.088, rollout_stds = N/A, action_magnitude = 0.768 ± 0.271, n_updates = 203000, time =  6.5, total_time = 1943.1 \n",
      "\n",
      "\n",
      "step =  214000, num_env_steps =  214000, scores =  4517.142 (n= 1), score_ema =  0.000, actor_loss = -263.901, critic_loss = 15.397, entropy_coef_loss = 0.071, entropy_coef = 0.088, rollout_stds = N/A, action_magnitude = 0.760 ± 0.274, n_updates = 204000, time =  6.6, total_time = 1949.7 \n",
      "\n",
      "\n",
      "step =  215000, num_env_steps =  215000, scores =  4342.312 (n= 1), score_ema =  0.000, actor_loss = -261.613, critic_loss = 14.843, entropy_coef_loss = 0.104, entropy_coef = 0.089, rollout_stds = N/A, action_magnitude = 0.757 ± 0.276, n_updates = 205000, time =  6.9, total_time = 1956.6 \n",
      "\n",
      "\n",
      "step =  216000, num_env_steps =  216000, scores =  4492.582 (n= 1), score_ema =  0.000, actor_loss = -264.126, critic_loss = 10.415, entropy_coef_loss = -0.018, entropy_coef = 0.088, rollout_stds = N/A, action_magnitude = 0.761 ± 0.273, n_updates = 206000, time =  6.7, total_time = 1963.3 \n",
      "\n",
      "\n",
      "step =  217000, num_env_steps =  217000, scores =  4525.942 (n= 1), score_ema =  0.000, actor_loss = -259.179, critic_loss = 15.094, entropy_coef_loss = 0.668, entropy_coef = 0.090, rollout_stds = N/A, action_magnitude = 0.767 ± 0.274, n_updates = 207000, time =  7.0, total_time = 1970.3 \n",
      "\n",
      "\n",
      "step =  218000, num_env_steps =  218000, scores =  4602.564 (n= 1), score_ema =  0.000, actor_loss = -258.487, critic_loss = 13.699, entropy_coef_loss = 1.048, entropy_coef = 0.090, rollout_stds = N/A, action_magnitude = 0.761 ± 0.273, n_updates = 208000, time =  7.0, total_time = 1977.3 \n",
      "\n",
      "\n",
      "step =  219000, num_env_steps =  219000, scores =  4647.753 (n= 1), score_ema =  0.000, actor_loss = -257.767, critic_loss = 16.306, entropy_coef_loss = 0.423, entropy_coef = 0.093, rollout_stds = N/A, action_magnitude = 0.764 ± 0.273, n_updates = 209000, time =  7.9, total_time = 1985.1 \n",
      "\n",
      "\n",
      "step =  220000, num_env_steps =  220000, scores =  4647.421 (n= 1), score_ema =  0.000, actor_loss = -263.497, critic_loss = 14.601, entropy_coef_loss = 0.004, entropy_coef = 0.092, rollout_stds = N/A, action_magnitude = 0.767 ± 0.273, n_updates = 210000, time =  6.4, total_time = 1991.5 \n",
      "\n",
      "saved experiment log 2024-10-08_13-43-48_236302~fXPQM9 at experiment_logs/HalfCheetah-v4/sac/2024-10-08_13-43-48_236302~fXPQM9.json\n",
      "\n",
      "\n",
      "step =  221000, num_env_steps =  221000, scores =  4526.262 (n= 1), score_ema =  0.000, actor_loss = -259.444, critic_loss = 16.915, entropy_coef_loss = 0.245, entropy_coef = 0.094, rollout_stds = N/A, action_magnitude = 0.764 ± 0.273, n_updates = 211000, time =  6.4, total_time = 1997.9 \n",
      "\n",
      "\n",
      "step =  222000, num_env_steps =  222000, scores =  4461.368 (n= 1), score_ema =  0.000, actor_loss = -256.618, critic_loss = 11.867, entropy_coef_loss = 0.099, entropy_coef = 0.094, rollout_stds = N/A, action_magnitude = 0.761 ± 0.274, n_updates = 212000, time =  6.9, total_time = 2004.8 \n",
      "\n",
      "\n",
      "step =  223000, num_env_steps =  223000, scores =  4770.231 (n= 1), score_ema =  0.000, actor_loss = -267.158, critic_loss = 288.605, entropy_coef_loss = 1.493, entropy_coef = 0.094, rollout_stds = N/A, action_magnitude = 0.765 ± 0.277, n_updates = 213000, time =  7.2, total_time = 2012.0 \n",
      "\n",
      "\n",
      "step =  224000, num_env_steps =  224000, scores =  4670.236 (n= 1), score_ema =  0.000, actor_loss = -252.997, critic_loss = 11.290, entropy_coef_loss = 0.545, entropy_coef = 0.091, rollout_stds = N/A, action_magnitude = 0.764 ± 0.274, n_updates = 214000, time =  6.6, total_time = 2018.6 \n",
      "\n",
      "\n",
      "step =  225000, num_env_steps =  225000, scores =  4438.191 (n= 1), score_ema =  0.000, actor_loss = -259.785, critic_loss = 13.556, entropy_coef_loss = 0.745, entropy_coef = 0.095, rollout_stds = N/A, action_magnitude = 0.764 ± 0.274, n_updates = 215000, time =  6.1, total_time = 2024.7 \n",
      "\n",
      "\n",
      "step =  226000, num_env_steps =  226000, scores =  4673.277 (n= 1), score_ema =  0.000, actor_loss = -271.053, critic_loss = 11.334, entropy_coef_loss = 0.894, entropy_coef = 0.095, rollout_stds = N/A, action_magnitude = 0.767 ± 0.274, n_updates = 216000, time =  6.5, total_time = 2031.1 \n",
      "\n",
      "\n",
      "step =  227000, num_env_steps =  227000, scores =  4671.930 (n= 1), score_ema =  0.000, actor_loss = -260.063, critic_loss = 11.999, entropy_coef_loss = 0.104, entropy_coef = 0.093, rollout_stds = N/A, action_magnitude = 0.769 ± 0.273, n_updates = 217000, time =  6.8, total_time = 2038.0 \n",
      "\n",
      "\n",
      "step =  228000, num_env_steps =  228000, scores =  4647.001 (n= 1), score_ema =  0.000, actor_loss = -251.901, critic_loss = 12.569, entropy_coef_loss = -0.242, entropy_coef = 0.095, rollout_stds = N/A, action_magnitude = 0.763 ± 0.274, n_updates = 218000, time =  6.5, total_time = 2044.5 \n",
      "\n",
      "\n",
      "step =  229000, num_env_steps =  229000, scores =  4826.069 (n= 1), score_ema =  0.000, actor_loss = -252.735, critic_loss = 11.760, entropy_coef_loss = -2.580, entropy_coef = 0.096, rollout_stds = N/A, action_magnitude = 0.776 ± 0.267, n_updates = 219000, time =  6.9, total_time = 2051.3 \n",
      "\n",
      "\n",
      "step =  230000, num_env_steps =  230000, scores =  4794.863 (n= 1), score_ema =  0.000, actor_loss = -261.855, critic_loss = 11.195, entropy_coef_loss = 0.688, entropy_coef = 0.093, rollout_stds = N/A, action_magnitude = 0.768 ± 0.269, n_updates = 220000, time =  7.3, total_time = 2058.7 \n",
      "\n",
      "saved experiment log 2024-10-08_13-43-48_236302~fXPQM9 at experiment_logs/HalfCheetah-v4/sac/2024-10-08_13-43-48_236302~fXPQM9.json\n",
      "\n",
      "\n",
      "step =  231000, num_env_steps =  231000, scores =  4696.684 (n= 1), score_ema =  0.000, actor_loss = -273.597, critic_loss = 14.956, entropy_coef_loss = 0.826, entropy_coef = 0.093, rollout_stds = N/A, action_magnitude = 0.762 ± 0.275, n_updates = 221000, time =  6.9, total_time = 2065.6 \n",
      "\n",
      "\n",
      "step =  232000, num_env_steps =  232000, scores =  4720.334 (n= 1), score_ema =  0.000, actor_loss = -260.649, critic_loss = 18.097, entropy_coef_loss = -1.517, entropy_coef = 0.096, rollout_stds = N/A, action_magnitude = 0.766 ± 0.273, n_updates = 222000, time =  6.5, total_time = 2072.1 \n",
      "\n",
      "\n",
      "step =  233000, num_env_steps =  233000, scores =  4475.055 (n= 1), score_ema =  0.000, actor_loss = -262.119, critic_loss = 354.944, entropy_coef_loss = -0.137, entropy_coef = 0.094, rollout_stds = N/A, action_magnitude = 0.750 ± 0.281, n_updates = 223000, time =  6.5, total_time = 2078.6 \n",
      "\n",
      "\n",
      "step =  234000, num_env_steps =  234000, scores =  4806.395 (n= 1), score_ema =  0.000, actor_loss = -251.356, critic_loss = 10.838, entropy_coef_loss = -1.590, entropy_coef = 0.094, rollout_stds = N/A, action_magnitude = 0.771 ± 0.270, n_updates = 224000, time =  6.3, total_time = 2084.9 \n",
      "\n",
      "\n",
      "step =  235000, num_env_steps =  235000, scores =  4665.680 (n= 1), score_ema =  0.000, actor_loss = -266.804, critic_loss = 11.571, entropy_coef_loss = 0.739, entropy_coef = 0.096, rollout_stds = N/A, action_magnitude = 0.759 ± 0.275, n_updates = 225000, time =  6.6, total_time = 2091.4 \n",
      "\n",
      "\n",
      "step =  236000, num_env_steps =  236000, scores =  4657.237 (n= 1), score_ema =  0.000, actor_loss = -269.971, critic_loss = 12.612, entropy_coef_loss = 0.626, entropy_coef = 0.098, rollout_stds = N/A, action_magnitude = 0.769 ± 0.275, n_updates = 226000, time =  7.6, total_time = 2099.0 \n",
      "\n",
      "\n",
      "step =  237000, num_env_steps =  237000, scores =  4691.334 (n= 1), score_ema =  0.000, actor_loss = -268.947, critic_loss = 11.384, entropy_coef_loss = -0.430, entropy_coef = 0.094, rollout_stds = N/A, action_magnitude = 0.761 ± 0.276, n_updates = 227000, time =  6.3, total_time = 2105.4 \n",
      "\n",
      "\n",
      "step =  238000, num_env_steps =  238000, scores =  4719.285 (n= 1), score_ema =  0.000, actor_loss = -265.688, critic_loss = 12.461, entropy_coef_loss = -0.874, entropy_coef = 0.094, rollout_stds = N/A, action_magnitude = 0.761 ± 0.276, n_updates = 228000, time =  6.3, total_time = 2111.7 \n",
      "\n",
      "\n",
      "step =  239000, num_env_steps =  239000, scores =  4508.449 (n= 1), score_ema =  0.000, actor_loss = -250.885, critic_loss = 10.365, entropy_coef_loss = -0.429, entropy_coef = 0.096, rollout_stds = N/A, action_magnitude = 0.760 ± 0.272, n_updates = 229000, time =  6.4, total_time = 2118.1 \n",
      "\n",
      "\n",
      "step =  240000, num_env_steps =  240000, scores =  4889.844 (n= 1), score_ema =  0.000, actor_loss = -260.920, critic_loss = 10.975, entropy_coef_loss = -0.794, entropy_coef = 0.095, rollout_stds = N/A, action_magnitude = 0.774 ± 0.267, n_updates = 230000, time =  7.5, total_time = 2125.6 \n",
      "\n",
      "saved experiment log 2024-10-08_13-43-48_236302~fXPQM9 at experiment_logs/HalfCheetah-v4/sac/2024-10-08_13-43-48_236302~fXPQM9.json\n",
      "\n",
      "\n",
      "step =  241000, num_env_steps =  241000, scores =  4709.277 (n= 1), score_ema =  0.000, actor_loss = -272.234, critic_loss = 361.452, entropy_coef_loss = -0.522, entropy_coef = 0.096, rollout_stds = N/A, action_magnitude = 0.768 ± 0.273, n_updates = 231000, time =  7.3, total_time = 2132.8 \n",
      "\n",
      "\n",
      "step =  242000, num_env_steps =  242000, scores =  4730.646 (n= 1), score_ema =  0.000, actor_loss = -274.496, critic_loss = 12.129, entropy_coef_loss = -0.215, entropy_coef = 0.096, rollout_stds = N/A, action_magnitude = 0.766 ± 0.276, n_updates = 232000, time =  7.3, total_time = 2140.1 \n",
      "\n",
      "\n",
      "step =  243000, num_env_steps =  243000, scores =  4781.275 (n= 1), score_ema =  0.000, actor_loss = -276.012, critic_loss = 11.341, entropy_coef_loss = 1.685, entropy_coef = 0.095, rollout_stds = N/A, action_magnitude = 0.757 ± 0.275, n_updates = 233000, time =  7.0, total_time = 2147.1 \n",
      "\n",
      "\n",
      "step =  244000, num_env_steps =  244000, scores =  4582.333 (n= 1), score_ema =  0.000, actor_loss = -263.148, critic_loss = 15.422, entropy_coef_loss = -1.087, entropy_coef = 0.096, rollout_stds = N/A, action_magnitude = 0.753 ± 0.279, n_updates = 234000, time =  7.0, total_time = 2154.1 \n",
      "\n",
      "\n",
      "step =  245000, num_env_steps =  245000, scores =  4894.717 (n= 1), score_ema =  0.000, actor_loss = -263.979, critic_loss = 9.593, entropy_coef_loss = -0.059, entropy_coef = 0.095, rollout_stds = N/A, action_magnitude = 0.765 ± 0.272, n_updates = 235000, time =  7.4, total_time = 2161.5 \n",
      "\n",
      "\n",
      "step =  246000, num_env_steps =  246000, scores =  4875.600 (n= 1), score_ema =  0.000, actor_loss = -267.356, critic_loss = 11.739, entropy_coef_loss = -1.013, entropy_coef = 0.097, rollout_stds = N/A, action_magnitude = 0.761 ± 0.275, n_updates = 236000, time =  7.1, total_time = 2168.6 \n",
      "\n",
      "\n",
      "step =  247000, num_env_steps =  247000, scores =  4748.090 (n= 1), score_ema =  0.000, actor_loss = -267.727, critic_loss = 11.393, entropy_coef_loss = 0.847, entropy_coef = 0.096, rollout_stds = N/A, action_magnitude = 0.765 ± 0.271, n_updates = 237000, time =  6.5, total_time = 2175.1 \n",
      "\n",
      "\n",
      "step =  248000, num_env_steps =  248000, scores =  4764.271 (n= 1), score_ema =  0.000, actor_loss = -275.038, critic_loss = 355.447, entropy_coef_loss = 0.294, entropy_coef = 0.096, rollout_stds = N/A, action_magnitude = 0.761 ± 0.273, n_updates = 238000, time =  6.9, total_time = 2182.1 \n",
      "\n",
      "\n",
      "step =  249000, num_env_steps =  249000, scores =  4812.784 (n= 1), score_ema =  0.000, actor_loss = -262.527, critic_loss = 15.301, entropy_coef_loss = -0.222, entropy_coef = 0.100, rollout_stds = N/A, action_magnitude = 0.764 ± 0.273, n_updates = 239000, time =  6.8, total_time = 2188.9 \n",
      "\n",
      "\n",
      "step =  250000, num_env_steps =  250000, scores =  4670.830 (n= 1), score_ema =  0.000, actor_loss = -271.391, critic_loss = 15.242, entropy_coef_loss = 0.668, entropy_coef = 0.097, rollout_stds = N/A, action_magnitude = 0.758 ± 0.278, n_updates = 240000, time =  6.3, total_time = 2195.2 \n",
      "\n",
      "saved experiment log 2024-10-08_13-43-48_236302~fXPQM9 at experiment_logs/HalfCheetah-v4/sac/2024-10-08_13-43-48_236302~fXPQM9.json\n",
      "\n",
      "\n",
      "step =  251000, num_env_steps =  251000, scores =  4986.578 (n= 1), score_ema =  0.000, actor_loss = -277.415, critic_loss = 18.837, entropy_coef_loss = -0.124, entropy_coef = 0.096, rollout_stds = N/A, action_magnitude = 0.774 ± 0.272, n_updates = 241000, time =  6.7, total_time = 2201.9 \n",
      "\n",
      "\n",
      "step =  252000, num_env_steps =  252000, scores =  4897.798 (n= 1), score_ema =  0.000, actor_loss = -268.959, critic_loss = 10.987, entropy_coef_loss = -0.119, entropy_coef = 0.094, rollout_stds = N/A, action_magnitude = 0.761 ± 0.274, n_updates = 242000, time =  6.2, total_time = 2208.1 \n",
      "\n",
      "\n",
      "step =  253000, num_env_steps =  253000, scores =  4742.189 (n= 1), score_ema =  0.000, actor_loss = -264.983, critic_loss = 384.701, entropy_coef_loss = 0.391, entropy_coef = 0.096, rollout_stds = N/A, action_magnitude = 0.766 ± 0.274, n_updates = 243000, time =  6.1, total_time = 2214.1 \n",
      "\n",
      "\n",
      "step =  254000, num_env_steps =  254000, scores =  4785.428 (n= 1), score_ema =  0.000, actor_loss = -282.934, critic_loss = 18.510, entropy_coef_loss = 0.580, entropy_coef = 0.096, rollout_stds = N/A, action_magnitude = 0.761 ± 0.277, n_updates = 244000, time =  6.1, total_time = 2220.3 \n",
      "\n",
      "\n",
      "step =  255000, num_env_steps =  255000, scores =  4638.271 (n= 1), score_ema =  0.000, actor_loss = -270.071, critic_loss = 335.483, entropy_coef_loss = 0.583, entropy_coef = 0.097, rollout_stds = N/A, action_magnitude = 0.757 ± 0.276, n_updates = 245000, time =  6.5, total_time = 2226.8 \n",
      "\n",
      "\n",
      "step =  256000, num_env_steps =  256000, scores =  4711.429 (n= 1), score_ema =  0.000, actor_loss = -271.832, critic_loss = 15.752, entropy_coef_loss = 0.581, entropy_coef = 0.098, rollout_stds = N/A, action_magnitude = 0.755 ± 0.278, n_updates = 246000, time =  7.7, total_time = 2234.5 \n",
      "\n",
      "\n",
      "step =  257000, num_env_steps =  257000, scores =  4657.192 (n= 1), score_ema =  0.000, actor_loss = -275.333, critic_loss = 11.272, entropy_coef_loss = -0.379, entropy_coef = 0.096, rollout_stds = N/A, action_magnitude = 0.753 ± 0.277, n_updates = 247000, time =  7.3, total_time = 2241.8 \n",
      "\n",
      "\n",
      "step =  258000, num_env_steps =  258000, scores =  4862.814 (n= 1), score_ema =  0.000, actor_loss = -278.780, critic_loss = 11.615, entropy_coef_loss = 0.608, entropy_coef = 0.101, rollout_stds = N/A, action_magnitude = 0.761 ± 0.280, n_updates = 248000, time =  7.4, total_time = 2249.2 \n",
      "\n",
      "\n",
      "step =  259000, num_env_steps =  259000, scores =  4591.760 (n= 1), score_ema =  0.000, actor_loss = -267.572, critic_loss = 12.774, entropy_coef_loss = -0.829, entropy_coef = 0.096, rollout_stds = N/A, action_magnitude = 0.752 ± 0.276, n_updates = 249000, time =  6.6, total_time = 2255.8 \n",
      "\n",
      "\n",
      "step =  260000, num_env_steps =  260000, scores =  4909.899 (n= 1), score_ema =  0.000, actor_loss = -276.631, critic_loss = 10.764, entropy_coef_loss = -0.193, entropy_coef = 0.096, rollout_stds = N/A, action_magnitude = 0.753 ± 0.280, n_updates = 250000, time =  7.1, total_time = 2262.9 \n",
      "\n",
      "saved experiment log 2024-10-08_13-43-48_236302~fXPQM9 at experiment_logs/HalfCheetah-v4/sac/2024-10-08_13-43-48_236302~fXPQM9.json\n",
      "\n",
      "\n",
      "step =  261000, num_env_steps =  261000, scores =  4872.243 (n= 1), score_ema =  0.000, actor_loss = -276.327, critic_loss = 12.250, entropy_coef_loss = 0.065, entropy_coef = 0.095, rollout_stds = N/A, action_magnitude = 0.760 ± 0.277, n_updates = 251000, time =  6.3, total_time = 2269.2 \n",
      "\n",
      "\n",
      "step =  262000, num_env_steps =  262000, scores =  4942.771 (n= 1), score_ema =  0.000, actor_loss = -281.629, critic_loss = 371.084, entropy_coef_loss = 0.635, entropy_coef = 0.093, rollout_stds = N/A, action_magnitude = 0.754 ± 0.280, n_updates = 252000, time =  6.1, total_time = 2275.3 \n",
      "\n",
      "\n",
      "step =  263000, num_env_steps =  263000, scores =  4725.501 (n= 1), score_ema =  0.000, actor_loss = -277.947, critic_loss = 13.484, entropy_coef_loss = 1.587, entropy_coef = 0.097, rollout_stds = N/A, action_magnitude = 0.754 ± 0.277, n_updates = 253000, time =  6.1, total_time = 2281.4 \n",
      "\n",
      "\n",
      "step =  264000, num_env_steps =  264000, scores =  4821.354 (n= 1), score_ema =  0.000, actor_loss = -272.918, critic_loss = 11.578, entropy_coef_loss = 0.038, entropy_coef = 0.099, rollout_stds = N/A, action_magnitude = 0.753 ± 0.281, n_updates = 254000, time =  6.1, total_time = 2287.4 \n",
      "\n",
      "\n",
      "step =  265000, num_env_steps =  265000, scores =  4842.159 (n= 1), score_ema =  0.000, actor_loss = -286.847, critic_loss = 382.720, entropy_coef_loss = 0.224, entropy_coef = 0.096, rollout_stds = N/A, action_magnitude = 0.759 ± 0.273, n_updates = 255000, time =  6.7, total_time = 2294.2 \n",
      "\n",
      "\n",
      "step =  266000, num_env_steps =  266000, scores =  4866.101 (n= 1), score_ema =  0.000, actor_loss = -275.012, critic_loss = 15.643, entropy_coef_loss = 0.935, entropy_coef = 0.098, rollout_stds = N/A, action_magnitude = 0.754 ± 0.280, n_updates = 256000, time =  6.4, total_time = 2300.6 \n",
      "\n",
      "\n",
      "step =  267000, num_env_steps =  267000, scores =  4855.667 (n= 1), score_ema =  0.000, actor_loss = -279.896, critic_loss = 13.869, entropy_coef_loss = 0.369, entropy_coef = 0.095, rollout_stds = N/A, action_magnitude = 0.761 ± 0.273, n_updates = 257000, time =  6.4, total_time = 2307.0 \n",
      "\n",
      "\n",
      "step =  268000, num_env_steps =  268000, scores =  4860.462 (n= 1), score_ema =  0.000, actor_loss = -276.782, critic_loss = 13.849, entropy_coef_loss = 0.698, entropy_coef = 0.099, rollout_stds = N/A, action_magnitude = 0.760 ± 0.274, n_updates = 258000, time =  8.0, total_time = 2315.0 \n",
      "\n",
      "\n",
      "step =  269000, num_env_steps =  269000, scores =  4977.596 (n= 1), score_ema =  0.000, actor_loss = -271.208, critic_loss = 14.179, entropy_coef_loss = -1.081, entropy_coef = 0.099, rollout_stds = N/A, action_magnitude = 0.763 ± 0.274, n_updates = 259000, time =  6.9, total_time = 2321.8 \n",
      "\n",
      "\n",
      "step =  270000, num_env_steps =  270000, scores =  4745.280 (n= 1), score_ema =  0.000, actor_loss = -285.289, critic_loss = 165.905, entropy_coef_loss = 1.130, entropy_coef = 0.096, rollout_stds = N/A, action_magnitude = 0.757 ± 0.277, n_updates = 260000, time =  8.0, total_time = 2329.8 \n",
      "\n",
      "saved experiment log 2024-10-08_13-43-48_236302~fXPQM9 at experiment_logs/HalfCheetah-v4/sac/2024-10-08_13-43-48_236302~fXPQM9.json\n",
      "\n",
      "\n",
      "step =  271000, num_env_steps =  271000, scores =  4943.155 (n= 1), score_ema =  0.000, actor_loss = -271.147, critic_loss = 14.755, entropy_coef_loss = 1.375, entropy_coef = 0.101, rollout_stds = N/A, action_magnitude = 0.767 ± 0.272, n_updates = 261000, time =  7.0, total_time = 2336.8 \n",
      "\n",
      "\n",
      "step =  272000, num_env_steps =  272000, scores =  5054.662 (n= 1), score_ema =  0.000, actor_loss = -277.711, critic_loss = 14.204, entropy_coef_loss = -0.372, entropy_coef = 0.101, rollout_stds = N/A, action_magnitude = 0.774 ± 0.269, n_updates = 262000, time =  7.7, total_time = 2344.4 \n",
      "\n",
      "\n",
      "step =  273000, num_env_steps =  273000, scores =  5019.417 (n= 1), score_ema =  0.000, actor_loss = -272.950, critic_loss = 11.783, entropy_coef_loss = 0.799, entropy_coef = 0.102, rollout_stds = N/A, action_magnitude = 0.770 ± 0.270, n_updates = 263000, time =  7.6, total_time = 2352.0 \n",
      "\n",
      "\n",
      "step =  274000, num_env_steps =  274000, scores =  4929.112 (n= 1), score_ema =  0.000, actor_loss = -275.217, critic_loss = 410.037, entropy_coef_loss = 1.316, entropy_coef = 0.103, rollout_stds = N/A, action_magnitude = 0.768 ± 0.272, n_updates = 264000, time =  7.9, total_time = 2359.9 \n",
      "\n",
      "\n",
      "step =  275000, num_env_steps =  275000, scores =  4907.931 (n= 1), score_ema =  0.000, actor_loss = -291.119, critic_loss = 19.092, entropy_coef_loss = -0.119, entropy_coef = 0.103, rollout_stds = N/A, action_magnitude = 0.760 ± 0.276, n_updates = 265000, time =  7.2, total_time = 2367.2 \n",
      "\n",
      "\n",
      "step =  276000, num_env_steps =  276000, scores =  4978.613 (n= 1), score_ema =  0.000, actor_loss = -273.197, critic_loss = 18.073, entropy_coef_loss = -0.114, entropy_coef = 0.104, rollout_stds = N/A, action_magnitude = 0.774 ± 0.271, n_updates = 266000, time =  6.5, total_time = 2373.7 \n",
      "\n",
      "\n",
      "step =  277000, num_env_steps =  277000, scores =  4881.962 (n= 1), score_ema =  0.000, actor_loss = -280.645, critic_loss = 12.577, entropy_coef_loss = -0.125, entropy_coef = 0.101, rollout_stds = N/A, action_magnitude = 0.763 ± 0.274, n_updates = 267000, time =  6.6, total_time = 2380.4 \n",
      "\n",
      "\n",
      "step =  278000, num_env_steps =  278000, scores =  4985.659 (n= 1), score_ema =  0.000, actor_loss = -283.016, critic_loss = 393.133, entropy_coef_loss = 0.360, entropy_coef = 0.098, rollout_stds = N/A, action_magnitude = 0.760 ± 0.275, n_updates = 268000, time =  6.5, total_time = 2386.9 \n",
      "\n",
      "\n",
      "step =  279000, num_env_steps =  279000, scores =  5015.351 (n= 1), score_ema =  0.000, actor_loss = -282.783, critic_loss = 13.882, entropy_coef_loss = 0.608, entropy_coef = 0.102, rollout_stds = N/A, action_magnitude = 0.765 ± 0.275, n_updates = 269000, time =  8.2, total_time = 2395.1 \n",
      "\n",
      "\n",
      "step =  280000, num_env_steps =  280000, scores =  4918.188 (n= 1), score_ema =  0.000, actor_loss = -282.372, critic_loss = 16.237, entropy_coef_loss = 0.074, entropy_coef = 0.102, rollout_stds = N/A, action_magnitude = 0.752 ± 0.283, n_updates = 270000, time =  6.7, total_time = 2401.7 \n",
      "\n",
      "saved experiment log 2024-10-08_13-43-48_236302~fXPQM9 at experiment_logs/HalfCheetah-v4/sac/2024-10-08_13-43-48_236302~fXPQM9.json\n",
      "\n",
      "\n",
      "step =  281000, num_env_steps =  281000, scores =  4981.502 (n= 1), score_ema =  0.000, actor_loss = -284.441, critic_loss = 450.868, entropy_coef_loss = 0.428, entropy_coef = 0.101, rollout_stds = N/A, action_magnitude = 0.762 ± 0.275, n_updates = 271000, time =  6.6, total_time = 2408.3 \n",
      "\n",
      "\n",
      "step =  282000, num_env_steps =  282000, scores =  4908.357 (n= 1), score_ema =  0.000, actor_loss = -275.372, critic_loss = 9.396, entropy_coef_loss = -0.747, entropy_coef = 0.098, rollout_stds = N/A, action_magnitude = 0.746 ± 0.284, n_updates = 272000, time =  7.5, total_time = 2415.8 \n",
      "\n",
      "\n",
      "step =  283000, num_env_steps =  283000, scores =  5096.510 (n= 1), score_ema =  0.000, actor_loss = -279.755, critic_loss = 11.323, entropy_coef_loss = -0.880, entropy_coef = 0.102, rollout_stds = N/A, action_magnitude = 0.764 ± 0.275, n_updates = 273000, time =  7.5, total_time = 2423.3 \n",
      "\n",
      "\n",
      "step =  284000, num_env_steps =  284000, scores =  4858.417 (n= 1), score_ema =  0.000, actor_loss = -291.424, critic_loss = 19.649, entropy_coef_loss = 1.188, entropy_coef = 0.101, rollout_stds = N/A, action_magnitude = 0.750 ± 0.282, n_updates = 274000, time =  8.2, total_time = 2431.5 \n",
      "\n",
      "\n",
      "step =  285000, num_env_steps =  285000, scores =  5003.136 (n= 1), score_ema =  0.000, actor_loss = -273.032, critic_loss = 339.605, entropy_coef_loss = -1.564, entropy_coef = 0.103, rollout_stds = N/A, action_magnitude = 0.758 ± 0.280, n_updates = 275000, time =  6.4, total_time = 2437.9 \n",
      "\n",
      "\n",
      "step =  286000, num_env_steps =  286000, scores =  5001.646 (n= 1), score_ema =  0.000, actor_loss = -279.951, critic_loss = 20.241, entropy_coef_loss = -1.148, entropy_coef = 0.101, rollout_stds = N/A, action_magnitude = 0.758 ± 0.281, n_updates = 276000, time =  8.0, total_time = 2445.9 \n",
      "\n",
      "\n",
      "step =  287000, num_env_steps =  287000, scores =  4883.560 (n= 1), score_ema =  0.000, actor_loss = -287.920, critic_loss = 13.125, entropy_coef_loss = 0.928, entropy_coef = 0.102, rollout_stds = N/A, action_magnitude = 0.758 ± 0.275, n_updates = 277000, time =  7.1, total_time = 2453.0 \n",
      "\n",
      "\n",
      "step =  288000, num_env_steps =  288000, scores =  5173.749 (n= 1), score_ema =  0.000, actor_loss = -278.014, critic_loss = 13.844, entropy_coef_loss = 0.095, entropy_coef = 0.104, rollout_stds = N/A, action_magnitude = 0.770 ± 0.268, n_updates = 278000, time =  7.6, total_time = 2460.6 \n",
      "\n",
      "\n",
      "step =  289000, num_env_steps =  289000, scores =  4970.933 (n= 1), score_ema =  0.000, actor_loss = -289.413, critic_loss = 11.885, entropy_coef_loss = -0.342, entropy_coef = 0.105, rollout_stds = N/A, action_magnitude = 0.771 ± 0.270, n_updates = 279000, time =  6.7, total_time = 2467.3 \n",
      "\n",
      "\n",
      "step =  290000, num_env_steps =  290000, scores =  5012.320 (n= 1), score_ema =  0.000, actor_loss = -274.073, critic_loss = 15.949, entropy_coef_loss = 0.003, entropy_coef = 0.104, rollout_stds = N/A, action_magnitude = 0.761 ± 0.275, n_updates = 280000, time =  7.7, total_time = 2475.0 \n",
      "\n",
      "saved experiment log 2024-10-08_13-43-48_236302~fXPQM9 at experiment_logs/HalfCheetah-v4/sac/2024-10-08_13-43-48_236302~fXPQM9.json\n",
      "\n",
      "\n",
      "step =  291000, num_env_steps =  291000, scores =  5041.909 (n= 1), score_ema =  0.000, actor_loss = -288.978, critic_loss = 12.672, entropy_coef_loss = 0.704, entropy_coef = 0.106, rollout_stds = N/A, action_magnitude = 0.761 ± 0.275, n_updates = 281000, time =  7.1, total_time = 2482.2 \n",
      "\n",
      "\n",
      "step =  292000, num_env_steps =  292000, scores =  4894.782 (n= 1), score_ema =  0.000, actor_loss = -282.068, critic_loss = 14.370, entropy_coef_loss = -1.428, entropy_coef = 0.108, rollout_stds = N/A, action_magnitude = 0.761 ± 0.275, n_updates = 282000, time =  7.2, total_time = 2489.4 \n",
      "\n",
      "\n",
      "step =  293000, num_env_steps =  293000, scores =  4998.352 (n= 1), score_ema =  0.000, actor_loss = -291.778, critic_loss = 10.775, entropy_coef_loss = -0.120, entropy_coef = 0.106, rollout_stds = N/A, action_magnitude = 0.758 ± 0.280, n_updates = 283000, time =  6.9, total_time = 2496.2 \n",
      "\n",
      "\n",
      "step =  294000, num_env_steps =  294000, scores =  5055.104 (n= 1), score_ema =  0.000, actor_loss = -284.991, critic_loss = 338.997, entropy_coef_loss = -0.549, entropy_coef = 0.108, rollout_stds = N/A, action_magnitude = 0.754 ± 0.280, n_updates = 284000, time =  6.9, total_time = 2503.1 \n",
      "\n",
      "\n",
      "step =  295000, num_env_steps =  295000, scores =  5006.660 (n= 1), score_ema =  0.000, actor_loss = -288.914, critic_loss = 14.678, entropy_coef_loss = -0.038, entropy_coef = 0.102, rollout_stds = N/A, action_magnitude = 0.759 ± 0.278, n_updates = 285000, time =  6.7, total_time = 2509.9 \n",
      "\n",
      "\n",
      "step =  296000, num_env_steps =  296000, scores =  4893.168 (n= 1), score_ema =  0.000, actor_loss = -291.972, critic_loss = 11.860, entropy_coef_loss = 0.215, entropy_coef = 0.103, rollout_stds = N/A, action_magnitude = 0.756 ± 0.277, n_updates = 286000, time =  6.6, total_time = 2516.5 \n",
      "\n",
      "\n",
      "step =  297000, num_env_steps =  297000, scores =  5173.955 (n= 1), score_ema =  0.000, actor_loss = -287.383, critic_loss = 11.376, entropy_coef_loss = -0.033, entropy_coef = 0.104, rollout_stds = N/A, action_magnitude = 0.759 ± 0.279, n_updates = 287000, time =  6.5, total_time = 2523.0 \n",
      "\n",
      "\n",
      "step =  298000, num_env_steps =  298000, scores =  4995.058 (n= 1), score_ema =  0.000, actor_loss = -292.086, critic_loss = 17.339, entropy_coef_loss = -0.077, entropy_coef = 0.103, rollout_stds = N/A, action_magnitude = 0.755 ± 0.277, n_updates = 288000, time =  7.2, total_time = 2530.2 \n",
      "\n",
      "\n",
      "step =  299000, num_env_steps =  299000, scores =  5020.928 (n= 1), score_ema =  0.000, actor_loss = -292.493, critic_loss = 228.571, entropy_coef_loss = -0.194, entropy_coef = 0.103, rollout_stds = N/A, action_magnitude = 0.749 ± 0.281, n_updates = 289000, time =  6.6, total_time = 2536.8 \n",
      "\n",
      "\n",
      "step =  300000, num_env_steps =  300000, scores =  5036.479 (n= 1), score_ema =  0.000, actor_loss = -288.932, critic_loss = 465.655, entropy_coef_loss = 0.442, entropy_coef = 0.107, rollout_stds = N/A, action_magnitude = 0.752 ± 0.282, n_updates = 290000, time =  6.6, total_time = 2543.4 \n",
      "\n",
      "saved experiment log 2024-10-08_13-43-48_236302~fXPQM9 at experiment_logs/HalfCheetah-v4/sac/2024-10-08_13-43-48_236302~fXPQM9.json\n",
      "\n",
      "\n",
      "step =  301000, num_env_steps =  301000, scores =  4951.239 (n= 1), score_ema =  0.000, actor_loss = -287.043, critic_loss = 8.658, entropy_coef_loss = 0.257, entropy_coef = 0.108, rollout_stds = N/A, action_magnitude = 0.755 ± 0.280, n_updates = 291000, time =  7.0, total_time = 2550.4 \n",
      "\n",
      "\n",
      "step =  302000, num_env_steps =  302000, scores =  5041.888 (n= 1), score_ema =  0.000, actor_loss = -284.156, critic_loss = 13.322, entropy_coef_loss = 0.257, entropy_coef = 0.105, rollout_stds = N/A, action_magnitude = 0.763 ± 0.275, n_updates = 292000, time =  6.6, total_time = 2556.9 \n",
      "\n",
      "\n",
      "step =  303000, num_env_steps =  303000, scores =  5187.482 (n= 1), score_ema =  0.000, actor_loss = -284.838, critic_loss = 12.212, entropy_coef_loss = 0.786, entropy_coef = 0.106, rollout_stds = N/A, action_magnitude = 0.755 ± 0.277, n_updates = 293000, time =  7.4, total_time = 2564.3 \n",
      "\n",
      "\n",
      "step =  304000, num_env_steps =  304000, scores =  4878.676 (n= 1), score_ema =  0.000, actor_loss = -285.407, critic_loss = 402.780, entropy_coef_loss = -0.033, entropy_coef = 0.106, rollout_stds = N/A, action_magnitude = 0.750 ± 0.280, n_updates = 294000, time =  7.1, total_time = 2571.3 \n",
      "\n",
      "\n",
      "step =  305000, num_env_steps =  305000, scores =  5307.241 (n= 1), score_ema =  0.000, actor_loss = -287.887, critic_loss = 10.121, entropy_coef_loss = 0.779, entropy_coef = 0.105, rollout_stds = N/A, action_magnitude = 0.764 ± 0.274, n_updates = 295000, time =  8.5, total_time = 2579.8 \n",
      "\n",
      "\n",
      "step =  306000, num_env_steps =  306000, scores =  5043.291 (n= 1), score_ema =  0.000, actor_loss = -284.733, critic_loss = 17.544, entropy_coef_loss = -0.262, entropy_coef = 0.107, rollout_stds = N/A, action_magnitude = 0.748 ± 0.283, n_updates = 296000, time =  8.1, total_time = 2587.9 \n",
      "\n",
      "\n",
      "step =  307000, num_env_steps =  307000, scores =  5122.906 (n= 1), score_ema =  0.000, actor_loss = -292.879, critic_loss = 11.616, entropy_coef_loss = 0.136, entropy_coef = 0.104, rollout_stds = N/A, action_magnitude = 0.751 ± 0.282, n_updates = 297000, time =  6.7, total_time = 2594.6 \n",
      "\n",
      "\n",
      "step =  308000, num_env_steps =  308000, scores =  5036.502 (n= 1), score_ema =  0.000, actor_loss = -293.361, critic_loss = 10.466, entropy_coef_loss = -0.607, entropy_coef = 0.108, rollout_stds = N/A, action_magnitude = 0.739 ± 0.283, n_updates = 298000, time =  7.3, total_time = 2601.8 \n",
      "\n",
      "\n",
      "step =  309000, num_env_steps =  309000, scores =  5239.718 (n= 1), score_ema =  0.000, actor_loss = -290.527, critic_loss = 15.819, entropy_coef_loss = 1.609, entropy_coef = 0.106, rollout_stds = N/A, action_magnitude = 0.757 ± 0.278, n_updates = 299000, time =  7.6, total_time = 2609.4 \n",
      "\n",
      "\n",
      "step =  310000, num_env_steps =  310000, scores =  5414.098 (n= 1), score_ema =  0.000, actor_loss = -293.293, critic_loss = 412.295, entropy_coef_loss = 1.294, entropy_coef = 0.107, rollout_stds = N/A, action_magnitude = 0.752 ± 0.282, n_updates = 300000, time =  6.8, total_time = 2616.2 \n",
      "\n",
      "saved experiment log 2024-10-08_13-43-48_236302~fXPQM9 at experiment_logs/HalfCheetah-v4/sac/2024-10-08_13-43-48_236302~fXPQM9.json\n",
      "\n",
      "\n",
      "step =  311000, num_env_steps =  311000, scores =  5264.078 (n= 1), score_ema =  0.000, actor_loss = -297.149, critic_loss = 12.530, entropy_coef_loss = 0.085, entropy_coef = 0.106, rollout_stds = N/A, action_magnitude = 0.755 ± 0.276, n_updates = 301000, time =  6.4, total_time = 2622.6 \n",
      "\n",
      "\n",
      "step =  312000, num_env_steps =  312000, scores =  5364.829 (n= 1), score_ema =  0.000, actor_loss = -290.435, critic_loss = 12.620, entropy_coef_loss = -0.446, entropy_coef = 0.108, rollout_stds = N/A, action_magnitude = 0.759 ± 0.275, n_updates = 302000, time =  6.1, total_time = 2628.7 \n",
      "\n",
      "\n",
      "step =  313000, num_env_steps =  313000, scores =  5303.535 (n= 1), score_ema =  0.000, actor_loss = -292.222, critic_loss = 12.739, entropy_coef_loss = 0.866, entropy_coef = 0.109, rollout_stds = N/A, action_magnitude = 0.767 ± 0.275, n_updates = 303000, time =  6.1, total_time = 2634.8 \n",
      "\n",
      "\n",
      "step =  314000, num_env_steps =  314000, scores =  5154.176 (n= 1), score_ema =  0.000, actor_loss = -286.716, critic_loss = 14.863, entropy_coef_loss = -0.970, entropy_coef = 0.105, rollout_stds = N/A, action_magnitude = 0.755 ± 0.280, n_updates = 304000, time =  6.1, total_time = 2640.9 \n",
      "\n",
      "\n",
      "step =  315000, num_env_steps =  315000, scores =  5142.008 (n= 1), score_ema =  0.000, actor_loss = -290.449, critic_loss = 12.312, entropy_coef_loss = 0.054, entropy_coef = 0.109, rollout_stds = N/A, action_magnitude = 0.755 ± 0.276, n_updates = 305000, time =  6.4, total_time = 2647.3 \n",
      "\n",
      "\n",
      "step =  316000, num_env_steps =  316000, scores =  5207.140 (n= 1), score_ema =  0.000, actor_loss = -285.959, critic_loss = 20.560, entropy_coef_loss = -0.482, entropy_coef = 0.112, rollout_stds = N/A, action_magnitude = 0.757 ± 0.277, n_updates = 306000, time =  6.0, total_time = 2653.3 \n",
      "\n",
      "\n",
      "step =  317000, num_env_steps =  317000, scores =  5274.675 (n= 1), score_ema =  0.000, actor_loss = -300.960, critic_loss = 387.274, entropy_coef_loss = 0.737, entropy_coef = 0.108, rollout_stds = N/A, action_magnitude = 0.761 ± 0.274, n_updates = 307000, time =  5.9, total_time = 2659.2 \n",
      "\n",
      "\n",
      "step =  318000, num_env_steps =  318000, scores =  5390.562 (n= 1), score_ema =  0.000, actor_loss = -287.692, critic_loss = 8.566, entropy_coef_loss = -0.366, entropy_coef = 0.110, rollout_stds = N/A, action_magnitude = 0.765 ± 0.275, n_updates = 308000, time =  5.7, total_time = 2664.9 \n",
      "\n",
      "\n",
      "step =  319000, num_env_steps =  319000, scores =  5297.311 (n= 1), score_ema =  0.000, actor_loss = -288.156, critic_loss = 15.245, entropy_coef_loss = -2.199, entropy_coef = 0.106, rollout_stds = N/A, action_magnitude = 0.754 ± 0.279, n_updates = 309000, time =  5.7, total_time = 2670.6 \n",
      "\n",
      "\n",
      "step =  320000, num_env_steps =  320000, scores =  5583.059 (n= 1), score_ema =  0.000, actor_loss = -298.854, critic_loss = 12.961, entropy_coef_loss = -0.400, entropy_coef = 0.107, rollout_stds = N/A, action_magnitude = 0.764 ± 0.273, n_updates = 310000, time =  6.3, total_time = 2676.9 \n",
      "\n",
      "saved experiment log 2024-10-08_13-43-48_236302~fXPQM9 at experiment_logs/HalfCheetah-v4/sac/2024-10-08_13-43-48_236302~fXPQM9.json\n",
      "\n",
      "\n",
      "step =  321000, num_env_steps =  321000, scores =  5207.257 (n= 1), score_ema =  0.000, actor_loss = -292.309, critic_loss = 36.447, entropy_coef_loss = 1.283, entropy_coef = 0.111, rollout_stds = N/A, action_magnitude = 0.750 ± 0.281, n_updates = 311000, time =  6.0, total_time = 2682.9 \n",
      "\n",
      "\n",
      "step =  322000, num_env_steps =  322000, scores =  5225.293 (n= 1), score_ema =  0.000, actor_loss = -287.336, critic_loss = 14.441, entropy_coef_loss = 0.632, entropy_coef = 0.108, rollout_stds = N/A, action_magnitude = 0.753 ± 0.277, n_updates = 312000, time =  6.5, total_time = 2689.4 \n",
      "\n",
      "\n",
      "step =  323000, num_env_steps =  323000, scores =  5384.010 (n= 1), score_ema =  0.000, actor_loss = -297.026, critic_loss = 12.464, entropy_coef_loss = -1.550, entropy_coef = 0.107, rollout_stds = N/A, action_magnitude = 0.755 ± 0.281, n_updates = 313000, time =  6.3, total_time = 2695.7 \n",
      "\n",
      "\n",
      "step =  324000, num_env_steps =  324000, scores =  5277.538 (n= 1), score_ema =  0.000, actor_loss = -288.083, critic_loss = 12.511, entropy_coef_loss = 0.719, entropy_coef = 0.110, rollout_stds = N/A, action_magnitude = 0.757 ± 0.275, n_updates = 314000, time =  6.3, total_time = 2702.0 \n",
      "\n",
      "\n",
      "step =  325000, num_env_steps =  325000, scores =  5298.358 (n= 1), score_ema =  0.000, actor_loss = -296.369, critic_loss = 17.349, entropy_coef_loss = 0.521, entropy_coef = 0.107, rollout_stds = N/A, action_magnitude = 0.746 ± 0.281, n_updates = 315000, time =  5.9, total_time = 2707.9 \n",
      "\n",
      "\n",
      "step =  326000, num_env_steps =  326000, scores =  5475.684 (n= 1), score_ema =  0.000, actor_loss = -300.063, critic_loss = 10.117, entropy_coef_loss = 0.281, entropy_coef = 0.109, rollout_stds = N/A, action_magnitude = 0.757 ± 0.276, n_updates = 316000, time =  6.1, total_time = 2714.0 \n",
      "\n",
      "\n",
      "step =  327000, num_env_steps =  327000, scores =  5459.211 (n= 1), score_ema =  0.000, actor_loss = -298.103, critic_loss = 15.483, entropy_coef_loss = -0.134, entropy_coef = 0.109, rollout_stds = N/A, action_magnitude = 0.752 ± 0.277, n_updates = 317000, time =  6.2, total_time = 2720.2 \n",
      "\n",
      "\n",
      "step =  328000, num_env_steps =  328000, scores =  5335.223 (n= 1), score_ema =  0.000, actor_loss = -306.303, critic_loss = 357.926, entropy_coef_loss = -0.551, entropy_coef = 0.109, rollout_stds = N/A, action_magnitude = 0.745 ± 0.281, n_updates = 318000, time =  6.3, total_time = 2726.5 \n",
      "\n",
      "\n",
      "step =  329000, num_env_steps =  329000, scores =  5372.461 (n= 1), score_ema =  0.000, actor_loss = -305.077, critic_loss = 434.932, entropy_coef_loss = -0.065, entropy_coef = 0.110, rollout_stds = N/A, action_magnitude = 0.749 ± 0.279, n_updates = 319000, time =  6.2, total_time = 2732.8 \n",
      "\n",
      "\n",
      "step =  330000, num_env_steps =  330000, scores =  5469.730 (n= 1), score_ema =  0.000, actor_loss = -299.198, critic_loss = 440.391, entropy_coef_loss = -0.873, entropy_coef = 0.110, rollout_stds = N/A, action_magnitude = 0.755 ± 0.279, n_updates = 320000, time =  6.4, total_time = 2739.2 \n",
      "\n",
      "saved experiment log 2024-10-08_13-43-48_236302~fXPQM9 at experiment_logs/HalfCheetah-v4/sac/2024-10-08_13-43-48_236302~fXPQM9.json\n",
      "\n",
      "\n",
      "step =  331000, num_env_steps =  331000, scores =  5310.940 (n= 1), score_ema =  0.000, actor_loss = -300.501, critic_loss = 477.533, entropy_coef_loss = -0.241, entropy_coef = 0.111, rollout_stds = N/A, action_magnitude = 0.744 ± 0.283, n_updates = 321000, time =  6.2, total_time = 2745.3 \n",
      "\n",
      "\n",
      "step =  332000, num_env_steps =  332000, scores =  5441.292 (n= 1), score_ema =  0.000, actor_loss = -301.102, critic_loss = 14.067, entropy_coef_loss = -0.095, entropy_coef = 0.112, rollout_stds = N/A, action_magnitude = 0.768 ± 0.273, n_updates = 322000, time =  6.2, total_time = 2751.5 \n",
      "\n",
      "\n",
      "step =  333000, num_env_steps =  333000, scores =  5431.731 (n= 1), score_ema =  0.000, actor_loss = -299.391, critic_loss = 14.244, entropy_coef_loss = 0.311, entropy_coef = 0.111, rollout_stds = N/A, action_magnitude = 0.768 ± 0.272, n_updates = 323000, time =  6.3, total_time = 2757.8 \n",
      "\n",
      "\n",
      "step =  334000, num_env_steps =  334000, scores =  5560.890 (n= 1), score_ema =  0.000, actor_loss = -295.541, critic_loss = 239.887, entropy_coef_loss = -0.684, entropy_coef = 0.111, rollout_stds = N/A, action_magnitude = 0.764 ± 0.274, n_updates = 324000, time =  6.3, total_time = 2764.0 \n",
      "\n",
      "\n",
      "step =  335000, num_env_steps =  335000, scores =  5369.548 (n= 1), score_ema =  0.000, actor_loss = -307.457, critic_loss = 12.140, entropy_coef_loss = -0.392, entropy_coef = 0.114, rollout_stds = N/A, action_magnitude = 0.749 ± 0.278, n_updates = 325000, time =  6.3, total_time = 2770.3 \n",
      "\n",
      "\n",
      "step =  336000, num_env_steps =  336000, scores =  5309.440 (n= 1), score_ema =  0.000, actor_loss = -296.233, critic_loss = 9.743, entropy_coef_loss = -0.077, entropy_coef = 0.114, rollout_stds = N/A, action_magnitude = 0.754 ± 0.277, n_updates = 326000, time =  6.2, total_time = 2776.5 \n",
      "\n",
      "\n",
      "step =  337000, num_env_steps =  337000, scores =  5556.092 (n= 1), score_ema =  0.000, actor_loss = -308.851, critic_loss = 11.003, entropy_coef_loss = 0.842, entropy_coef = 0.114, rollout_stds = N/A, action_magnitude = 0.768 ± 0.272, n_updates = 327000, time =  6.0, total_time = 2782.5 \n",
      "\n",
      "\n",
      "step =  338000, num_env_steps =  338000, scores =  5524.042 (n= 1), score_ema =  0.000, actor_loss = -308.319, critic_loss = 17.655, entropy_coef_loss = -0.200, entropy_coef = 0.113, rollout_stds = N/A, action_magnitude = 0.762 ± 0.273, n_updates = 328000, time =  5.8, total_time = 2788.3 \n",
      "\n",
      "\n",
      "step =  339000, num_env_steps =  339000, scores =  5479.529 (n= 1), score_ema =  0.000, actor_loss = -293.874, critic_loss = 13.726, entropy_coef_loss = 0.203, entropy_coef = 0.114, rollout_stds = N/A, action_magnitude = 0.752 ± 0.280, n_updates = 329000, time =  6.0, total_time = 2794.3 \n",
      "\n",
      "\n",
      "step =  340000, num_env_steps =  340000, scores =  5328.664 (n= 1), score_ema =  0.000, actor_loss = -300.743, critic_loss = 14.060, entropy_coef_loss = -0.590, entropy_coef = 0.115, rollout_stds = N/A, action_magnitude = 0.758 ± 0.275, n_updates = 330000, time =  5.9, total_time = 2800.1 \n",
      "\n",
      "saved experiment log 2024-10-08_13-43-48_236302~fXPQM9 at experiment_logs/HalfCheetah-v4/sac/2024-10-08_13-43-48_236302~fXPQM9.json\n",
      "\n",
      "\n",
      "step =  341000, num_env_steps =  341000, scores =  5313.401 (n= 1), score_ema =  0.000, actor_loss = -307.144, critic_loss = 17.156, entropy_coef_loss = -0.295, entropy_coef = 0.110, rollout_stds = N/A, action_magnitude = 0.756 ± 0.274, n_updates = 331000, time =  5.8, total_time = 2806.0 \n",
      "\n",
      "\n",
      "step =  342000, num_env_steps =  342000, scores =  5491.524 (n= 1), score_ema =  0.000, actor_loss = -303.701, critic_loss = 12.102, entropy_coef_loss = -0.289, entropy_coef = 0.114, rollout_stds = N/A, action_magnitude = 0.759 ± 0.274, n_updates = 332000, time =  6.0, total_time = 2812.0 \n",
      "\n",
      "\n",
      "step =  343000, num_env_steps =  343000, scores =  5517.268 (n= 1), score_ema =  0.000, actor_loss = -304.354, critic_loss = 16.587, entropy_coef_loss = 1.058, entropy_coef = 0.113, rollout_stds = N/A, action_magnitude = 0.757 ± 0.279, n_updates = 333000, time =  6.1, total_time = 2818.1 \n",
      "\n",
      "\n",
      "step =  344000, num_env_steps =  344000, scores =  5302.885 (n= 1), score_ema =  0.000, actor_loss = -307.136, critic_loss = 16.159, entropy_coef_loss = 0.984, entropy_coef = 0.114, rollout_stds = N/A, action_magnitude = 0.757 ± 0.275, n_updates = 334000, time =  5.8, total_time = 2823.9 \n",
      "\n",
      "\n",
      "step =  345000, num_env_steps =  345000, scores =  5226.991 (n= 1), score_ema =  0.000, actor_loss = -306.243, critic_loss = 448.861, entropy_coef_loss = -0.402, entropy_coef = 0.116, rollout_stds = N/A, action_magnitude = 0.755 ± 0.280, n_updates = 335000, time =  5.7, total_time = 2829.7 \n",
      "\n",
      "\n",
      "step =  346000, num_env_steps =  346000, scores =  5397.036 (n= 1), score_ema =  0.000, actor_loss = -300.482, critic_loss = 13.614, entropy_coef_loss = -1.472, entropy_coef = 0.113, rollout_stds = N/A, action_magnitude = 0.756 ± 0.277, n_updates = 336000, time =  5.9, total_time = 2835.6 \n",
      "\n",
      "\n",
      "step =  347000, num_env_steps =  347000, scores =  5314.386 (n= 1), score_ema =  0.000, actor_loss = -307.045, critic_loss = 10.089, entropy_coef_loss = 0.228, entropy_coef = 0.115, rollout_stds = N/A, action_magnitude = 0.750 ± 0.281, n_updates = 337000, time =  5.7, total_time = 2841.3 \n",
      "\n",
      "\n",
      "step =  348000, num_env_steps =  348000, scores =  5354.571 (n= 1), score_ema =  0.000, actor_loss = -303.469, critic_loss = 14.953, entropy_coef_loss = 0.108, entropy_coef = 0.115, rollout_stds = N/A, action_magnitude = 0.756 ± 0.280, n_updates = 338000, time =  5.8, total_time = 2847.1 \n",
      "\n",
      "\n",
      "step =  349000, num_env_steps =  349000, scores =  5424.191 (n= 1), score_ema =  0.000, actor_loss = -308.665, critic_loss = 12.401, entropy_coef_loss = -1.032, entropy_coef = 0.113, rollout_stds = N/A, action_magnitude = 0.748 ± 0.279, n_updates = 339000, time =  6.4, total_time = 2853.4 \n",
      "\n",
      "\n",
      "step =  350000, num_env_steps =  350000, scores =  5514.762 (n= 1), score_ema =  0.000, actor_loss = -311.199, critic_loss = 13.989, entropy_coef_loss = -0.233, entropy_coef = 0.117, rollout_stds = N/A, action_magnitude = 0.766 ± 0.270, n_updates = 340000, time =  6.1, total_time = 2859.5 \n",
      "\n",
      "saved experiment log 2024-10-08_13-43-48_236302~fXPQM9 at experiment_logs/HalfCheetah-v4/sac/2024-10-08_13-43-48_236302~fXPQM9.json\n",
      "\n",
      "\n",
      "step =  351000, num_env_steps =  351000, scores =  5577.548 (n= 1), score_ema =  0.000, actor_loss = -309.355, critic_loss = 14.131, entropy_coef_loss = 0.044, entropy_coef = 0.115, rollout_stds = N/A, action_magnitude = 0.757 ± 0.274, n_updates = 341000, time =  6.3, total_time = 2865.9 \n",
      "\n",
      "\n",
      "step =  352000, num_env_steps =  352000, scores =  5470.384 (n= 1), score_ema =  0.000, actor_loss = -312.429, critic_loss = 14.573, entropy_coef_loss = 0.925, entropy_coef = 0.116, rollout_stds = N/A, action_magnitude = 0.760 ± 0.275, n_updates = 342000, time =  6.3, total_time = 2872.1 \n",
      "\n",
      "\n",
      "step =  353000, num_env_steps =  353000, scores =  5548.665 (n= 1), score_ema =  0.000, actor_loss = -305.343, critic_loss = 18.077, entropy_coef_loss = -0.402, entropy_coef = 0.115, rollout_stds = N/A, action_magnitude = 0.765 ± 0.276, n_updates = 343000, time =  6.1, total_time = 2878.3 \n",
      "\n",
      "\n",
      "step =  354000, num_env_steps =  354000, scores =  5448.079 (n= 1), score_ema =  0.000, actor_loss = -302.919, critic_loss = 12.159, entropy_coef_loss = -0.191, entropy_coef = 0.116, rollout_stds = N/A, action_magnitude = 0.755 ± 0.279, n_updates = 344000, time =  6.1, total_time = 2884.4 \n",
      "\n",
      "\n",
      "step =  355000, num_env_steps =  355000, scores =  5623.260 (n= 1), score_ema =  0.000, actor_loss = -309.145, critic_loss = 12.768, entropy_coef_loss = 0.723, entropy_coef = 0.118, rollout_stds = N/A, action_magnitude = 0.759 ± 0.277, n_updates = 345000, time =  6.6, total_time = 2891.0 \n",
      "\n",
      "\n",
      "step =  356000, num_env_steps =  356000, scores =  5471.171 (n= 1), score_ema =  0.000, actor_loss = -320.673, critic_loss = 476.515, entropy_coef_loss = 0.349, entropy_coef = 0.117, rollout_stds = N/A, action_magnitude = 0.753 ± 0.282, n_updates = 346000, time =  6.8, total_time = 2897.8 \n",
      "\n",
      "\n",
      "step =  357000, num_env_steps =  357000, scores =  5601.184 (n= 1), score_ema =  0.000, actor_loss = -308.175, critic_loss = 14.449, entropy_coef_loss = -0.188, entropy_coef = 0.115, rollout_stds = N/A, action_magnitude = 0.756 ± 0.276, n_updates = 347000, time =  7.5, total_time = 2905.3 \n",
      "\n",
      "\n",
      "step =  358000, num_env_steps =  358000, scores =  5728.862 (n= 1), score_ema =  0.000, actor_loss = -307.466, critic_loss = 10.384, entropy_coef_loss = -0.739, entropy_coef = 0.118, rollout_stds = N/A, action_magnitude = 0.768 ± 0.270, n_updates = 348000, time =  6.7, total_time = 2912.0 \n",
      "\n",
      "\n",
      "step =  359000, num_env_steps =  359000, scores =  5596.410 (n= 1), score_ema =  0.000, actor_loss = -319.017, critic_loss = 29.289, entropy_coef_loss = 1.131, entropy_coef = 0.115, rollout_stds = N/A, action_magnitude = 0.755 ± 0.277, n_updates = 349000, time =  7.5, total_time = 2919.5 \n",
      "\n",
      "\n",
      "step =  360000, num_env_steps =  360000, scores =  5605.236 (n= 1), score_ema =  0.000, actor_loss = -302.519, critic_loss = 47.646, entropy_coef_loss = -0.993, entropy_coef = 0.119, rollout_stds = N/A, action_magnitude = 0.759 ± 0.275, n_updates = 350000, time =  6.5, total_time = 2925.9 \n",
      "\n",
      "saved experiment log 2024-10-08_13-43-48_236302~fXPQM9 at experiment_logs/HalfCheetah-v4/sac/2024-10-08_13-43-48_236302~fXPQM9.json\n",
      "\n",
      "\n",
      "step =  361000, num_env_steps =  361000, scores =  4774.216 (n= 1), score_ema =  0.000, actor_loss = -306.363, critic_loss = 12.431, entropy_coef_loss = -1.307, entropy_coef = 0.116, rollout_stds = N/A, action_magnitude = 0.728 ± 0.289, n_updates = 351000, time =  7.1, total_time = 2933.0 \n",
      "\n",
      "\n",
      "step =  362000, num_env_steps =  362000, scores =  5675.999 (n= 1), score_ema =  0.000, actor_loss = -320.980, critic_loss = 14.192, entropy_coef_loss = 0.412, entropy_coef = 0.119, rollout_stds = N/A, action_magnitude = 0.770 ± 0.273, n_updates = 352000, time =  6.6, total_time = 2939.7 \n",
      "\n",
      "\n",
      "step =  363000, num_env_steps =  363000, scores =  5554.552 (n= 1), score_ema =  0.000, actor_loss = -313.334, critic_loss = 16.800, entropy_coef_loss = 1.113, entropy_coef = 0.118, rollout_stds = N/A, action_magnitude = 0.769 ± 0.274, n_updates = 353000, time =  6.4, total_time = 2946.0 \n",
      "\n",
      "\n",
      "step =  364000, num_env_steps =  364000, scores =  5549.675 (n= 1), score_ema =  0.000, actor_loss = -310.540, critic_loss = 14.453, entropy_coef_loss = -0.922, entropy_coef = 0.116, rollout_stds = N/A, action_magnitude = 0.765 ± 0.276, n_updates = 354000, time =  7.4, total_time = 2953.4 \n",
      "\n",
      "\n",
      "step =  365000, num_env_steps =  365000, scores =  5582.439 (n= 1), score_ema =  0.000, actor_loss = -311.801, critic_loss = 17.532, entropy_coef_loss = 0.014, entropy_coef = 0.120, rollout_stds = N/A, action_magnitude = 0.771 ± 0.270, n_updates = 355000, time =  6.6, total_time = 2960.0 \n",
      "\n",
      "\n",
      "step =  366000, num_env_steps =  366000, scores =  5491.401 (n= 1), score_ema =  0.000, actor_loss = -310.915, critic_loss = 15.651, entropy_coef_loss = -0.761, entropy_coef = 0.122, rollout_stds = N/A, action_magnitude = 0.760 ± 0.273, n_updates = 356000, time =  6.7, total_time = 2966.6 \n",
      "\n",
      "\n",
      "step =  367000, num_env_steps =  367000, scores =  5550.528 (n= 1), score_ema =  0.000, actor_loss = -311.121, critic_loss = 18.374, entropy_coef_loss = -0.557, entropy_coef = 0.119, rollout_stds = N/A, action_magnitude = 0.758 ± 0.277, n_updates = 357000, time =  7.0, total_time = 2973.6 \n",
      "\n",
      "\n",
      "step =  368000, num_env_steps =  368000, scores =  5641.349 (n= 1), score_ema =  0.000, actor_loss = -313.991, critic_loss = 11.803, entropy_coef_loss = -0.148, entropy_coef = 0.119, rollout_stds = N/A, action_magnitude = 0.753 ± 0.281, n_updates = 358000, time =  6.5, total_time = 2980.2 \n",
      "\n",
      "\n",
      "step =  369000, num_env_steps =  369000, scores =  5656.271 (n= 1), score_ema =  0.000, actor_loss = -316.218, critic_loss = 14.295, entropy_coef_loss = 0.009, entropy_coef = 0.120, rollout_stds = N/A, action_magnitude = 0.767 ± 0.271, n_updates = 359000, time =  6.6, total_time = 2986.8 \n",
      "\n",
      "\n",
      "step =  370000, num_env_steps =  370000, scores =  5607.227 (n= 1), score_ema =  0.000, actor_loss = -319.168, critic_loss = 331.339, entropy_coef_loss = -0.195, entropy_coef = 0.122, rollout_stds = N/A, action_magnitude = 0.754 ± 0.278, n_updates = 360000, time =  6.6, total_time = 2993.4 \n",
      "\n",
      "saved experiment log 2024-10-08_13-43-48_236302~fXPQM9 at experiment_logs/HalfCheetah-v4/sac/2024-10-08_13-43-48_236302~fXPQM9.json\n",
      "\n",
      "\n",
      "step =  371000, num_env_steps =  371000, scores =  5563.720 (n= 1), score_ema =  0.000, actor_loss = -312.521, critic_loss = 21.721, entropy_coef_loss = -0.040, entropy_coef = 0.121, rollout_stds = N/A, action_magnitude = 0.760 ± 0.279, n_updates = 361000, time =  6.5, total_time = 2999.9 \n",
      "\n",
      "\n",
      "step =  372000, num_env_steps =  372000, scores =  5709.564 (n= 1), score_ema =  0.000, actor_loss = -313.282, critic_loss = 15.638, entropy_coef_loss = 0.572, entropy_coef = 0.124, rollout_stds = N/A, action_magnitude = 0.766 ± 0.275, n_updates = 362000, time =  7.0, total_time = 3006.9 \n",
      "\n",
      "\n",
      "step =  373000, num_env_steps =  373000, scores =  5496.864 (n= 1), score_ema =  0.000, actor_loss = -313.319, critic_loss = 20.380, entropy_coef_loss = 0.638, entropy_coef = 0.122, rollout_stds = N/A, action_magnitude = 0.764 ± 0.271, n_updates = 363000, time =  6.9, total_time = 3013.8 \n",
      "\n",
      "\n",
      "step =  374000, num_env_steps =  374000, scores =  5691.274 (n= 1), score_ema =  0.000, actor_loss = -311.233, critic_loss = 21.197, entropy_coef_loss = -0.786, entropy_coef = 0.124, rollout_stds = N/A, action_magnitude = 0.766 ± 0.274, n_updates = 364000, time =  7.1, total_time = 3020.9 \n",
      "\n",
      "\n",
      "step =  375000, num_env_steps =  375000, scores =  5541.662 (n= 1), score_ema =  0.000, actor_loss = -317.652, critic_loss = 204.073, entropy_coef_loss = 0.509, entropy_coef = 0.122, rollout_stds = N/A, action_magnitude = 0.760 ± 0.275, n_updates = 365000, time =  7.7, total_time = 3028.6 \n",
      "\n",
      "\n",
      "step =  376000, num_env_steps =  376000, scores =  5564.682 (n= 1), score_ema =  0.000, actor_loss = -324.999, critic_loss = 19.541, entropy_coef_loss = 1.134, entropy_coef = 0.126, rollout_stds = N/A, action_magnitude = 0.757 ± 0.278, n_updates = 366000, time =  6.9, total_time = 3035.5 \n",
      "\n",
      "\n",
      "step =  377000, num_env_steps =  377000, scores =  5599.841 (n= 1), score_ema =  0.000, actor_loss = -308.355, critic_loss = 467.571, entropy_coef_loss = -1.168, entropy_coef = 0.124, rollout_stds = N/A, action_magnitude = 0.759 ± 0.278, n_updates = 367000, time =  6.5, total_time = 3042.0 \n",
      "\n",
      "\n",
      "step =  378000, num_env_steps =  378000, scores =  5703.293 (n= 1), score_ema =  0.000, actor_loss = -319.613, critic_loss = 17.143, entropy_coef_loss = -0.973, entropy_coef = 0.121, rollout_stds = N/A, action_magnitude = 0.757 ± 0.277, n_updates = 368000, time =  6.8, total_time = 3048.8 \n",
      "\n",
      "\n",
      "step =  379000, num_env_steps =  379000, scores =  5451.890 (n= 1), score_ema =  0.000, actor_loss = -309.490, critic_loss = 13.003, entropy_coef_loss = -1.294, entropy_coef = 0.121, rollout_stds = N/A, action_magnitude = 0.754 ± 0.277, n_updates = 369000, time =  7.9, total_time = 3056.7 \n",
      "\n",
      "\n",
      "step =  380000, num_env_steps =  380000, scores =  5633.183 (n= 1), score_ema =  0.000, actor_loss = -321.144, critic_loss = 24.246, entropy_coef_loss = -0.901, entropy_coef = 0.121, rollout_stds = N/A, action_magnitude = 0.752 ± 0.278, n_updates = 370000, time =  7.2, total_time = 3063.9 \n",
      "\n",
      "saved experiment log 2024-10-08_13-43-48_236302~fXPQM9 at experiment_logs/HalfCheetah-v4/sac/2024-10-08_13-43-48_236302~fXPQM9.json\n",
      "\n",
      "\n",
      "step =  381000, num_env_steps =  381000, scores =  5646.158 (n= 1), score_ema =  0.000, actor_loss = -318.312, critic_loss = 13.334, entropy_coef_loss = -0.460, entropy_coef = 0.124, rollout_stds = N/A, action_magnitude = 0.759 ± 0.280, n_updates = 371000, time =  7.3, total_time = 3071.2 \n",
      "\n",
      "\n",
      "step =  382000, num_env_steps =  382000, scores =  5575.978 (n= 1), score_ema =  0.000, actor_loss = -316.400, critic_loss = 12.819, entropy_coef_loss = -0.759, entropy_coef = 0.124, rollout_stds = N/A, action_magnitude = 0.756 ± 0.278, n_updates = 372000, time =  6.3, total_time = 3077.5 \n",
      "\n",
      "\n",
      "step =  383000, num_env_steps =  383000, scores =  5721.180 (n= 1), score_ema =  0.000, actor_loss = -310.986, critic_loss = 574.384, entropy_coef_loss = -0.533, entropy_coef = 0.122, rollout_stds = N/A, action_magnitude = 0.756 ± 0.277, n_updates = 373000, time =  6.2, total_time = 3083.7 \n",
      "\n",
      "\n",
      "step =  384000, num_env_steps =  384000, scores =  5641.800 (n= 1), score_ema =  0.000, actor_loss = -315.264, critic_loss = 14.465, entropy_coef_loss = -0.088, entropy_coef = 0.126, rollout_stds = N/A, action_magnitude = 0.755 ± 0.279, n_updates = 374000, time =  6.2, total_time = 3089.9 \n",
      "\n",
      "\n",
      "step =  385000, num_env_steps =  385000, scores =  5676.719 (n= 1), score_ema =  0.000, actor_loss = -322.105, critic_loss = 17.490, entropy_coef_loss = -0.315, entropy_coef = 0.124, rollout_stds = N/A, action_magnitude = 0.747 ± 0.280, n_updates = 375000, time =  6.1, total_time = 3096.0 \n",
      "\n",
      "\n",
      "step =  386000, num_env_steps =  386000, scores =  5597.826 (n= 1), score_ema =  0.000, actor_loss = -321.469, critic_loss = 12.069, entropy_coef_loss = 0.037, entropy_coef = 0.126, rollout_stds = N/A, action_magnitude = 0.753 ± 0.273, n_updates = 376000, time =  6.1, total_time = 3102.1 \n",
      "\n",
      "\n",
      "step =  387000, num_env_steps =  387000, scores =  5556.683 (n= 1), score_ema =  0.000, actor_loss = -329.610, critic_loss = 13.016, entropy_coef_loss = 0.955, entropy_coef = 0.124, rollout_stds = N/A, action_magnitude = 0.758 ± 0.276, n_updates = 377000, time =  6.1, total_time = 3108.2 \n",
      "\n",
      "\n",
      "step =  388000, num_env_steps =  388000, scores =  5604.940 (n= 1), score_ema =  0.000, actor_loss = -323.720, critic_loss = 29.338, entropy_coef_loss = 0.220, entropy_coef = 0.122, rollout_stds = N/A, action_magnitude = 0.754 ± 0.278, n_updates = 378000, time =  6.3, total_time = 3114.5 \n",
      "\n",
      "\n",
      "step =  389000, num_env_steps =  389000, scores =  5750.526 (n= 1), score_ema =  0.000, actor_loss = -322.679, critic_loss = 13.403, entropy_coef_loss = 0.028, entropy_coef = 0.123, rollout_stds = N/A, action_magnitude = 0.757 ± 0.277, n_updates = 379000, time =  5.9, total_time = 3120.4 \n",
      "\n",
      "\n",
      "step =  390000, num_env_steps =  390000, scores =  5844.288 (n= 1), score_ema =  0.000, actor_loss = -325.454, critic_loss = 13.272, entropy_coef_loss = -1.240, entropy_coef = 0.122, rollout_stds = N/A, action_magnitude = 0.767 ± 0.274, n_updates = 380000, time =  5.8, total_time = 3126.3 \n",
      "\n",
      "saved experiment log 2024-10-08_13-43-48_236302~fXPQM9 at experiment_logs/HalfCheetah-v4/sac/2024-10-08_13-43-48_236302~fXPQM9.json\n",
      "\n",
      "\n",
      "step =  391000, num_env_steps =  391000, scores =  5729.377 (n= 1), score_ema =  0.000, actor_loss = -316.100, critic_loss = 13.776, entropy_coef_loss = -1.058, entropy_coef = 0.125, rollout_stds = N/A, action_magnitude = 0.757 ± 0.279, n_updates = 381000, time =  5.8, total_time = 3132.1 \n",
      "\n",
      "\n",
      "step =  392000, num_env_steps =  392000, scores =  5645.389 (n= 1), score_ema =  0.000, actor_loss = -329.523, critic_loss = 17.117, entropy_coef_loss = -0.142, entropy_coef = 0.125, rollout_stds = N/A, action_magnitude = 0.758 ± 0.273, n_updates = 382000, time =  6.0, total_time = 3138.1 \n",
      "\n",
      "\n",
      "step =  393000, num_env_steps =  393000, scores =  5673.221 (n= 1), score_ema =  0.000, actor_loss = -332.485, critic_loss = 674.972, entropy_coef_loss = 1.147, entropy_coef = 0.123, rollout_stds = N/A, action_magnitude = 0.759 ± 0.276, n_updates = 383000, time =  5.9, total_time = 3144.1 \n",
      "\n",
      "\n",
      "step =  394000, num_env_steps =  394000, scores =  5608.596 (n= 1), score_ema =  0.000, actor_loss = -338.261, critic_loss = 20.156, entropy_coef_loss = -0.058, entropy_coef = 0.126, rollout_stds = N/A, action_magnitude = 0.761 ± 0.273, n_updates = 384000, time =  5.9, total_time = 3149.9 \n",
      "\n",
      "\n",
      "step =  395000, num_env_steps =  395000, scores =  5572.600 (n= 1), score_ema =  0.000, actor_loss = -336.621, critic_loss = 16.118, entropy_coef_loss = 0.037, entropy_coef = 0.126, rollout_stds = N/A, action_magnitude = 0.753 ± 0.282, n_updates = 385000, time =  5.7, total_time = 3155.6 \n",
      "\n",
      "\n",
      "step =  396000, num_env_steps =  396000, scores =  5708.349 (n= 1), score_ema =  0.000, actor_loss = -330.951, critic_loss = 14.697, entropy_coef_loss = 1.058, entropy_coef = 0.127, rollout_stds = N/A, action_magnitude = 0.760 ± 0.276, n_updates = 386000, time =  5.7, total_time = 3161.4 \n",
      "\n",
      "\n",
      "step =  397000, num_env_steps =  397000, scores =  5627.161 (n= 1), score_ema =  0.000, actor_loss = -323.307, critic_loss = 10.714, entropy_coef_loss = -0.723, entropy_coef = 0.125, rollout_stds = N/A, action_magnitude = 0.746 ± 0.281, n_updates = 387000, time =  5.8, total_time = 3167.1 \n",
      "\n",
      "\n",
      "step =  398000, num_env_steps =  398000, scores =  5628.075 (n= 1), score_ema =  0.000, actor_loss = -327.281, critic_loss = 12.698, entropy_coef_loss = -0.972, entropy_coef = 0.122, rollout_stds = N/A, action_magnitude = 0.753 ± 0.277, n_updates = 388000, time =  5.9, total_time = 3173.0 \n",
      "\n",
      "\n",
      "step =  399000, num_env_steps =  399000, scores =  5439.609 (n= 1), score_ema =  0.000, actor_loss = -321.502, critic_loss = 479.412, entropy_coef_loss = -0.393, entropy_coef = 0.125, rollout_stds = N/A, action_magnitude = 0.744 ± 0.281, n_updates = 389000, time =  5.8, total_time = 3178.8 \n",
      "\n",
      "\n",
      "step =  400000, num_env_steps =  400000, scores =  5692.559 (n= 1), score_ema =  0.000, actor_loss = -331.908, critic_loss = 477.362, entropy_coef_loss = 0.337, entropy_coef = 0.126, rollout_stds = N/A, action_magnitude = 0.753 ± 0.276, n_updates = 390000, time =  5.8, total_time = 3184.6 \n",
      "\n",
      "saved experiment log 2024-10-08_13-43-48_236302~fXPQM9 at experiment_logs/HalfCheetah-v4/sac/2024-10-08_13-43-48_236302~fXPQM9.json\n",
      "\n",
      "\n",
      "step =  401000, num_env_steps =  401000, scores =  5770.739 (n= 1), score_ema =  0.000, actor_loss = -328.298, critic_loss = 1354.940, entropy_coef_loss = 0.950, entropy_coef = 0.125, rollout_stds = N/A, action_magnitude = 0.759 ± 0.276, n_updates = 391000, time =  5.8, total_time = 3190.4 \n",
      "\n",
      "\n",
      "step =  402000, num_env_steps =  402000, scores =  5558.336 (n= 1), score_ema =  0.000, actor_loss = -329.322, critic_loss = 14.966, entropy_coef_loss = -0.888, entropy_coef = 0.125, rollout_stds = N/A, action_magnitude = 0.752 ± 0.278, n_updates = 392000, time =  5.7, total_time = 3196.1 \n",
      "\n",
      "\n",
      "step =  403000, num_env_steps =  403000, scores =  5617.936 (n= 1), score_ema =  0.000, actor_loss = -330.078, critic_loss = 16.146, entropy_coef_loss = -0.494, entropy_coef = 0.127, rollout_stds = N/A, action_magnitude = 0.756 ± 0.278, n_updates = 393000, time =  5.9, total_time = 3202.1 \n",
      "\n",
      "\n",
      "step =  404000, num_env_steps =  404000, scores =  5582.035 (n= 1), score_ema =  0.000, actor_loss = -333.877, critic_loss = 12.418, entropy_coef_loss = 0.006, entropy_coef = 0.125, rollout_stds = N/A, action_magnitude = 0.745 ± 0.282, n_updates = 394000, time =  7.4, total_time = 3209.5 \n",
      "\n",
      "\n",
      "step =  405000, num_env_steps =  405000, scores =  5728.139 (n= 1), score_ema =  0.000, actor_loss = -329.124, critic_loss = 16.128, entropy_coef_loss = -0.286, entropy_coef = 0.126, rollout_stds = N/A, action_magnitude = 0.756 ± 0.277, n_updates = 395000, time =  7.0, total_time = 3216.4 \n",
      "\n",
      "\n",
      "step =  406000, num_env_steps =  406000, scores =  5731.232 (n= 1), score_ema =  0.000, actor_loss = -331.021, critic_loss = 11.613, entropy_coef_loss = -0.240, entropy_coef = 0.127, rollout_stds = N/A, action_magnitude = 0.760 ± 0.274, n_updates = 396000, time =  6.8, total_time = 3223.2 \n",
      "\n",
      "\n",
      "step =  407000, num_env_steps =  407000, scores =  5806.354 (n= 1), score_ema =  0.000, actor_loss = -319.723, critic_loss = 14.996, entropy_coef_loss = -1.149, entropy_coef = 0.127, rollout_stds = N/A, action_magnitude = 0.757 ± 0.276, n_updates = 397000, time =  6.7, total_time = 3230.0 \n",
      "\n",
      "\n",
      "step =  408000, num_env_steps =  408000, scores =  5780.258 (n= 1), score_ema =  0.000, actor_loss = -324.583, critic_loss = 18.911, entropy_coef_loss = -0.433, entropy_coef = 0.127, rollout_stds = N/A, action_magnitude = 0.755 ± 0.277, n_updates = 398000, time =  6.7, total_time = 3236.6 \n",
      "\n",
      "\n",
      "step =  409000, num_env_steps =  409000, scores =  5779.083 (n= 1), score_ema =  0.000, actor_loss = -332.312, critic_loss = 627.790, entropy_coef_loss = 0.714, entropy_coef = 0.128, rollout_stds = N/A, action_magnitude = 0.762 ± 0.272, n_updates = 399000, time =  6.6, total_time = 3243.3 \n",
      "\n",
      "\n",
      "step =  410000, num_env_steps =  410000, scores =  5784.733 (n= 1), score_ema =  0.000, actor_loss = -325.746, critic_loss = 16.299, entropy_coef_loss = 0.316, entropy_coef = 0.132, rollout_stds = N/A, action_magnitude = 0.752 ± 0.277, n_updates = 400000, time =  7.3, total_time = 3250.5 \n",
      "\n",
      "saved experiment log 2024-10-08_13-43-48_236302~fXPQM9 at experiment_logs/HalfCheetah-v4/sac/2024-10-08_13-43-48_236302~fXPQM9.json\n",
      "\n",
      "\n",
      "step =  411000, num_env_steps =  411000, scores =  5842.181 (n= 1), score_ema =  0.000, actor_loss = -342.336, critic_loss = 28.622, entropy_coef_loss = 1.529, entropy_coef = 0.130, rollout_stds = N/A, action_magnitude = 0.752 ± 0.277, n_updates = 401000, time =  6.8, total_time = 3257.3 \n",
      "\n",
      "\n",
      "step =  412000, num_env_steps =  412000, scores =  5369.444 (n= 1), score_ema =  0.000, actor_loss = -327.014, critic_loss = 13.328, entropy_coef_loss = 0.035, entropy_coef = 0.126, rollout_stds = N/A, action_magnitude = 0.734 ± 0.284, n_updates = 402000, time =  6.8, total_time = 3264.1 \n",
      "\n",
      "\n",
      "step =  413000, num_env_steps =  413000, scores =  5755.696 (n= 1), score_ema =  0.000, actor_loss = -335.303, critic_loss = 14.287, entropy_coef_loss = 0.077, entropy_coef = 0.129, rollout_stds = N/A, action_magnitude = 0.759 ± 0.271, n_updates = 403000, time =  6.5, total_time = 3270.7 \n",
      "\n",
      "\n",
      "step =  414000, num_env_steps =  414000, scores =  5664.239 (n= 1), score_ema =  0.000, actor_loss = -335.991, critic_loss = 18.578, entropy_coef_loss = -0.371, entropy_coef = 0.126, rollout_stds = N/A, action_magnitude = 0.752 ± 0.276, n_updates = 404000, time =  6.2, total_time = 3276.8 \n",
      "\n",
      "\n",
      "step =  415000, num_env_steps =  415000, scores =  5583.716 (n= 1), score_ema =  0.000, actor_loss = -328.317, critic_loss = 11.011, entropy_coef_loss = -0.587, entropy_coef = 0.128, rollout_stds = N/A, action_magnitude = 0.751 ± 0.276, n_updates = 405000, time =  6.4, total_time = 3283.3 \n",
      "\n",
      "\n",
      "step =  416000, num_env_steps =  416000, scores =  5612.912 (n= 1), score_ema =  0.000, actor_loss = -340.435, critic_loss = 12.900, entropy_coef_loss = 0.857, entropy_coef = 0.128, rollout_stds = N/A, action_magnitude = 0.744 ± 0.279, n_updates = 406000, time =  6.8, total_time = 3290.1 \n",
      "\n",
      "\n",
      "step =  417000, num_env_steps =  417000, scores =  5576.170 (n= 1), score_ema =  0.000, actor_loss = -340.388, critic_loss = 12.891, entropy_coef_loss = 1.400, entropy_coef = 0.128, rollout_stds = N/A, action_magnitude = 0.749 ± 0.280, n_updates = 407000, time =  6.3, total_time = 3296.4 \n",
      "\n",
      "\n",
      "step =  418000, num_env_steps =  418000, scores =  5891.463 (n= 1), score_ema =  0.000, actor_loss = -338.239, critic_loss = 20.479, entropy_coef_loss = 0.241, entropy_coef = 0.129, rollout_stds = N/A, action_magnitude = 0.759 ± 0.275, n_updates = 408000, time =  7.1, total_time = 3303.5 \n",
      "\n",
      "\n",
      "step =  419000, num_env_steps =  419000, scores =  5665.913 (n= 1), score_ema =  0.000, actor_loss = -328.743, critic_loss = 17.176, entropy_coef_loss = -0.090, entropy_coef = 0.128, rollout_stds = N/A, action_magnitude = 0.758 ± 0.275, n_updates = 409000, time =  6.2, total_time = 3309.6 \n",
      "\n",
      "\n",
      "step =  420000, num_env_steps =  420000, scores =  5512.258 (n= 1), score_ema =  0.000, actor_loss = -335.666, critic_loss = 656.358, entropy_coef_loss = -0.222, entropy_coef = 0.129, rollout_stds = N/A, action_magnitude = 0.746 ± 0.277, n_updates = 410000, time =  7.3, total_time = 3316.9 \n",
      "\n",
      "saved experiment log 2024-10-08_13-43-48_236302~fXPQM9 at experiment_logs/HalfCheetah-v4/sac/2024-10-08_13-43-48_236302~fXPQM9.json\n",
      "\n",
      "\n",
      "step =  421000, num_env_steps =  421000, scores =  5574.436 (n= 1), score_ema =  0.000, actor_loss = -346.745, critic_loss = 13.874, entropy_coef_loss = 1.112, entropy_coef = 0.131, rollout_stds = N/A, action_magnitude = 0.749 ± 0.281, n_updates = 411000, time =  6.2, total_time = 3323.1 \n",
      "\n",
      "\n",
      "step =  422000, num_env_steps =  422000, scores =  5737.591 (n= 1), score_ema =  0.000, actor_loss = -338.532, critic_loss = 543.224, entropy_coef_loss = -0.303, entropy_coef = 0.132, rollout_stds = N/A, action_magnitude = 0.762 ± 0.273, n_updates = 412000, time =  6.3, total_time = 3329.4 \n",
      "\n",
      "\n",
      "step =  423000, num_env_steps =  423000, scores =  5885.901 (n= 1), score_ema =  0.000, actor_loss = -334.871, critic_loss = 450.903, entropy_coef_loss = 0.450, entropy_coef = 0.132, rollout_stds = N/A, action_magnitude = 0.760 ± 0.273, n_updates = 413000, time =  6.3, total_time = 3335.7 \n",
      "\n",
      "\n",
      "step =  424000, num_env_steps =  424000, scores =  5901.776 (n= 1), score_ema =  0.000, actor_loss = -326.388, critic_loss = 10.257, entropy_coef_loss = -0.602, entropy_coef = 0.131, rollout_stds = N/A, action_magnitude = 0.767 ± 0.272, n_updates = 414000, time =  6.3, total_time = 3342.0 \n",
      "\n",
      "\n",
      "step =  425000, num_env_steps =  425000, scores =  5858.444 (n= 1), score_ema =  0.000, actor_loss = -343.306, critic_loss = 10.976, entropy_coef_loss = 0.460, entropy_coef = 0.130, rollout_stds = N/A, action_magnitude = 0.754 ± 0.278, n_updates = 415000, time =  6.2, total_time = 3348.2 \n",
      "\n",
      "\n",
      "step =  426000, num_env_steps =  426000, scores =  5767.013 (n= 1), score_ema =  0.000, actor_loss = -343.416, critic_loss = 11.000, entropy_coef_loss = 0.568, entropy_coef = 0.128, rollout_stds = N/A, action_magnitude = 0.749 ± 0.277, n_updates = 416000, time =  6.2, total_time = 3354.5 \n",
      "\n",
      "\n",
      "step =  427000, num_env_steps =  427000, scores =  5766.294 (n= 1), score_ema =  0.000, actor_loss = -325.614, critic_loss = 581.824, entropy_coef_loss = -1.753, entropy_coef = 0.130, rollout_stds = N/A, action_magnitude = 0.754 ± 0.275, n_updates = 417000, time =  6.3, total_time = 3360.8 \n",
      "\n",
      "\n",
      "step =  428000, num_env_steps =  428000, scores =  5942.225 (n= 1), score_ema =  0.000, actor_loss = -334.695, critic_loss = 14.087, entropy_coef_loss = 0.566, entropy_coef = 0.132, rollout_stds = N/A, action_magnitude = 0.762 ± 0.272, n_updates = 418000, time =  6.3, total_time = 3367.1 \n",
      "\n",
      "\n",
      "step =  429000, num_env_steps =  429000, scores =  5744.933 (n= 1), score_ema =  0.000, actor_loss = -348.048, critic_loss = 26.785, entropy_coef_loss = 0.746, entropy_coef = 0.128, rollout_stds = N/A, action_magnitude = 0.759 ± 0.276, n_updates = 419000, time =  6.7, total_time = 3373.8 \n",
      "\n",
      "\n",
      "step =  430000, num_env_steps =  430000, scores =  5585.569 (n= 1), score_ema =  0.000, actor_loss = -333.999, critic_loss = 12.250, entropy_coef_loss = -1.201, entropy_coef = 0.131, rollout_stds = N/A, action_magnitude = 0.757 ± 0.275, n_updates = 420000, time =  6.2, total_time = 3380.1 \n",
      "\n",
      "saved experiment log 2024-10-08_13-43-48_236302~fXPQM9 at experiment_logs/HalfCheetah-v4/sac/2024-10-08_13-43-48_236302~fXPQM9.json\n",
      "\n",
      "\n",
      "step =  431000, num_env_steps =  431000, scores =  5990.265 (n= 1), score_ema =  0.000, actor_loss = -337.601, critic_loss = 16.512, entropy_coef_loss = 0.515, entropy_coef = 0.127, rollout_stds = N/A, action_magnitude = 0.761 ± 0.278, n_updates = 421000, time =  6.1, total_time = 3386.2 \n",
      "\n",
      "\n",
      "step =  432000, num_env_steps =  432000, scores =  5760.433 (n= 1), score_ema =  0.000, actor_loss = -334.416, critic_loss = 13.504, entropy_coef_loss = 0.371, entropy_coef = 0.131, rollout_stds = N/A, action_magnitude = 0.756 ± 0.274, n_updates = 422000, time =  6.2, total_time = 3392.3 \n",
      "\n",
      "\n",
      "step =  433000, num_env_steps =  433000, scores =  5763.225 (n= 1), score_ema =  0.000, actor_loss = -339.735, critic_loss = 13.357, entropy_coef_loss = 0.345, entropy_coef = 0.132, rollout_stds = N/A, action_magnitude = 0.753 ± 0.275, n_updates = 423000, time =  6.8, total_time = 3399.1 \n",
      "\n",
      "\n",
      "step =  434000, num_env_steps =  434000, scores =  5870.229 (n= 1), score_ema =  0.000, actor_loss = -338.149, critic_loss = 19.395, entropy_coef_loss = -0.265, entropy_coef = 0.133, rollout_stds = N/A, action_magnitude = 0.761 ± 0.275, n_updates = 424000, time =  6.6, total_time = 3405.7 \n",
      "\n",
      "\n",
      "step =  435000, num_env_steps =  435000, scores =  5700.729 (n= 1), score_ema =  0.000, actor_loss = -328.092, critic_loss = 79.495, entropy_coef_loss = 0.473, entropy_coef = 0.132, rollout_stds = N/A, action_magnitude = 0.752 ± 0.278, n_updates = 425000, time =  6.6, total_time = 3412.3 \n",
      "\n",
      "\n",
      "step =  436000, num_env_steps =  436000, scores =  5722.590 (n= 1), score_ema =  0.000, actor_loss = -345.192, critic_loss = 560.726, entropy_coef_loss = 0.481, entropy_coef = 0.133, rollout_stds = N/A, action_magnitude = 0.757 ± 0.278, n_updates = 426000, time =  7.1, total_time = 3419.4 \n",
      "\n",
      "\n",
      "step =  437000, num_env_steps =  437000, scores =  5885.338 (n= 1), score_ema =  0.000, actor_loss = -350.158, critic_loss = 1066.341, entropy_coef_loss = 0.532, entropy_coef = 0.130, rollout_stds = N/A, action_magnitude = 0.757 ± 0.279, n_updates = 427000, time =  7.1, total_time = 3426.5 \n",
      "\n",
      "\n",
      "step =  438000, num_env_steps =  438000, scores =  5774.665 (n= 1), score_ema =  0.000, actor_loss = -349.302, critic_loss = 17.072, entropy_coef_loss = -0.300, entropy_coef = 0.135, rollout_stds = N/A, action_magnitude = 0.761 ± 0.275, n_updates = 428000, time =  6.5, total_time = 3433.0 \n",
      "\n",
      "\n",
      "step =  439000, num_env_steps =  439000, scores =  5964.545 (n= 1), score_ema =  0.000, actor_loss = -338.426, critic_loss = 22.512, entropy_coef_loss = -0.955, entropy_coef = 0.131, rollout_stds = N/A, action_magnitude = 0.764 ± 0.275, n_updates = 429000, time =  6.3, total_time = 3439.2 \n",
      "\n",
      "\n",
      "step =  440000, num_env_steps =  440000, scores =  5874.564 (n= 1), score_ema =  0.000, actor_loss = -333.937, critic_loss = 15.138, entropy_coef_loss = -0.041, entropy_coef = 0.134, rollout_stds = N/A, action_magnitude = 0.765 ± 0.271, n_updates = 430000, time =  6.5, total_time = 3445.7 \n",
      "\n",
      "saved experiment log 2024-10-08_13-43-48_236302~fXPQM9 at experiment_logs/HalfCheetah-v4/sac/2024-10-08_13-43-48_236302~fXPQM9.json\n",
      "\n",
      "\n",
      "step =  441000, num_env_steps =  441000, scores =  5919.243 (n= 1), score_ema =  0.000, actor_loss = -345.916, critic_loss = 13.891, entropy_coef_loss = -0.344, entropy_coef = 0.133, rollout_stds = N/A, action_magnitude = 0.753 ± 0.282, n_updates = 431000, time =  6.9, total_time = 3452.6 \n",
      "\n",
      "\n",
      "step =  442000, num_env_steps =  442000, scores =  6053.730 (n= 1), score_ema =  0.000, actor_loss = -336.724, critic_loss = 12.733, entropy_coef_loss = -1.130, entropy_coef = 0.133, rollout_stds = N/A, action_magnitude = 0.769 ± 0.269, n_updates = 432000, time =  6.8, total_time = 3459.4 \n",
      "\n",
      "\n",
      "step =  443000, num_env_steps =  443000, scores =  5942.636 (n= 1), score_ema =  0.000, actor_loss = -351.420, critic_loss = 11.730, entropy_coef_loss = 0.328, entropy_coef = 0.134, rollout_stds = N/A, action_magnitude = 0.759 ± 0.277, n_updates = 433000, time =  6.9, total_time = 3466.4 \n",
      "\n",
      "\n",
      "step =  444000, num_env_steps =  444000, scores =  5987.692 (n= 1), score_ema =  0.000, actor_loss = -336.105, critic_loss = 233.920, entropy_coef_loss = -0.614, entropy_coef = 0.136, rollout_stds = N/A, action_magnitude = 0.765 ± 0.275, n_updates = 434000, time =  7.2, total_time = 3473.5 \n",
      "\n",
      "\n",
      "step =  445000, num_env_steps =  445000, scores =  5755.870 (n= 1), score_ema =  0.000, actor_loss = -346.458, critic_loss = 572.051, entropy_coef_loss = 0.359, entropy_coef = 0.131, rollout_stds = N/A, action_magnitude = 0.756 ± 0.272, n_updates = 435000, time =  6.8, total_time = 3480.3 \n",
      "\n",
      "\n",
      "step =  446000, num_env_steps =  446000, scores =  6088.397 (n= 1), score_ema =  0.000, actor_loss = -339.266, critic_loss = 16.309, entropy_coef_loss = -0.561, entropy_coef = 0.135, rollout_stds = N/A, action_magnitude = 0.764 ± 0.274, n_updates = 436000, time =  6.5, total_time = 3486.8 \n",
      "\n",
      "\n",
      "step =  447000, num_env_steps =  447000, scores =  5958.848 (n= 1), score_ema =  0.000, actor_loss = -334.307, critic_loss = 29.781, entropy_coef_loss = -0.453, entropy_coef = 0.133, rollout_stds = N/A, action_magnitude = 0.758 ± 0.276, n_updates = 437000, time =  6.6, total_time = 3493.4 \n",
      "\n",
      "\n",
      "step =  448000, num_env_steps =  448000, scores =  5845.785 (n= 1), score_ema =  0.000, actor_loss = -338.750, critic_loss = 22.365, entropy_coef_loss = 0.194, entropy_coef = 0.132, rollout_stds = N/A, action_magnitude = 0.760 ± 0.274, n_updates = 438000, time =  6.5, total_time = 3499.9 \n",
      "\n",
      "\n",
      "step =  449000, num_env_steps =  449000, scores =  5677.843 (n= 1), score_ema =  0.000, actor_loss = -346.584, critic_loss = 22.230, entropy_coef_loss = 0.296, entropy_coef = 0.137, rollout_stds = N/A, action_magnitude = 0.759 ± 0.275, n_updates = 439000, time =  7.4, total_time = 3507.3 \n",
      "\n",
      "\n",
      "step =  450000, num_env_steps =  450000, scores =  6001.285 (n= 1), score_ema =  0.000, actor_loss = -348.306, critic_loss = 14.827, entropy_coef_loss = -0.125, entropy_coef = 0.139, rollout_stds = N/A, action_magnitude = 0.763 ± 0.276, n_updates = 440000, time =  7.7, total_time = 3515.0 \n",
      "\n",
      "saved experiment log 2024-10-08_13-43-48_236302~fXPQM9 at experiment_logs/HalfCheetah-v4/sac/2024-10-08_13-43-48_236302~fXPQM9.json\n",
      "\n",
      "\n",
      "step =  451000, num_env_steps =  451000, scores =  5894.122 (n= 1), score_ema =  0.000, actor_loss = -338.692, critic_loss = 8.885, entropy_coef_loss = -0.670, entropy_coef = 0.133, rollout_stds = N/A, action_magnitude = 0.756 ± 0.278, n_updates = 441000, time =  7.5, total_time = 3522.5 \n",
      "\n",
      "\n",
      "step =  452000, num_env_steps =  452000, scores =  6109.147 (n= 1), score_ema =  0.000, actor_loss = -349.076, critic_loss = 13.780, entropy_coef_loss = -0.025, entropy_coef = 0.133, rollout_stds = N/A, action_magnitude = 0.764 ± 0.272, n_updates = 442000, time =  7.1, total_time = 3529.6 \n",
      "\n",
      "\n",
      "step =  453000, num_env_steps =  453000, scores =  6094.711 (n= 1), score_ema =  0.000, actor_loss = -356.017, critic_loss = 14.579, entropy_coef_loss = 0.395, entropy_coef = 0.134, rollout_stds = N/A, action_magnitude = 0.765 ± 0.270, n_updates = 443000, time =  6.8, total_time = 3536.4 \n",
      "\n",
      "\n",
      "step =  454000, num_env_steps =  454000, scores =  5992.605 (n= 1), score_ema =  0.000, actor_loss = -345.274, critic_loss = 14.662, entropy_coef_loss = 0.542, entropy_coef = 0.136, rollout_stds = N/A, action_magnitude = 0.759 ± 0.275, n_updates = 444000, time =  7.5, total_time = 3543.9 \n",
      "\n",
      "\n",
      "step =  455000, num_env_steps =  455000, scores =  5982.932 (n= 1), score_ema =  0.000, actor_loss = -349.521, critic_loss = 16.912, entropy_coef_loss = -0.058, entropy_coef = 0.136, rollout_stds = N/A, action_magnitude = 0.754 ± 0.276, n_updates = 445000, time =  7.0, total_time = 3550.9 \n",
      "\n",
      "\n",
      "step =  456000, num_env_steps =  456000, scores =  5824.896 (n= 1), score_ema =  0.000, actor_loss = -343.669, critic_loss = 15.098, entropy_coef_loss = 0.860, entropy_coef = 0.137, rollout_stds = N/A, action_magnitude = 0.750 ± 0.278, n_updates = 446000, time =  7.6, total_time = 3558.5 \n",
      "\n",
      "\n",
      "step =  457000, num_env_steps =  457000, scores =  5953.744 (n= 1), score_ema =  0.000, actor_loss = -342.491, critic_loss = 19.893, entropy_coef_loss = -1.346, entropy_coef = 0.140, rollout_stds = N/A, action_magnitude = 0.764 ± 0.274, n_updates = 447000, time =  6.9, total_time = 3565.4 \n",
      "\n",
      "\n",
      "step =  458000, num_env_steps =  458000, scores =  6036.514 (n= 1), score_ema =  0.000, actor_loss = -349.210, critic_loss = 605.770, entropy_coef_loss = 0.364, entropy_coef = 0.138, rollout_stds = N/A, action_magnitude = 0.760 ± 0.275, n_updates = 448000, time =  7.1, total_time = 3572.5 \n",
      "\n",
      "\n",
      "step =  459000, num_env_steps =  459000, scores =  6098.505 (n= 1), score_ema =  0.000, actor_loss = -342.827, critic_loss = 643.521, entropy_coef_loss = -0.260, entropy_coef = 0.139, rollout_stds = N/A, action_magnitude = 0.754 ± 0.281, n_updates = 449000, time =  6.9, total_time = 3579.4 \n",
      "\n",
      "\n",
      "step =  460000, num_env_steps =  460000, scores =  6011.331 (n= 1), score_ema =  0.000, actor_loss = -341.651, critic_loss = 15.822, entropy_coef_loss = 0.136, entropy_coef = 0.134, rollout_stds = N/A, action_magnitude = 0.766 ± 0.271, n_updates = 450000, time =  6.8, total_time = 3586.1 \n",
      "\n",
      "saved experiment log 2024-10-08_13-43-48_236302~fXPQM9 at experiment_logs/HalfCheetah-v4/sac/2024-10-08_13-43-48_236302~fXPQM9.json\n",
      "\n",
      "\n",
      "step =  461000, num_env_steps =  461000, scores =  6100.350 (n= 1), score_ema =  0.000, actor_loss = -351.690, critic_loss = 19.088, entropy_coef_loss = -0.024, entropy_coef = 0.137, rollout_stds = N/A, action_magnitude = 0.768 ± 0.272, n_updates = 451000, time =  6.9, total_time = 3593.0 \n",
      "\n",
      "\n",
      "step =  462000, num_env_steps =  462000, scores =  6159.363 (n= 1), score_ema =  0.000, actor_loss = -347.243, critic_loss = 611.441, entropy_coef_loss = 0.810, entropy_coef = 0.139, rollout_stds = N/A, action_magnitude = 0.771 ± 0.268, n_updates = 452000, time =  6.6, total_time = 3599.6 \n",
      "\n",
      "\n",
      "step =  463000, num_env_steps =  463000, scores =  5926.066 (n= 1), score_ema =  0.000, actor_loss = -341.921, critic_loss = 16.199, entropy_coef_loss = -0.670, entropy_coef = 0.135, rollout_stds = N/A, action_magnitude = 0.758 ± 0.271, n_updates = 453000, time =  6.6, total_time = 3606.2 \n",
      "\n",
      "\n",
      "step =  464000, num_env_steps =  464000, scores =  5808.355 (n= 1), score_ema =  0.000, actor_loss = -347.137, critic_loss = 15.337, entropy_coef_loss = 0.563, entropy_coef = 0.135, rollout_stds = N/A, action_magnitude = 0.753 ± 0.275, n_updates = 454000, time =  6.9, total_time = 3613.1 \n",
      "\n",
      "\n",
      "step =  465000, num_env_steps =  465000, scores =  6001.618 (n= 1), score_ema =  0.000, actor_loss = -350.031, critic_loss = 10.279, entropy_coef_loss = -0.374, entropy_coef = 0.139, rollout_stds = N/A, action_magnitude = 0.761 ± 0.274, n_updates = 455000, time =  6.7, total_time = 3619.8 \n",
      "\n",
      "\n",
      "step =  466000, num_env_steps =  466000, scores =  5973.077 (n= 1), score_ema =  0.000, actor_loss = -346.013, critic_loss = 11.826, entropy_coef_loss = 0.577, entropy_coef = 0.136, rollout_stds = N/A, action_magnitude = 0.758 ± 0.274, n_updates = 456000, time =  6.6, total_time = 3626.4 \n",
      "\n",
      "\n",
      "step =  467000, num_env_steps =  467000, scores =  6057.735 (n= 1), score_ema =  0.000, actor_loss = -346.969, critic_loss = 14.715, entropy_coef_loss = -0.144, entropy_coef = 0.138, rollout_stds = N/A, action_magnitude = 0.763 ± 0.273, n_updates = 457000, time =  6.6, total_time = 3633.1 \n",
      "\n",
      "\n",
      "step =  468000, num_env_steps =  468000, scores =  6002.221 (n= 1), score_ema =  0.000, actor_loss = -347.290, critic_loss = 18.803, entropy_coef_loss = -0.117, entropy_coef = 0.138, rollout_stds = N/A, action_magnitude = 0.755 ± 0.277, n_updates = 458000, time =  6.4, total_time = 3639.5 \n",
      "\n",
      "\n",
      "step =  469000, num_env_steps =  469000, scores =  6241.974 (n= 1), score_ema =  0.000, actor_loss = -348.120, critic_loss = 646.523, entropy_coef_loss = 0.254, entropy_coef = 0.142, rollout_stds = N/A, action_magnitude = 0.770 ± 0.271, n_updates = 459000, time =  6.3, total_time = 3645.8 \n",
      "\n",
      "\n",
      "step =  470000, num_env_steps =  470000, scores =  5827.940 (n= 1), score_ema =  0.000, actor_loss = -348.500, critic_loss = 668.285, entropy_coef_loss = -1.331, entropy_coef = 0.137, rollout_stds = N/A, action_magnitude = 0.750 ± 0.278, n_updates = 460000, time =  6.6, total_time = 3652.4 \n",
      "\n",
      "saved experiment log 2024-10-08_13-43-48_236302~fXPQM9 at experiment_logs/HalfCheetah-v4/sac/2024-10-08_13-43-48_236302~fXPQM9.json\n",
      "\n",
      "\n",
      "step =  471000, num_env_steps =  471000, scores =  6025.565 (n= 1), score_ema =  0.000, actor_loss = -348.190, critic_loss = 20.761, entropy_coef_loss = 0.339, entropy_coef = 0.137, rollout_stds = N/A, action_magnitude = 0.760 ± 0.275, n_updates = 461000, time =  6.4, total_time = 3658.8 \n",
      "\n",
      "\n",
      "step =  472000, num_env_steps =  472000, scores =  5904.607 (n= 1), score_ema =  0.000, actor_loss = -354.350, critic_loss = 11.185, entropy_coef_loss = 0.686, entropy_coef = 0.135, rollout_stds = N/A, action_magnitude = 0.754 ± 0.277, n_updates = 462000, time =  7.5, total_time = 3666.3 \n",
      "\n",
      "\n",
      "step =  473000, num_env_steps =  473000, scores =  6037.147 (n= 1), score_ema =  0.000, actor_loss = -341.308, critic_loss = 16.453, entropy_coef_loss = 0.363, entropy_coef = 0.138, rollout_stds = N/A, action_magnitude = 0.767 ± 0.270, n_updates = 463000, time =  7.3, total_time = 3673.6 \n",
      "\n",
      "\n",
      "step =  474000, num_env_steps =  474000, scores =  6167.615 (n= 1), score_ema =  0.000, actor_loss = -359.985, critic_loss = 15.258, entropy_coef_loss = 0.607, entropy_coef = 0.133, rollout_stds = N/A, action_magnitude = 0.764 ± 0.274, n_updates = 464000, time =  6.6, total_time = 3680.2 \n",
      "\n",
      "\n",
      "step =  475000, num_env_steps =  475000, scores =  6109.150 (n= 1), score_ema =  0.000, actor_loss = -355.808, critic_loss = 16.688, entropy_coef_loss = -0.498, entropy_coef = 0.139, rollout_stds = N/A, action_magnitude = 0.766 ± 0.272, n_updates = 465000, time =  6.5, total_time = 3686.6 \n",
      "\n",
      "\n",
      "step =  476000, num_env_steps =  476000, scores =  6036.867 (n= 1), score_ema =  0.000, actor_loss = -339.546, critic_loss = 11.542, entropy_coef_loss = -0.271, entropy_coef = 0.138, rollout_stds = N/A, action_magnitude = 0.758 ± 0.274, n_updates = 466000, time =  6.6, total_time = 3693.2 \n",
      "\n",
      "\n",
      "step =  477000, num_env_steps =  477000, scores =  5883.879 (n= 1), score_ema =  0.000, actor_loss = -352.749, critic_loss = 641.734, entropy_coef_loss = 0.868, entropy_coef = 0.136, rollout_stds = N/A, action_magnitude = 0.749 ± 0.282, n_updates = 467000, time =  6.4, total_time = 3699.7 \n",
      "\n",
      "\n",
      "step =  478000, num_env_steps =  478000, scores =  2608.838 (n= 1), score_ema =  0.000, actor_loss = -349.148, critic_loss = 19.935, entropy_coef_loss = -0.122, entropy_coef = 0.139, rollout_stds = N/A, action_magnitude = 0.612 ± 0.305, n_updates = 468000, time =  6.7, total_time = 3706.4 \n",
      "\n",
      "\n",
      "step =  479000, num_env_steps =  479000, scores =  6197.700 (n= 1), score_ema =  0.000, actor_loss = -354.597, critic_loss = 603.097, entropy_coef_loss = -0.216, entropy_coef = 0.136, rollout_stds = N/A, action_magnitude = 0.763 ± 0.277, n_updates = 469000, time =  6.5, total_time = 3712.9 \n",
      "\n",
      "\n",
      "step =  480000, num_env_steps =  480000, scores =  6086.293 (n= 1), score_ema =  0.000, actor_loss = -352.819, critic_loss = 23.990, entropy_coef_loss = -0.251, entropy_coef = 0.137, rollout_stds = N/A, action_magnitude = 0.760 ± 0.276, n_updates = 470000, time =  6.4, total_time = 3719.3 \n",
      "\n",
      "saved experiment log 2024-10-08_13-43-48_236302~fXPQM9 at experiment_logs/HalfCheetah-v4/sac/2024-10-08_13-43-48_236302~fXPQM9.json\n",
      "\n",
      "\n",
      "step =  481000, num_env_steps =  481000, scores =  6059.479 (n= 1), score_ema =  0.000, actor_loss = -353.318, critic_loss = 89.409, entropy_coef_loss = -0.219, entropy_coef = 0.140, rollout_stds = N/A, action_magnitude = 0.757 ± 0.274, n_updates = 471000, time =  6.7, total_time = 3726.1 \n",
      "\n",
      "\n",
      "step =  482000, num_env_steps =  482000, scores =  6055.236 (n= 1), score_ema =  0.000, actor_loss = -360.847, critic_loss = 18.518, entropy_coef_loss = -0.025, entropy_coef = 0.138, rollout_stds = N/A, action_magnitude = 0.756 ± 0.278, n_updates = 472000, time =  6.8, total_time = 3732.9 \n",
      "\n",
      "\n",
      "step =  483000, num_env_steps =  483000, scores =  6124.759 (n= 1), score_ema =  0.000, actor_loss = -356.968, critic_loss = 13.788, entropy_coef_loss = 0.779, entropy_coef = 0.140, rollout_stds = N/A, action_magnitude = 0.760 ± 0.275, n_updates = 473000, time =  6.5, total_time = 3739.3 \n",
      "\n",
      "\n",
      "step =  484000, num_env_steps =  484000, scores =  6137.850 (n= 1), score_ema =  0.000, actor_loss = -350.086, critic_loss = 16.695, entropy_coef_loss = 0.385, entropy_coef = 0.140, rollout_stds = N/A, action_magnitude = 0.760 ± 0.274, n_updates = 474000, time =  6.5, total_time = 3745.9 \n",
      "\n",
      "\n",
      "step =  485000, num_env_steps =  485000, scores =  5903.738 (n= 1), score_ema =  0.000, actor_loss = -353.887, critic_loss = 16.484, entropy_coef_loss = -0.849, entropy_coef = 0.146, rollout_stds = N/A, action_magnitude = 0.752 ± 0.280, n_updates = 475000, time =  6.3, total_time = 3752.2 \n",
      "\n",
      "\n",
      "step =  486000, num_env_steps =  486000, scores =  5847.143 (n= 1), score_ema =  0.000, actor_loss = -351.782, critic_loss = 25.832, entropy_coef_loss = -0.181, entropy_coef = 0.139, rollout_stds = N/A, action_magnitude = 0.751 ± 0.280, n_updates = 476000, time =  6.7, total_time = 3758.9 \n",
      "\n",
      "\n",
      "step =  487000, num_env_steps =  487000, scores =  6028.726 (n= 1), score_ema =  0.000, actor_loss = -354.618, critic_loss = 14.487, entropy_coef_loss = -0.685, entropy_coef = 0.140, rollout_stds = N/A, action_magnitude = 0.753 ± 0.276, n_updates = 477000, time =  6.6, total_time = 3765.5 \n",
      "\n",
      "\n",
      "step =  488000, num_env_steps =  488000, scores =  5979.739 (n= 1), score_ema =  0.000, actor_loss = -353.368, critic_loss = 654.868, entropy_coef_loss = -0.485, entropy_coef = 0.141, rollout_stds = N/A, action_magnitude = 0.754 ± 0.277, n_updates = 478000, time =  7.0, total_time = 3772.5 \n",
      "\n",
      "\n",
      "step =  489000, num_env_steps =  489000, scores =  6107.503 (n= 1), score_ema =  0.000, actor_loss = -353.385, critic_loss = 12.633, entropy_coef_loss = 0.181, entropy_coef = 0.141, rollout_stds = N/A, action_magnitude = 0.764 ± 0.272, n_updates = 479000, time =  6.6, total_time = 3779.2 \n",
      "\n",
      "\n",
      "step =  490000, num_env_steps =  490000, scores =  6144.032 (n= 1), score_ema =  0.000, actor_loss = -354.416, critic_loss = 23.306, entropy_coef_loss = -0.182, entropy_coef = 0.136, rollout_stds = N/A, action_magnitude = 0.766 ± 0.273, n_updates = 480000, time =  6.4, total_time = 3785.6 \n",
      "\n",
      "saved experiment log 2024-10-08_13-43-48_236302~fXPQM9 at experiment_logs/HalfCheetah-v4/sac/2024-10-08_13-43-48_236302~fXPQM9.json\n",
      "\n",
      "\n",
      "step =  491000, num_env_steps =  491000, scores =  5912.593 (n= 1), score_ema =  0.000, actor_loss = -349.646, critic_loss = 615.410, entropy_coef_loss = -0.592, entropy_coef = 0.140, rollout_stds = N/A, action_magnitude = 0.749 ± 0.280, n_updates = 481000, time =  7.3, total_time = 3793.0 \n",
      "\n",
      "\n",
      "step =  492000, num_env_steps =  492000, scores =  1541.227 (n= 1), score_ema =  0.000, actor_loss = -364.700, critic_loss = 16.437, entropy_coef_loss = 1.217, entropy_coef = 0.140, rollout_stds = N/A, action_magnitude = 0.579 ± 0.303, n_updates = 482000, time = 10.1, total_time = 3803.1 \n",
      "\n",
      "\n",
      "step =  493000, num_env_steps =  493000, scores =  5822.172 (n= 1), score_ema =  0.000, actor_loss = -357.094, critic_loss = 16.376, entropy_coef_loss = 0.017, entropy_coef = 0.141, rollout_stds = N/A, action_magnitude = 0.752 ± 0.280, n_updates = 483000, time = 10.0, total_time = 3813.1 \n",
      "\n",
      "\n",
      "step =  494000, num_env_steps =  494000, scores =  6036.381 (n= 1), score_ema =  0.000, actor_loss = -357.646, critic_loss = 18.115, entropy_coef_loss = 0.139, entropy_coef = 0.137, rollout_stds = N/A, action_magnitude = 0.752 ± 0.278, n_updates = 484000, time =  9.6, total_time = 3822.6 \n",
      "\n",
      "\n",
      "step =  495000, num_env_steps =  495000, scores =  6095.441 (n= 1), score_ema =  0.000, actor_loss = -352.932, critic_loss = 29.306, entropy_coef_loss = 0.450, entropy_coef = 0.141, rollout_stds = N/A, action_magnitude = 0.756 ± 0.277, n_updates = 485000, time =  9.8, total_time = 3832.4 \n",
      "\n",
      "\n",
      "step =  496000, num_env_steps =  496000, scores =  6199.498 (n= 1), score_ema =  0.000, actor_loss = -356.586, critic_loss = 25.792, entropy_coef_loss = 0.070, entropy_coef = 0.141, rollout_stds = N/A, action_magnitude = 0.756 ± 0.278, n_updates = 486000, time =  9.7, total_time = 3842.1 \n",
      "\n",
      "\n",
      "step =  497000, num_env_steps =  497000, scores =  6143.900 (n= 1), score_ema =  0.000, actor_loss = -356.590, critic_loss = 24.285, entropy_coef_loss = -0.254, entropy_coef = 0.141, rollout_stds = N/A, action_magnitude = 0.759 ± 0.277, n_updates = 487000, time =  9.7, total_time = 3851.8 \n",
      "\n",
      "\n",
      "step =  498000, num_env_steps =  498000, scores =  6232.671 (n= 1), score_ema =  0.000, actor_loss = -345.724, critic_loss = 11.930, entropy_coef_loss = -0.719, entropy_coef = 0.142, rollout_stds = N/A, action_magnitude = 0.754 ± 0.277, n_updates = 488000, time =  9.6, total_time = 3861.4 \n",
      "\n",
      "\n",
      "step =  499000, num_env_steps =  499000, scores =  6204.060 (n= 1), score_ema =  0.000, actor_loss = -351.635, critic_loss = 14.910, entropy_coef_loss = 0.040, entropy_coef = 0.138, rollout_stds = N/A, action_magnitude = 0.756 ± 0.279, n_updates = 489000, time = 10.4, total_time = 3871.8 \n",
      "\n",
      "\n",
      "step =  500000, num_env_steps =  500000, scores =  6112.934 (n= 1), score_ema =  0.000, actor_loss = -356.009, critic_loss = 18.441, entropy_coef_loss = -0.500, entropy_coef = 0.144, rollout_stds = N/A, action_magnitude = 0.751 ± 0.277, n_updates = 490000, time = 10.4, total_time = 3882.2 \n",
      "\n",
      "saved experiment log 2024-10-08_13-43-48_236302~fXPQM9 at experiment_logs/HalfCheetah-v4/sac/2024-10-08_13-43-48_236302~fXPQM9.json\n",
      "\n",
      "\n",
      "step =  501000, num_env_steps =  501000, scores =  6022.229 (n= 1), score_ema =  0.000, actor_loss = -364.029, critic_loss = 16.157, entropy_coef_loss = 0.420, entropy_coef = 0.138, rollout_stds = N/A, action_magnitude = 0.746 ± 0.282, n_updates = 491000, time =  9.7, total_time = 3891.9 \n",
      "\n",
      "\n",
      "step =  502000, num_env_steps =  502000, scores =  6225.865 (n= 1), score_ema =  0.000, actor_loss = -352.981, critic_loss = 13.860, entropy_coef_loss = 0.072, entropy_coef = 0.139, rollout_stds = N/A, action_magnitude = 0.750 ± 0.280, n_updates = 492000, time =  9.4, total_time = 3901.3 \n",
      "\n",
      "\n",
      "step =  503000, num_env_steps =  503000, scores =  6045.322 (n= 1), score_ema =  0.000, actor_loss = -359.287, critic_loss = 20.101, entropy_coef_loss = 0.537, entropy_coef = 0.137, rollout_stds = N/A, action_magnitude = 0.746 ± 0.280, n_updates = 493000, time =  6.7, total_time = 3908.0 \n",
      "\n",
      "\n",
      "step =  504000, num_env_steps =  504000, scores =  6262.238 (n= 1), score_ema =  0.000, actor_loss = -354.741, critic_loss = 14.189, entropy_coef_loss = -0.354, entropy_coef = 0.139, rollout_stds = N/A, action_magnitude = 0.751 ± 0.281, n_updates = 494000, time =  6.6, total_time = 3914.5 \n",
      "\n",
      "\n",
      "step =  505000, num_env_steps =  505000, scores =  6332.496 (n= 1), score_ema =  0.000, actor_loss = -348.452, critic_loss = 22.720, entropy_coef_loss = -0.299, entropy_coef = 0.144, rollout_stds = N/A, action_magnitude = 0.763 ± 0.272, n_updates = 495000, time =  6.6, total_time = 3921.1 \n",
      "\n",
      "\n",
      "step =  506000, num_env_steps =  506000, scores =  6201.938 (n= 1), score_ema =  0.000, actor_loss = -365.079, critic_loss = 14.570, entropy_coef_loss = -0.008, entropy_coef = 0.142, rollout_stds = N/A, action_magnitude = 0.755 ± 0.276, n_updates = 496000, time =  6.6, total_time = 3927.7 \n",
      "\n",
      "\n",
      "step =  507000, num_env_steps =  507000, scores =  6145.305 (n= 1), score_ema =  0.000, actor_loss = -355.989, critic_loss = 17.439, entropy_coef_loss = -0.574, entropy_coef = 0.141, rollout_stds = N/A, action_magnitude = 0.759 ± 0.277, n_updates = 497000, time =  6.7, total_time = 3934.4 \n",
      "\n",
      "\n",
      "step =  508000, num_env_steps =  508000, scores =  6234.234 (n= 1), score_ema =  0.000, actor_loss = -355.410, critic_loss = 17.362, entropy_coef_loss = -0.136, entropy_coef = 0.143, rollout_stds = N/A, action_magnitude = 0.754 ± 0.280, n_updates = 498000, time =  6.6, total_time = 3941.0 \n",
      "\n",
      "\n",
      "step =  509000, num_env_steps =  509000, scores =  6168.313 (n= 1), score_ema =  0.000, actor_loss = -357.113, critic_loss = 11.098, entropy_coef_loss = -0.466, entropy_coef = 0.139, rollout_stds = N/A, action_magnitude = 0.754 ± 0.277, n_updates = 499000, time =  7.0, total_time = 3948.0 \n",
      "\n",
      "\n",
      "step =  510000, num_env_steps =  510000, scores =  6103.293 (n= 1), score_ema =  0.000, actor_loss = -370.394, critic_loss = 13.474, entropy_coef_loss = 0.057, entropy_coef = 0.141, rollout_stds = N/A, action_magnitude = 0.757 ± 0.274, n_updates = 500000, time =  6.7, total_time = 3954.6 \n",
      "\n",
      "saved experiment log 2024-10-08_13-43-48_236302~fXPQM9 at experiment_logs/HalfCheetah-v4/sac/2024-10-08_13-43-48_236302~fXPQM9.json\n",
      "\n",
      "\n",
      "step =  511000, num_env_steps =  511000, scores =  6191.330 (n= 1), score_ema =  0.000, actor_loss = -367.496, critic_loss = 652.707, entropy_coef_loss = 0.490, entropy_coef = 0.140, rollout_stds = N/A, action_magnitude = 0.761 ± 0.274, n_updates = 501000, time =  6.6, total_time = 3961.3 \n",
      "\n",
      "\n",
      "step =  512000, num_env_steps =  512000, scores =  6086.259 (n= 1), score_ema =  0.000, actor_loss = -374.522, critic_loss = 14.047, entropy_coef_loss = 0.783, entropy_coef = 0.143, rollout_stds = N/A, action_magnitude = 0.746 ± 0.284, n_updates = 502000, time =  6.8, total_time = 3968.0 \n",
      "\n",
      "\n",
      "step =  513000, num_env_steps =  513000, scores =  6297.194 (n= 1), score_ema =  0.000, actor_loss = -359.616, critic_loss = 15.608, entropy_coef_loss = -0.296, entropy_coef = 0.146, rollout_stds = N/A, action_magnitude = 0.765 ± 0.271, n_updates = 503000, time =  6.6, total_time = 3974.7 \n",
      "\n",
      "\n",
      "step =  514000, num_env_steps =  514000, scores =  6247.081 (n= 1), score_ema =  0.000, actor_loss = -360.988, critic_loss = 16.031, entropy_coef_loss = 0.401, entropy_coef = 0.138, rollout_stds = N/A, action_magnitude = 0.752 ± 0.281, n_updates = 504000, time =  6.9, total_time = 3981.6 \n",
      "\n",
      "\n",
      "step =  515000, num_env_steps =  515000, scores =  5868.516 (n= 1), score_ema =  0.000, actor_loss = -360.976, critic_loss = 11.449, entropy_coef_loss = 0.206, entropy_coef = 0.144, rollout_stds = N/A, action_magnitude = 0.745 ± 0.280, n_updates = 505000, time =  7.0, total_time = 3988.6 \n",
      "\n",
      "\n",
      "step =  516000, num_env_steps =  516000, scores =  6168.371 (n= 1), score_ema =  0.000, actor_loss = -365.265, critic_loss = 12.014, entropy_coef_loss = -0.239, entropy_coef = 0.141, rollout_stds = N/A, action_magnitude = 0.754 ± 0.276, n_updates = 506000, time =  6.8, total_time = 3995.4 \n",
      "\n",
      "\n",
      "step =  517000, num_env_steps =  517000, scores =  6093.915 (n= 1), score_ema =  0.000, actor_loss = -362.455, critic_loss = 18.893, entropy_coef_loss = 0.487, entropy_coef = 0.146, rollout_stds = N/A, action_magnitude = 0.750 ± 0.280, n_updates = 507000, time =  6.7, total_time = 4002.1 \n",
      "\n",
      "\n",
      "step =  518000, num_env_steps =  518000, scores =  6173.691 (n= 1), score_ema =  0.000, actor_loss = -356.818, critic_loss = 20.475, entropy_coef_loss = 1.056, entropy_coef = 0.141, rollout_stds = N/A, action_magnitude = 0.756 ± 0.278, n_updates = 508000, time =  6.5, total_time = 4008.6 \n",
      "\n",
      "\n",
      "step =  519000, num_env_steps =  519000, scores =  6441.731 (n= 1), score_ema =  0.000, actor_loss = -365.657, critic_loss = 593.577, entropy_coef_loss = -1.198, entropy_coef = 0.140, rollout_stds = N/A, action_magnitude = 0.760 ± 0.275, n_updates = 509000, time =  6.8, total_time = 4015.4 \n",
      "\n",
      "\n",
      "step =  520000, num_env_steps =  520000, scores =  6301.386 (n= 1), score_ema =  0.000, actor_loss = -361.069, critic_loss = 21.212, entropy_coef_loss = 0.165, entropy_coef = 0.141, rollout_stds = N/A, action_magnitude = 0.758 ± 0.276, n_updates = 510000, time =  6.9, total_time = 4022.2 \n",
      "\n",
      "saved experiment log 2024-10-08_13-43-48_236302~fXPQM9 at experiment_logs/HalfCheetah-v4/sac/2024-10-08_13-43-48_236302~fXPQM9.json\n",
      "\n",
      "\n",
      "step =  521000, num_env_steps =  521000, scores =  6205.673 (n= 1), score_ema =  0.000, actor_loss = -364.586, critic_loss = 12.134, entropy_coef_loss = -0.140, entropy_coef = 0.141, rollout_stds = N/A, action_magnitude = 0.756 ± 0.277, n_updates = 511000, time =  6.7, total_time = 4028.9 \n",
      "\n",
      "\n",
      "step =  522000, num_env_steps =  522000, scores =  6118.146 (n= 1), score_ema =  0.000, actor_loss = -363.309, critic_loss = 18.962, entropy_coef_loss = -0.068, entropy_coef = 0.147, rollout_stds = N/A, action_magnitude = 0.757 ± 0.273, n_updates = 512000, time =  6.5, total_time = 4035.5 \n",
      "\n",
      "\n",
      "step =  523000, num_env_steps =  523000, scores =  6141.283 (n= 1), score_ema =  0.000, actor_loss = -348.730, critic_loss = 13.896, entropy_coef_loss = -0.779, entropy_coef = 0.145, rollout_stds = N/A, action_magnitude = 0.751 ± 0.279, n_updates = 513000, time =  7.1, total_time = 4042.5 \n",
      "\n",
      "\n",
      "step =  524000, num_env_steps =  524000, scores =  6435.624 (n= 1), score_ema =  0.000, actor_loss = -374.372, critic_loss = 17.936, entropy_coef_loss = 0.239, entropy_coef = 0.141, rollout_stds = N/A, action_magnitude = 0.746 ± 0.285, n_updates = 514000, time =  7.4, total_time = 4050.0 \n",
      "\n",
      "\n",
      "step =  525000, num_env_steps =  525000, scores =  6378.091 (n= 1), score_ema =  0.000, actor_loss = -367.386, critic_loss = 13.110, entropy_coef_loss = 0.633, entropy_coef = 0.143, rollout_stds = N/A, action_magnitude = 0.758 ± 0.276, n_updates = 515000, time =  6.6, total_time = 4056.6 \n",
      "\n",
      "\n",
      "step =  526000, num_env_steps =  526000, scores =  6159.008 (n= 1), score_ema =  0.000, actor_loss = -373.894, critic_loss = 50.080, entropy_coef_loss = 1.031, entropy_coef = 0.145, rollout_stds = N/A, action_magnitude = 0.752 ± 0.275, n_updates = 516000, time =  6.5, total_time = 4063.1 \n",
      "\n",
      "\n",
      "step =  527000, num_env_steps =  527000, scores =  6335.998 (n= 1), score_ema =  0.000, actor_loss = -358.976, critic_loss = 16.403, entropy_coef_loss = -0.267, entropy_coef = 0.139, rollout_stds = N/A, action_magnitude = 0.747 ± 0.281, n_updates = 517000, time =  6.7, total_time = 4069.8 \n",
      "\n",
      "\n",
      "step =  528000, num_env_steps =  528000, scores =  6247.203 (n= 1), score_ema =  0.000, actor_loss = -350.453, critic_loss = 18.046, entropy_coef_loss = -0.842, entropy_coef = 0.141, rollout_stds = N/A, action_magnitude = 0.754 ± 0.279, n_updates = 518000, time =  6.7, total_time = 4076.5 \n",
      "\n",
      "\n",
      "step =  529000, num_env_steps =  529000, scores =  4694.548 (n= 1), score_ema =  0.000, actor_loss = -363.824, critic_loss = 14.432, entropy_coef_loss = -0.285, entropy_coef = 0.144, rollout_stds = N/A, action_magnitude = 0.805 ± 0.263, n_updates = 519000, time =  6.6, total_time = 4083.1 \n",
      "\n",
      "\n",
      "step =  530000, num_env_steps =  530000, scores =  6271.323 (n= 1), score_ema =  0.000, actor_loss = -370.123, critic_loss = 12.608, entropy_coef_loss = 1.210, entropy_coef = 0.141, rollout_stds = N/A, action_magnitude = 0.748 ± 0.281, n_updates = 520000, time =  6.8, total_time = 4089.9 \n",
      "\n",
      "saved experiment log 2024-10-08_13-43-48_236302~fXPQM9 at experiment_logs/HalfCheetah-v4/sac/2024-10-08_13-43-48_236302~fXPQM9.json\n",
      "\n",
      "\n",
      "step =  531000, num_env_steps =  531000, scores =  5968.002 (n= 1), score_ema =  0.000, actor_loss = -360.130, critic_loss = 685.424, entropy_coef_loss = -0.355, entropy_coef = 0.145, rollout_stds = N/A, action_magnitude = 0.747 ± 0.280, n_updates = 521000, time =  6.8, total_time = 4096.7 \n",
      "\n",
      "\n",
      "step =  532000, num_env_steps =  532000, scores =  6266.775 (n= 1), score_ema =  0.000, actor_loss = -357.599, critic_loss = 12.727, entropy_coef_loss = -1.446, entropy_coef = 0.147, rollout_stds = N/A, action_magnitude = 0.756 ± 0.277, n_updates = 522000, time =  6.8, total_time = 4103.5 \n",
      "\n",
      "\n",
      "step =  533000, num_env_steps =  533000, scores =  6243.514 (n= 1), score_ema =  0.000, actor_loss = -362.801, critic_loss = 1245.845, entropy_coef_loss = -0.758, entropy_coef = 0.148, rollout_stds = N/A, action_magnitude = 0.751 ± 0.284, n_updates = 523000, time =  6.6, total_time = 4110.1 \n",
      "\n",
      "\n",
      "step =  534000, num_env_steps =  534000, scores =  6228.950 (n= 1), score_ema =  0.000, actor_loss = -369.830, critic_loss = 20.658, entropy_coef_loss = 1.071, entropy_coef = 0.143, rollout_stds = N/A, action_magnitude = 0.748 ± 0.282, n_updates = 524000, time =  6.8, total_time = 4116.9 \n",
      "\n",
      "\n",
      "step =  535000, num_env_steps =  535000, scores =  6127.261 (n= 1), score_ema =  0.000, actor_loss = -371.508, critic_loss = 13.328, entropy_coef_loss = -0.612, entropy_coef = 0.144, rollout_stds = N/A, action_magnitude = 0.751 ± 0.276, n_updates = 525000, time =  6.6, total_time = 4123.5 \n",
      "\n",
      "\n",
      "step =  536000, num_env_steps =  536000, scores =  6305.257 (n= 1), score_ema =  0.000, actor_loss = -367.526, critic_loss = 13.322, entropy_coef_loss = 0.738, entropy_coef = 0.148, rollout_stds = N/A, action_magnitude = 0.752 ± 0.281, n_updates = 526000, time =  6.5, total_time = 4130.0 \n",
      "\n",
      "\n",
      "step =  537000, num_env_steps =  537000, scores =  6246.469 (n= 1), score_ema =  0.000, actor_loss = -363.068, critic_loss = 19.530, entropy_coef_loss = -0.799, entropy_coef = 0.143, rollout_stds = N/A, action_magnitude = 0.746 ± 0.281, n_updates = 527000, time =  6.9, total_time = 4136.9 \n",
      "\n",
      "\n",
      "step =  538000, num_env_steps =  538000, scores =  6453.360 (n= 1), score_ema =  0.000, actor_loss = -371.662, critic_loss = 18.739, entropy_coef_loss = -0.586, entropy_coef = 0.151, rollout_stds = N/A, action_magnitude = 0.755 ± 0.282, n_updates = 528000, time =  7.4, total_time = 4144.3 \n",
      "\n",
      "\n",
      "step =  539000, num_env_steps =  539000, scores =  6341.102 (n= 1), score_ema =  0.000, actor_loss = -368.087, critic_loss = 697.080, entropy_coef_loss = 0.510, entropy_coef = 0.145, rollout_stds = N/A, action_magnitude = 0.749 ± 0.279, n_updates = 529000, time =  6.6, total_time = 4150.9 \n",
      "\n",
      "\n",
      "step =  540000, num_env_steps =  540000, scores =  6379.154 (n= 1), score_ema =  0.000, actor_loss = -372.559, critic_loss = 31.399, entropy_coef_loss = 0.980, entropy_coef = 0.143, rollout_stds = N/A, action_magnitude = 0.751 ± 0.277, n_updates = 530000, time =  6.8, total_time = 4157.7 \n",
      "\n",
      "saved experiment log 2024-10-08_13-43-48_236302~fXPQM9 at experiment_logs/HalfCheetah-v4/sac/2024-10-08_13-43-48_236302~fXPQM9.json\n",
      "\n",
      "\n",
      "step =  541000, num_env_steps =  541000, scores =  6196.256 (n= 1), score_ema =  0.000, actor_loss = -360.003, critic_loss = 13.430, entropy_coef_loss = 0.033, entropy_coef = 0.147, rollout_stds = N/A, action_magnitude = 0.745 ± 0.283, n_updates = 531000, time =  7.1, total_time = 4164.8 \n",
      "\n",
      "\n",
      "step =  542000, num_env_steps =  542000, scores =  6599.040 (n= 1), score_ema =  0.000, actor_loss = -362.266, critic_loss = 713.056, entropy_coef_loss = -0.625, entropy_coef = 0.147, rollout_stds = N/A, action_magnitude = 0.759 ± 0.279, n_updates = 532000, time =  6.8, total_time = 4171.6 \n",
      "\n",
      "\n",
      "step =  543000, num_env_steps =  543000, scores =  6050.731 (n= 1), score_ema =  0.000, actor_loss = -362.916, critic_loss = 239.255, entropy_coef_loss = 0.630, entropy_coef = 0.144, rollout_stds = N/A, action_magnitude = 0.748 ± 0.280, n_updates = 533000, time =  6.4, total_time = 4178.0 \n",
      "\n",
      "\n",
      "step =  544000, num_env_steps =  544000, scores =  6037.553 (n= 1), score_ema =  0.000, actor_loss = -370.373, critic_loss = 478.231, entropy_coef_loss = -1.401, entropy_coef = 0.148, rollout_stds = N/A, action_magnitude = 0.747 ± 0.279, n_updates = 534000, time =  6.7, total_time = 4184.7 \n",
      "\n",
      "\n",
      "step =  545000, num_env_steps =  545000, scores =  6182.608 (n= 1), score_ema =  0.000, actor_loss = -372.348, critic_loss = 1555.358, entropy_coef_loss = 0.287, entropy_coef = 0.143, rollout_stds = N/A, action_magnitude = 0.748 ± 0.282, n_updates = 535000, time =  6.7, total_time = 4191.4 \n",
      "\n",
      "\n",
      "step =  546000, num_env_steps =  546000, scores =  6409.150 (n= 1), score_ema =  0.000, actor_loss = -384.988, critic_loss = 14.577, entropy_coef_loss = 0.744, entropy_coef = 0.148, rollout_stds = N/A, action_magnitude = 0.751 ± 0.279, n_updates = 536000, time =  7.1, total_time = 4198.5 \n",
      "\n",
      "\n",
      "step =  547000, num_env_steps =  547000, scores =  6071.771 (n= 1), score_ema =  0.000, actor_loss = -363.885, critic_loss = 18.055, entropy_coef_loss = 0.207, entropy_coef = 0.146, rollout_stds = N/A, action_magnitude = 0.742 ± 0.285, n_updates = 537000, time =  6.5, total_time = 4204.9 \n",
      "\n",
      "\n",
      "step =  548000, num_env_steps =  548000, scores =  5955.403 (n= 1), score_ema =  0.000, actor_loss = -369.271, critic_loss = 698.135, entropy_coef_loss = -0.238, entropy_coef = 0.149, rollout_stds = N/A, action_magnitude = 0.743 ± 0.282, n_updates = 538000, time =  6.1, total_time = 4211.1 \n",
      "\n",
      "\n",
      "step =  549000, num_env_steps =  549000, scores =  6364.417 (n= 1), score_ema =  0.000, actor_loss = -379.297, critic_loss = 16.313, entropy_coef_loss = 0.253, entropy_coef = 0.145, rollout_stds = N/A, action_magnitude = 0.750 ± 0.284, n_updates = 539000, time =  9.7, total_time = 4220.8 \n",
      "\n",
      "\n",
      "step =  550000, num_env_steps =  550000, scores =  6393.614 (n= 1), score_ema =  0.000, actor_loss = -377.165, critic_loss = 16.767, entropy_coef_loss = -0.174, entropy_coef = 0.144, rollout_stds = N/A, action_magnitude = 0.751 ± 0.282, n_updates = 540000, time =  9.6, total_time = 4230.3 \n",
      "\n",
      "saved experiment log 2024-10-08_13-43-48_236302~fXPQM9 at experiment_logs/HalfCheetah-v4/sac/2024-10-08_13-43-48_236302~fXPQM9.json\n",
      "\n",
      "\n",
      "step =  551000, num_env_steps =  551000, scores =  6335.427 (n= 1), score_ema =  0.000, actor_loss = -374.572, critic_loss = 16.847, entropy_coef_loss = 1.069, entropy_coef = 0.146, rollout_stds = N/A, action_magnitude = 0.743 ± 0.284, n_updates = 541000, time =  9.6, total_time = 4239.9 \n",
      "\n",
      "\n",
      "step =  552000, num_env_steps =  552000, scores =  6393.045 (n= 1), score_ema =  0.000, actor_loss = -374.348, critic_loss = 12.658, entropy_coef_loss = -0.162, entropy_coef = 0.143, rollout_stds = N/A, action_magnitude = 0.754 ± 0.280, n_updates = 542000, time = 10.2, total_time = 4250.1 \n",
      "\n",
      "\n",
      "step =  553000, num_env_steps =  553000, scores =  6266.166 (n= 1), score_ema =  0.000, actor_loss = -378.329, critic_loss = 23.554, entropy_coef_loss = -0.184, entropy_coef = 0.145, rollout_stds = N/A, action_magnitude = 0.750 ± 0.278, n_updates = 543000, time =  9.4, total_time = 4259.5 \n",
      "\n",
      "\n",
      "step =  554000, num_env_steps =  554000, scores =  6402.699 (n= 1), score_ema =  0.000, actor_loss = -373.474, critic_loss = 22.250, entropy_coef_loss = 0.317, entropy_coef = 0.146, rollout_stds = N/A, action_magnitude = 0.755 ± 0.278, n_updates = 544000, time =  9.8, total_time = 4269.3 \n",
      "\n",
      "\n",
      "step =  555000, num_env_steps =  555000, scores =  6398.632 (n= 1), score_ema =  0.000, actor_loss = -368.839, critic_loss = 15.159, entropy_coef_loss = 0.220, entropy_coef = 0.144, rollout_stds = N/A, action_magnitude = 0.744 ± 0.282, n_updates = 545000, time = 10.3, total_time = 4279.6 \n",
      "\n",
      "\n",
      "step =  556000, num_env_steps =  556000, scores =  6487.032 (n= 1), score_ema =  0.000, actor_loss = -378.608, critic_loss = 716.473, entropy_coef_loss = -0.101, entropy_coef = 0.144, rollout_stds = N/A, action_magnitude = 0.756 ± 0.280, n_updates = 546000, time = 10.3, total_time = 4289.9 \n",
      "\n",
      "\n",
      "step =  557000, num_env_steps =  557000, scores =  6437.098 (n= 1), score_ema =  0.000, actor_loss = -380.109, critic_loss = 11.435, entropy_coef_loss = 0.593, entropy_coef = 0.143, rollout_stds = N/A, action_magnitude = 0.739 ± 0.285, n_updates = 547000, time = 10.7, total_time = 4300.7 \n",
      "\n",
      "\n",
      "step =  558000, num_env_steps =  558000, scores =  6130.939 (n= 1), score_ema =  0.000, actor_loss = -379.291, critic_loss = 14.223, entropy_coef_loss = 0.098, entropy_coef = 0.145, rollout_stds = N/A, action_magnitude = 0.738 ± 0.282, n_updates = 548000, time = 10.1, total_time = 4310.8 \n",
      "\n",
      "\n",
      "step =  559000, num_env_steps =  559000, scores =  6338.206 (n= 1), score_ema =  0.000, actor_loss = -373.062, critic_loss = 14.469, entropy_coef_loss = -0.305, entropy_coef = 0.147, rollout_stds = N/A, action_magnitude = 0.750 ± 0.276, n_updates = 549000, time = 10.0, total_time = 4320.8 \n",
      "\n",
      "\n",
      "step =  560000, num_env_steps =  560000, scores =  6396.117 (n= 1), score_ema =  0.000, actor_loss = -371.885, critic_loss = 19.378, entropy_coef_loss = 0.722, entropy_coef = 0.149, rollout_stds = N/A, action_magnitude = 0.744 ± 0.282, n_updates = 550000, time = 10.1, total_time = 4330.9 \n",
      "\n",
      "saved experiment log 2024-10-08_13-43-48_236302~fXPQM9 at experiment_logs/HalfCheetah-v4/sac/2024-10-08_13-43-48_236302~fXPQM9.json\n",
      "\n",
      "\n",
      "step =  561000, num_env_steps =  561000, scores =  6279.893 (n= 1), score_ema =  0.000, actor_loss = -375.420, critic_loss = 13.957, entropy_coef_loss = 1.099, entropy_coef = 0.147, rollout_stds = N/A, action_magnitude = 0.744 ± 0.285, n_updates = 551000, time = 10.5, total_time = 4341.3 \n",
      "\n",
      "\n",
      "step =  562000, num_env_steps =  562000, scores =  6271.924 (n= 1), score_ema =  0.000, actor_loss = -371.490, critic_loss = 735.204, entropy_coef_loss = -1.176, entropy_coef = 0.149, rollout_stds = N/A, action_magnitude = 0.746 ± 0.281, n_updates = 552000, time = 10.1, total_time = 4351.4 \n",
      "\n",
      "\n",
      "step =  563000, num_env_steps =  563000, scores =  6242.592 (n= 1), score_ema =  0.000, actor_loss = -379.218, critic_loss = 16.923, entropy_coef_loss = 0.125, entropy_coef = 0.148, rollout_stds = N/A, action_magnitude = 0.745 ± 0.281, n_updates = 553000, time = 10.0, total_time = 4361.4 \n",
      "\n",
      "\n",
      "step =  564000, num_env_steps =  564000, scores =  5432.424 (n= 1), score_ema =  0.000, actor_loss = -374.631, critic_loss = 16.987, entropy_coef_loss = -0.153, entropy_coef = 0.146, rollout_stds = N/A, action_magnitude = 0.721 ± 0.288, n_updates = 554000, time = 10.0, total_time = 4371.4 \n",
      "\n",
      "\n",
      "step =  565000, num_env_steps =  565000, scores =  6202.807 (n= 1), score_ema =  0.000, actor_loss = -380.897, critic_loss = 20.880, entropy_coef_loss = 0.708, entropy_coef = 0.147, rollout_stds = N/A, action_magnitude = 0.741 ± 0.280, n_updates = 555000, time = 10.2, total_time = 4381.7 \n",
      "\n",
      "\n",
      "step =  566000, num_env_steps =  566000, scores =  6349.459 (n= 1), score_ema =  0.000, actor_loss = -376.204, critic_loss = 15.558, entropy_coef_loss = 0.577, entropy_coef = 0.148, rollout_stds = N/A, action_magnitude = 0.746 ± 0.281, n_updates = 556000, time = 10.1, total_time = 4391.8 \n",
      "\n",
      "\n",
      "step =  567000, num_env_steps =  567000, scores =  6274.603 (n= 1), score_ema =  0.000, actor_loss = -373.265, critic_loss = 28.492, entropy_coef_loss = -0.205, entropy_coef = 0.147, rollout_stds = N/A, action_magnitude = 0.740 ± 0.283, n_updates = 557000, time =  9.7, total_time = 4401.5 \n",
      "\n",
      "\n",
      "step =  568000, num_env_steps =  568000, scores =  6376.714 (n= 1), score_ema =  0.000, actor_loss = -385.276, critic_loss = 72.837, entropy_coef_loss = 0.947, entropy_coef = 0.148, rollout_stds = N/A, action_magnitude = 0.738 ± 0.287, n_updates = 558000, time = 10.1, total_time = 4411.6 \n",
      "\n",
      "\n",
      "step =  569000, num_env_steps =  569000, scores =  6566.867 (n= 1), score_ema =  0.000, actor_loss = -370.437, critic_loss = 16.501, entropy_coef_loss = -1.688, entropy_coef = 0.146, rollout_stds = N/A, action_magnitude = 0.746 ± 0.282, n_updates = 559000, time =  9.9, total_time = 4421.5 \n",
      "\n",
      "\n",
      "step =  570000, num_env_steps =  570000, scores =  6314.581 (n= 1), score_ema =  0.000, actor_loss = -381.850, critic_loss = 18.529, entropy_coef_loss = 0.006, entropy_coef = 0.148, rollout_stds = N/A, action_magnitude = 0.734 ± 0.286, n_updates = 560000, time = 10.0, total_time = 4431.5 \n",
      "\n",
      "saved experiment log 2024-10-08_13-43-48_236302~fXPQM9 at experiment_logs/HalfCheetah-v4/sac/2024-10-08_13-43-48_236302~fXPQM9.json\n",
      "\n",
      "\n",
      "step =  571000, num_env_steps =  571000, scores =  6431.933 (n= 1), score_ema =  0.000, actor_loss = -372.329, critic_loss = 370.249, entropy_coef_loss = -0.159, entropy_coef = 0.146, rollout_stds = N/A, action_magnitude = 0.744 ± 0.283, n_updates = 561000, time = 10.0, total_time = 4441.6 \n",
      "\n",
      "\n",
      "step =  572000, num_env_steps =  572000, scores =  6059.232 (n= 1), score_ema =  0.000, actor_loss = -375.175, critic_loss = 711.610, entropy_coef_loss = -0.730, entropy_coef = 0.146, rollout_stds = N/A, action_magnitude = 0.736 ± 0.284, n_updates = 562000, time =  9.6, total_time = 4451.2 \n",
      "\n",
      "\n",
      "step =  573000, num_env_steps =  573000, scores =  5948.799 (n= 1), score_ema =  0.000, actor_loss = -373.513, critic_loss = 18.994, entropy_coef_loss = 0.242, entropy_coef = 0.148, rollout_stds = N/A, action_magnitude = 0.731 ± 0.286, n_updates = 563000, time =  9.7, total_time = 4460.9 \n",
      "\n",
      "\n",
      "step =  574000, num_env_steps =  574000, scores =  6351.605 (n= 1), score_ema =  0.000, actor_loss = -369.739, critic_loss = 11.530, entropy_coef_loss = -1.267, entropy_coef = 0.153, rollout_stds = N/A, action_magnitude = 0.753 ± 0.277, n_updates = 564000, time =  9.3, total_time = 4470.2 \n",
      "\n",
      "\n",
      "step =  575000, num_env_steps =  575000, scores =  6406.363 (n= 1), score_ema =  0.000, actor_loss = -374.569, critic_loss = 1096.913, entropy_coef_loss = -0.374, entropy_coef = 0.149, rollout_stds = N/A, action_magnitude = 0.747 ± 0.279, n_updates = 565000, time = 11.6, total_time = 4481.8 \n",
      "\n",
      "\n",
      "saved experiment log 2024-10-08_13-43-48_236302~fXPQM9 at experiment_logs/HalfCheetah-v4/sac/2024-10-08_13-43-48_236302~fXPQM9.json\n",
      "keyboard interrupt\n",
      "closing envs\n",
      "envs closed\n",
      "model db closed\n",
      "done\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "'2024-09-25_16-31-21_748992~egIuot'"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": "logger.experiment_log['experiment_id']",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-25T19:28:38.199879Z",
     "start_time": "2024-09-25T19:28:37.969996Z"
    }
   },
   "id": "bc8c5c974988ba38",
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "66c40f43fdaba700"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
