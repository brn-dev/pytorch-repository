{"experiment_id": "2024-10-09_17-57-25_107700~LnzIqV", "experiment_tags": ["SACDebug", "HalfCheetah-v4", "Debug"], "start_time": "2024-10-09 17:57:25.107700", "end_time": "2024-10-09 18:36:30.011061", "end_exception": null, "hyper_parameters": {"_type": "SACDebug", "_type_fq": "__main__.SACDebug", "env": "<SingletonVectorEnv instance>", "num_envs": 1, "env_specs": [{"_count": 1, "id": "HalfCheetah-v4", "entry_point": "gymnasium.envs.mujoco.half_cheetah_v4:HalfCheetahEnv", "reward_threshold": 4.8000e+03, "nondeterministic": false, "max_episode_steps": 1000, "order_enforce": true, "autoreset": false, "disable_env_checker": false, "apply_api_compatibility": false, "kwargs": {"render_mode": null}, "additional_wrappers": [], "vector_entry_point": null, "namespace": null, "name": "HalfCheetah", "version": 4}], "policy": {}, "policy_parameter_count": 362256, "policy_repr": "DebugSACPolicy(\n  (feature_extractor): IdentityExtractor()\n  (actor): Actor(\n    (features_extractor): FlattenExtractor(\n      (flatten): Flatten(start_dim=1, end_dim=-1)\n    )\n    (latent_pi): Sequential(\n      (0): Linear(in_features=17, out_features=256, bias=True)\n      (1): ReLU()\n      (2): Linear(in_features=256, out_features=256, bias=True)\n      (3): ReLU()\n    )\n    (mu): Linear(in_features=256, out_features=6, bias=True)\n    (log_std): Linear(in_features=256, out_features=6, bias=True)\n  )\n  (critic): ContinuousCritic(\n    (features_extractor): FlattenExtractor(\n      (flatten): Flatten(start_dim=1, end_dim=-1)\n    )\n    (qf0): Sequential(\n      (0): Linear(in_features=23, out_features=256, bias=True)\n      (1): ReLU()\n      (2): Linear(in_features=256, out_features=256, bias=True)\n      (3): ReLU()\n      (4): Linear(in_features=256, out_features=1, bias=True)\n    )\n    (qf1): Sequential(\n      (0): Linear(in_features=23, out_features=256, bias=True)\n      (1): ReLU()\n      (2): Linear(in_features=256, out_features=256, bias=True)\n      (3): ReLU()\n      (4): Linear(in_features=256, out_features=1, bias=True)\n    )\n  )\n  (target_critic): ContinuousCritic(\n    (features_extractor): FlattenExtractor(\n      (flatten): Flatten(start_dim=1, end_dim=-1)\n    )\n    (qf0): Sequential(\n      (0): Linear(in_features=23, out_features=256, bias=True)\n      (1): ReLU()\n      (2): Linear(in_features=256, out_features=256, bias=True)\n      (3): ReLU()\n      (4): Linear(in_features=256, out_features=1, bias=True)\n    )\n    (qf1): Sequential(\n      (0): Linear(in_features=23, out_features=256, bias=True)\n      (1): ReLU()\n      (2): Linear(in_features=256, out_features=256, bias=True)\n      (3): ReLU()\n      (4): Linear(in_features=256, out_features=1, bias=True)\n    )\n  )\n  (target_shared_feature_extractor): IdentityExtractor()\n)", "buffer": {}, "gamma": 9.9000e-01, "sde_noise_sample_freq": null, "torch_device": "cuda:0", "torch_dtype": "torch.float32", "tau": 5.0000e-03, "rollout_steps": 1, "gradient_steps": 1, "optimization_batch_size": 256, "action_noise": null, "warmup_steps": 10000, "actor_optimizer": {"_type": "Adam", "_type_fq": "torch.optim.adam.Adam", "lr": 3.0000e-04, "weight_decay": 0, "maximize": false, "foreach": null, "differentiable": false, "fused": null, "betas": [9.0000e-01, 9.9900e-01], "eps": 1.0000e-08, "amsgrad": false, "capturable": false, "repr": "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0003\n    maximize: False\n    weight_decay: 0\n)"}, "critic_optimizer": {"_type": "Adam", "_type_fq": "torch.optim.adam.Adam", "lr": 3.0000e-04, "weight_decay": 0, "maximize": false, "foreach": null, "differentiable": false, "fused": null, "betas": [9.0000e-01, 9.9900e-01], "eps": 1.0000e-08, "amsgrad": false, "capturable": false, "repr": "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0003\n    maximize: False\n    weight_decay: 0\n)"}, "entropy_coef_optimizer": {"_type": "Adam", "_type_fq": "torch.optim.adam.Adam", "lr": 3.0000e-04, "weight_decay": 0, "maximize": false, "foreach": null, "differentiable": false, "fused": null, "betas": [9.0000e-01, 9.9900e-01], "eps": 1.0000e-08, "amsgrad": false, "capturable": false, "repr": "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0003\n    maximize: False\n    weight_decay: 0\n)"}, "weigh_and_reduce_entropy_coef_loss": "<built-in method mean of type object, module=torch>", "weigh_and_reduce_actor_loss": "<built-in method mean of type object, module=torch>", "weigh_critic_loss": "<function identity, module=src.torch_functions>", "target_update_interval": 1, "target_entropy": -6.0000e+00, "entropy_coef": "dynamic"}, "system_info": {"platform": "Windows", "platform_release": "10", "architecture": "AMD64", "processor": {"name": "AMD Ryzen 9 3900X 12-Core Processor", "cores": 12, "logical_cores": 24, "speed": "3793 MHz"}, "gpu": [{"name": "NVIDIA GeForce RTX 3070", "video_processor": "NVIDIA GeForce RTX 3070", "adapter_ram": "-1 MB", "adapter_dac_type": "Integrated RAMDAC", "manufacturer": "NVIDIA", "memory": "8192 MB", "memory_clock": "6800 MHz", "compute_capability": "8.6"}], "ram_speed": "3600 MHz", "ram": "64 GB"}, "setup": {"sac.py": "from typing import Any\n\nimport gymnasium\nimport torch\n\nfrom src.reinforcement_learning.core.action_selectors.action_selector import ActionSelector\nfrom src.reinforcement_learning.core.policies.base_policy import BasePolicy\nfrom src.reinforcement_learning.core.policy_construction import InitActionSelectorFunction\n\npolicy_construction_hyper_parameter = {}\n\ndef init_action_selector(latent_dim: int, action_dim: int, hyper_parameters: dict[str, 'Any']) -> 'ActionSelector':\n    from src.reinforcement_learning.core.action_selectors.predicted_std_action_selector \\\n        import PredictedStdActionSelector\n    from src.reinforcement_learning.core.action_selectors.squashed_diag_gaussian_action_selector import \\\n        SquashedDiagGaussianActionSelector\n    from src.weight_initialization import orthogonal_initialization\n\n    return PredictedStdActionSelector(\n        latent_dim=latent_dim,\n        action_dim=action_dim,\n        base_std=1.0,\n        squash_output=True,\n        # action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n        # log_std_net_initialization=lambda module: orthogonal_initialization(module, gain=0.1),\n    )\n    # return PredictedStdActionSelector(\n    #     latent_dim=latent_dim,\n    #     action_dim=action_dim,\n    #     std=1.0,\n    #     std_learnable=True,\n    #     action_net_initialization=lambda module: orthogonal_initialization(module, gain=0.01),\n    # )\n\n\n\ndef init_policy(\n        init_action_selector_: 'InitActionSelectorFunction',\n        hyper_parameters: dict[str, 'Any']\n) -> 'BasePolicy':\n    import torch\n    from torch import nn\n    import numpy as np\n\n    from src.reinforcement_learning.algorithms.sac.sac_policy import SACPolicy\n    from src.reinforcement_learning.algorithms.sac.sac_crossq_policy import SACCrossQPolicy\n    from src.networks.core.seq_net import SeqNet\n    from src.networks.core.net import Net\n    from src.networks.skip_nets.additive_skip_connection import AdditiveSkipConnection\n    from src.weight_initialization import orthogonal_initialization\n    from src.reinforcement_learning.core.policies.components.actor import Actor\n    from src.reinforcement_learning.core.policies.components.q_critic import QCritic\n    from src.networks.normalization.batch_renorm import BatchRenorm\n\n    # in_size = 376\n    # action_size = 17\n    # actor_out_sizes = [512, 512, 256, 256, 256, 256, 256, 256]\n    # critic_out_sizes = [512, 512, 256, 256, 256, 1]\n\n    in_size = 17\n    action_size = 6\n\n    actor_layers = 3\n    actor_features = 96\n\n    critic_layers = 2\n    critic_features = 96\n\n    hidden_activation_function = nn.ELU\n\n    # actor_net = nn.Sequential(\n    #     nn.Linear(in_size, actor_features),\n    #     hidden_activation_function(),\n    #     SeqNet.from_layer_provider(\n    #         layer_provider=lambda layer_nr, is_last_layer, in_features, out_features:\n    #         AdditiveSkipConnection(Net.seq_as_net(\n    #             orthogonal_initialization(nn.Linear(in_features, out_features), gain=np.sqrt(2)),\n    #             hidden_activation_function(),\n    #             orthogonal_initialization(nn.Linear(in_features, out_features), gain=np.sqrt(2)),\n    #             nn.Tanh() if is_last_layer else hidden_activation_function(),\n    #         )),\n    #         num_features=actor_features,\n    #         num_layers=actor_layers,\n    #     )\n    # )\n    #\n    # critic = QCritic(\n    #     n_critics=2,\n    #     create_q_network=lambda: nn.Sequential(\n    #         nn.Linear(in_size + action_size, critic_features),\n    #         hidden_activation_function(),\n    #         SeqNet.from_layer_provider(\n    #             layer_provider=lambda layer_nr, is_last_layer, in_features, out_features:\n    #             AdditiveSkipConnection(Net.seq_as_net(\n    #                 orthogonal_initialization(nn.Linear(in_features, out_features), gain=np.sqrt(2)),\n    #                 hidden_activation_function(),\n    #                 orthogonal_initialization(nn.Linear(in_features, out_features), gain=np.sqrt(2)),\n    #                 hidden_activation_function(),\n    #             )),\n    #             num_features=critic_features,\n    #             num_layers=critic_layers,\n    #         ),\n    #         nn.Linear(critic_features, 1)\n    #     )\n    # )\n\n    actor_net = nn.Sequential(\n        nn.Linear(in_size, 256),\n        nn.ReLU(),\n        nn.Linear(256, 256),\n        nn.ReLU(),\n    )\n\n    critic = QCritic(\n        n_critics=2,\n        create_q_network=lambda: nn.Sequential(\n            nn.Linear(in_size + action_size, 256),\n            nn.ReLU(),\n            # BatchRenorm(256),\n            nn.Linear(256, 256),\n            nn.ReLU(),\n            # BatchRenorm(256),\n            nn.Linear(256, 1)\n        )\n    )\n\n    return SACPolicy(\n        actor=Actor(actor_net, init_action_selector_(\n            latent_dim=256,\n            action_dim=action_size,\n            hyper_parameters=hyper_parameters,\n        )),\n        critic=critic\n    )\n\ndef init_optimizer(pol: 'BasePolicy', hyper_parameters: dict[str, 'Any']) -> 'torch.optim.Optimizer':\n    import torch.optim\n    return torch.optim.AdamW(pol.parameters(), lr=3e-4, weight_decay=1e-4)\n\ndef wrap_env(env_: 'gymnasium.vector.VectorEnv', hyper_parameters: dict[str, 'Any']) -> 'gymnasium.Env':\n    from src.reinforcement_learning.gym.wrappers.transform_reward_wrapper import TransformRewardWrapper\n    from gymnasium.wrappers import RescaleAction\n    from src.np_functions import symmetric_log\n\n\n    # env_ = TransformRewardWrapper(env_, lambda reward_: 1 * reward_)\n    # env_ = RescaleAction(env_, min_action=-1.0, max_action=1.0)\n    return env_\n", "notebook": "from sac import init_policy, init_action_selector\nfrom stable_baselines3.common.env_util import make_vec_env\nimport stable_baselines3 as sb\nfrom src.reinforcement_learning.gym.parallelize_env import parallelize_env_async\nimport gymnasium\n\nenv_name = 'HalfCheetah-v4'\n# env_kwargs = {'forward_reward_weight': 1.25, 'healthy_reward': 0.5, 'ctrl_cost_weight': 0.001 }\n# env_kwargs = {'forward_reward_weight': 1.25, 'ctrl_cost_weight': 0.1 }\n# env_kwargs = {'forward_reward_weight': 1.25, 'ctrl_cost_weight': 0.05 }\nenv_kwargs = {}\nnum_envs = 1\n\ndef create_env(render_mode: str | None):\n    return gymnasium.make(env_name, render_mode=render_mode, **env_kwargs)\n\n# env = parallelize_env_async(lambda: create_env(render_mode=None), num_envs)\nenv = create_env(render_mode=None)\n\nsb_sac = sb.SAC(\"MlpPolicy\", env, verbose=10, learning_starts=10000, stats_window_size=1) # , seed=594371)\n\nfrom src.reinforcement_learning.core.polyak_update import polyak_update\nfrom src.reinforcement_learning.core.buffers.replay.base_replay_buffer import ReplayBufferSamples\nfrom src.hyper_parameters import HyperParameters\nimport torch\nfrom src.reinforcement_learning.core.type_aliases import TensorObs\nfrom typing import Optional\nfrom src.reinforcement_learning.core.policies.components.feature_extractors import FeatureExtractor\nimport copy\nfrom src.console import print_warning\nfrom src.tags import Tags\nfrom src.reinforcement_learning.core.policies.components.actor import Actor\nfrom src.reinforcement_learning.core.policies.components.q_critic import QCritic\nfrom src.reinforcement_learning.core.policies.base_policy import BasePolicy\nimport stable_baselines3 as sb\n\n\nclass DebugSACPolicy(BasePolicy):\n    \n    actor: sb.sac.policies.Actor\n\n    def __init__(\n            self,\n            actor: Actor,\n            critic: QCritic,\n            shared_feature_extractor: Optional[FeatureExtractor] = None\n    ):\n        super().__init__(actor, shared_feature_extractor)\n        self.actor = sb_sac.actor\n        self.critic = sb_sac.critic\n\n        self._build_target()\n\n        self._check_action_selector()\n        \n    @property\n    def uses_sde(self):\n        return False\n        \n    def act(self, obs: TensorObs) -> torch.Tensor:\n        return self.actor(obs, False)\n    \n    def reset_sde_noise(self, batch_size: int) -> None:\n        pass\n        \n\n    def collect_hyper_parameters(self) -> HyperParameters:\n        return {}\n\n    def collect_tags(self) -> Tags:\n        return []\n\n    def _check_action_selector(self):\n        # if not isinstance(self.actor.action_selector, (PredictedStdActionSelector, StateDependentNoiseActionSelector)):\n        #     print_warning('SAC not being used with PredictedStdAction Selector or gSDE. LogStds should be clamped!')\n        pass\n\n    def _build_target(self):\n        self.target_critic = copy.deepcopy(self.critic)\n        self.target_critic.set_training_mode(False)\n\n        self.target_shared_feature_extractor = copy.deepcopy(self.shared_feature_extractor)\n        self.target_shared_feature_extractor.set_trainable(False)\n\n    def forward(self):\n        raise NotImplementedError('forward is not used in SACPolicy')\n\n    def compute_target_values(\n            self,\n            replay_samples: ReplayBufferSamples,\n            entropy_coef: torch.Tensor,\n            gamma: float,\n    ):\n        with torch.no_grad():\n            next_observations = replay_samples.next_observations\n\n            next_actions, next_actions_log_prob = self.actor.action_log_prob(\n                self.shared_feature_extractor(next_observations)\n            )\n\n            next_q_values = torch.cat(\n                self.target_critic(self.target_shared_feature_extractor(next_observations), next_actions),\n                dim=-1\n            )\n            next_q_values, _ = torch.min(next_q_values, dim=-1, keepdim=True)\n            next_q_values = next_q_values - entropy_coef * next_actions_log_prob.reshape(-1, 1)\n\n            target_q_values = replay_samples.rewards + (1 - replay_samples.dones) * gamma * next_q_values\n\n            return target_q_values\n\n\n    def perform_polyak_update(self, tau: float):\n        polyak_update(self.critic.parameters(), self.target_critic.parameters(), tau)\n        polyak_update(\n            self.shared_feature_extractor.parameters(),\n            self.target_shared_feature_extractor.parameters(),\n            tau\n        )\n\n    def set_train_mode(self, mode: bool) -> None:\n        self.actor.set_training_mode(mode)\n        self.critic.set_training_mode(mode)\n        # Leaving target_critic on train_mode = False\n\n        self.shared_feature_extractor.set_train_mode(mode)\n        # Leaving target_shared_feature_extractor on train_mode = False\n\n        self.train_mode = mode\n\nfrom src.reinforcement_learning.algorithms.sac.sac import SACLoggingConfig, SAC\nfrom dataclasses import dataclass\nfrom typing import Type, Optional, Any, Literal\n\nimport gymnasium\nimport numpy as np\nimport torch\nimport torch.nn.functional as F\nfrom torch import optim\n\nfrom src.function_types import TorchTensorFn\nfrom src.module_analysis import calculate_grad_norm\nfrom src.hyper_parameters import HyperParameters\nfrom src.reinforcement_learning.algorithms.base.base_algorithm import PolicyProvider\nfrom src.reinforcement_learning.algorithms.base.off_policy_algorithm import OffPolicyAlgorithm, ReplayBuf\nfrom src.reinforcement_learning.algorithms.sac.sac_crossq_policy import SACCrossQPolicy\nfrom src.reinforcement_learning.algorithms.sac.sac_policy import SACPolicy\nfrom src.reinforcement_learning.core.action_noise import ActionNoise\nfrom src.reinforcement_learning.core.buffers.replay.base_replay_buffer import BaseReplayBuffer, ReplayBufferSamples\nfrom src.reinforcement_learning.core.buffers.replay.replay_buffer import ReplayBuffer\nfrom src.reinforcement_learning.core.callback import Callback\nfrom src.reinforcement_learning.core.infos import InfoDict, concat_infos\nfrom src.reinforcement_learning.core.logging import LoggingConfig, log_if_enabled\nfrom src.reinforcement_learning.core.loss_config import weigh_and_reduce_loss, LossLoggingConfig\nfrom src.reinforcement_learning.core.type_aliases import OptimizerProvider, TensorObs, detach_obs\nfrom src.reinforcement_learning.gym.env_analysis import get_single_action_space\nfrom src.tags import Tags\nfrom src.torch_device import TorchDevice\nfrom src.torch_functions import identity\nfrom src.repr_utils import func_repr\n\nfrom typing import Literal\n\nSAC_DEFAULT_OPTIMIZER_PROVIDER = lambda params: optim.AdamW(params, lr=3e-4, weight_decay=1e-4)\nAUTO_TARGET_ENTROPY = 'auto'\n\n\nclass SACDebug(SAC):\n    \n    @property\n    def replay_buffer(self):\n        return self.buffer\n\n    buffer: BaseReplayBuffer\n    target_entropy: float\n    log_ent_coef: Optional[torch.Tensor]\n    entropy_coef_optimizer: Optional[optim.Optimizer]\n    entropy_coef_tensor: Optional[torch.Tensor]\n    \n    def collect_hyper_parameters(self) -> HyperParameters:\n        print(f'{type(self.policy) = }, {type(self.policy.actor) = }, {type(self.policy.critic) = }, {type(self.policy.target_critic) = }, {type(self.buffer) = }')\n        return super().collect_hyper_parameters()\n    \n    \n    def _setup_entropy_optimization(\n            self,\n            entropy_coef: float,\n            target_entropy: float | Literal['auto'],\n            entropy_coef_optimizer_provider: Optional[OptimizerProvider],\n    ):\n        if target_entropy == 'auto':\n            self.target_entropy = float(-np.prod(get_single_action_space(self.env).shape).astype(np.float32))\n        else:\n            self.target_entropy = float(target_entropy)\n\n        if entropy_coef_optimizer_provider is not None:\n            self.log_ent_coef = torch.log(\n                torch.tensor([entropy_coef], device=self.torch_device, dtype=self.torch_dtype)\n            ).requires_grad_(True)\n            self.entropy_coef_optimizer = entropy_coef_optimizer_provider([self.log_ent_coef])\n            self.entropy_coef_tensor = None\n        else:\n            self.log_ent_coef = None\n            self.entropy_coef_optimizer = None\n            self.entropy_coef_tensor = torch.tensor(entropy_coef, device=self.torch_device, dtype=self.torch_dtype)\n\n    # def get_and_optimize_entropy_coef(\n    #         self,\n    #         actions_pi_log_prob: torch.Tensor,\n    #         info: InfoDict\n    # ) -> torch.Tensor:\n    #     if self.entropy_coef_optimizer is not None:\n    #         entropy_coef = torch.exp(self.log_ent_coef.detach())\n    # \n    #         entropy_coef_loss = weigh_and_reduce_loss(\n    #             raw_loss=-self.log_ent_coef * (actions_pi_log_prob + self.target_entropy).detach(),\n    #             weigh_and_reduce_function=self.weigh_and_reduce_entropy_coef_loss,\n    #             info=info,\n    #             loss_name='entropy_coef_loss',\n    #             logging_config=self.logging_config.entropy_coef_loss\n    #         )\n    #         self.entropy_coef_optimizer.zero_grad()\n    #         entropy_coef_loss.backward()\n    #         self.entropy_coef_optimizer.step()\n    # \n    #         return entropy_coef\n    #     else:\n    #         return self.entropy_coef_tensor\n    # \n    # def calculate_critic_loss(\n    #         self,\n    #         observation_features: TensorObs,\n    #         replay_samples: ReplayBufferSamples,\n    #         entropy_coef: torch.Tensor,\n    #         info: InfoDict,\n    # ):\n    #     target_q_values = self.policy.compute_target_values(\n    #         replay_samples=replay_samples,\n    #         entropy_coef=entropy_coef,\n    #         gamma=self.gamma,\n    #     )\n    #     # critic loss should not influence shared feature extractor\n    #     current_q_values = self.critic(detach_obs(observation_features), replay_samples.actions)\n    # \n    #     # noinspection PyTypeChecker\n    #     critic_loss: torch.Tensor = 0.5 * sum(\n    #         F.mse_loss(current_q, target_q_values) for current_q in current_q_values\n    #     )\n    #     critic_loss = weigh_and_reduce_loss(\n    #         raw_loss=critic_loss,\n    #         weigh_and_reduce_function=self.weigh_critic_loss,\n    #         info=info,\n    #         loss_name='critic_loss',\n    #         logging_config=self.logging_config.critic_loss,\n    #     )\n    #     return critic_loss\n    # \n    # def calculate_actor_loss(\n    #         self,\n    #         observation_features: TensorObs,\n    #         actions_pi: torch.Tensor,\n    #         actions_pi_log_prob: torch.Tensor,\n    #         entropy_coef: torch.Tensor,\n    #         info: InfoDict,\n    # ) -> torch.Tensor:\n    #     q_values_pi = torch.cat(self.critic(observation_features, actions_pi), dim=-1)\n    #     min_q_values_pi, _ = torch.min(q_values_pi, dim=-1, keepdim=True)\n    #     actor_loss = entropy_coef * actions_pi_log_prob - min_q_values_pi\n    # \n    #     actor_loss = weigh_and_reduce_loss(\n    #         raw_loss=actor_loss,\n    #         weigh_and_reduce_function=self.weigh_and_reduce_actor_loss,\n    #         info=info,\n    #         loss_name='actor_loss',\n    #         logging_config=self.logging_config.actor_loss,\n    #     )\n    # \n    #     return actor_loss\n\n    def optimize(self, last_obs: np.ndarray, last_episode_starts: np.ndarray, info: InfoDict) -> None:\n        ent_coef_losses, ent_coefs = [], []\n        actor_losses, critic_losses = [], []\n\n        for gradient_step in range(self.gradient_steps):\n            # Sample replay buffer\n            replay_data = self.replay_buffer.sample(self.optimization_batch_size, env=None)  # type: ignore[union-attr]\n\n            # We need to sample because `log_std` may have changed between two gradient steps\n            # if self.sde_noise_sample_freq:\n            #     self.actor.reset_noise()\n\n            # Action by the current actor for the sampled state\n            actions_pi, log_prob = self.actor.action_log_prob(replay_data.observations)\n            log_prob = log_prob.reshape(-1, 1)\n\n            ent_coef_loss = None\n            if self.entropy_coef_optimizer is not None and self.log_ent_coef is not None:\n                # Important: detach the variable from the graph\n                # so we don't change it with other losses\n                # see https://github.com/rail-berkeley/softlearning/issues/60\n                ent_coef = torch.exp(self.log_ent_coef.detach())\n                ent_coef_loss = -(self.log_ent_coef * (log_prob + self.target_entropy).detach()).mean()\n                ent_coef_losses.append(ent_coef_loss.item())\n            else:\n                ent_coef = self.entropy_coef_tensor\n\n            ent_coefs.append(ent_coef.item())\n\n            # Optimize entropy coefficient, also called\n            # entropy temperature or alpha in the paper\n            if ent_coef_loss is not None and self.entropy_coef_optimizer is not None:\n                self.entropy_coef_optimizer.zero_grad()\n                ent_coef_loss.backward()\n                self.entropy_coef_optimizer.step()\n\n            with torch.no_grad():\n                # Select action according to policy\n                next_actions, next_log_prob = self.actor.action_log_prob(replay_data.next_observations)\n                # Compute the next Q values: min over all critics targets\n                next_q_values = torch.cat(self.policy.target_critic(replay_data.next_observations, next_actions), dim=1)\n                next_q_values, _ = torch.min(next_q_values, dim=1, keepdim=True)\n                # add entropy term\n                next_q_values = next_q_values - ent_coef * next_log_prob.reshape(-1, 1)\n                # td error + entropy term\n                target_q_values = replay_data.rewards + (1 - replay_data.dones) * self.gamma * next_q_values\n\n            # Get current Q-values estimates for each critic network\n            # using action from the replay buffer\n            current_q_values = self.critic(replay_data.observations, replay_data.actions)\n\n            # Compute critic loss\n            critic_loss = 0.5 * sum(F.mse_loss(current_q, target_q_values) for current_q in current_q_values)\n            assert isinstance(critic_loss, torch.Tensor)  # for type checker\n            critic_losses.append(critic_loss.item())  # type: ignore[union-attr]\n\n            # Optimize the critic\n            self.critic.optimizer.zero_grad()\n            critic_loss.backward()\n            self.critic.optimizer.step()\n\n            # Compute actor loss\n            # Alternative: actor_loss = torch.mean(log_prob - qf1_pi)\n            # Min over all critic networks\n            q_values_pi = torch.cat(self.critic(replay_data.observations, actions_pi), dim=1)\n            min_qf_pi, _ = torch.min(q_values_pi, dim=1, keepdim=True)\n            actor_loss = (ent_coef * log_prob - min_qf_pi).mean()\n            actor_losses.append(actor_loss.item())\n\n            # Optimize the actor\n            self.actor.optimizer.zero_grad()\n            actor_loss.backward()\n            self.actor.optimizer.step()\n\n            # Update target networks\n            if gradient_step % self.target_update_interval == 0:\n                polyak_update(self.critic.parameters(), self.policy.target_critic.parameters(), self.tau)\n                # Copy running stats, see GH issue #996\n        \n        info['entropy_coef'] = np.array(ent_coefs)\n        info['final_entropy_coef_loss'] = np.array(ent_coef_losses)\n        info['final_actor_loss'] = np.array(actor_losses)\n        info['final_critic_loss'] = np.array(critic_losses)\n\nimport inspect\nimport time\n\nfrom gymnasium import Env\n\nfrom sac import init_action_selector, init_policy, init_optimizer, wrap_env, policy_construction_hyper_parameter\nfrom src.datetime import get_current_timestamp\nfrom src.experiment_logging.experiment_logger import ExperimentLogger, log_experiment\nfrom src.model_db.dummy_model_db import DummyModelDB\nfrom src.reinforcement_learning.algorithms.policy_mitosis.mitosis_policy_info import MitosisPolicyInfo\nfrom src.module_analysis import count_parameters\nfrom src.moving_averages import ExponentialMovingAverage\nfrom src.reinforcement_learning.core.policies.base_policy import BasePolicy\nfrom src.reinforcement_learning.core.policy_construction import PolicyConstruction\nfrom src.stopwatch import Stopwatch\nfrom src.summary_statistics import format_summary_statics\nfrom typing import Any\nfrom src.reinforcement_learning.core.callback import Callback\n\nimport torch\nfrom torch import optim\nimport gymnasium as gym\nimport numpy as np\n\nget_ipython().run_line_magic('load_ext', 'autoreload')\nget_ipython().run_line_magic('autoreload', '2')\n\nfrom src.summary_statistics import maybe_compute_summary_statistics\nfrom src.reinforcement_learning.core.loss_config import LossLoggingConfig\nfrom src.reinforcement_learning.algorithms.sac.sac import SAC, SACLoggingConfig\ndef get_setup() -> dict[str, str]:\n    import inspect\n    import sac\n    return {\n        'sac.py': inspect.getsource(sac),\n        'notebook': _ih[1] + '\\n\\n' + _ih[-4] + '\\n\\n' + _ih[-3] + '\\n\\n' + _ih[-2] + '\\n\\n' + _ih[-1], # first and last cell input (imports and this cell)\n    }\n\npolicy_id: str\npolicy: BasePolicy\noptimizer: optim.Optimizer\nwrapped_env: Env\nsteps_trained: int\ndef get_policy(create_new_if_exists: bool):\n    \n    global policy_id, policy, optimizer, wrapped_env, steps_trained\n    \n    policy_in_ram = 'policy' in globals()\n    if not policy_in_ram or create_new_if_exists:\n        if not policy_in_ram:\n            print('No policy in RAM, creating a new one')\n        \n        policy_id = get_current_timestamp()\n        policy, optimizer, wrapped_env = PolicyConstruction.init_from_info(\n            env=env,\n            info=PolicyConstruction.create_policy_initialization_info(\n                init_action_selector=init_action_selector,\n                init_policy=init_policy,\n                init_optimizer=init_optimizer,\n                wrap_env=wrap_env,\n                hyper_parameters=policy_construction_hyper_parameter,\n            ),\n        )\n        steps_trained = 0\n        print(f'New policy {policy_id} created')\n    \n    if parent_policy_id is not None:\n        model_entry = policy_db.load_model_state_dict(policy, parent_policy_id)\n        steps_trained = model_entry['model_info']['steps_trained']\n        print(f'Loading state dict from policy {parent_policy_id}')\n    \n    print(f'Using policy {policy_id} with parent policy {parent_policy_id}')\n    return policy_id, policy, optimizer, wrapped_env, steps_trained\n\nscore_mean_ema = ExponentialMovingAverage(alpha=0.25)\nstep_stopwatch = Stopwatch()\ntotal_stopwatch = Stopwatch()\nbest_iteration_score = -1e6\n\ndef on_rollout_done(rl: SAC, step: int, info: dict[str, Any], scheduler_values: dict[str, Any]):\n    \n    if step % 1000 != 0:\n        return\n    \n    # tail_indices = rl.buffer.tail_indices(1000)\n    \n    # rewards = rl.buffer.rewards[tail_indices]\n    # if 'raw_rewards' in info['rollout']:\n    #     rewards = info['rollout']['raw_rewards']\n    \n    # episode_scores = compute_episode_returns(\n    #     rewards=rewards,\n    #     episode_starts=np.repeat(np.arange(len(tail_indices)).reshape(-1, 1), num_envs, axis=1) % 1000 == 0,\n    #     last_episode_starts=info['last_episode_starts'],\n    #     gamma=1.0,\n    #     gae_lambda=1.0,\n    #     normalize_rewards=None,\n    #     remove_unfinished_episodes=True,\n    # )\n    \n    # episode_scores = rl.buffer.compute_most_recent_episode_scores(rl.num_envs)\n    # \n    # if len(episode_scores) > 0:\n    # \n    #     global best_iteration_score\n    #     iteration_score = episode_scores.mean()\n    #     score_moving_average = score_mean_ema.update(iteration_score)\n    #     if iteration_score >= best_iteration_score:\n    #         best_iteration_score = iteration_score\n    #         policy_db.save_model_state_dict(\n    #             model_id=policy_id,\n    #             parent_model_id=parent_policy_id,\n    #             model_info={\n    #                 'score': iteration_score.item(),\n    #                 'steps_trained': steps_trained,\n    #                 'wrap_env_source_code': wrap_env_source_code_source,\n    #                 'init_policy_source_code': init_policy_source\n    #             },\n    #             model=policy,\n    #             optimizer=optimizer,\n    #         )\n    #     info['score_moving_average'] = score_moving_average\n    # \n    # info['episode_scores'] = episode_scores\n        \ndef on_optimization_done(rl: SAC, step: int, info: dict[str, Any], scheduler_values: dict[str, Any]):\n    # global steps_trained\n    # steps_trained += rl.buffer.pos\n    \n    if step % 1000 != 0:\n        return\n    num_env_steps = step * rl.num_envs\n    \n    step_time = step_stopwatch.reset()\n    total_time = total_stopwatch.time_passed()\n    \n    # TODO!!\n    # tail_indices = rl.buffer.tail_indices(1000)\n    \n    # episode_scores = info.get('episode_scores')\n    score_moving_average = info.get('score_moving_average') or 0.0\n    \n    tail_indices = np.arange(rl.buffer.pos - 1000, rl.buffer.pos)\n    episode_scores = rl.buffer.rewards[tail_indices].sum(axis=0)\n    \n    scores = format_summary_statics(\n        episode_scores, \n        mean_format=' 6.3f',\n        std_format='4.3f',\n        min_value_format=' 6.3f',\n        max_value_format='5.3f',\n        n_format='>2'\n    )\n    # scores2 = format_summary_statics(\n    #     rl.buffer.compute_most_recent_episode_scores(rl.num_envs, lambda r: 1 * r), \n    #     mean_format=' 6.3f',\n    #     std_format='4.3f',\n    #     min_value_format=' 6.3f',\n    #     max_value_format='5.3f',\n    #     n_format='>2'\n    # )\n    # advantages = format_summary_statics(\n    #     rl.buffer.advantages, \n    #     mean_format=' 6.3f',\n    #     std_format='.1f',\n    #     min_value_format=' 7.3f',\n    #     max_value_format='6.3f',\n    # )\n    actor_loss = format_summary_statics(\n        info['final_actor_loss'],  \n        mean_format=' 5.3f',\n        # std_format='5.3f',\n        std_format=None,\n        min_value_format=None,\n        max_value_format=None,\n    )\n    # actor_loss_raw = format_summary_statics(\n    #     info['raw_actor_loss'],  \n    #     mean_format=' 5.3f',\n    #     std_format='5.3f',\n    #     min_value_format=None,\n    #     max_value_format=None,\n    # )\n    entropy_coef_loss = None if 'final_entropy_coef_loss' not in info else format_summary_statics(\n        info['final_entropy_coef_loss'], \n        mean_format='5.3f',\n#         std_format='5.3f',\n        std_format=None,\n        min_value_format=None,\n        max_value_format=None,\n    )\n    critic_loss = format_summary_statics(\n        info['final_critic_loss'], \n        mean_format='5.3f',\n#         std_format='5.3f',\n        std_format=None,\n        min_value_format=None,\n        max_value_format=None,\n    )\n    entropy_coef = format_summary_statics(\n        info['entropy_coef'],\n        mean_format='5.3f',\n#         std_format='5.3f',\n        std_format=None,\n        min_value_format=None,\n        max_value_format=None,\n    )\n    # resets = format_summary_statics(\n    #     rl.buffer.dones.astype(int).sum(axis=0), \n    #     mean_format='.2f',\n    #     std_format=None,\n    #     min_value_format='1d',\n    #     max_value_format=None,\n    # )\n    # kl_div = info['actor_kl_divergence'][-1]\n    # grad_norm = format_summary_statics(\n    #     info['grad_norm'], \n    #     mean_format=' 6.3f',\n    #     std_format='.1f',\n    #     min_value_format=' 7.3f',\n    #     max_value_format='6.3f',\n    # )\n    action_stds = info['rollout'].get('action_stds')\n    if action_stds is not None:\n        rollout_action_stds = format_summary_statics(\n            action_stds,\n            mean_format='5.3f',\n            std_format='5.3f',\n            min_value_format=None,\n            max_value_format=None,\n        )\n    else:\n        rollout_action_stds = 'N/A'\n    action_magnitude = format_summary_statics(\n        np.abs(rl.buffer.actions[tail_indices]),\n        mean_format='5.3f',\n        std_format='5.3f',\n        min_value_format=None,\n        max_value_format=None,\n    )\n    # ppo_epochs = info['nr_ppo_epochs']\n    # ppo_updates = info['nr_ppo_updates']\n    # expl_var = rl.buffer.compute_critic_explained_variance()\n    print(f\"{step = : >7}, \"\n          f\"{num_env_steps = : >7}, \"\n          f\"{scores = :s}, \"\n          # f\"{scores2 = :s}, \"\n          f'score_ema = {score_moving_average: 6.3f}, '\n          # f\"{advantages = :s}, \"\n          f\"{actor_loss = :s}, \"\n          # f\"{actor_loss_raw = :s}, \"\n          f\"{critic_loss = :s}, \"\n          +(f\"{entropy_coef_loss = :s}, \" if entropy_coef_loss is not None else '')+\n          f\"{entropy_coef = :s}, \"\n          f\"rollout_stds = {rollout_action_stds:s}, \"\n          f\"{action_magnitude = :s}, \"\n          # f\"{expl_var = :.3f}, \"\n          # f\"{kl_div = :.4f}, \"\n          # f\"{ppo_epochs = }, \"\n          # f\"{ppo_updates = }, \"\n          # f\"{grad_norm = :s}, \"\n          f\"n_updates = {rl.gradient_steps_performed}, \"\n          # f\"{resets = :s}, \"\n          f\"time = {step_time:4.1f}, \"\n          f\"total_time = {total_time:4.1f} \\n\"\n          )\n    logger.add_item({\n        'step': step,\n        'num_env_steps': num_env_steps,\n        'scores': maybe_compute_summary_statistics(episode_scores),\n        'actor_loss': maybe_compute_summary_statistics(info['final_actor_loss']),\n        'entropy_coef_loss': maybe_compute_summary_statistics(info.get('final_entropy_coef_loss')),\n        'critic_loss': maybe_compute_summary_statistics(info['final_critic_loss']),\n        'entropy_coef': maybe_compute_summary_statistics(info['entropy_coef']),\n        'action_stds': maybe_compute_summary_statistics(action_stds),\n        'action_magnitude': maybe_compute_summary_statistics(np.abs(rl.buffer.actions[tail_indices])),\n        'num_gradient_steps': rl.gradient_steps_performed,\n        'step_time': step_time,\n        'total_time': total_time\n    })\n    if step % 10000 == 0:\n        logger.save_experiment_log()\n        print()\n    print()\n    \n    # if episode_scores is not None and len(episode_scores) > 0 and episode_scores.mean().item() < -500:\n    #     logger.save_experiment_log()\n    #     raise ValueError('Score too low, policy probably fucked :(')\n\ndevice = torch.device(\"cuda:0\") if True else torch.device('cpu')\nprint(f'using device {device}')\n\ndef create_env(render_mode: str | None):\n    return gym.make(env_name, render_mode=render_mode, **env_kwargs)\n\nwrap_env_source_code_source = inspect.getsource(wrap_env)\ninit_policy_source = inspect.getsource(init_policy)\n\nenv_name = 'HalfCheetah-v4'\n# env_kwargs = {'forward_reward_weight': 1.25, 'healthy_reward': 0.5, 'ctrl_cost_weight': 0.001 }\n# env_kwargs = {'forward_reward_weight': 1.25, 'ctrl_cost_weight': 0.1 }\n# env_kwargs = {'forward_reward_weight': 1.25, 'ctrl_cost_weight': 0.05 }\nenv_kwargs = {}\nnum_envs = 1\n    \n# policy_db = TinyModelDB[MitosisPolicyInfo](base_path=f'saved_models/rl/{env_name}')\npolicy_db = DummyModelDB[MitosisPolicyInfo]()\nprint(f'{policy_db = }')\n\nparent_policy_id=None  # '2024-04-28_20.57.23'\n\n# TODO\n# env = parallelize_env_async(lambda: create_env(render_mode=None), num_envs)\nenv = create_env(render_mode=None)\n\nlogger = ExperimentLogger(f'experiment_logs/{env_name}/sac/')\n\ntry:\n    policy_id, policy, optimizer, wrapped_env, steps_trained = get_policy(create_new_if_exists=False)\n    print(f'{count_parameters(policy) = }')\n    print(f'{env = }, {num_envs = }')\n        \n    with ((torch.autograd.set_detect_anomaly(False))):\n        algo = SACDebug(\n            env=wrapped_env,\n            policy=DebugSACPolicy(policy.actor, policy.critic),\n            actor_optimizer_provider=lambda params: optim.Adam(params, lr=3e-4),  # (params, lr=3e-4, betas=(0.5, 0.999)),\n            critic_optimizer_provider=lambda params: optim.Adam(params, lr=3e-4),  # (params, lr=3e-4, betas=(0.5, 0.999)),\n            # weigh_and_reduce_actor_loss=lambda l: 1 * l.mean(),\n            # weigh_critic_loss=lambda l: 1 * l,\n            buffer_size=1_000_000,\n            reward_scale=1,\n            gamma=0.99,\n            tau=0.005,\n            entropy_coef_optimizer_provider=lambda params: optim.Adam(params, lr=3e-4),\n            entropy_coef=1.0,\n            rollout_steps=1,\n            gradient_steps=1,\n            warmup_steps=10_000,\n            optimization_batch_size=256,\n            target_update_interval=1,\n            # sde_noise_sample_freq=50,\n            callback=Callback(\n                on_rollout_done=on_rollout_done,\n                rollout_schedulers={},\n                on_optimization_done=on_optimization_done,\n                optimization_schedulers={},\n            ),\n            logging_config=SACLoggingConfig(log_rollout_infos=True, log_rollout_action_stds=True,\n                                            log_last_obs=True, log_entropy_coef=True,\n                                            entropy_coef_loss=LossLoggingConfig(log_final=True),\n                                            actor_loss=LossLoggingConfig(log_final=True, log_raw=True),\n                                            critic_loss=LossLoggingConfig(log_final=True)),\n            torch_device=device,\n        )\n        \n        # Todo!\n        algo.buffer = sb_sac.replay_buffer\n        algo.buffer.to_torch = lambda arr: torch.tensor(arr, device='cuda', dtype=torch.float32)\n        \n        total_stopwatch.reset()\n        with log_experiment(\n            logger,\n            experiment_tags=algo.collect_tags() + ['Debug'],\n            hyper_parameters=algo.collect_hyper_parameters(),\n            setup=get_setup(),\n        ) as x:\n            logger.save_experiment_log()\n            print('\\nStarting Training\\n\\n')\n            # import cProfile\n            # pr = cProfile.Profile()\n            # pr.enable()\n            algo.learn(5_000_000)\n            # pr.disable()  \n            # pr.dump_stats('profile_stats.pstat')\nexcept KeyboardInterrupt:\n    print('keyboard interrupt')\nfinally:\n    print('closing envs')\n    time.sleep(0.5)\n    env.close()\n    print('envs closed')\n    policy_db.close()\n    print('model db closed')\n    \n\nprint('done')"}, "notes": [], "model_db_references": [], "logs_by_category": {"__default": [{"step": 11000, "num_env_steps": 11000, "scores": {"n": 1, "mean": -2.6421e+02}, "actor_loss": {"n": 1, "mean": -1.7958e+01}, "entropy_coef_loss": {"n": 1, "mean": -3.0185e+00}, "critic_loss": {"n": 1, "mean": 2.0528e+00}, "entropy_coef": {"n": 1, "mean": 7.4062e-01}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 5.2519e-01, "std": 2.8425e-01, "min_value": 3.4257e-04, "max_value": 9.9880e-01}, "num_gradient_steps": 0, "step_time": 1.2801e+01, "total_time": 1.2776e+01, "__timestamp": "2024-10-09 17:57:37.883386"}, {"step": 12000, "num_env_steps": 12000, "scores": {"n": 1, "mean": -2.2944e+02}, "actor_loss": {"n": 1, "mean": -2.5734e+01}, "entropy_coef_loss": {"n": 1, "mean": -5.8912e+00}, "critic_loss": {"n": 1, "mean": 1.7186e+00}, "entropy_coef": {"n": 1, "mean": 5.4903e-01}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 5.3830e-01, "std": 2.8742e-01, "min_value": 6.4600e-05, "max_value": 9.9775e-01}, "num_gradient_steps": 0, "step_time": 9.2203e+00, "total_time": 2.1996e+01, "__timestamp": "2024-10-09 17:57:47.103666"}, {"step": 13000, "num_env_steps": 13000, "scores": {"n": 1, "mean": -2.1426e+02}, "actor_loss": {"n": 1, "mean": -3.0231e+01}, "entropy_coef_loss": {"n": 1, "mean": -8.7329e+00}, "critic_loss": {"n": 1, "mean": 1.2932e+00}, "entropy_coef": {"n": 1, "mean": 4.0776e-01}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 5.3993e-01, "std": 2.8847e-01, "min_value": 3.6740e-04, "max_value": 9.9833e-01}, "num_gradient_steps": 0, "step_time": 9.2342e+00, "total_time": 3.1230e+01, "__timestamp": "2024-10-09 17:57:56.338848"}, {"step": 14000, "num_env_steps": 14000, "scores": {"n": 1, "mean": -2.7501e+02}, "actor_loss": {"n": 1, "mean": -3.2213e+01}, "entropy_coef_loss": {"n": 1, "mean": -1.1591e+01}, "critic_loss": {"n": 1, "mean": 1.3920e+00}, "entropy_coef": {"n": 1, "mean": 3.0286e-01}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 5.4737e-01, "std": 2.9066e-01, "min_value": 5.2154e-07, "max_value": 9.9919e-01}, "num_gradient_steps": 0, "step_time": 9.1624e+00, "total_time": 4.0393e+01, "__timestamp": "2024-10-09 17:58:05.501233"}, {"step": 15000, "num_env_steps": 15000, "scores": {"n": 1, "mean": -1.7448e+02}, "actor_loss": {"n": 1, "mean": -3.2782e+01}, "entropy_coef_loss": {"n": 1, "mean": -1.3862e+01}, "critic_loss": {"n": 1, "mean": 1.7445e+00}, "entropy_coef": {"n": 1, "mean": 2.2588e-01}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 5.5599e-01, "std": 2.9101e-01, "min_value": 1.4102e-04, "max_value": 9.9962e-01}, "num_gradient_steps": 0, "step_time": 9.2422e+00, "total_time": 4.9635e+01, "__timestamp": "2024-10-09 17:58:14.742469"}, {"step": 16000, "num_env_steps": 16000, "scores": {"n": 1, "mean": -2.6478e+02}, "actor_loss": {"n": 1, "mean": -3.2695e+01}, "entropy_coef_loss": {"n": 1, "mean": -1.5578e+01}, "critic_loss": {"n": 1, "mean": 6.1855e+00}, "entropy_coef": {"n": 1, "mean": 1.6942e-01}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 5.6089e-01, "std": 2.9336e-01, "min_value": 1.6564e-04, "max_value": 9.9908e-01}, "num_gradient_steps": 0, "step_time": 9.2491e+00, "total_time": 5.8884e+01, "__timestamp": "2024-10-09 17:58:23.992587"}, {"step": 17000, "num_env_steps": 17000, "scores": {"n": 1, "mean": -2.7218e+02}, "actor_loss": {"n": 1, "mean": -3.2078e+01}, "entropy_coef_loss": {"n": 1, "mean": -1.6682e+01}, "critic_loss": {"n": 1, "mean": 1.8664e+00}, "entropy_coef": {"n": 1, "mean": 1.2775e-01}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 5.8011e-01, "std": 2.9391e-01, "min_value": 2.2304e-04, "max_value": 9.9890e-01}, "num_gradient_steps": 0, "step_time": 9.5893e+00, "total_time": 6.8473e+01, "__timestamp": "2024-10-09 17:58:33.580915"}, {"step": 18000, "num_env_steps": 18000, "scores": {"n": 1, "mean": -2.4348e+02}, "actor_loss": {"n": 1, "mean": -3.1564e+01}, "entropy_coef_loss": {"n": 1, "mean": -1.8115e+01}, "critic_loss": {"n": 1, "mean": 1.8617e+00}, "entropy_coef": {"n": 1, "mean": 9.6772e-02}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 5.8618e-01, "std": 2.9920e-01, "min_value": 5.4371e-04, "max_value": 9.9887e-01}, "num_gradient_steps": 0, "step_time": 9.5512e+00, "total_time": 7.8024e+01, "__timestamp": "2024-10-09 17:58:43.132092"}, {"step": 19000, "num_env_steps": 19000, "scores": {"n": 1, "mean": -2.8192e+02}, "actor_loss": {"n": 1, "mean": -2.9970e+01}, "entropy_coef_loss": {"n": 1, "mean": -1.8254e+01}, "critic_loss": {"n": 1, "mean": 1.5173e+00}, "entropy_coef": {"n": 1, "mean": 7.3647e-02}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 5.8591e-01, "std": 2.9754e-01, "min_value": 2.6178e-04, "max_value": 9.9881e-01}, "num_gradient_steps": 0, "step_time": 9.9601e+00, "total_time": 8.7984e+01, "__timestamp": "2024-10-09 17:58:53.093175"}, {"step": 20000, "num_env_steps": 20000, "scores": {"n": 1, "mean": -2.7774e+02}, "actor_loss": {"n": 1, "mean": -2.7715e+01}, "entropy_coef_loss": {"n": 1, "mean": -1.7390e+01}, "critic_loss": {"n": 1, "mean": 1.4011e+00}, "entropy_coef": {"n": 1, "mean": 5.6294e-02}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 6.0314e-01, "std": 2.9418e-01, "min_value": 4.8104e-04, "max_value": 9.9937e-01}, "num_gradient_steps": 0, "step_time": 1.0041e+01, "total_time": 9.8025e+01, "__timestamp": "2024-10-09 17:59:03.133779"}, {"step": 21000, "num_env_steps": 21000, "scores": {"n": 1, "mean": -1.2639e+02}, "actor_loss": {"n": 1, "mean": -2.6249e+01}, "entropy_coef_loss": {"n": 1, "mean": -1.6714e+01}, "critic_loss": {"n": 1, "mean": 1.1945e+00}, "entropy_coef": {"n": 1, "mean": 4.3284e-02}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 6.0762e-01, "std": 2.9429e-01, "min_value": 1.6861e-04, "max_value": 9.9952e-01}, "num_gradient_steps": 0, "step_time": 9.2185e+00, "total_time": 1.0724e+02, "__timestamp": "2024-10-09 17:59:12.351237"}, {"step": 22000, "num_env_steps": 22000, "scores": {"n": 1, "mean": -2.0177e+02}, "actor_loss": {"n": 1, "mean": -2.5794e+01}, "entropy_coef_loss": {"n": 1, "mean": -1.3759e+01}, "critic_loss": {"n": 1, "mean": 1.5902e+00}, "entropy_coef": {"n": 1, "mean": 3.3483e-02}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 6.0442e-01, "std": 3.0016e-01, "min_value": 1.6546e-04, "max_value": 9.9983e-01}, "num_gradient_steps": 0, "step_time": 9.6803e+00, "total_time": 1.1692e+02, "__timestamp": "2024-10-09 17:59:22.032497"}, {"step": 23000, "num_env_steps": 23000, "scores": {"n": 1, "mean": -2.3738e+02}, "actor_loss": {"n": 1, "mean": -2.4087e+01}, "entropy_coef_loss": {"n": 1, "mean": -1.3920e+01}, "critic_loss": {"n": 1, "mean": 1.3925e+00}, "entropy_coef": {"n": 1, "mean": 2.5995e-02}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 5.9533e-01, "std": 3.0083e-01, "min_value": 5.4610e-04, "max_value": 9.9979e-01}, "num_gradient_steps": 0, "step_time": 9.5195e+00, "total_time": 1.2644e+02, "__timestamp": "2024-10-09 17:59:31.552007"}, {"step": 24000, "num_env_steps": 24000, "scores": {"n": 1, "mean": -3.3095e+01}, "actor_loss": {"n": 1, "mean": -2.2386e+01}, "entropy_coef_loss": {"n": 1, "mean": -1.1962e+01}, "critic_loss": {"n": 1, "mean": 1.8451e+00}, "entropy_coef": {"n": 1, "mean": 2.0262e-02}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 5.8801e-01, "std": 2.9914e-01, "min_value": 2.0546e-04, "max_value": 9.9998e-01}, "num_gradient_steps": 0, "step_time": 9.8274e+00, "total_time": 1.3627e+02, "__timestamp": "2024-10-09 17:59:41.378416"}, {"step": 25000, "num_env_steps": 25000, "scores": {"n": 1, "mean": 2.4392e+02}, "actor_loss": {"n": 1, "mean": -2.2774e+01}, "entropy_coef_loss": {"n": 1, "mean": -1.0649e+01}, "critic_loss": {"n": 1, "mean": 1.6496e+00}, "entropy_coef": {"n": 1, "mean": 1.6083e-02}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 6.0852e-01, "std": 3.0553e-01, "min_value": 5.1896e-04, "max_value": 9.9997e-01}, "num_gradient_steps": 0, "step_time": 9.4152e+00, "total_time": 1.4569e+02, "__timestamp": "2024-10-09 17:59:50.794615"}, {"step": 26000, "num_env_steps": 26000, "scores": {"n": 1, "mean": 1.2736e+02}, "actor_loss": {"n": 1, "mean": -2.2703e+01}, "entropy_coef_loss": {"n": 1, "mean": -8.4560e+00}, "critic_loss": {"n": 1, "mean": 1.6728e+00}, "entropy_coef": {"n": 1, "mean": 1.2989e-02}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 5.9503e-01, "std": 3.0116e-01, "min_value": 1.6239e-04, "max_value": 9.9998e-01}, "num_gradient_steps": 0, "step_time": 9.6553e+00, "total_time": 1.5534e+02, "__timestamp": "2024-10-09 18:00:00.449921"}, {"step": 27000, "num_env_steps": 27000, "scores": {"n": 1, "mean": 4.7310e+01}, "actor_loss": {"n": 1, "mean": -2.1822e+01}, "entropy_coef_loss": {"n": 1, "mean": -1.9155e+00}, "critic_loss": {"n": 1, "mean": 1.6827e+00}, "entropy_coef": {"n": 1, "mean": 1.0950e-02}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 5.6030e-01, "std": 2.9925e-01, "min_value": 1.0545e-04, "max_value": 9.9985e-01}, "num_gradient_steps": 0, "step_time": 9.7362e+00, "total_time": 1.6508e+02, "__timestamp": "2024-10-09 18:00:10.185101"}, {"step": 28000, "num_env_steps": 28000, "scores": {"n": 1, "mean": 1.1742e+02}, "actor_loss": {"n": 1, "mean": -2.0981e+01}, "entropy_coef_loss": {"n": 1, "mean": -2.1038e+00}, "critic_loss": {"n": 1, "mean": 2.3351e+00}, "entropy_coef": {"n": 1, "mean": 9.7547e-03}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 6.0992e-01, "std": 3.0242e-01, "min_value": 3.7253e-07, "max_value": 1.0000e+00}, "num_gradient_steps": 0, "step_time": 9.7528e+00, "total_time": 1.7483e+02, "__timestamp": "2024-10-09 18:00:19.938863"}, {"step": 29000, "num_env_steps": 29000, "scores": {"n": 1, "mean": -2.4206e+02}, "actor_loss": {"n": 1, "mean": -1.9473e+01}, "entropy_coef_loss": {"n": 1, "mean": -8.8259e-01}, "critic_loss": {"n": 1, "mean": 1.8349e+00}, "entropy_coef": {"n": 1, "mean": 9.0774e-03}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 6.6564e-01, "std": 3.0001e-01, "min_value": 1.4581e-04, "max_value": 9.9999e-01}, "num_gradient_steps": 0, "step_time": 9.6293e+00, "total_time": 1.8446e+02, "__timestamp": "2024-10-09 18:00:29.568130"}, {"step": 30000, "num_env_steps": 30000, "scores": {"n": 1, "mean": 5.6672e+02}, "actor_loss": {"n": 1, "mean": -1.8833e+01}, "entropy_coef_loss": {"n": 1, "mean": -1.2502e+00}, "critic_loss": {"n": 1, "mean": 1.7742e+00}, "entropy_coef": {"n": 1, "mean": 8.5138e-03}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 6.4357e-01, "std": 3.0413e-01, "min_value": 4.7442e-04, "max_value": 9.9999e-01}, "num_gradient_steps": 0, "step_time": 9.3220e+00, "total_time": 1.9378e+02, "__timestamp": "2024-10-09 18:00:38.890115"}, {"step": 31000, "num_env_steps": 31000, "scores": {"n": 1, "mean": 3.4339e+01}, "actor_loss": {"n": 1, "mean": -1.8440e+01}, "entropy_coef_loss": {"n": 1, "mean": 1.5435e+00}, "critic_loss": {"n": 1, "mean": 1.6116e+00}, "entropy_coef": {"n": 1, "mean": 8.6639e-03}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 6.5019e-01, "std": 3.0316e-01, "min_value": 1.4526e-04, "max_value": 1.0000e+00}, "num_gradient_steps": 0, "step_time": 9.4991e+00, "total_time": 2.0328e+02, "__timestamp": "2024-10-09 18:00:48.389262"}, {"step": 32000, "num_env_steps": 32000, "scores": {"n": 1, "mean": 9.2178e+02}, "actor_loss": {"n": 1, "mean": -2.0742e+01}, "entropy_coef_loss": {"n": 1, "mean": 1.8573e+00}, "critic_loss": {"n": 1, "mean": 1.7088e+00}, "entropy_coef": {"n": 1, "mean": 9.4307e-03}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 6.8632e-01, "std": 3.0102e-01, "min_value": 1.1408e-03, "max_value": 1.0000e+00}, "num_gradient_steps": 0, "step_time": 9.4243e+00, "total_time": 2.1270e+02, "__timestamp": "2024-10-09 18:00:57.813565"}, {"step": 33000, "num_env_steps": 33000, "scores": {"n": 1, "mean": 1.2448e+03}, "actor_loss": {"n": 1, "mean": -1.9933e+01}, "entropy_coef_loss": {"n": 1, "mean": -4.9406e-01}, "critic_loss": {"n": 1, "mean": 1.7183e+00}, "entropy_coef": {"n": 1, "mean": 1.0111e-02}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 6.9375e-01, "std": 2.9816e-01, "min_value": 2.8226e-04, "max_value": 1.0000e+00}, "num_gradient_steps": 0, "step_time": 9.7618e+00, "total_time": 2.2247e+02, "__timestamp": "2024-10-09 18:01:07.574405"}, {"step": 34000, "num_env_steps": 34000, "scores": {"n": 1, "mean": 1.4926e+03}, "actor_loss": {"n": 1, "mean": -2.2063e+01}, "entropy_coef_loss": {"n": 1, "mean": 2.9850e+00}, "critic_loss": {"n": 1, "mean": 2.0976e+00}, "entropy_coef": {"n": 1, "mean": 1.1152e-02}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.0346e-01, "std": 2.9645e-01, "min_value": 1.0991e-04, "max_value": 9.9998e-01}, "num_gradient_steps": 0, "step_time": 9.3828e+00, "total_time": 2.3185e+02, "__timestamp": "2024-10-09 18:01:16.957231"}, {"step": 35000, "num_env_steps": 35000, "scores": {"n": 1, "mean": 1.5326e+03}, "actor_loss": {"n": 1, "mean": -2.3919e+01}, "entropy_coef_loss": {"n": 1, "mean": 1.0384e+00}, "critic_loss": {"n": 1, "mean": 2.2612e+00}, "entropy_coef": {"n": 1, "mean": 1.3557e-02}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.2450e-01, "std": 2.9095e-01, "min_value": 6.6516e-04, "max_value": 1.0000e+00}, "num_gradient_steps": 0, "step_time": 9.9462e+00, "total_time": 2.4180e+02, "__timestamp": "2024-10-09 18:01:26.903478"}, {"step": 36000, "num_env_steps": 36000, "scores": {"n": 1, "mean": -5.8312e+01}, "actor_loss": {"n": 1, "mean": -2.3895e+01}, "entropy_coef_loss": {"n": 1, "mean": -9.5223e-01}, "critic_loss": {"n": 1, "mean": 2.5374e+00}, "entropy_coef": {"n": 1, "mean": 1.4581e-02}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 6.6257e-01, "std": 2.9885e-01, "min_value": 9.2141e-05, "max_value": 1.0000e+00}, "num_gradient_steps": 0, "step_time": 9.6538e+00, "total_time": 2.5145e+02, "__timestamp": "2024-10-09 18:01:36.557325"}, {"step": 37000, "num_env_steps": 37000, "scores": {"n": 1, "mean": 1.6513e+03}, "actor_loss": {"n": 1, "mean": -2.4399e+01}, "entropy_coef_loss": {"n": 1, "mean": -1.1265e+00}, "critic_loss": {"n": 1, "mean": 2.4409e+00}, "entropy_coef": {"n": 1, "mean": 1.5269e-02}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.1340e-01, "std": 2.9508e-01, "min_value": 4.9776e-04, "max_value": 9.9998e-01}, "num_gradient_steps": 0, "step_time": 9.4766e+00, "total_time": 2.6093e+02, "__timestamp": "2024-10-09 18:01:46.033926"}, {"step": 38000, "num_env_steps": 38000, "scores": {"n": 1, "mean": 1.9083e+03}, "actor_loss": {"n": 1, "mean": -2.9695e+01}, "entropy_coef_loss": {"n": 1, "mean": 9.7679e-01}, "critic_loss": {"n": 1, "mean": 2.6313e+00}, "entropy_coef": {"n": 1, "mean": 1.6686e-02}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.0697e-01, "std": 2.9239e-01, "min_value": 1.4567e-04, "max_value": 1.0000e+00}, "num_gradient_steps": 0, "step_time": 9.3794e+00, "total_time": 2.7031e+02, "__timestamp": "2024-10-09 18:01:55.414375"}, {"step": 39000, "num_env_steps": 39000, "scores": {"n": 1, "mean": 8.2046e+01}, "actor_loss": {"n": 1, "mean": -3.1374e+01}, "entropy_coef_loss": {"n": 1, "mean": 1.2456e+00}, "critic_loss": {"n": 1, "mean": 3.1056e+00}, "entropy_coef": {"n": 1, "mean": 1.7717e-02}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 6.5164e-01, "std": 3.0284e-01, "min_value": 1.6707e-04, "max_value": 9.9999e-01}, "num_gradient_steps": 0, "step_time": 9.5949e+00, "total_time": 2.7990e+02, "__timestamp": "2024-10-09 18:02:05.009300"}, {"step": 40000, "num_env_steps": 40000, "scores": {"n": 1, "mean": 2.4380e+02}, "actor_loss": {"n": 1, "mean": -3.1655e+01}, "entropy_coef_loss": {"n": 1, "mean": 1.1579e+00}, "critic_loss": {"n": 1, "mean": 3.1669e+00}, "entropy_coef": {"n": 1, "mean": 1.8102e-02}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 6.4671e-01, "std": 3.0103e-01, "min_value": 5.4300e-04, "max_value": 9.9999e-01}, "num_gradient_steps": 0, "step_time": 9.8742e+00, "total_time": 2.8977e+02, "__timestamp": "2024-10-09 18:02:14.882531"}, {"step": 41000, "num_env_steps": 41000, "scores": {"n": 1, "mean": 1.0505e+02}, "actor_loss": {"n": 1, "mean": -2.9489e+01}, "entropy_coef_loss": {"n": 1, "mean": -2.1390e-01}, "critic_loss": {"n": 1, "mean": 2.7448e+00}, "entropy_coef": {"n": 1, "mean": 1.8655e-02}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 6.5206e-01, "std": 3.0441e-01, "min_value": 3.7110e-04, "max_value": 9.9999e-01}, "num_gradient_steps": 0, "step_time": 9.3497e+00, "total_time": 2.9912e+02, "__timestamp": "2024-10-09 18:02:24.232206"}, {"step": 42000, "num_env_steps": 42000, "scores": {"n": 1, "mean": 1.9482e+03}, "actor_loss": {"n": 1, "mean": -2.6087e+01}, "entropy_coef_loss": {"n": 1, "mean": 1.7364e-01}, "critic_loss": {"n": 1, "mean": 3.7812e+00}, "entropy_coef": {"n": 1, "mean": 2.0187e-02}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.1873e-01, "std": 2.9065e-01, "min_value": 2.7196e-04, "max_value": 1.0000e+00}, "num_gradient_steps": 0, "step_time": 9.7535e+00, "total_time": 3.0888e+02, "__timestamp": "2024-10-09 18:02:33.986748"}, {"step": 43000, "num_env_steps": 43000, "scores": {"n": 1, "mean": 2.0800e+03}, "actor_loss": {"n": 1, "mean": -3.7497e+01}, "entropy_coef_loss": {"n": 1, "mean": 1.7727e+00}, "critic_loss": {"n": 1, "mean": 1.0746e+01}, "entropy_coef": {"n": 1, "mean": 2.1640e-02}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.0871e-01, "std": 2.9756e-01, "min_value": 5.8825e-04, "max_value": 9.9999e-01}, "num_gradient_steps": 0, "step_time": 9.7964e+00, "total_time": 3.1867e+02, "__timestamp": "2024-10-09 18:02:43.783190"}, {"step": 44000, "num_env_steps": 44000, "scores": {"n": 1, "mean": 1.8769e+03}, "actor_loss": {"n": 1, "mean": -3.8294e+01}, "entropy_coef_loss": {"n": 1, "mean": -1.7038e+00}, "critic_loss": {"n": 1, "mean": 3.3548e+00}, "entropy_coef": {"n": 1, "mean": 2.2791e-02}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.2390e-01, "std": 2.9223e-01, "min_value": 2.7119e-04, "max_value": 9.9999e-01}, "num_gradient_steps": 0, "step_time": 9.5543e+00, "total_time": 3.2823e+02, "__timestamp": "2024-10-09 18:02:53.336520"}, {"step": 45000, "num_env_steps": 45000, "scores": {"n": 1, "mean": 2.0436e+03}, "actor_loss": {"n": 1, "mean": -3.6804e+01}, "entropy_coef_loss": {"n": 1, "mean": -5.6015e-01}, "critic_loss": {"n": 1, "mean": 4.3281e+00}, "entropy_coef": {"n": 1, "mean": 2.3778e-02}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.3104e-01, "std": 2.8882e-01, "min_value": 2.0316e-04, "max_value": 9.9997e-01}, "num_gradient_steps": 0, "step_time": 9.5075e+00, "total_time": 3.3774e+02, "__timestamp": "2024-10-09 18:03:02.844004"}, {"step": 46000, "num_env_steps": 46000, "scores": {"n": 1, "mean": 1.8673e+03}, "actor_loss": {"n": 1, "mean": -3.8280e+01}, "entropy_coef_loss": {"n": 1, "mean": 5.0502e-01}, "critic_loss": {"n": 1, "mean": 4.1317e+00}, "entropy_coef": {"n": 1, "mean": 2.4861e-02}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.1834e-01, "std": 2.9042e-01, "min_value": 7.8534e-04, "max_value": 9.9997e-01}, "num_gradient_steps": 0, "step_time": 9.6341e+00, "total_time": 3.4737e+02, "__timestamp": "2024-10-09 18:03:12.478056"}, {"step": 47000, "num_env_steps": 47000, "scores": {"n": 1, "mean": 2.1344e+03}, "actor_loss": {"n": 1, "mean": -4.3115e+01}, "entropy_coef_loss": {"n": 1, "mean": -6.9533e-01}, "critic_loss": {"n": 1, "mean": 5.0681e+00}, "entropy_coef": {"n": 1, "mean": 2.5301e-02}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.1882e-01, "std": 2.9323e-01, "min_value": 6.1086e-04, "max_value": 9.9996e-01}, "num_gradient_steps": 0, "step_time": 9.8034e+00, "total_time": 3.5717e+02, "__timestamp": "2024-10-09 18:03:22.282440"}, {"step": 48000, "num_env_steps": 48000, "scores": {"n": 1, "mean": 4.0405e+02}, "actor_loss": {"n": 1, "mean": -4.1741e+01}, "entropy_coef_loss": {"n": 1, "mean": -7.1998e-01}, "critic_loss": {"n": 1, "mean": 3.9939e+00}, "entropy_coef": {"n": 1, "mean": 2.6185e-02}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 6.7554e-01, "std": 2.9481e-01, "min_value": 2.1404e-04, "max_value": 1.0000e+00}, "num_gradient_steps": 0, "step_time": 9.5640e+00, "total_time": 3.6674e+02, "__timestamp": "2024-10-09 18:03:31.846483"}, {"step": 49000, "num_env_steps": 49000, "scores": {"n": 1, "mean": 2.2261e+03}, "actor_loss": {"n": 1, "mean": -4.6368e+01}, "entropy_coef_loss": {"n": 1, "mean": -1.9936e+00}, "critic_loss": {"n": 1, "mean": 5.0849e+00}, "entropy_coef": {"n": 1, "mean": 2.7112e-02}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.1707e-01, "std": 2.8762e-01, "min_value": 4.4994e-05, "max_value": 9.9995e-01}, "num_gradient_steps": 0, "step_time": 9.3432e+00, "total_time": 3.7608e+02, "__timestamp": "2024-10-09 18:03:41.188664"}, {"step": 50000, "num_env_steps": 50000, "scores": {"n": 1, "mean": 2.3209e+03}, "actor_loss": {"n": 1, "mean": -5.1047e+01}, "entropy_coef_loss": {"n": 1, "mean": 5.3722e-01}, "critic_loss": {"n": 1, "mean": 5.8727e+00}, "entropy_coef": {"n": 1, "mean": 2.6989e-02}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.0392e-01, "std": 2.9630e-01, "min_value": 2.2978e-04, "max_value": 9.9998e-01}, "num_gradient_steps": 0, "step_time": 9.7451e+00, "total_time": 3.8583e+02, "__timestamp": "2024-10-09 18:03:50.934717"}, {"step": 51000, "num_env_steps": 51000, "scores": {"n": 1, "mean": 2.1904e+03}, "actor_loss": {"n": 1, "mean": -5.2056e+01}, "entropy_coef_loss": {"n": 1, "mean": 1.6915e+00}, "critic_loss": {"n": 1, "mean": 4.5313e+00}, "entropy_coef": {"n": 1, "mean": 2.7879e-02}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 6.9998e-01, "std": 3.0029e-01, "min_value": 1.8704e-04, "max_value": 9.9997e-01}, "num_gradient_steps": 0, "step_time": 9.4796e+00, "total_time": 3.9531e+02, "__timestamp": "2024-10-09 18:04:00.414288"}, {"step": 52000, "num_env_steps": 52000, "scores": {"n": 1, "mean": 2.5613e+03}, "actor_loss": {"n": 1, "mean": -5.7868e+01}, "entropy_coef_loss": {"n": 1, "mean": -2.6743e-01}, "critic_loss": {"n": 1, "mean": 5.9839e+00}, "entropy_coef": {"n": 1, "mean": 3.0627e-02}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.1040e-01, "std": 2.9379e-01, "min_value": 1.1671e-04, "max_value": 9.9995e-01}, "num_gradient_steps": 0, "step_time": 9.6670e+00, "total_time": 4.0497e+02, "__timestamp": "2024-10-09 18:04:10.081262"}, {"step": 53000, "num_env_steps": 53000, "scores": {"n": 1, "mean": 2.4617e+03}, "actor_loss": {"n": 1, "mean": -6.2994e+01}, "entropy_coef_loss": {"n": 1, "mean": 6.0321e-01}, "critic_loss": {"n": 1, "mean": 5.8880e+00}, "entropy_coef": {"n": 1, "mean": 3.0984e-02}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.1434e-01, "std": 2.9071e-01, "min_value": 8.1360e-06, "max_value": 1.0000e+00}, "num_gradient_steps": 0, "step_time": 9.5222e+00, "total_time": 4.1449e+02, "__timestamp": "2024-10-09 18:04:19.602492"}, {"step": 54000, "num_env_steps": 54000, "scores": {"n": 1, "mean": 2.4830e+03}, "actor_loss": {"n": 1, "mean": -6.5218e+01}, "entropy_coef_loss": {"n": 1, "mean": 4.8067e-01}, "critic_loss": {"n": 1, "mean": 5.1245e+00}, "entropy_coef": {"n": 1, "mean": 3.2411e-02}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.2068e-01, "std": 2.9058e-01, "min_value": 1.7375e-05, "max_value": 9.9999e-01}, "num_gradient_steps": 0, "step_time": 9.3407e+00, "total_time": 4.2384e+02, "__timestamp": "2024-10-09 18:04:28.944233"}, {"step": 55000, "num_env_steps": 55000, "scores": {"n": 1, "mean": 2.5587e+03}, "actor_loss": {"n": 1, "mean": -5.7557e+01}, "entropy_coef_loss": {"n": 1, "mean": 8.1394e-01}, "critic_loss": {"n": 1, "mean": 5.0281e+01}, "entropy_coef": {"n": 1, "mean": 3.2207e-02}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.1550e-01, "std": 2.8839e-01, "min_value": 1.1602e-04, "max_value": 9.9998e-01}, "num_gradient_steps": 0, "step_time": 9.2084e+00, "total_time": 4.3304e+02, "__timestamp": "2024-10-09 18:04:38.152593"}, {"step": 56000, "num_env_steps": 56000, "scores": {"n": 1, "mean": 2.5835e+03}, "actor_loss": {"n": 1, "mean": -6.7413e+01}, "entropy_coef_loss": {"n": 1, "mean": 3.3645e-01}, "critic_loss": {"n": 1, "mean": 5.0326e+00}, "entropy_coef": {"n": 1, "mean": 3.3150e-02}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 6.9794e-01, "std": 2.9622e-01, "min_value": 3.5688e-05, "max_value": 9.9999e-01}, "num_gradient_steps": 0, "step_time": 9.5315e+00, "total_time": 4.4258e+02, "__timestamp": "2024-10-09 18:04:47.683070"}, {"step": 57000, "num_env_steps": 57000, "scores": {"n": 1, "mean": 2.3797e+03}, "actor_loss": {"n": 1, "mean": -6.7316e+01}, "entropy_coef_loss": {"n": 1, "mean": 9.2171e-01}, "critic_loss": {"n": 1, "mean": 5.8892e+00}, "entropy_coef": {"n": 1, "mean": 3.4002e-02}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.2278e-01, "std": 2.9090e-01, "min_value": 3.6770e-04, "max_value": 9.9999e-01}, "num_gradient_steps": 0, "step_time": 9.7248e+00, "total_time": 4.5230e+02, "__timestamp": "2024-10-09 18:04:57.408909"}, {"step": 58000, "num_env_steps": 58000, "scores": {"n": 1, "mean": 2.7488e+03}, "actor_loss": {"n": 1, "mean": -7.5670e+01}, "entropy_coef_loss": {"n": 1, "mean": -2.9815e-01}, "critic_loss": {"n": 1, "mean": 1.6556e+01}, "entropy_coef": {"n": 1, "mean": 3.3989e-02}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.1420e-01, "std": 2.9187e-01, "min_value": 1.2192e-04, "max_value": 9.9999e-01}, "num_gradient_steps": 0, "step_time": 9.3152e+00, "total_time": 4.6162e+02, "__timestamp": "2024-10-09 18:05:06.723096"}, {"step": 59000, "num_env_steps": 59000, "scores": {"n": 1, "mean": 2.7439e+03}, "actor_loss": {"n": 1, "mean": -7.8529e+01}, "entropy_coef_loss": {"n": 1, "mean": -5.5391e-01}, "critic_loss": {"n": 1, "mean": 6.6003e+00}, "entropy_coef": {"n": 1, "mean": 3.5726e-02}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.2387e-01, "std": 2.9109e-01, "min_value": 2.1574e-04, "max_value": 9.9997e-01}, "num_gradient_steps": 0, "step_time": 9.4983e+00, "total_time": 4.7111e+02, "__timestamp": "2024-10-09 18:05:16.222398"}, {"step": 60000, "num_env_steps": 60000, "scores": {"n": 1, "mean": 2.8763e+03}, "actor_loss": {"n": 1, "mean": -7.4133e+01}, "entropy_coef_loss": {"n": 1, "mean": 3.8778e-01}, "critic_loss": {"n": 1, "mean": 9.6644e+01}, "entropy_coef": {"n": 1, "mean": 3.6908e-02}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.2232e-01, "std": 2.9055e-01, "min_value": 1.3218e-04, "max_value": 9.9999e-01}, "num_gradient_steps": 0, "step_time": 9.1101e+00, "total_time": 4.8022e+02, "__timestamp": "2024-10-09 18:05:25.331516"}, {"step": 61000, "num_env_steps": 61000, "scores": {"n": 1, "mean": 2.4037e+03}, "actor_loss": {"n": 1, "mean": -8.3392e+01}, "entropy_coef_loss": {"n": 1, "mean": 5.2910e-01}, "critic_loss": {"n": 1, "mean": 8.6362e+00}, "entropy_coef": {"n": 1, "mean": 3.7296e-02}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.1835e-01, "std": 2.9208e-01, "min_value": 3.9013e-05, "max_value": 1.0000e+00}, "num_gradient_steps": 0, "step_time": 9.1741e+00, "total_time": 4.8940e+02, "__timestamp": "2024-10-09 18:05:34.505658"}, {"step": 62000, "num_env_steps": 62000, "scores": {"n": 1, "mean": 2.6708e+03}, "actor_loss": {"n": 1, "mean": -8.3720e+01}, "entropy_coef_loss": {"n": 1, "mean": -7.0390e-01}, "critic_loss": {"n": 1, "mean": 7.6215e+00}, "entropy_coef": {"n": 1, "mean": 3.8943e-02}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.3082e-01, "std": 2.8887e-01, "min_value": 4.2677e-05, "max_value": 1.0000e+00}, "num_gradient_steps": 0, "step_time": 9.7495e+00, "total_time": 4.9915e+02, "__timestamp": "2024-10-09 18:05:44.256196"}, {"step": 63000, "num_env_steps": 63000, "scores": {"n": 1, "mean": 2.9340e+03}, "actor_loss": {"n": 1, "mean": -8.5093e+01}, "entropy_coef_loss": {"n": 1, "mean": 7.1277e-01}, "critic_loss": {"n": 1, "mean": 8.5027e+00}, "entropy_coef": {"n": 1, "mean": 3.9121e-02}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.2265e-01, "std": 2.8791e-01, "min_value": 1.8296e-04, "max_value": 9.9998e-01}, "num_gradient_steps": 0, "step_time": 9.6061e+00, "total_time": 5.0875e+02, "__timestamp": "2024-10-09 18:05:53.862327"}, {"step": 64000, "num_env_steps": 64000, "scores": {"n": 1, "mean": 2.7378e+03}, "actor_loss": {"n": 1, "mean": -8.5114e+01}, "entropy_coef_loss": {"n": 1, "mean": -1.0230e+00}, "critic_loss": {"n": 1, "mean": 7.0649e+01}, "entropy_coef": {"n": 1, "mean": 3.9469e-02}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.1847e-01, "std": 2.9061e-01, "min_value": 2.1791e-04, "max_value": 9.9997e-01}, "num_gradient_steps": 0, "step_time": 9.6375e+00, "total_time": 5.1839e+02, "__timestamp": "2024-10-09 18:06:03.498820"}, {"step": 65000, "num_env_steps": 65000, "scores": {"n": 1, "mean": 2.9682e+03}, "actor_loss": {"n": 1, "mean": -8.9995e+01}, "entropy_coef_loss": {"n": 1, "mean": 2.2134e-01}, "critic_loss": {"n": 1, "mean": 6.9177e+00}, "entropy_coef": {"n": 1, "mean": 4.0214e-02}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.2637e-01, "std": 2.8470e-01, "min_value": 1.6950e-04, "max_value": 9.9998e-01}, "num_gradient_steps": 0, "step_time": 9.3567e+00, "total_time": 5.2775e+02, "__timestamp": "2024-10-09 18:06:12.856513"}, {"step": 66000, "num_env_steps": 66000, "scores": {"n": 1, "mean": 2.9455e+03}, "actor_loss": {"n": 1, "mean": -9.0335e+01}, "entropy_coef_loss": {"n": 1, "mean": -1.4627e+00}, "critic_loss": {"n": 1, "mean": 7.8928e+00}, "entropy_coef": {"n": 1, "mean": 4.1605e-02}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.2741e-01, "std": 2.8749e-01, "min_value": 8.3629e-05, "max_value": 1.0000e+00}, "num_gradient_steps": 0, "step_time": 9.3418e+00, "total_time": 5.3709e+02, "__timestamp": "2024-10-09 18:06:22.197279"}, {"step": 67000, "num_env_steps": 67000, "scores": {"n": 1, "mean": 3.0345e+03}, "actor_loss": {"n": 1, "mean": -9.7462e+01}, "entropy_coef_loss": {"n": 1, "mean": 7.7433e-01}, "critic_loss": {"n": 1, "mean": 7.4452e+00}, "entropy_coef": {"n": 1, "mean": 4.2712e-02}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.2184e-01, "std": 2.8984e-01, "min_value": 1.8263e-04, "max_value": 9.9999e-01}, "num_gradient_steps": 0, "step_time": 9.2875e+00, "total_time": 5.4638e+02, "__timestamp": "2024-10-09 18:06:31.485777"}, {"step": 68000, "num_env_steps": 68000, "scores": {"n": 1, "mean": 2.9050e+03}, "actor_loss": {"n": 1, "mean": -9.8485e+01}, "entropy_coef_loss": {"n": 1, "mean": 1.3880e+00}, "critic_loss": {"n": 1, "mean": 1.1228e+01}, "entropy_coef": {"n": 1, "mean": 4.2443e-02}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.2335e-01, "std": 2.8965e-01, "min_value": 1.6904e-04, "max_value": 9.9996e-01}, "num_gradient_steps": 0, "step_time": 9.2626e+00, "total_time": 5.5564e+02, "__timestamp": "2024-10-09 18:06:40.747327"}, {"step": 69000, "num_env_steps": 69000, "scores": {"n": 1, "mean": 2.9568e+03}, "actor_loss": {"n": 1, "mean": -1.0487e+02}, "entropy_coef_loss": {"n": 1, "mean": -8.3523e-02}, "critic_loss": {"n": 1, "mean": 2.2470e+01}, "entropy_coef": {"n": 1, "mean": 4.4735e-02}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.2481e-01, "std": 2.9080e-01, "min_value": 1.1390e-04, "max_value": 9.9999e-01}, "num_gradient_steps": 0, "step_time": 9.2920e+00, "total_time": 5.6493e+02, "__timestamp": "2024-10-09 18:06:50.039291"}, {"step": 70000, "num_env_steps": 70000, "scores": {"n": 1, "mean": 2.4813e+03}, "actor_loss": {"n": 1, "mean": -1.0510e+02}, "entropy_coef_loss": {"n": 1, "mean": 1.1042e+00}, "critic_loss": {"n": 1, "mean": 8.5764e+00}, "entropy_coef": {"n": 1, "mean": 4.5308e-02}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.2060e-01, "std": 2.8872e-01, "min_value": 3.8147e-06, "max_value": 1.0000e+00}, "num_gradient_steps": 0, "step_time": 9.2691e+00, "total_time": 5.7420e+02, "__timestamp": "2024-10-09 18:06:59.309440"}, {"step": 71000, "num_env_steps": 71000, "scores": {"n": 1, "mean": 1.3615e+03}, "actor_loss": {"n": 1, "mean": -1.0993e+02}, "entropy_coef_loss": {"n": 1, "mean": -3.7534e-01}, "critic_loss": {"n": 1, "mean": 1.2055e+01}, "entropy_coef": {"n": 1, "mean": 4.7457e-02}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 6.9230e-01, "std": 2.9408e-01, "min_value": 1.3613e-03, "max_value": 1.0000e+00}, "num_gradient_steps": 0, "step_time": 9.3610e+00, "total_time": 5.8356e+02, "__timestamp": "2024-10-09 18:07:08.670485"}, {"step": 72000, "num_env_steps": 72000, "scores": {"n": 1, "mean": 3.9776e+02}, "actor_loss": {"n": 1, "mean": -1.1391e+02}, "entropy_coef_loss": {"n": 1, "mean": 9.7263e-01}, "critic_loss": {"n": 1, "mean": 1.0674e+01}, "entropy_coef": {"n": 1, "mean": 4.5946e-02}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 6.7938e-01, "std": 2.9685e-01, "min_value": 1.2591e-04, "max_value": 9.9999e-01}, "num_gradient_steps": 0, "step_time": 9.7165e+00, "total_time": 5.9328e+02, "__timestamp": "2024-10-09 18:07:18.386943"}, {"step": 73000, "num_env_steps": 73000, "scores": {"n": 1, "mean": 3.1735e+03}, "actor_loss": {"n": 1, "mean": -1.0738e+02}, "entropy_coef_loss": {"n": 1, "mean": 6.6073e-01}, "critic_loss": {"n": 1, "mean": 1.0761e+01}, "entropy_coef": {"n": 1, "mean": 4.5074e-02}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.2820e-01, "std": 2.8535e-01, "min_value": 2.1079e-03, "max_value": 9.9999e-01}, "num_gradient_steps": 0, "step_time": 9.2183e+00, "total_time": 6.0250e+02, "__timestamp": "2024-10-09 18:07:27.604259"}, {"step": 74000, "num_env_steps": 74000, "scores": {"n": 1, "mean": 3.1672e+03}, "actor_loss": {"n": 1, "mean": -1.1460e+02}, "entropy_coef_loss": {"n": 1, "mean": -5.0455e-02}, "critic_loss": {"n": 1, "mean": 1.0346e+01}, "entropy_coef": {"n": 1, "mean": 4.6775e-02}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.2941e-01, "std": 2.8666e-01, "min_value": 1.1118e-04, "max_value": 1.0000e+00}, "num_gradient_steps": 0, "step_time": 9.7614e+00, "total_time": 6.1226e+02, "__timestamp": "2024-10-09 18:07:37.365657"}, {"step": 75000, "num_env_steps": 75000, "scores": {"n": 1, "mean": 3.1049e+03}, "actor_loss": {"n": 1, "mean": -1.1187e+02}, "entropy_coef_loss": {"n": 1, "mean": 9.3743e-01}, "critic_loss": {"n": 1, "mean": 1.5990e+01}, "entropy_coef": {"n": 1, "mean": 4.6817e-02}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.2565e-01, "std": 2.8526e-01, "min_value": 6.9674e-05, "max_value": 9.9999e-01}, "num_gradient_steps": 0, "step_time": 9.4583e+00, "total_time": 6.2172e+02, "__timestamp": "2024-10-09 18:07:46.823989"}, {"step": 76000, "num_env_steps": 76000, "scores": {"n": 1, "mean": 2.9563e+03}, "actor_loss": {"n": 1, "mean": -1.1415e+02}, "entropy_coef_loss": {"n": 1, "mean": 1.3331e-01}, "critic_loss": {"n": 1, "mean": 9.5340e+00}, "entropy_coef": {"n": 1, "mean": 4.7119e-02}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.2795e-01, "std": 2.8357e-01, "min_value": 1.3985e-03, "max_value": 9.9999e-01}, "num_gradient_steps": 0, "step_time": 9.7348e+00, "total_time": 6.3145e+02, "__timestamp": "2024-10-09 18:07:56.558817"}, {"step": 77000, "num_env_steps": 77000, "scores": {"n": 1, "mean": 2.9825e+03}, "actor_loss": {"n": 1, "mean": -1.1258e+02}, "entropy_coef_loss": {"n": 1, "mean": -7.4367e-01}, "critic_loss": {"n": 1, "mean": 8.9551e+00}, "entropy_coef": {"n": 1, "mean": 4.8473e-02}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.3151e-01, "std": 2.8656e-01, "min_value": 1.0772e-03, "max_value": 9.9998e-01}, "num_gradient_steps": 0, "step_time": 9.3326e+00, "total_time": 6.4078e+02, "__timestamp": "2024-10-09 18:08:05.892443"}, {"step": 78000, "num_env_steps": 78000, "scores": {"n": 1, "mean": 2.9790e+03}, "actor_loss": {"n": 1, "mean": -1.2395e+02}, "entropy_coef_loss": {"n": 1, "mean": 7.8171e-01}, "critic_loss": {"n": 1, "mean": 1.1746e+01}, "entropy_coef": {"n": 1, "mean": 4.9785e-02}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.3526e-01, "std": 2.8088e-01, "min_value": 1.6104e-03, "max_value": 9.9998e-01}, "num_gradient_steps": 0, "step_time": 1.0535e+01, "total_time": 6.5132e+02, "__timestamp": "2024-10-09 18:08:16.427275"}, {"step": 79000, "num_env_steps": 79000, "scores": {"n": 1, "mean": 3.0800e+03}, "actor_loss": {"n": 1, "mean": -1.1758e+02}, "entropy_coef_loss": {"n": 1, "mean": -9.3641e-02}, "critic_loss": {"n": 1, "mean": 4.4599e+01}, "entropy_coef": {"n": 1, "mean": 5.0521e-02}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.3508e-01, "std": 2.8483e-01, "min_value": 3.2957e-04, "max_value": 9.9998e-01}, "num_gradient_steps": 0, "step_time": 1.0288e+01, "total_time": 6.6161e+02, "__timestamp": "2024-10-09 18:08:26.714799"}, {"step": 80000, "num_env_steps": 80000, "scores": {"n": 1, "mean": 2.9650e+03}, "actor_loss": {"n": 1, "mean": -1.2393e+02}, "entropy_coef_loss": {"n": 1, "mean": 5.9771e-01}, "critic_loss": {"n": 1, "mean": 1.1377e+01}, "entropy_coef": {"n": 1, "mean": 5.1315e-02}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.3372e-01, "std": 2.8417e-01, "min_value": 6.6400e-05, "max_value": 1.0000e+00}, "num_gradient_steps": 0, "step_time": 9.3886e+00, "total_time": 6.7099e+02, "__timestamp": "2024-10-09 18:08:36.102358"}, {"step": 81000, "num_env_steps": 81000, "scores": {"n": 1, "mean": 3.5410e+03}, "actor_loss": {"n": 1, "mean": -1.2284e+02}, "entropy_coef_loss": {"n": 1, "mean": -1.5213e-01}, "critic_loss": {"n": 1, "mean": 1.4728e+01}, "entropy_coef": {"n": 1, "mean": 5.1158e-02}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.3957e-01, "std": 2.8163e-01, "min_value": 1.0679e-04, "max_value": 9.9998e-01}, "num_gradient_steps": 0, "step_time": 9.4773e+00, "total_time": 6.8047e+02, "__timestamp": "2024-10-09 18:08:45.580637"}, {"step": 82000, "num_env_steps": 82000, "scores": {"n": 1, "mean": 3.6520e+03}, "actor_loss": {"n": 1, "mean": -1.3151e+02}, "entropy_coef_loss": {"n": 1, "mean": 1.4181e+00}, "critic_loss": {"n": 1, "mean": 1.1480e+01}, "entropy_coef": {"n": 1, "mean": 5.0939e-02}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.2179e-01, "std": 2.9373e-01, "min_value": 1.7637e-03, "max_value": 9.9999e-01}, "num_gradient_steps": 0, "step_time": 9.5836e+00, "total_time": 6.9006e+02, "__timestamp": "2024-10-09 18:08:55.163248"}, {"step": 83000, "num_env_steps": 83000, "scores": {"n": 1, "mean": 3.1637e+03}, "actor_loss": {"n": 1, "mean": -1.2928e+02}, "entropy_coef_loss": {"n": 1, "mean": 4.4034e-01}, "critic_loss": {"n": 1, "mean": 1.1201e+01}, "entropy_coef": {"n": 1, "mean": 5.2324e-02}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.2973e-01, "std": 2.8737e-01, "min_value": 1.5631e-04, "max_value": 9.9998e-01}, "num_gradient_steps": 0, "step_time": 9.4899e+00, "total_time": 6.9955e+02, "__timestamp": "2024-10-09 18:09:04.653197"}, {"step": 84000, "num_env_steps": 84000, "scores": {"n": 1, "mean": 3.2224e+03}, "actor_loss": {"n": 1, "mean": -1.3395e+02}, "entropy_coef_loss": {"n": 1, "mean": -2.7670e-04}, "critic_loss": {"n": 1, "mean": 1.0794e+01}, "entropy_coef": {"n": 1, "mean": 5.4832e-02}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.3646e-01, "std": 2.8384e-01, "min_value": 3.7193e-05, "max_value": 9.9999e-01}, "num_gradient_steps": 0, "step_time": 9.4429e+00, "total_time": 7.0899e+02, "__timestamp": "2024-10-09 18:09:14.097048"}, {"step": 85000, "num_env_steps": 85000, "scores": {"n": 1, "mean": 3.3517e+03}, "actor_loss": {"n": 1, "mean": -1.3257e+02}, "entropy_coef_loss": {"n": 1, "mean": -3.9608e-01}, "critic_loss": {"n": 1, "mean": 1.2762e+01}, "entropy_coef": {"n": 1, "mean": 5.4601e-02}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.3633e-01, "std": 2.8183e-01, "min_value": 2.7398e-04, "max_value": 1.0000e+00}, "num_gradient_steps": 0, "step_time": 9.3638e+00, "total_time": 7.1835e+02, "__timestamp": "2024-10-09 18:09:23.459831"}, {"step": 86000, "num_env_steps": 86000, "scores": {"n": 1, "mean": 3.3983e+03}, "actor_loss": {"n": 1, "mean": -1.3000e+02}, "entropy_coef_loss": {"n": 1, "mean": -5.7802e-01}, "critic_loss": {"n": 1, "mean": 1.0253e+01}, "entropy_coef": {"n": 1, "mean": 5.3582e-02}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.4267e-01, "std": 2.8238e-01, "min_value": 2.2724e-05, "max_value": 9.9999e-01}, "num_gradient_steps": 0, "step_time": 9.5171e+00, "total_time": 7.2787e+02, "__timestamp": "2024-10-09 18:09:32.976911"}, {"step": 87000, "num_env_steps": 87000, "scores": {"n": 1, "mean": 3.5241e+03}, "actor_loss": {"n": 1, "mean": -1.3328e+02}, "entropy_coef_loss": {"n": 1, "mean": 5.4694e-01}, "critic_loss": {"n": 1, "mean": 1.1105e+01}, "entropy_coef": {"n": 1, "mean": 5.5229e-02}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.3842e-01, "std": 2.8461e-01, "min_value": 5.8830e-05, "max_value": 9.9998e-01}, "num_gradient_steps": 0, "step_time": 9.6011e+00, "total_time": 7.3747e+02, "__timestamp": "2024-10-09 18:09:42.578052"}, {"step": 88000, "num_env_steps": 88000, "scores": {"n": 1, "mean": 3.4825e+03}, "actor_loss": {"n": 1, "mean": -1.3958e+02}, "entropy_coef_loss": {"n": 1, "mean": 1.8198e+00}, "critic_loss": {"n": 1, "mean": 1.3254e+01}, "entropy_coef": {"n": 1, "mean": 5.5348e-02}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.2947e-01, "std": 2.8544e-01, "min_value": 1.5676e-04, "max_value": 9.9995e-01}, "num_gradient_steps": 0, "step_time": 9.5546e+00, "total_time": 7.4702e+02, "__timestamp": "2024-10-09 18:09:52.132696"}, {"step": 89000, "num_env_steps": 89000, "scores": {"n": 1, "mean": 3.1712e+03}, "actor_loss": {"n": 1, "mean": -1.4534e+02}, "entropy_coef_loss": {"n": 1, "mean": -1.4751e+00}, "critic_loss": {"n": 1, "mean": 1.1757e+01}, "entropy_coef": {"n": 1, "mean": 5.7495e-02}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.4138e-01, "std": 2.8348e-01, "min_value": 3.4294e-04, "max_value": 9.9997e-01}, "num_gradient_steps": 0, "step_time": 9.5450e+00, "total_time": 7.5657e+02, "__timestamp": "2024-10-09 18:10:01.678655"}, {"step": 90000, "num_env_steps": 90000, "scores": {"n": 1, "mean": 3.6535e+03}, "actor_loss": {"n": 1, "mean": -1.3915e+02}, "entropy_coef_loss": {"n": 1, "mean": 8.8572e-01}, "critic_loss": {"n": 1, "mean": 1.3960e+01}, "entropy_coef": {"n": 1, "mean": 5.8542e-02}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.3359e-01, "std": 2.8480e-01, "min_value": 8.1931e-04, "max_value": 9.9998e-01}, "num_gradient_steps": 0, "step_time": 9.6344e+00, "total_time": 7.6620e+02, "__timestamp": "2024-10-09 18:10:11.313090"}, {"step": 91000, "num_env_steps": 91000, "scores": {"n": 1, "mean": 3.6891e+03}, "actor_loss": {"n": 1, "mean": -1.4857e+02}, "entropy_coef_loss": {"n": 1, "mean": -5.8991e-01}, "critic_loss": {"n": 1, "mean": 1.2395e+01}, "entropy_coef": {"n": 1, "mean": 5.8615e-02}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.3837e-01, "std": 2.8333e-01, "min_value": 2.1454e-03, "max_value": 9.9998e-01}, "num_gradient_steps": 0, "step_time": 1.0939e+01, "total_time": 7.7714e+02, "__timestamp": "2024-10-09 18:10:22.252128"}, {"step": 92000, "num_env_steps": 92000, "scores": {"n": 1, "mean": 3.5259e+03}, "actor_loss": {"n": 1, "mean": -1.4281e+02}, "entropy_coef_loss": {"n": 1, "mean": 1.2196e+00}, "critic_loss": {"n": 1, "mean": 1.1329e+02}, "entropy_coef": {"n": 1, "mean": 6.0386e-02}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.4299e-01, "std": 2.8132e-01, "min_value": 7.3944e-04, "max_value": 9.9991e-01}, "num_gradient_steps": 0, "step_time": 1.0122e+01, "total_time": 7.8727e+02, "__timestamp": "2024-10-09 18:10:32.372877"}, {"step": 93000, "num_env_steps": 93000, "scores": {"n": 1, "mean": 3.5090e+03}, "actor_loss": {"n": 1, "mean": -1.4559e+02}, "entropy_coef_loss": {"n": 1, "mean": 1.4570e-01}, "critic_loss": {"n": 1, "mean": 1.2492e+01}, "entropy_coef": {"n": 1, "mean": 5.8611e-02}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.3546e-01, "std": 2.8411e-01, "min_value": 1.7074e-04, "max_value": 9.9998e-01}, "num_gradient_steps": 0, "step_time": 9.7030e+00, "total_time": 7.9697e+02, "__timestamp": "2024-10-09 18:10:42.075893"}, {"step": 94000, "num_env_steps": 94000, "scores": {"n": 1, "mean": 3.7822e+03}, "actor_loss": {"n": 1, "mean": -1.5187e+02}, "entropy_coef_loss": {"n": 1, "mean": 7.2738e-01}, "critic_loss": {"n": 1, "mean": 1.8205e+01}, "entropy_coef": {"n": 1, "mean": 5.8382e-02}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.3612e-01, "std": 2.8144e-01, "min_value": 7.1466e-04, "max_value": 1.0000e+00}, "num_gradient_steps": 0, "step_time": 1.0586e+01, "total_time": 8.0755e+02, "__timestamp": "2024-10-09 18:10:52.663139"}, {"step": 95000, "num_env_steps": 95000, "scores": {"n": 1, "mean": 3.7803e+03}, "actor_loss": {"n": 1, "mean": -1.5055e+02}, "entropy_coef_loss": {"n": 1, "mean": 1.8026e-01}, "critic_loss": {"n": 1, "mean": 1.5459e+01}, "entropy_coef": {"n": 1, "mean": 5.8567e-02}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.3787e-01, "std": 2.8389e-01, "min_value": 1.0939e-03, "max_value": 9.9993e-01}, "num_gradient_steps": 0, "step_time": 1.0533e+01, "total_time": 8.1809e+02, "__timestamp": "2024-10-09 18:11:03.196363"}, {"step": 96000, "num_env_steps": 96000, "scores": {"n": 1, "mean": 3.7445e+03}, "actor_loss": {"n": 1, "mean": -1.5355e+02}, "entropy_coef_loss": {"n": 1, "mean": 7.9931e-01}, "critic_loss": {"n": 1, "mean": 1.0417e+01}, "entropy_coef": {"n": 1, "mean": 6.1019e-02}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.3439e-01, "std": 2.8598e-01, "min_value": 1.3422e-03, "max_value": 9.9995e-01}, "num_gradient_steps": 0, "step_time": 1.0858e+01, "total_time": 8.2895e+02, "__timestamp": "2024-10-09 18:11:14.054803"}, {"step": 97000, "num_env_steps": 97000, "scores": {"n": 1, "mean": 3.5928e+03}, "actor_loss": {"n": 1, "mean": -1.5845e+02}, "entropy_coef_loss": {"n": 1, "mean": -1.1074e+00}, "critic_loss": {"n": 1, "mean": 1.4086e+01}, "entropy_coef": {"n": 1, "mean": 6.2721e-02}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.4508e-01, "std": 2.7818e-01, "min_value": 2.5219e-04, "max_value": 9.9993e-01}, "num_gradient_steps": 0, "step_time": 1.0970e+01, "total_time": 8.3992e+02, "__timestamp": "2024-10-09 18:11:25.024612"}, {"step": 98000, "num_env_steps": 98000, "scores": {"n": 1, "mean": 4.0121e+03}, "actor_loss": {"n": 1, "mean": -1.5434e+02}, "entropy_coef_loss": {"n": 1, "mean": 2.2835e-01}, "critic_loss": {"n": 1, "mean": 1.1978e+01}, "entropy_coef": {"n": 1, "mean": 6.3708e-02}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.5511e-01, "std": 2.7607e-01, "min_value": 2.1040e-05, "max_value": 9.9995e-01}, "num_gradient_steps": 0, "step_time": 1.0465e+01, "total_time": 8.5038e+02, "__timestamp": "2024-10-09 18:11:35.489013"}, {"step": 99000, "num_env_steps": 99000, "scores": {"n": 1, "mean": 3.8536e+03}, "actor_loss": {"n": 1, "mean": -1.5810e+02}, "entropy_coef_loss": {"n": 1, "mean": -2.9452e-01}, "critic_loss": {"n": 1, "mean": 1.1082e+01}, "entropy_coef": {"n": 1, "mean": 6.3809e-02}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.4984e-01, "std": 2.7758e-01, "min_value": 1.5855e-05, "max_value": 9.9998e-01}, "num_gradient_steps": 0, "step_time": 1.0358e+01, "total_time": 8.6074e+02, "__timestamp": "2024-10-09 18:11:45.847898"}, {"step": 100000, "num_env_steps": 100000, "scores": {"n": 1, "mean": 3.8302e+03}, "actor_loss": {"n": 1, "mean": -1.6412e+02}, "entropy_coef_loss": {"n": 1, "mean": -1.2441e+00}, "critic_loss": {"n": 1, "mean": 7.5761e+01}, "entropy_coef": {"n": 1, "mean": 6.4283e-02}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.4144e-01, "std": 2.7792e-01, "min_value": 4.3809e-03, "max_value": 9.9996e-01}, "num_gradient_steps": 0, "step_time": 1.0266e+01, "total_time": 8.7100e+02, "__timestamp": "2024-10-09 18:11:56.113618"}, {"step": 101000, "num_env_steps": 101000, "scores": {"n": 1, "mean": 3.8847e+03}, "actor_loss": {"n": 1, "mean": -1.6344e+02}, "entropy_coef_loss": {"n": 1, "mean": 1.3758e+00}, "critic_loss": {"n": 1, "mean": 1.2044e+01}, "entropy_coef": {"n": 1, "mean": 6.3735e-02}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.5622e-01, "std": 2.7592e-01, "min_value": 9.3764e-04, "max_value": 9.9993e-01}, "num_gradient_steps": 0, "step_time": 1.0015e+01, "total_time": 8.8102e+02, "__timestamp": "2024-10-09 18:12:06.127242"}, {"step": 102000, "num_env_steps": 102000, "scores": {"n": 1, "mean": 3.5764e+03}, "actor_loss": {"n": 1, "mean": -1.6339e+02}, "entropy_coef_loss": {"n": 1, "mean": 2.1819e-01}, "critic_loss": {"n": 1, "mean": 5.5197e+01}, "entropy_coef": {"n": 1, "mean": 6.6586e-02}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.4233e-01, "std": 2.8095e-01, "min_value": 3.6561e-04, "max_value": 1.0000e+00}, "num_gradient_steps": 0, "step_time": 1.0341e+01, "total_time": 8.9136e+02, "__timestamp": "2024-10-09 18:12:16.468389"}, {"step": 103000, "num_env_steps": 103000, "scores": {"n": 1, "mean": 3.9180e+03}, "actor_loss": {"n": 1, "mean": -1.6279e+02}, "entropy_coef_loss": {"n": 1, "mean": -1.0118e+00}, "critic_loss": {"n": 1, "mean": 1.2308e+01}, "entropy_coef": {"n": 1, "mean": 6.6922e-02}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.4169e-01, "std": 2.8563e-01, "min_value": 1.5507e-04, "max_value": 9.9992e-01}, "num_gradient_steps": 0, "step_time": 1.0431e+01, "total_time": 9.0179e+02, "__timestamp": "2024-10-09 18:12:26.900761"}, {"step": 104000, "num_env_steps": 104000, "scores": {"n": 1, "mean": 4.0450e+03}, "actor_loss": {"n": 1, "mean": -1.7438e+02}, "entropy_coef_loss": {"n": 1, "mean": 4.2555e-01}, "critic_loss": {"n": 1, "mean": 1.2108e+01}, "entropy_coef": {"n": 1, "mean": 6.6637e-02}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.4107e-01, "std": 2.8402e-01, "min_value": 5.7399e-05, "max_value": 9.9994e-01}, "num_gradient_steps": 0, "step_time": 1.0066e+01, "total_time": 9.1186e+02, "__timestamp": "2024-10-09 18:12:36.966061"}, {"step": 105000, "num_env_steps": 105000, "scores": {"n": 1, "mean": 3.9780e+03}, "actor_loss": {"n": 1, "mean": -1.7450e+02}, "entropy_coef_loss": {"n": 1, "mean": 6.0796e-01}, "critic_loss": {"n": 1, "mean": 1.6534e+01}, "entropy_coef": {"n": 1, "mean": 6.7888e-02}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.4738e-01, "std": 2.8153e-01, "min_value": 6.9514e-04, "max_value": 9.9996e-01}, "num_gradient_steps": 0, "step_time": 1.0747e+01, "total_time": 9.2261e+02, "__timestamp": "2024-10-09 18:12:47.713710"}, {"step": 106000, "num_env_steps": 106000, "scores": {"n": 1, "mean": 1.4432e+03}, "actor_loss": {"n": 1, "mean": -1.6799e+02}, "entropy_coef_loss": {"n": 1, "mean": -2.5749e-01}, "critic_loss": {"n": 1, "mean": 1.1821e+01}, "entropy_coef": {"n": 1, "mean": 6.8511e-02}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 6.6395e-01, "std": 2.9896e-01, "min_value": 2.3425e-04, "max_value": 9.9998e-01}, "num_gradient_steps": 0, "step_time": 1.0586e+01, "total_time": 9.3319e+02, "__timestamp": "2024-10-09 18:12:58.298672"}, {"step": 107000, "num_env_steps": 107000, "scores": {"n": 1, "mean": 4.0744e+03}, "actor_loss": {"n": 1, "mean": -1.7365e+02}, "entropy_coef_loss": {"n": 1, "mean": 1.1798e+00}, "critic_loss": {"n": 1, "mean": 1.1376e+01}, "entropy_coef": {"n": 1, "mean": 6.9699e-02}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.4680e-01, "std": 2.8048e-01, "min_value": 2.5436e-05, "max_value": 9.9999e-01}, "num_gradient_steps": 0, "step_time": 9.9078e+00, "total_time": 9.4310e+02, "__timestamp": "2024-10-09 18:13:08.207444"}, {"step": 108000, "num_env_steps": 108000, "scores": {"n": 1, "mean": 3.9349e+03}, "actor_loss": {"n": 1, "mean": -1.7139e+02}, "entropy_coef_loss": {"n": 1, "mean": -5.7287e-01}, "critic_loss": {"n": 1, "mean": 1.2094e+02}, "entropy_coef": {"n": 1, "mean": 6.7413e-02}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.4696e-01, "std": 2.7558e-01, "min_value": 3.6191e-04, "max_value": 9.9996e-01}, "num_gradient_steps": 0, "step_time": 1.0224e+01, "total_time": 9.5332e+02, "__timestamp": "2024-10-09 18:13:18.431770"}, {"step": 109000, "num_env_steps": 109000, "scores": {"n": 1, "mean": 9.9654e+01}, "actor_loss": {"n": 1, "mean": -1.7216e+02}, "entropy_coef_loss": {"n": 1, "mean": 3.8578e-01}, "critic_loss": {"n": 1, "mean": 1.3811e+01}, "entropy_coef": {"n": 1, "mean": 6.7858e-02}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 6.1292e-01, "std": 3.0082e-01, "min_value": 2.8357e-05, "max_value": 9.9999e-01}, "num_gradient_steps": 0, "step_time": 1.0906e+01, "total_time": 9.6423e+02, "__timestamp": "2024-10-09 18:13:29.337127"}, {"step": 110000, "num_env_steps": 110000, "scores": {"n": 1, "mean": 3.5915e+03}, "actor_loss": {"n": 1, "mean": -1.7921e+02}, "entropy_coef_loss": {"n": 1, "mean": 8.1014e-01}, "critic_loss": {"n": 1, "mean": 2.3215e+02}, "entropy_coef": {"n": 1, "mean": 6.8186e-02}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.4584e-01, "std": 2.8109e-01, "min_value": 1.0598e-04, "max_value": 1.0000e+00}, "num_gradient_steps": 0, "step_time": 1.0659e+01, "total_time": 9.7489e+02, "__timestamp": "2024-10-09 18:13:39.996213"}, {"step": 111000, "num_env_steps": 111000, "scores": {"n": 1, "mean": 3.6776e+03}, "actor_loss": {"n": 1, "mean": -1.7441e+02}, "entropy_coef_loss": {"n": 1, "mean": -4.4681e-01}, "critic_loss": {"n": 1, "mean": 1.2068e+02}, "entropy_coef": {"n": 1, "mean": 6.8797e-02}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.4492e-01, "std": 2.7664e-01, "min_value": 5.1379e-05, "max_value": 9.9995e-01}, "num_gradient_steps": 0, "step_time": 1.1460e+01, "total_time": 9.8635e+02, "__timestamp": "2024-10-09 18:13:51.457673"}, {"step": 112000, "num_env_steps": 112000, "scores": {"n": 1, "mean": 2.4998e+03}, "actor_loss": {"n": 1, "mean": -1.8124e+02}, "entropy_coef_loss": {"n": 1, "mean": 5.7293e-01}, "critic_loss": {"n": 1, "mean": 1.7551e+01}, "entropy_coef": {"n": 1, "mean": 7.0239e-02}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 6.9314e-01, "std": 2.9600e-01, "min_value": 3.7551e-06, "max_value": 9.9998e-01}, "num_gradient_steps": 0, "step_time": 9.9702e+00, "total_time": 9.9632e+02, "__timestamp": "2024-10-09 18:14:01.427880"}, {"step": 113000, "num_env_steps": 113000, "scores": {"n": 1, "mean": 4.1172e+03}, "actor_loss": {"n": 1, "mean": -1.8234e+02}, "entropy_coef_loss": {"n": 1, "mean": 1.6028e+00}, "critic_loss": {"n": 1, "mean": 1.8096e+01}, "entropy_coef": {"n": 1, "mean": 7.0802e-02}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.4640e-01, "std": 2.7739e-01, "min_value": 1.3395e-04, "max_value": 9.9994e-01}, "num_gradient_steps": 0, "step_time": 9.4857e+00, "total_time": 1.0058e+03, "__timestamp": "2024-10-09 18:14:10.913617"}, {"step": 114000, "num_env_steps": 114000, "scores": {"n": 1, "mean": 3.6417e+03}, "actor_loss": {"n": 1, "mean": -1.8545e+02}, "entropy_coef_loss": {"n": 1, "mean": -4.2724e-01}, "critic_loss": {"n": 1, "mean": 1.4262e+01}, "entropy_coef": {"n": 1, "mean": 7.1624e-02}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.4659e-01, "std": 2.7879e-01, "min_value": 5.1913e-04, "max_value": 9.9998e-01}, "num_gradient_steps": 0, "step_time": 9.5032e+00, "total_time": 1.0153e+03, "__timestamp": "2024-10-09 18:14:20.416795"}, {"step": 115000, "num_env_steps": 115000, "scores": {"n": 1, "mean": 4.0008e+03}, "actor_loss": {"n": 1, "mean": -1.7476e+02}, "entropy_coef_loss": {"n": 1, "mean": -1.3231e+00}, "critic_loss": {"n": 1, "mean": 1.5990e+01}, "entropy_coef": {"n": 1, "mean": 6.9879e-02}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.4555e-01, "std": 2.7701e-01, "min_value": 3.5048e-05, "max_value": 9.9994e-01}, "num_gradient_steps": 0, "step_time": 1.0169e+01, "total_time": 1.0255e+03, "__timestamp": "2024-10-09 18:14:30.585108"}, {"step": 116000, "num_env_steps": 116000, "scores": {"n": 1, "mean": 3.6714e+03}, "actor_loss": {"n": 1, "mean": -1.8217e+02}, "entropy_coef_loss": {"n": 1, "mean": 3.6723e-01}, "critic_loss": {"n": 1, "mean": 1.9937e+01}, "entropy_coef": {"n": 1, "mean": 7.3264e-02}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.3609e-01, "std": 2.8329e-01, "min_value": 6.0648e-05, "max_value": 9.9998e-01}, "num_gradient_steps": 0, "step_time": 1.0060e+01, "total_time": 1.0355e+03, "__timestamp": "2024-10-09 18:14:40.645554"}, {"step": 117000, "num_env_steps": 117000, "scores": {"n": 1, "mean": 7.3065e+02}, "actor_loss": {"n": 1, "mean": -1.7823e+02}, "entropy_coef_loss": {"n": 1, "mean": 4.0278e-01}, "critic_loss": {"n": 1, "mean": 1.4276e+01}, "entropy_coef": {"n": 1, "mean": 7.2945e-02}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 6.1760e-01, "std": 3.0115e-01, "min_value": 2.3807e-04, "max_value": 9.9983e-01}, "num_gradient_steps": 0, "step_time": 1.0059e+01, "total_time": 1.0456e+03, "__timestamp": "2024-10-09 18:14:50.704913"}, {"step": 118000, "num_env_steps": 118000, "scores": {"n": 1, "mean": 4.3047e+03}, "actor_loss": {"n": 1, "mean": -1.8813e+02}, "entropy_coef_loss": {"n": 1, "mean": -1.7119e-01}, "critic_loss": {"n": 1, "mean": 1.7071e+01}, "entropy_coef": {"n": 1, "mean": 7.2515e-02}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.4940e-01, "std": 2.7993e-01, "min_value": 3.8601e-04, "max_value": 9.9996e-01}, "num_gradient_steps": 0, "step_time": 9.4039e+00, "total_time": 1.0550e+03, "__timestamp": "2024-10-09 18:15:00.109779"}, {"step": 119000, "num_env_steps": 119000, "scores": {"n": 1, "mean": 3.9274e+03}, "actor_loss": {"n": 1, "mean": -1.8086e+02}, "entropy_coef_loss": {"n": 1, "mean": 2.3119e+00}, "critic_loss": {"n": 1, "mean": 1.5035e+01}, "entropy_coef": {"n": 1, "mean": 7.1896e-02}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.4181e-01, "std": 2.8100e-01, "min_value": 3.7530e-04, "max_value": 1.0000e+00}, "num_gradient_steps": 0, "step_time": 9.5253e+00, "total_time": 1.0645e+03, "__timestamp": "2024-10-09 18:15:09.635087"}, {"step": 120000, "num_env_steps": 120000, "scores": {"n": 1, "mean": 4.4092e+03}, "actor_loss": {"n": 1, "mean": -1.9070e+02}, "entropy_coef_loss": {"n": 1, "mean": 8.4652e-01}, "critic_loss": {"n": 1, "mean": 1.2732e+01}, "entropy_coef": {"n": 1, "mean": 7.2783e-02}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.4799e-01, "std": 2.7664e-01, "min_value": 2.6169e-03, "max_value": 9.9982e-01}, "num_gradient_steps": 0, "step_time": 9.7043e+00, "total_time": 1.0742e+03, "__timestamp": "2024-10-09 18:15:19.338416"}, {"step": 121000, "num_env_steps": 121000, "scores": {"n": 1, "mean": 3.8087e+03}, "actor_loss": {"n": 1, "mean": -1.8758e+02}, "entropy_coef_loss": {"n": 1, "mean": 2.4535e-01}, "critic_loss": {"n": 1, "mean": 1.7631e+01}, "entropy_coef": {"n": 1, "mean": 7.4170e-02}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.3718e-01, "std": 2.8115e-01, "min_value": 2.4052e-04, "max_value": 9.9994e-01}, "num_gradient_steps": 0, "step_time": 9.8587e+00, "total_time": 1.0841e+03, "__timestamp": "2024-10-09 18:15:29.197129"}, {"step": 122000, "num_env_steps": 122000, "scores": {"n": 1, "mean": 5.9355e+01}, "actor_loss": {"n": 1, "mean": -1.7436e+02}, "entropy_coef_loss": {"n": 1, "mean": -1.3808e+00}, "critic_loss": {"n": 1, "mean": 2.1164e+02}, "entropy_coef": {"n": 1, "mean": 7.3511e-02}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 6.0456e-01, "std": 2.9943e-01, "min_value": 4.8161e-04, "max_value": 9.9997e-01}, "num_gradient_steps": 0, "step_time": 9.7395e+00, "total_time": 1.0938e+03, "__timestamp": "2024-10-09 18:15:38.937590"}, {"step": 123000, "num_env_steps": 123000, "scores": {"n": 1, "mean": 4.1296e+03}, "actor_loss": {"n": 1, "mean": -1.8955e+02}, "entropy_coef_loss": {"n": 1, "mean": 8.3122e-01}, "critic_loss": {"n": 1, "mean": 1.4478e+01}, "entropy_coef": {"n": 1, "mean": 7.2883e-02}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.4615e-01, "std": 2.7633e-01, "min_value": 1.3574e-03, "max_value": 9.9985e-01}, "num_gradient_steps": 0, "step_time": 9.7208e+00, "total_time": 1.1035e+03, "__timestamp": "2024-10-09 18:15:48.658405"}, {"step": 124000, "num_env_steps": 124000, "scores": {"n": 1, "mean": 4.1068e+03}, "actor_loss": {"n": 1, "mean": -1.8068e+02}, "entropy_coef_loss": {"n": 1, "mean": 9.6654e-01}, "critic_loss": {"n": 1, "mean": 1.6427e+01}, "entropy_coef": {"n": 1, "mean": 7.3837e-02}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.4062e-01, "std": 2.8055e-01, "min_value": 1.0967e-05, "max_value": 9.9996e-01}, "num_gradient_steps": 0, "step_time": 9.7463e+00, "total_time": 1.1133e+03, "__timestamp": "2024-10-09 18:15:58.403672"}, {"step": 125000, "num_env_steps": 125000, "scores": {"n": 1, "mean": 4.2405e+03}, "actor_loss": {"n": 1, "mean": -1.9547e+02}, "entropy_coef_loss": {"n": 1, "mean": 1.5951e+00}, "critic_loss": {"n": 1, "mean": 1.6658e+01}, "entropy_coef": {"n": 1, "mean": 7.3888e-02}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.3429e-01, "std": 2.8394e-01, "min_value": 1.6600e-04, "max_value": 9.9993e-01}, "num_gradient_steps": 0, "step_time": 9.7782e+00, "total_time": 1.1231e+03, "__timestamp": "2024-10-09 18:16:08.181892"}, {"step": 126000, "num_env_steps": 126000, "scores": {"n": 1, "mean": 4.2166e+03}, "actor_loss": {"n": 1, "mean": -1.8502e+02}, "entropy_coef_loss": {"n": 1, "mean": -1.2909e+00}, "critic_loss": {"n": 1, "mean": 1.6089e+01}, "entropy_coef": {"n": 1, "mean": 7.6840e-02}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.3850e-01, "std": 2.8188e-01, "min_value": 4.7656e-04, "max_value": 9.9998e-01}, "num_gradient_steps": 0, "step_time": 9.6286e+00, "total_time": 1.1327e+03, "__timestamp": "2024-10-09 18:16:17.811483"}, {"step": 127000, "num_env_steps": 127000, "scores": {"n": 1, "mean": 3.9060e+03}, "actor_loss": {"n": 1, "mean": -1.9401e+02}, "entropy_coef_loss": {"n": 1, "mean": -5.6031e-01}, "critic_loss": {"n": 1, "mean": 1.5333e+01}, "entropy_coef": {"n": 1, "mean": 7.6196e-02}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.4003e-01, "std": 2.8135e-01, "min_value": 1.0190e-03, "max_value": 1.0000e+00}, "num_gradient_steps": 0, "step_time": 9.8707e+00, "total_time": 1.1426e+03, "__timestamp": "2024-10-09 18:16:27.682141"}, {"step": 128000, "num_env_steps": 128000, "scores": {"n": 1, "mean": 4.2499e+03}, "actor_loss": {"n": 1, "mean": -1.9846e+02}, "entropy_coef_loss": {"n": 1, "mean": -6.8438e-01}, "critic_loss": {"n": 1, "mean": 1.6893e+01}, "entropy_coef": {"n": 1, "mean": 7.5642e-02}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.4460e-01, "std": 2.7920e-01, "min_value": 3.0309e-04, "max_value": 9.9987e-01}, "num_gradient_steps": 0, "step_time": 9.7295e+00, "total_time": 1.1523e+03, "__timestamp": "2024-10-09 18:16:37.411609"}, {"step": 129000, "num_env_steps": 129000, "scores": {"n": 1, "mean": 4.2284e+03}, "actor_loss": {"n": 1, "mean": -2.0246e+02}, "entropy_coef_loss": {"n": 1, "mean": -3.2185e-01}, "critic_loss": {"n": 1, "mean": 1.5447e+01}, "entropy_coef": {"n": 1, "mean": 7.7556e-02}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.4316e-01, "std": 2.8044e-01, "min_value": 5.6352e-04, "max_value": 9.9998e-01}, "num_gradient_steps": 0, "step_time": 9.6964e+00, "total_time": 1.1620e+03, "__timestamp": "2024-10-09 18:16:47.106968"}, {"step": 130000, "num_env_steps": 130000, "scores": {"n": 1, "mean": 4.1162e+03}, "actor_loss": {"n": 1, "mean": -1.9774e+02}, "entropy_coef_loss": {"n": 1, "mean": 1.0912e+00}, "critic_loss": {"n": 1, "mean": 1.6416e+01}, "entropy_coef": {"n": 1, "mean": 7.8322e-02}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.4210e-01, "std": 2.8123e-01, "min_value": 1.0540e-04, "max_value": 9.9997e-01}, "num_gradient_steps": 0, "step_time": 9.3927e+00, "total_time": 1.1714e+03, "__timestamp": "2024-10-09 18:16:56.500629"}, {"step": 131000, "num_env_steps": 131000, "scores": {"n": 1, "mean": 4.3717e+03}, "actor_loss": {"n": 1, "mean": -1.9443e+02}, "entropy_coef_loss": {"n": 1, "mean": 7.0611e-01}, "critic_loss": {"n": 1, "mean": 1.5447e+01}, "entropy_coef": {"n": 1, "mean": 7.7414e-02}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.3867e-01, "std": 2.8296e-01, "min_value": 3.7682e-04, "max_value": 9.9996e-01}, "num_gradient_steps": 0, "step_time": 9.4875e+00, "total_time": 1.1809e+03, "__timestamp": "2024-10-09 18:17:05.987159"}, {"step": 132000, "num_env_steps": 132000, "scores": {"n": 1, "mean": 4.2496e+03}, "actor_loss": {"n": 1, "mean": -2.0653e+02}, "entropy_coef_loss": {"n": 1, "mean": 5.7592e-01}, "critic_loss": {"n": 1, "mean": 1.3075e+02}, "entropy_coef": {"n": 1, "mean": 7.8947e-02}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.4618e-01, "std": 2.7510e-01, "min_value": 1.5897e-03, "max_value": 9.9999e-01}, "num_gradient_steps": 0, "step_time": 9.4278e+00, "total_time": 1.1903e+03, "__timestamp": "2024-10-09 18:17:15.415987"}, {"step": 133000, "num_env_steps": 133000, "scores": {"n": 1, "mean": 4.2050e+03}, "actor_loss": {"n": 1, "mean": -1.9530e+02}, "entropy_coef_loss": {"n": 1, "mean": -3.9424e-01}, "critic_loss": {"n": 1, "mean": 1.6358e+01}, "entropy_coef": {"n": 1, "mean": 7.8294e-02}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.4085e-01, "std": 2.7693e-01, "min_value": 5.0683e-04, "max_value": 9.9998e-01}, "num_gradient_steps": 0, "step_time": 9.2848e+00, "total_time": 1.1996e+03, "__timestamp": "2024-10-09 18:17:24.699837"}, {"step": 134000, "num_env_steps": 134000, "scores": {"n": 1, "mean": 4.3750e+03}, "actor_loss": {"n": 1, "mean": -1.9986e+02}, "entropy_coef_loss": {"n": 1, "mean": 7.0917e-01}, "critic_loss": {"n": 1, "mean": 2.2698e+01}, "entropy_coef": {"n": 1, "mean": 8.1462e-02}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.4857e-01, "std": 2.7662e-01, "min_value": 4.1287e-04, "max_value": 9.9991e-01}, "num_gradient_steps": 0, "step_time": 9.3280e+00, "total_time": 1.2089e+03, "__timestamp": "2024-10-09 18:17:34.028829"}, {"step": 135000, "num_env_steps": 135000, "scores": {"n": 1, "mean": 4.2923e+03}, "actor_loss": {"n": 1, "mean": -2.1006e+02}, "entropy_coef_loss": {"n": 1, "mean": 1.0230e+00}, "critic_loss": {"n": 1, "mean": 1.8461e+01}, "entropy_coef": {"n": 1, "mean": 8.1325e-02}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.4960e-01, "std": 2.7716e-01, "min_value": 9.1875e-04, "max_value": 9.9994e-01}, "num_gradient_steps": 0, "step_time": 9.2840e+00, "total_time": 1.2182e+03, "__timestamp": "2024-10-09 18:17:43.312865"}, {"step": 136000, "num_env_steps": 136000, "scores": {"n": 1, "mean": 4.3225e+03}, "actor_loss": {"n": 1, "mean": -2.0194e+02}, "entropy_coef_loss": {"n": 1, "mean": -4.3499e-01}, "critic_loss": {"n": 1, "mean": 1.3721e+01}, "entropy_coef": {"n": 1, "mean": 8.2560e-02}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.3636e-01, "std": 2.8033e-01, "min_value": 6.6698e-05, "max_value": 9.9979e-01}, "num_gradient_steps": 0, "step_time": 9.3865e+00, "total_time": 1.2276e+03, "__timestamp": "2024-10-09 18:17:52.699372"}, {"step": 137000, "num_env_steps": 137000, "scores": {"n": 1, "mean": 4.3786e+03}, "actor_loss": {"n": 1, "mean": -2.0510e+02}, "entropy_coef_loss": {"n": 1, "mean": -3.4869e-01}, "critic_loss": {"n": 1, "mean": 1.7984e+01}, "entropy_coef": {"n": 1, "mean": 8.2253e-02}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.4824e-01, "std": 2.7481e-01, "min_value": 1.8015e-03, "max_value": 9.9990e-01}, "num_gradient_steps": 0, "step_time": 9.5696e+00, "total_time": 1.2372e+03, "__timestamp": "2024-10-09 18:18:02.267947"}, {"step": 138000, "num_env_steps": 138000, "scores": {"n": 1, "mean": 4.5129e+03}, "actor_loss": {"n": 1, "mean": -1.9542e+02}, "entropy_coef_loss": {"n": 1, "mean": -3.2954e-01}, "critic_loss": {"n": 1, "mean": 1.6172e+01}, "entropy_coef": {"n": 1, "mean": 8.2742e-02}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.5725e-01, "std": 2.7280e-01, "min_value": 2.4512e-03, "max_value": 9.9997e-01}, "num_gradient_steps": 0, "step_time": 9.3946e+00, "total_time": 1.2466e+03, "__timestamp": "2024-10-09 18:18:11.663568"}, {"step": 139000, "num_env_steps": 139000, "scores": {"n": 1, "mean": 4.0954e+03}, "actor_loss": {"n": 1, "mean": -1.9645e+02}, "entropy_coef_loss": {"n": 1, "mean": -3.8584e-01}, "critic_loss": {"n": 1, "mean": 1.7903e+01}, "entropy_coef": {"n": 1, "mean": 8.3506e-02}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.5454e-01, "std": 2.7320e-01, "min_value": 5.1191e-04, "max_value": 9.9996e-01}, "num_gradient_steps": 0, "step_time": 9.4846e+00, "total_time": 1.2560e+03, "__timestamp": "2024-10-09 18:18:21.148134"}, {"step": 140000, "num_env_steps": 140000, "scores": {"n": 1, "mean": 4.3810e+03}, "actor_loss": {"n": 1, "mean": -2.1239e+02}, "entropy_coef_loss": {"n": 1, "mean": 1.6581e+00}, "critic_loss": {"n": 1, "mean": 1.3898e+01}, "entropy_coef": {"n": 1, "mean": 8.3131e-02}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.4522e-01, "std": 2.7951e-01, "min_value": 2.3156e-05, "max_value": 9.9978e-01}, "num_gradient_steps": 0, "step_time": 9.2865e+00, "total_time": 1.2653e+03, "__timestamp": "2024-10-09 18:18:30.434662"}, {"step": 141000, "num_env_steps": 141000, "scores": {"n": 1, "mean": 4.3683e+03}, "actor_loss": {"n": 1, "mean": -2.1323e+02}, "entropy_coef_loss": {"n": 1, "mean": -7.0111e-01}, "critic_loss": {"n": 1, "mean": 2.6625e+02}, "entropy_coef": {"n": 1, "mean": 8.6064e-02}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.5290e-01, "std": 2.7558e-01, "min_value": 1.0628e-03, "max_value": 9.9996e-01}, "num_gradient_steps": 0, "step_time": 9.3039e+00, "total_time": 1.2746e+03, "__timestamp": "2024-10-09 18:18:39.738542"}, {"step": 142000, "num_env_steps": 142000, "scores": {"n": 1, "mean": 4.3439e+03}, "actor_loss": {"n": 1, "mean": -2.1227e+02}, "entropy_coef_loss": {"n": 1, "mean": -4.6815e-01}, "critic_loss": {"n": 1, "mean": 1.8748e+01}, "entropy_coef": {"n": 1, "mean": 8.7993e-02}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.5653e-01, "std": 2.7361e-01, "min_value": 2.4889e-04, "max_value": 9.9997e-01}, "num_gradient_steps": 0, "step_time": 9.4141e+00, "total_time": 1.2840e+03, "__timestamp": "2024-10-09 18:18:49.152109"}, {"step": 143000, "num_env_steps": 143000, "scores": {"n": 1, "mean": 4.5367e+03}, "actor_loss": {"n": 1, "mean": -2.1103e+02}, "entropy_coef_loss": {"n": 1, "mean": -9.3022e-01}, "critic_loss": {"n": 1, "mean": 2.5656e+01}, "entropy_coef": {"n": 1, "mean": 8.6259e-02}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.5320e-01, "std": 2.7364e-01, "min_value": 5.9780e-04, "max_value": 9.9989e-01}, "num_gradient_steps": 0, "step_time": 9.8289e+00, "total_time": 1.2939e+03, "__timestamp": "2024-10-09 18:18:58.981520"}, {"step": 144000, "num_env_steps": 144000, "scores": {"n": 1, "mean": 4.3773e+03}, "actor_loss": {"n": 1, "mean": -2.0962e+02}, "entropy_coef_loss": {"n": 1, "mean": -2.4786e-03}, "critic_loss": {"n": 1, "mean": 1.7096e+01}, "entropy_coef": {"n": 1, "mean": 8.6877e-02}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.6057e-01, "std": 2.7167e-01, "min_value": 5.5850e-05, "max_value": 9.9989e-01}, "num_gradient_steps": 0, "step_time": 9.5383e+00, "total_time": 1.3034e+03, "__timestamp": "2024-10-09 18:19:08.518802"}, {"step": 145000, "num_env_steps": 145000, "scores": {"n": 1, "mean": 4.4441e+03}, "actor_loss": {"n": 1, "mean": -2.0714e+02}, "entropy_coef_loss": {"n": 1, "mean": -6.3512e-01}, "critic_loss": {"n": 1, "mean": 2.1185e+02}, "entropy_coef": {"n": 1, "mean": 8.5557e-02}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.5777e-01, "std": 2.7350e-01, "min_value": 3.2389e-04, "max_value": 9.9994e-01}, "num_gradient_steps": 0, "step_time": 9.4672e+00, "total_time": 1.3129e+03, "__timestamp": "2024-10-09 18:19:17.986035"}, {"step": 146000, "num_env_steps": 146000, "scores": {"n": 1, "mean": 4.4936e+03}, "actor_loss": {"n": 1, "mean": -2.1354e+02}, "entropy_coef_loss": {"n": 1, "mean": -3.6498e-01}, "critic_loss": {"n": 1, "mean": 1.4897e+01}, "entropy_coef": {"n": 1, "mean": 8.9293e-02}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.5795e-01, "std": 2.7322e-01, "min_value": 4.7356e-05, "max_value": 9.9997e-01}, "num_gradient_steps": 0, "step_time": 9.3976e+00, "total_time": 1.3223e+03, "__timestamp": "2024-10-09 18:19:27.384665"}, {"step": 147000, "num_env_steps": 147000, "scores": {"n": 1, "mean": 4.5164e+03}, "actor_loss": {"n": 1, "mean": -2.1304e+02}, "entropy_coef_loss": {"n": 1, "mean": -4.8631e-01}, "critic_loss": {"n": 1, "mean": 1.9511e+01}, "entropy_coef": {"n": 1, "mean": 8.9896e-02}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.5830e-01, "std": 2.7000e-01, "min_value": 4.8559e-05, "max_value": 9.9982e-01}, "num_gradient_steps": 0, "step_time": 9.5947e+00, "total_time": 1.3319e+03, "__timestamp": "2024-10-09 18:19:36.978371"}, {"step": 148000, "num_env_steps": 148000, "scores": {"n": 1, "mean": 4.2609e+03}, "actor_loss": {"n": 1, "mean": -2.1334e+02}, "entropy_coef_loss": {"n": 1, "mean": -2.2165e+00}, "critic_loss": {"n": 1, "mean": 1.6365e+01}, "entropy_coef": {"n": 1, "mean": 8.9275e-02}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.5355e-01, "std": 2.7641e-01, "min_value": 4.9913e-04, "max_value": 9.9994e-01}, "num_gradient_steps": 0, "step_time": 9.4858e+00, "total_time": 1.3414e+03, "__timestamp": "2024-10-09 18:19:46.464142"}, {"step": 149000, "num_env_steps": 149000, "scores": {"n": 1, "mean": 4.4269e+03}, "actor_loss": {"n": 1, "mean": -2.1215e+02}, "entropy_coef_loss": {"n": 1, "mean": -4.5886e-01}, "critic_loss": {"n": 1, "mean": 1.7391e+01}, "entropy_coef": {"n": 1, "mean": 8.9746e-02}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.5688e-01, "std": 2.7565e-01, "min_value": 3.2875e-04, "max_value": 9.9992e-01}, "num_gradient_steps": 0, "step_time": 9.3422e+00, "total_time": 1.3507e+03, "__timestamp": "2024-10-09 18:19:55.807374"}, {"step": 150000, "num_env_steps": 150000, "scores": {"n": 1, "mean": 4.4022e+03}, "actor_loss": {"n": 1, "mean": -2.2498e+02}, "entropy_coef_loss": {"n": 1, "mean": 1.3989e+00}, "critic_loss": {"n": 1, "mean": 1.5861e+01}, "entropy_coef": {"n": 1, "mean": 9.0843e-02}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.5435e-01, "std": 2.7090e-01, "min_value": 3.8010e-04, "max_value": 9.9988e-01}, "num_gradient_steps": 0, "step_time": 9.4063e+00, "total_time": 1.3601e+03, "__timestamp": "2024-10-09 18:20:05.212675"}, {"step": 151000, "num_env_steps": 151000, "scores": {"n": 1, "mean": 4.6576e+03}, "actor_loss": {"n": 1, "mean": -2.2053e+02}, "entropy_coef_loss": {"n": 1, "mean": -5.2932e-01}, "critic_loss": {"n": 1, "mean": 1.6684e+01}, "entropy_coef": {"n": 1, "mean": 9.1956e-02}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.6239e-01, "std": 2.7180e-01, "min_value": 5.4978e-04, "max_value": 9.9985e-01}, "num_gradient_steps": 0, "step_time": 9.4017e+00, "total_time": 1.3695e+03, "__timestamp": "2024-10-09 18:20:14.614358"}, {"step": 152000, "num_env_steps": 152000, "scores": {"n": 1, "mean": 4.5481e+03}, "actor_loss": {"n": 1, "mean": -2.1599e+02}, "entropy_coef_loss": {"n": 1, "mean": -6.5019e-03}, "critic_loss": {"n": 1, "mean": 1.6860e+01}, "entropy_coef": {"n": 1, "mean": 9.1481e-02}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.6226e-01, "std": 2.7060e-01, "min_value": 1.4671e-04, "max_value": 9.9994e-01}, "num_gradient_steps": 0, "step_time": 9.5136e+00, "total_time": 1.3790e+03, "__timestamp": "2024-10-09 18:20:24.128917"}, {"step": 153000, "num_env_steps": 153000, "scores": {"n": 1, "mean": 4.5106e+03}, "actor_loss": {"n": 1, "mean": -2.2024e+02}, "entropy_coef_loss": {"n": 1, "mean": 4.3670e-01}, "critic_loss": {"n": 1, "mean": 2.6937e+01}, "entropy_coef": {"n": 1, "mean": 9.2993e-02}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.5447e-01, "std": 2.7429e-01, "min_value": 4.8035e-04, "max_value": 9.9994e-01}, "num_gradient_steps": 0, "step_time": 9.5804e+00, "total_time": 1.3886e+03, "__timestamp": "2024-10-09 18:20:33.709282"}, {"step": 154000, "num_env_steps": 154000, "scores": {"n": 1, "mean": 4.6617e+03}, "actor_loss": {"n": 1, "mean": -2.2253e+02}, "entropy_coef_loss": {"n": 1, "mean": 4.0399e-02}, "critic_loss": {"n": 1, "mean": 1.6987e+01}, "entropy_coef": {"n": 1, "mean": 9.0262e-02}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.5745e-01, "std": 2.7377e-01, "min_value": 5.7213e-05, "max_value": 9.9984e-01}, "num_gradient_steps": 0, "step_time": 9.6235e+00, "total_time": 1.3982e+03, "__timestamp": "2024-10-09 18:20:43.331795"}, {"step": 155000, "num_env_steps": 155000, "scores": {"n": 1, "mean": 4.6218e+03}, "actor_loss": {"n": 1, "mean": -2.2466e+02}, "entropy_coef_loss": {"n": 1, "mean": -1.0224e+00}, "critic_loss": {"n": 1, "mean": 1.4793e+01}, "entropy_coef": {"n": 1, "mean": 9.4189e-02}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.6478e-01, "std": 2.6909e-01, "min_value": 2.5207e-04, "max_value": 9.9973e-01}, "num_gradient_steps": 0, "step_time": 9.7473e+00, "total_time": 1.4080e+03, "__timestamp": "2024-10-09 18:20:53.080072"}, {"step": 156000, "num_env_steps": 156000, "scores": {"n": 1, "mean": 4.5561e+03}, "actor_loss": {"n": 1, "mean": -2.2762e+02}, "entropy_coef_loss": {"n": 1, "mean": -7.7460e-02}, "critic_loss": {"n": 1, "mean": 1.8528e+01}, "entropy_coef": {"n": 1, "mean": 9.4135e-02}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.6220e-01, "std": 2.6993e-01, "min_value": 2.5815e-04, "max_value": 9.9992e-01}, "num_gradient_steps": 0, "step_time": 9.9187e+00, "total_time": 1.4179e+03, "__timestamp": "2024-10-09 18:21:02.998777"}, {"step": 157000, "num_env_steps": 157000, "scores": {"n": 1, "mean": 4.4424e+03}, "actor_loss": {"n": 1, "mean": -2.3367e+02}, "entropy_coef_loss": {"n": 1, "mean": 1.3156e+00}, "critic_loss": {"n": 1, "mean": 1.9980e+01}, "entropy_coef": {"n": 1, "mean": 9.3132e-02}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.4955e-01, "std": 2.7813e-01, "min_value": 3.2510e-04, "max_value": 9.9993e-01}, "num_gradient_steps": 0, "step_time": 1.1387e+01, "total_time": 1.4293e+03, "__timestamp": "2024-10-09 18:21:14.386129"}, {"step": 158000, "num_env_steps": 158000, "scores": {"n": 1, "mean": 4.6194e+03}, "actor_loss": {"n": 1, "mean": -2.2680e+02}, "entropy_coef_loss": {"n": 1, "mean": -8.8787e-01}, "critic_loss": {"n": 1, "mean": 1.3972e+01}, "entropy_coef": {"n": 1, "mean": 9.3895e-02}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.6063e-01, "std": 2.6759e-01, "min_value": 1.4651e-04, "max_value": 9.9979e-01}, "num_gradient_steps": 0, "step_time": 1.0727e+01, "total_time": 1.4400e+03, "__timestamp": "2024-10-09 18:21:25.113304"}, {"step": 159000, "num_env_steps": 159000, "scores": {"n": 1, "mean": 4.3605e+03}, "actor_loss": {"n": 1, "mean": -2.1987e+02}, "entropy_coef_loss": {"n": 1, "mean": -1.4951e-02}, "critic_loss": {"n": 1, "mean": 1.5951e+01}, "entropy_coef": {"n": 1, "mean": 9.6297e-02}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.5606e-01, "std": 2.7397e-01, "min_value": 5.9411e-05, "max_value": 9.9999e-01}, "num_gradient_steps": 0, "step_time": 9.5514e+00, "total_time": 1.4496e+03, "__timestamp": "2024-10-09 18:21:34.663885"}, {"step": 160000, "num_env_steps": 160000, "scores": {"n": 1, "mean": 4.4564e+03}, "actor_loss": {"n": 1, "mean": -2.3433e+02}, "entropy_coef_loss": {"n": 1, "mean": 5.5580e-01}, "critic_loss": {"n": 1, "mean": 1.9913e+01}, "entropy_coef": {"n": 1, "mean": 9.7445e-02}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.5730e-01, "std": 2.7224e-01, "min_value": 5.1135e-04, "max_value": 9.9997e-01}, "num_gradient_steps": 0, "step_time": 9.3057e+00, "total_time": 1.4589e+03, "__timestamp": "2024-10-09 18:21:43.969488"}, {"step": 161000, "num_env_steps": 161000, "scores": {"n": 1, "mean": 4.4376e+03}, "actor_loss": {"n": 1, "mean": -2.3324e+02}, "entropy_coef_loss": {"n": 1, "mean": 7.9670e-01}, "critic_loss": {"n": 1, "mean": 1.6201e+01}, "entropy_coef": {"n": 1, "mean": 9.5241e-02}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.5735e-01, "std": 2.7379e-01, "min_value": 6.6209e-04, "max_value": 9.9990e-01}, "num_gradient_steps": 0, "step_time": 9.4267e+00, "total_time": 1.4683e+03, "__timestamp": "2024-10-09 18:21:53.397165"}, {"step": 162000, "num_env_steps": 162000, "scores": {"n": 1, "mean": 4.5792e+03}, "actor_loss": {"n": 1, "mean": -2.4432e+02}, "entropy_coef_loss": {"n": 1, "mean": 9.9293e-02}, "critic_loss": {"n": 1, "mean": 2.0890e+01}, "entropy_coef": {"n": 1, "mean": 9.5158e-02}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.6525e-01, "std": 2.6675e-01, "min_value": 6.6052e-04, "max_value": 9.9982e-01}, "num_gradient_steps": 0, "step_time": 9.3468e+00, "total_time": 1.4776e+03, "__timestamp": "2024-10-09 18:22:02.744010"}, {"step": 163000, "num_env_steps": 163000, "scores": {"n": 1, "mean": 4.4896e+03}, "actor_loss": {"n": 1, "mean": -2.3111e+02}, "entropy_coef_loss": {"n": 1, "mean": -9.1875e-01}, "critic_loss": {"n": 1, "mean": 1.7235e+01}, "entropy_coef": {"n": 1, "mean": 9.7098e-02}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.5369e-01, "std": 2.7318e-01, "min_value": 2.3264e-04, "max_value": 9.9995e-01}, "num_gradient_steps": 0, "step_time": 9.3231e+00, "total_time": 1.4870e+03, "__timestamp": "2024-10-09 18:22:12.066077"}, {"step": 164000, "num_env_steps": 164000, "scores": {"n": 1, "mean": 4.6267e+03}, "actor_loss": {"n": 1, "mean": -2.2682e+02}, "entropy_coef_loss": {"n": 1, "mean": -8.0007e-01}, "critic_loss": {"n": 1, "mean": 1.6677e+01}, "entropy_coef": {"n": 1, "mean": 9.8090e-02}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.5562e-01, "std": 2.7631e-01, "min_value": 1.0020e-04, "max_value": 9.9982e-01}, "num_gradient_steps": 0, "step_time": 9.3948e+00, "total_time": 1.4964e+03, "__timestamp": "2024-10-09 18:22:21.461855"}, {"step": 165000, "num_env_steps": 165000, "scores": {"n": 1, "mean": 4.8028e+03}, "actor_loss": {"n": 1, "mean": -2.2975e+02}, "entropy_coef_loss": {"n": 1, "mean": -2.9598e-02}, "critic_loss": {"n": 1, "mean": 1.7240e+01}, "entropy_coef": {"n": 1, "mean": 9.9108e-02}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.6042e-01, "std": 2.7009e-01, "min_value": 1.1504e-03, "max_value": 9.9969e-01}, "num_gradient_steps": 0, "step_time": 9.3539e+00, "total_time": 1.5057e+03, "__timestamp": "2024-10-09 18:22:30.815716"}, {"step": 166000, "num_env_steps": 166000, "scores": {"n": 1, "mean": 4.6073e+03}, "actor_loss": {"n": 1, "mean": -2.3764e+02}, "entropy_coef_loss": {"n": 1, "mean": 1.5047e+00}, "critic_loss": {"n": 1, "mean": 1.0870e+02}, "entropy_coef": {"n": 1, "mean": 1.0109e-01}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.6901e-01, "std": 2.6649e-01, "min_value": 1.2102e-04, "max_value": 9.9992e-01}, "num_gradient_steps": 0, "step_time": 9.3390e+00, "total_time": 1.5150e+03, "__timestamp": "2024-10-09 18:22:40.153727"}, {"step": 167000, "num_env_steps": 167000, "scores": {"n": 1, "mean": 4.6766e+03}, "actor_loss": {"n": 1, "mean": -2.3850e+02}, "entropy_coef_loss": {"n": 1, "mean": -5.0827e-01}, "critic_loss": {"n": 1, "mean": 2.9891e+02}, "entropy_coef": {"n": 1, "mean": 1.0182e-01}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.6578e-01, "std": 2.6894e-01, "min_value": 2.8564e-04, "max_value": 9.9998e-01}, "num_gradient_steps": 0, "step_time": 9.3136e+00, "total_time": 1.5244e+03, "__timestamp": "2024-10-09 18:22:49.468364"}, {"step": 168000, "num_env_steps": 168000, "scores": {"n": 1, "mean": 4.6635e+03}, "actor_loss": {"n": 1, "mean": -2.3444e+02}, "entropy_coef_loss": {"n": 1, "mean": -8.0589e-01}, "critic_loss": {"n": 1, "mean": 2.0146e+01}, "entropy_coef": {"n": 1, "mean": 1.0277e-01}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.7202e-01, "std": 2.6520e-01, "min_value": 1.2853e-03, "max_value": 9.9992e-01}, "num_gradient_steps": 0, "step_time": 9.3364e+00, "total_time": 1.5337e+03, "__timestamp": "2024-10-09 18:22:58.804723"}, {"step": 169000, "num_env_steps": 169000, "scores": {"n": 1, "mean": 4.6695e+03}, "actor_loss": {"n": 1, "mean": -2.3326e+02}, "entropy_coef_loss": {"n": 1, "mean": -1.1660e-01}, "critic_loss": {"n": 1, "mean": 1.4020e+01}, "entropy_coef": {"n": 1, "mean": 1.0023e-01}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.6474e-01, "std": 2.6562e-01, "min_value": 6.9685e-04, "max_value": 9.9993e-01}, "num_gradient_steps": 0, "step_time": 9.3220e+00, "total_time": 1.5430e+03, "__timestamp": "2024-10-09 18:23:08.125745"}, {"step": 170000, "num_env_steps": 170000, "scores": {"n": 1, "mean": 4.8771e+03}, "actor_loss": {"n": 1, "mean": -2.4339e+02}, "entropy_coef_loss": {"n": 1, "mean": 4.2367e-01}, "critic_loss": {"n": 1, "mean": 1.5250e+01}, "entropy_coef": {"n": 1, "mean": 1.0269e-01}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.6768e-01, "std": 2.6638e-01, "min_value": 1.5865e-03, "max_value": 9.9999e-01}, "num_gradient_steps": 0, "step_time": 9.3274e+00, "total_time": 1.5523e+03, "__timestamp": "2024-10-09 18:23:17.453127"}, {"step": 171000, "num_env_steps": 171000, "scores": {"n": 1, "mean": 4.7171e+03}, "actor_loss": {"n": 1, "mean": -2.4069e+02}, "entropy_coef_loss": {"n": 1, "mean": -2.0257e-01}, "critic_loss": {"n": 1, "mean": 1.3071e+01}, "entropy_coef": {"n": 1, "mean": 1.0267e-01}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.6967e-01, "std": 2.6515e-01, "min_value": 2.6107e-04, "max_value": 9.9998e-01}, "num_gradient_steps": 0, "step_time": 9.3695e+00, "total_time": 1.5617e+03, "__timestamp": "2024-10-09 18:23:26.822656"}, {"step": 172000, "num_env_steps": 172000, "scores": {"n": 1, "mean": 4.6526e+03}, "actor_loss": {"n": 1, "mean": -2.4586e+02}, "entropy_coef_loss": {"n": 1, "mean": 5.2768e-02}, "critic_loss": {"n": 1, "mean": 1.6066e+01}, "entropy_coef": {"n": 1, "mean": 1.0129e-01}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.6023e-01, "std": 2.7026e-01, "min_value": 8.8692e-05, "max_value": 9.9995e-01}, "num_gradient_steps": 0, "step_time": 9.3435e+00, "total_time": 1.5711e+03, "__timestamp": "2024-10-09 18:23:36.166131"}, {"step": 173000, "num_env_steps": 173000, "scores": {"n": 1, "mean": 4.6824e+03}, "actor_loss": {"n": 1, "mean": -2.4001e+02}, "entropy_coef_loss": {"n": 1, "mean": 6.7416e-02}, "critic_loss": {"n": 1, "mean": 2.0334e+02}, "entropy_coef": {"n": 1, "mean": 1.0328e-01}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.6732e-01, "std": 2.6736e-01, "min_value": 3.6463e-04, "max_value": 9.9991e-01}, "num_gradient_steps": 0, "step_time": 9.3187e+00, "total_time": 1.5804e+03, "__timestamp": "2024-10-09 18:23:45.485867"}, {"step": 174000, "num_env_steps": 174000, "scores": {"n": 1, "mean": 4.6112e+03}, "actor_loss": {"n": 1, "mean": -2.4018e+02}, "entropy_coef_loss": {"n": 1, "mean": 2.0372e-01}, "critic_loss": {"n": 1, "mean": 2.2830e+01}, "entropy_coef": {"n": 1, "mean": 1.0709e-01}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.6145e-01, "std": 2.7112e-01, "min_value": 3.5882e-04, "max_value": 9.9987e-01}, "num_gradient_steps": 0, "step_time": 9.4773e+00, "total_time": 1.5899e+03, "__timestamp": "2024-10-09 18:23:54.963142"}, {"step": 175000, "num_env_steps": 175000, "scores": {"n": 1, "mean": 4.3161e+03}, "actor_loss": {"n": 1, "mean": -2.3334e+02}, "entropy_coef_loss": {"n": 1, "mean": -5.7538e-02}, "critic_loss": {"n": 1, "mean": 2.4867e+01}, "entropy_coef": {"n": 1, "mean": 1.0420e-01}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.6256e-01, "std": 2.6756e-01, "min_value": 3.1429e-04, "max_value": 9.9985e-01}, "num_gradient_steps": 0, "step_time": 9.3699e+00, "total_time": 1.5992e+03, "__timestamp": "2024-10-09 18:24:04.332018"}, {"step": 176000, "num_env_steps": 176000, "scores": {"n": 1, "mean": 4.4427e+03}, "actor_loss": {"n": 1, "mean": -2.3600e+02}, "entropy_coef_loss": {"n": 1, "mean": -1.3868e-01}, "critic_loss": {"n": 1, "mean": 1.4483e+01}, "entropy_coef": {"n": 1, "mean": 1.0490e-01}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.5870e-01, "std": 2.7006e-01, "min_value": 7.9870e-06, "max_value": 9.9991e-01}, "num_gradient_steps": 0, "step_time": 9.3461e+00, "total_time": 1.6086e+03, "__timestamp": "2024-10-09 18:24:13.678115"}, {"step": 177000, "num_env_steps": 177000, "scores": {"n": 1, "mean": 4.7365e+03}, "actor_loss": {"n": 1, "mean": -2.4178e+02}, "entropy_coef_loss": {"n": 1, "mean": -3.5532e-01}, "critic_loss": {"n": 1, "mean": 1.6235e+01}, "entropy_coef": {"n": 1, "mean": 1.0792e-01}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.6744e-01, "std": 2.6476e-01, "min_value": 1.0786e-03, "max_value": 9.9985e-01}, "num_gradient_steps": 0, "step_time": 9.3103e+00, "total_time": 1.6179e+03, "__timestamp": "2024-10-09 18:24:22.989411"}, {"step": 178000, "num_env_steps": 178000, "scores": {"n": 1, "mean": 4.8320e+03}, "actor_loss": {"n": 1, "mean": -2.4341e+02}, "entropy_coef_loss": {"n": 1, "mean": -7.1582e-01}, "critic_loss": {"n": 1, "mean": 1.9441e+01}, "entropy_coef": {"n": 1, "mean": 1.0901e-01}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.7043e-01, "std": 2.6923e-01, "min_value": 1.6382e-04, "max_value": 9.9985e-01}, "num_gradient_steps": 0, "step_time": 9.3259e+00, "total_time": 1.6272e+03, "__timestamp": "2024-10-09 18:24:32.315292"}, {"step": 179000, "num_env_steps": 179000, "scores": {"n": 1, "mean": 4.7128e+03}, "actor_loss": {"n": 1, "mean": -2.2842e+02}, "entropy_coef_loss": {"n": 1, "mean": 5.9963e-01}, "critic_loss": {"n": 1, "mean": 1.0861e+02}, "entropy_coef": {"n": 1, "mean": 1.0565e-01}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.7223e-01, "std": 2.6247e-01, "min_value": 1.0588e-03, "max_value": 9.9982e-01}, "num_gradient_steps": 0, "step_time": 9.3283e+00, "total_time": 1.6365e+03, "__timestamp": "2024-10-09 18:24:41.642551"}, {"step": 180000, "num_env_steps": 180000, "scores": {"n": 1, "mean": 4.9200e+03}, "actor_loss": {"n": 1, "mean": -2.4988e+02}, "entropy_coef_loss": {"n": 1, "mean": 2.6306e-01}, "critic_loss": {"n": 1, "mean": 1.4237e+01}, "entropy_coef": {"n": 1, "mean": 1.0926e-01}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.7917e-01, "std": 2.6167e-01, "min_value": 4.5091e-04, "max_value": 9.9991e-01}, "num_gradient_steps": 0, "step_time": 9.2859e+00, "total_time": 1.6458e+03, "__timestamp": "2024-10-09 18:24:50.928479"}, {"step": 181000, "num_env_steps": 181000, "scores": {"n": 1, "mean": 4.6693e+03}, "actor_loss": {"n": 1, "mean": -2.4455e+02}, "entropy_coef_loss": {"n": 1, "mean": 1.9936e-01}, "critic_loss": {"n": 1, "mean": 1.3959e+01}, "entropy_coef": {"n": 1, "mean": 1.0886e-01}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.7095e-01, "std": 2.6367e-01, "min_value": 6.2081e-04, "max_value": 9.9989e-01}, "num_gradient_steps": 0, "step_time": 9.3372e+00, "total_time": 1.6552e+03, "__timestamp": "2024-10-09 18:25:00.265654"}, {"step": 182000, "num_env_steps": 182000, "scores": {"n": 1, "mean": 4.8532e+03}, "actor_loss": {"n": 1, "mean": -2.4556e+02}, "entropy_coef_loss": {"n": 1, "mean": 4.5284e-01}, "critic_loss": {"n": 1, "mean": 1.6811e+01}, "entropy_coef": {"n": 1, "mean": 1.0665e-01}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.7167e-01, "std": 2.6373e-01, "min_value": 7.8320e-04, "max_value": 9.9993e-01}, "num_gradient_steps": 0, "step_time": 9.3819e+00, "total_time": 1.6645e+03, "__timestamp": "2024-10-09 18:25:09.647511"}, {"step": 183000, "num_env_steps": 183000, "scores": {"n": 1, "mean": 4.7957e+03}, "actor_loss": {"n": 1, "mean": -2.4324e+02}, "entropy_coef_loss": {"n": 1, "mean": -2.0173e-01}, "critic_loss": {"n": 1, "mean": 1.9942e+01}, "entropy_coef": {"n": 1, "mean": 1.0524e-01}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.6173e-01, "std": 2.6888e-01, "min_value": 3.9503e-05, "max_value": 9.9998e-01}, "num_gradient_steps": 0, "step_time": 9.3288e+00, "total_time": 1.6739e+03, "__timestamp": "2024-10-09 18:25:18.976311"}, {"step": 184000, "num_env_steps": 184000, "scores": {"n": 1, "mean": 4.5096e+03}, "actor_loss": {"n": 1, "mean": -2.4322e+02}, "entropy_coef_loss": {"n": 1, "mean": -2.2484e-02}, "critic_loss": {"n": 1, "mean": 3.7296e+02}, "entropy_coef": {"n": 1, "mean": 1.0738e-01}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.6727e-01, "std": 2.6362e-01, "min_value": 1.7345e-05, "max_value": 9.9981e-01}, "num_gradient_steps": 0, "step_time": 9.3431e+00, "total_time": 1.6832e+03, "__timestamp": "2024-10-09 18:25:28.320402"}, {"step": 185000, "num_env_steps": 185000, "scores": {"n": 1, "mean": 4.7268e+03}, "actor_loss": {"n": 1, "mean": -2.4504e+02}, "entropy_coef_loss": {"n": 1, "mean": -8.8758e-01}, "critic_loss": {"n": 1, "mean": 1.7485e+01}, "entropy_coef": {"n": 1, "mean": 1.0543e-01}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.6625e-01, "std": 2.6675e-01, "min_value": 1.6100e-03, "max_value": 1.0000e+00}, "num_gradient_steps": 0, "step_time": 1.0605e+01, "total_time": 1.6938e+03, "__timestamp": "2024-10-09 18:25:38.925718"}, {"step": 186000, "num_env_steps": 186000, "scores": {"n": 1, "mean": 5.0166e+03}, "actor_loss": {"n": 1, "mean": -2.5014e+02}, "entropy_coef_loss": {"n": 1, "mean": 1.4865e+00}, "critic_loss": {"n": 1, "mean": 1.7939e+01}, "entropy_coef": {"n": 1, "mean": 1.0952e-01}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.6934e-01, "std": 2.6408e-01, "min_value": 1.7864e-04, "max_value": 9.9973e-01}, "num_gradient_steps": 0, "step_time": 1.0378e+01, "total_time": 1.7042e+03, "__timestamp": "2024-10-09 18:25:49.303168"}, {"step": 187000, "num_env_steps": 187000, "scores": {"n": 1, "mean": 4.5313e+03}, "actor_loss": {"n": 1, "mean": -2.4654e+02}, "entropy_coef_loss": {"n": 1, "mean": 1.0704e-01}, "critic_loss": {"n": 1, "mean": 1.1327e+01}, "entropy_coef": {"n": 1, "mean": 1.1089e-01}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.6807e-01, "std": 2.6511e-01, "min_value": 3.4323e-04, "max_value": 9.9980e-01}, "num_gradient_steps": 0, "step_time": 1.0899e+01, "total_time": 1.7151e+03, "__timestamp": "2024-10-09 18:26:00.201912"}, {"step": 188000, "num_env_steps": 188000, "scores": {"n": 1, "mean": 4.7828e+03}, "actor_loss": {"n": 1, "mean": -2.5776e+02}, "entropy_coef_loss": {"n": 1, "mean": 6.0713e-01}, "critic_loss": {"n": 1, "mean": 1.5767e+01}, "entropy_coef": {"n": 1, "mean": 1.1019e-01}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.7547e-01, "std": 2.6068e-01, "min_value": 2.3842e-06, "max_value": 9.9991e-01}, "num_gradient_steps": 0, "step_time": 1.0643e+01, "total_time": 1.7257e+03, "__timestamp": "2024-10-09 18:26:10.846333"}, {"step": 189000, "num_env_steps": 189000, "scores": {"n": 1, "mean": 4.9705e+03}, "actor_loss": {"n": 1, "mean": -2.4990e+02}, "entropy_coef_loss": {"n": 1, "mean": 2.1211e-01}, "critic_loss": {"n": 1, "mean": 1.5887e+01}, "entropy_coef": {"n": 1, "mean": 1.1504e-01}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.7331e-01, "std": 2.6487e-01, "min_value": 5.6001e-04, "max_value": 9.9987e-01}, "num_gradient_steps": 0, "step_time": 1.0604e+01, "total_time": 1.7363e+03, "__timestamp": "2024-10-09 18:26:21.449816"}, {"step": 190000, "num_env_steps": 190000, "scores": {"n": 1, "mean": 4.8944e+03}, "actor_loss": {"n": 1, "mean": -2.4975e+02}, "entropy_coef_loss": {"n": 1, "mean": -1.3661e-01}, "critic_loss": {"n": 1, "mean": 1.5151e+01}, "entropy_coef": {"n": 1, "mean": 1.1292e-01}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.7010e-01, "std": 2.6556e-01, "min_value": 7.0360e-04, "max_value": 9.9982e-01}, "num_gradient_steps": 0, "step_time": 1.0765e+01, "total_time": 1.7471e+03, "__timestamp": "2024-10-09 18:26:32.216075"}, {"step": 191000, "num_env_steps": 191000, "scores": {"n": 1, "mean": 4.6358e+03}, "actor_loss": {"n": 1, "mean": -2.5468e+02}, "entropy_coef_loss": {"n": 1, "mean": 2.7490e-01}, "critic_loss": {"n": 1, "mean": 1.8533e+01}, "entropy_coef": {"n": 1, "mean": 1.1363e-01}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.6878e-01, "std": 2.6074e-01, "min_value": 6.5953e-04, "max_value": 9.9985e-01}, "num_gradient_steps": 0, "step_time": 1.0481e+01, "total_time": 1.7576e+03, "__timestamp": "2024-10-09 18:26:42.695734"}, {"step": 192000, "num_env_steps": 192000, "scores": {"n": 1, "mean": 4.9231e+03}, "actor_loss": {"n": 1, "mean": -2.4289e+02}, "entropy_coef_loss": {"n": 1, "mean": 4.2950e-01}, "critic_loss": {"n": 1, "mean": 1.5346e+01}, "entropy_coef": {"n": 1, "mean": 1.1166e-01}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.7209e-01, "std": 2.6126e-01, "min_value": 7.8514e-05, "max_value": 9.9985e-01}, "num_gradient_steps": 0, "step_time": 1.0424e+01, "total_time": 1.7680e+03, "__timestamp": "2024-10-09 18:26:53.120305"}, {"step": 193000, "num_env_steps": 193000, "scores": {"n": 1, "mean": 4.8351e+03}, "actor_loss": {"n": 1, "mean": -2.5537e+02}, "entropy_coef_loss": {"n": 1, "mean": -9.1242e-02}, "critic_loss": {"n": 1, "mean": 2.0285e+01}, "entropy_coef": {"n": 1, "mean": 1.1168e-01}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.6946e-01, "std": 2.6422e-01, "min_value": 1.8796e-04, "max_value": 9.9985e-01}, "num_gradient_steps": 0, "step_time": 1.1049e+01, "total_time": 1.7791e+03, "__timestamp": "2024-10-09 18:27:04.169793"}, {"step": 194000, "num_env_steps": 194000, "scores": {"n": 1, "mean": 4.8139e+03}, "actor_loss": {"n": 1, "mean": -2.6317e+02}, "entropy_coef_loss": {"n": 1, "mean": 1.0590e+00}, "critic_loss": {"n": 1, "mean": 1.5054e+01}, "entropy_coef": {"n": 1, "mean": 1.1388e-01}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.6935e-01, "std": 2.6491e-01, "min_value": 5.1039e-04, "max_value": 9.9996e-01}, "num_gradient_steps": 0, "step_time": 1.0335e+01, "total_time": 1.7894e+03, "__timestamp": "2024-10-09 18:27:14.504662"}, {"step": 195000, "num_env_steps": 195000, "scores": {"n": 1, "mean": 4.6443e+03}, "actor_loss": {"n": 1, "mean": -2.5147e+02}, "entropy_coef_loss": {"n": 1, "mean": 2.3736e-01}, "critic_loss": {"n": 1, "mean": 1.3372e+01}, "entropy_coef": {"n": 1, "mean": 1.1768e-01}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.7296e-01, "std": 2.6343e-01, "min_value": 7.3695e-04, "max_value": 9.9994e-01}, "num_gradient_steps": 0, "step_time": 1.0097e+01, "total_time": 1.7995e+03, "__timestamp": "2024-10-09 18:27:24.600425"}, {"step": 196000, "num_env_steps": 196000, "scores": {"n": 1, "mean": 4.9875e+03}, "actor_loss": {"n": 1, "mean": -2.5790e+02}, "entropy_coef_loss": {"n": 1, "mean": 6.0126e-01}, "critic_loss": {"n": 1, "mean": 1.5456e+01}, "entropy_coef": {"n": 1, "mean": 1.1518e-01}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.7750e-01, "std": 2.6002e-01, "min_value": 3.2477e-04, "max_value": 9.9960e-01}, "num_gradient_steps": 0, "step_time": 1.0069e+01, "total_time": 1.8096e+03, "__timestamp": "2024-10-09 18:27:34.670872"}, {"step": 197000, "num_env_steps": 197000, "scores": {"n": 1, "mean": 4.7821e+03}, "actor_loss": {"n": 1, "mean": -2.5776e+02}, "entropy_coef_loss": {"n": 1, "mean": 5.4110e-01}, "critic_loss": {"n": 1, "mean": 2.5715e+01}, "entropy_coef": {"n": 1, "mean": 1.1449e-01}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.7569e-01, "std": 2.6205e-01, "min_value": 5.1305e-04, "max_value": 9.9992e-01}, "num_gradient_steps": 0, "step_time": 1.0138e+01, "total_time": 1.8197e+03, "__timestamp": "2024-10-09 18:27:44.808368"}, {"step": 198000, "num_env_steps": 198000, "scores": {"n": 1, "mean": 4.8572e+03}, "actor_loss": {"n": 1, "mean": -2.5165e+02}, "entropy_coef_loss": {"n": 1, "mean": -1.0925e-01}, "critic_loss": {"n": 1, "mean": 3.6209e+02}, "entropy_coef": {"n": 1, "mean": 1.1258e-01}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.6751e-01, "std": 2.6506e-01, "min_value": 7.1859e-04, "max_value": 9.9995e-01}, "num_gradient_steps": 0, "step_time": 1.0062e+01, "total_time": 1.8298e+03, "__timestamp": "2024-10-09 18:27:54.870469"}, {"step": 199000, "num_env_steps": 199000, "scores": {"n": 1, "mean": 4.8134e+03}, "actor_loss": {"n": 1, "mean": -2.5579e+02}, "entropy_coef_loss": {"n": 1, "mean": 6.1300e-01}, "critic_loss": {"n": 1, "mean": 4.0054e+02}, "entropy_coef": {"n": 1, "mean": 1.1263e-01}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.7170e-01, "std": 2.6135e-01, "min_value": 7.6592e-06, "max_value": 9.9986e-01}, "num_gradient_steps": 0, "step_time": 1.0048e+01, "total_time": 1.8398e+03, "__timestamp": "2024-10-09 18:28:04.919682"}, {"step": 200000, "num_env_steps": 200000, "scores": {"n": 1, "mean": 4.8133e+03}, "actor_loss": {"n": 1, "mean": -2.5949e+02}, "entropy_coef_loss": {"n": 1, "mean": 8.5405e-02}, "critic_loss": {"n": 1, "mean": 1.3953e+01}, "entropy_coef": {"n": 1, "mean": 1.1755e-01}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.6873e-01, "std": 2.6629e-01, "min_value": 1.0066e-04, "max_value": 9.9988e-01}, "num_gradient_steps": 0, "step_time": 1.0067e+01, "total_time": 1.8499e+03, "__timestamp": "2024-10-09 18:28:14.986312"}, {"step": 201000, "num_env_steps": 201000, "scores": {"n": 1, "mean": 4.7984e+03}, "actor_loss": {"n": 1, "mean": -2.5430e+02}, "entropy_coef_loss": {"n": 1, "mean": 2.4030e-01}, "critic_loss": {"n": 1, "mean": 1.9464e+01}, "entropy_coef": {"n": 1, "mean": 1.1760e-01}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.7408e-01, "std": 2.6072e-01, "min_value": 1.4016e-04, "max_value": 9.9990e-01}, "num_gradient_steps": 0, "step_time": 9.9668e+00, "total_time": 1.8598e+03, "__timestamp": "2024-10-09 18:28:24.953134"}, {"step": 202000, "num_env_steps": 202000, "scores": {"n": 1, "mean": 4.9077e+03}, "actor_loss": {"n": 1, "mean": -2.6118e+02}, "entropy_coef_loss": {"n": 1, "mean": 1.4340e+00}, "critic_loss": {"n": 1, "mean": 1.9022e+01}, "entropy_coef": {"n": 1, "mean": 1.1715e-01}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.7674e-01, "std": 2.6149e-01, "min_value": 2.2826e-04, "max_value": 9.9994e-01}, "num_gradient_steps": 0, "step_time": 9.6287e+00, "total_time": 1.8695e+03, "__timestamp": "2024-10-09 18:28:34.581878"}, {"step": 203000, "num_env_steps": 203000, "scores": {"n": 1, "mean": 4.7394e+03}, "actor_loss": {"n": 1, "mean": -2.5886e+02}, "entropy_coef_loss": {"n": 1, "mean": 1.1763e+00}, "critic_loss": {"n": 1, "mean": 3.4335e+01}, "entropy_coef": {"n": 1, "mean": 1.2013e-01}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.6839e-01, "std": 2.6415e-01, "min_value": 1.8394e-05, "max_value": 9.9993e-01}, "num_gradient_steps": 0, "step_time": 9.6405e+00, "total_time": 1.8791e+03, "__timestamp": "2024-10-09 18:28:44.222366"}, {"step": 204000, "num_env_steps": 204000, "scores": {"n": 1, "mean": 4.6577e+03}, "actor_loss": {"n": 1, "mean": -2.5245e+02}, "entropy_coef_loss": {"n": 1, "mean": 1.1530e-01}, "critic_loss": {"n": 1, "mean": 1.4760e+01}, "entropy_coef": {"n": 1, "mean": 1.1900e-01}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.6979e-01, "std": 2.6260e-01, "min_value": 3.4153e-05, "max_value": 9.9998e-01}, "num_gradient_steps": 0, "step_time": 9.6607e+00, "total_time": 1.8888e+03, "__timestamp": "2024-10-09 18:28:53.883064"}, {"step": 205000, "num_env_steps": 205000, "scores": {"n": 1, "mean": 4.8605e+03}, "actor_loss": {"n": 1, "mean": -2.6217e+02}, "entropy_coef_loss": {"n": 1, "mean": -1.0983e-01}, "critic_loss": {"n": 1, "mean": 2.1423e+01}, "entropy_coef": {"n": 1, "mean": 1.1809e-01}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.7560e-01, "std": 2.5906e-01, "min_value": 8.1182e-05, "max_value": 9.9983e-01}, "num_gradient_steps": 0, "step_time": 9.6312e+00, "total_time": 1.8984e+03, "__timestamp": "2024-10-09 18:29:03.514267"}, {"step": 206000, "num_env_steps": 206000, "scores": {"n": 1, "mean": 4.8442e+03}, "actor_loss": {"n": 1, "mean": -2.6243e+02}, "entropy_coef_loss": {"n": 1, "mean": -9.8042e-01}, "critic_loss": {"n": 1, "mean": 1.5439e+01}, "entropy_coef": {"n": 1, "mean": 1.1446e-01}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.6623e-01, "std": 2.6625e-01, "min_value": 7.1988e-05, "max_value": 9.9999e-01}, "num_gradient_steps": 0, "step_time": 9.5456e+00, "total_time": 1.9080e+03, "__timestamp": "2024-10-09 18:29:13.059901"}, {"step": 207000, "num_env_steps": 207000, "scores": {"n": 1, "mean": 4.7864e+03}, "actor_loss": {"n": 1, "mean": -2.6729e+02}, "entropy_coef_loss": {"n": 1, "mean": -1.4146e-01}, "critic_loss": {"n": 1, "mean": 1.7619e+01}, "entropy_coef": {"n": 1, "mean": 1.1945e-01}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.6155e-01, "std": 2.6996e-01, "min_value": 1.2370e-03, "max_value": 9.9986e-01}, "num_gradient_steps": 0, "step_time": 9.6414e+00, "total_time": 1.9176e+03, "__timestamp": "2024-10-09 18:29:22.701276"}, {"step": 208000, "num_env_steps": 208000, "scores": {"n": 1, "mean": 4.9592e+03}, "actor_loss": {"n": 1, "mean": -2.5969e+02}, "entropy_coef_loss": {"n": 1, "mean": 2.0559e-01}, "critic_loss": {"n": 1, "mean": 1.2803e+01}, "entropy_coef": {"n": 1, "mean": 1.1720e-01}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.7290e-01, "std": 2.6368e-01, "min_value": 2.0477e-04, "max_value": 9.9974e-01}, "num_gradient_steps": 0, "step_time": 9.6135e+00, "total_time": 1.9272e+03, "__timestamp": "2024-10-09 18:29:32.313740"}, {"step": 209000, "num_env_steps": 209000, "scores": {"n": 1, "mean": 4.8141e+03}, "actor_loss": {"n": 1, "mean": -2.7251e+02}, "entropy_coef_loss": {"n": 1, "mean": 1.4824e+00}, "critic_loss": {"n": 1, "mean": 1.5514e+01}, "entropy_coef": {"n": 1, "mean": 1.1724e-01}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.7243e-01, "std": 2.6443e-01, "min_value": 1.7211e-04, "max_value": 9.9998e-01}, "num_gradient_steps": 0, "step_time": 9.6390e+00, "total_time": 1.9368e+03, "__timestamp": "2024-10-09 18:29:41.952763"}, {"step": 210000, "num_env_steps": 210000, "scores": {"n": 1, "mean": 5.0520e+03}, "actor_loss": {"n": 1, "mean": -2.6676e+02}, "entropy_coef_loss": {"n": 1, "mean": 8.7681e-01}, "critic_loss": {"n": 1, "mean": 1.6347e+01}, "entropy_coef": {"n": 1, "mean": 1.2048e-01}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.7687e-01, "std": 2.5680e-01, "min_value": 1.8971e-03, "max_value": 9.9998e-01}, "num_gradient_steps": 0, "step_time": 9.7037e+00, "total_time": 1.9465e+03, "__timestamp": "2024-10-09 18:29:51.657449"}, {"step": 211000, "num_env_steps": 211000, "scores": {"n": 1, "mean": 4.9527e+03}, "actor_loss": {"n": 1, "mean": -2.5699e+02}, "entropy_coef_loss": {"n": 1, "mean": -1.1743e+00}, "critic_loss": {"n": 1, "mean": 1.5029e+01}, "entropy_coef": {"n": 1, "mean": 1.2202e-01}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.7385e-01, "std": 2.6435e-01, "min_value": 7.2876e-07, "max_value": 9.9977e-01}, "num_gradient_steps": 0, "step_time": 9.5919e+00, "total_time": 1.9561e+03, "__timestamp": "2024-10-09 18:30:01.248322"}, {"step": 212000, "num_env_steps": 212000, "scores": {"n": 1, "mean": 5.0019e+03}, "actor_loss": {"n": 1, "mean": -2.6372e+02}, "entropy_coef_loss": {"n": 1, "mean": 9.4795e-01}, "critic_loss": {"n": 1, "mean": 1.3774e+01}, "entropy_coef": {"n": 1, "mean": 1.2139e-01}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.7578e-01, "std": 2.6274e-01, "min_value": 1.4600e-04, "max_value": 9.9990e-01}, "num_gradient_steps": 0, "step_time": 9.6727e+00, "total_time": 1.9658e+03, "__timestamp": "2024-10-09 18:30:10.922012"}, {"step": 213000, "num_env_steps": 213000, "scores": {"n": 1, "mean": 4.9040e+03}, "actor_loss": {"n": 1, "mean": -2.6096e+02}, "entropy_coef_loss": {"n": 1, "mean": -9.8321e-01}, "critic_loss": {"n": 1, "mean": 1.1038e+02}, "entropy_coef": {"n": 1, "mean": 1.2175e-01}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.7449e-01, "std": 2.6424e-01, "min_value": 1.0496e-03, "max_value": 9.9996e-01}, "num_gradient_steps": 0, "step_time": 9.5933e+00, "total_time": 1.9754e+03, "__timestamp": "2024-10-09 18:30:20.515293"}, {"step": 214000, "num_env_steps": 214000, "scores": {"n": 1, "mean": 4.9250e+03}, "actor_loss": {"n": 1, "mean": -2.6153e+02}, "entropy_coef_loss": {"n": 1, "mean": 3.4795e-02}, "critic_loss": {"n": 1, "mean": 2.2373e+01}, "entropy_coef": {"n": 1, "mean": 1.1980e-01}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.7061e-01, "std": 2.6537e-01, "min_value": 1.2828e-03, "max_value": 9.9995e-01}, "num_gradient_steps": 0, "step_time": 9.5740e+00, "total_time": 1.9850e+03, "__timestamp": "2024-10-09 18:30:30.089312"}, {"step": 215000, "num_env_steps": 215000, "scores": {"n": 1, "mean": 5.0250e+03}, "actor_loss": {"n": 1, "mean": -2.5393e+02}, "entropy_coef_loss": {"n": 1, "mean": -3.3389e-01}, "critic_loss": {"n": 1, "mean": 2.9340e+02}, "entropy_coef": {"n": 1, "mean": 1.2074e-01}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.7348e-01, "std": 2.6154e-01, "min_value": 4.4708e-04, "max_value": 9.9981e-01}, "num_gradient_steps": 0, "step_time": 9.6117e+00, "total_time": 1.9946e+03, "__timestamp": "2024-10-09 18:30:39.699967"}, {"step": 216000, "num_env_steps": 216000, "scores": {"n": 1, "mean": 5.1201e+03}, "actor_loss": {"n": 1, "mean": -2.6890e+02}, "entropy_coef_loss": {"n": 1, "mean": -6.8021e-01}, "critic_loss": {"n": 1, "mean": 1.8827e+01}, "entropy_coef": {"n": 1, "mean": 1.2372e-01}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.7833e-01, "std": 2.6119e-01, "min_value": 2.4664e-04, "max_value": 9.9982e-01}, "num_gradient_steps": 0, "step_time": 9.6277e+00, "total_time": 2.0042e+03, "__timestamp": "2024-10-09 18:30:49.327646"}, {"step": 217000, "num_env_steps": 217000, "scores": {"n": 1, "mean": 4.5946e+03}, "actor_loss": {"n": 1, "mean": -2.6112e+02}, "entropy_coef_loss": {"n": 1, "mean": -4.4204e-01}, "critic_loss": {"n": 1, "mean": 1.4719e+01}, "entropy_coef": {"n": 1, "mean": 1.2382e-01}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.6133e-01, "std": 2.6870e-01, "min_value": 1.3125e-04, "max_value": 9.9993e-01}, "num_gradient_steps": 0, "step_time": 1.0206e+01, "total_time": 2.0144e+03, "__timestamp": "2024-10-09 18:30:59.533772"}, {"step": 218000, "num_env_steps": 218000, "scores": {"n": 1, "mean": 4.8118e+03}, "actor_loss": {"n": 1, "mean": -2.7333e+02}, "entropy_coef_loss": {"n": 1, "mean": 3.2021e-01}, "critic_loss": {"n": 1, "mean": 3.9697e+02}, "entropy_coef": {"n": 1, "mean": 1.2357e-01}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.7808e-01, "std": 2.5882e-01, "min_value": 1.5379e-03, "max_value": 9.9997e-01}, "num_gradient_steps": 0, "step_time": 1.0296e+01, "total_time": 2.0247e+03, "__timestamp": "2024-10-09 18:31:09.830072"}, {"step": 219000, "num_env_steps": 219000, "scores": {"n": 1, "mean": 5.0475e+03}, "actor_loss": {"n": 1, "mean": -2.6394e+02}, "entropy_coef_loss": {"n": 1, "mean": 3.7870e-01}, "critic_loss": {"n": 1, "mean": 1.5827e+01}, "entropy_coef": {"n": 1, "mean": 1.2589e-01}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.7934e-01, "std": 2.6167e-01, "min_value": 7.1964e-04, "max_value": 9.9987e-01}, "num_gradient_steps": 0, "step_time": 9.6468e+00, "total_time": 2.0344e+03, "__timestamp": "2024-10-09 18:31:19.477915"}, {"step": 220000, "num_env_steps": 220000, "scores": {"n": 1, "mean": 4.7909e+03}, "actor_loss": {"n": 1, "mean": -2.6076e+02}, "entropy_coef_loss": {"n": 1, "mean": -6.9789e-01}, "critic_loss": {"n": 1, "mean": 1.5568e+01}, "entropy_coef": {"n": 1, "mean": 1.2302e-01}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.6534e-01, "std": 2.6765e-01, "min_value": 2.1708e-04, "max_value": 9.9990e-01}, "num_gradient_steps": 0, "step_time": 9.6298e+00, "total_time": 2.0440e+03, "__timestamp": "2024-10-09 18:31:29.106667"}, {"step": 221000, "num_env_steps": 221000, "scores": {"n": 1, "mean": 5.1091e+03}, "actor_loss": {"n": 1, "mean": -2.5573e+02}, "entropy_coef_loss": {"n": 1, "mean": -1.5258e+00}, "critic_loss": {"n": 1, "mean": 2.0420e+01}, "entropy_coef": {"n": 1, "mean": 1.2297e-01}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.7118e-01, "std": 2.6325e-01, "min_value": 7.5410e-04, "max_value": 9.9993e-01}, "num_gradient_steps": 0, "step_time": 9.6444e+00, "total_time": 2.0536e+03, "__timestamp": "2024-10-09 18:31:38.751099"}, {"step": 222000, "num_env_steps": 222000, "scores": {"n": 1, "mean": 4.7806e+03}, "actor_loss": {"n": 1, "mean": -2.6464e+02}, "entropy_coef_loss": {"n": 1, "mean": 3.9414e-01}, "critic_loss": {"n": 1, "mean": 3.0265e+02}, "entropy_coef": {"n": 1, "mean": 1.2165e-01}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.6398e-01, "std": 2.6761e-01, "min_value": 5.5596e-05, "max_value": 9.9996e-01}, "num_gradient_steps": 0, "step_time": 9.9254e+00, "total_time": 2.0636e+03, "__timestamp": "2024-10-09 18:31:48.677542"}, {"step": 223000, "num_env_steps": 223000, "scores": {"n": 1, "mean": 4.9126e+03}, "actor_loss": {"n": 1, "mean": -2.6113e+02}, "entropy_coef_loss": {"n": 1, "mean": -4.9139e-01}, "critic_loss": {"n": 1, "mean": 1.6230e+01}, "entropy_coef": {"n": 1, "mean": 1.2339e-01}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.7091e-01, "std": 2.6329e-01, "min_value": 5.1990e-05, "max_value": 9.9993e-01}, "num_gradient_steps": 0, "step_time": 1.0253e+01, "total_time": 2.0738e+03, "__timestamp": "2024-10-09 18:31:58.930936"}, {"step": 224000, "num_env_steps": 224000, "scores": {"n": 1, "mean": 4.9550e+03}, "actor_loss": {"n": 1, "mean": -2.6343e+02}, "entropy_coef_loss": {"n": 1, "mean": 5.3832e-02}, "critic_loss": {"n": 1, "mean": 1.4365e+01}, "entropy_coef": {"n": 1, "mean": 1.2534e-01}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.6638e-01, "std": 2.6798e-01, "min_value": 4.1218e-04, "max_value": 9.9981e-01}, "num_gradient_steps": 0, "step_time": 1.0110e+01, "total_time": 2.0839e+03, "__timestamp": "2024-10-09 18:32:09.039681"}, {"step": 225000, "num_env_steps": 225000, "scores": {"n": 1, "mean": 4.9195e+03}, "actor_loss": {"n": 1, "mean": -2.6212e+02}, "entropy_coef_loss": {"n": 1, "mean": -8.7693e-03}, "critic_loss": {"n": 1, "mean": 1.6966e+01}, "entropy_coef": {"n": 1, "mean": 1.2203e-01}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.7281e-01, "std": 2.6138e-01, "min_value": 1.1558e-03, "max_value": 9.9971e-01}, "num_gradient_steps": 0, "step_time": 1.0062e+01, "total_time": 2.0940e+03, "__timestamp": "2024-10-09 18:32:19.101253"}, {"step": 226000, "num_env_steps": 226000, "scores": {"n": 1, "mean": 5.0212e+03}, "actor_loss": {"n": 1, "mean": -2.7698e+02}, "entropy_coef_loss": {"n": 1, "mean": -3.5461e-01}, "critic_loss": {"n": 1, "mean": 2.5918e+01}, "entropy_coef": {"n": 1, "mean": 1.2350e-01}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.7195e-01, "std": 2.6467e-01, "min_value": 8.9238e-05, "max_value": 9.9986e-01}, "num_gradient_steps": 0, "step_time": 1.0286e+01, "total_time": 2.1043e+03, "__timestamp": "2024-10-09 18:32:29.387026"}, {"step": 227000, "num_env_steps": 227000, "scores": {"n": 1, "mean": 4.9350e+03}, "actor_loss": {"n": 1, "mean": -2.7437e+02}, "entropy_coef_loss": {"n": 1, "mean": -4.6366e-01}, "critic_loss": {"n": 1, "mean": 1.7910e+01}, "entropy_coef": {"n": 1, "mean": 1.2320e-01}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.7527e-01, "std": 2.5841e-01, "min_value": 1.0332e-04, "max_value": 9.9979e-01}, "num_gradient_steps": 0, "step_time": 1.0265e+01, "total_time": 2.1145e+03, "__timestamp": "2024-10-09 18:32:39.652073"}, {"step": 228000, "num_env_steps": 228000, "scores": {"n": 1, "mean": 4.9963e+03}, "actor_loss": {"n": 1, "mean": -2.6394e+02}, "entropy_coef_loss": {"n": 1, "mean": -1.1673e-01}, "critic_loss": {"n": 1, "mean": 4.2450e+02}, "entropy_coef": {"n": 1, "mean": 1.3058e-01}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.8448e-01, "std": 2.5549e-01, "min_value": 6.4599e-04, "max_value": 9.9993e-01}, "num_gradient_steps": 0, "step_time": 1.0179e+01, "total_time": 2.1247e+03, "__timestamp": "2024-10-09 18:32:49.830664"}, {"step": 229000, "num_env_steps": 229000, "scores": {"n": 1, "mean": 5.1621e+03}, "actor_loss": {"n": 1, "mean": -2.6906e+02}, "entropy_coef_loss": {"n": 1, "mean": 1.0668e-01}, "critic_loss": {"n": 1, "mean": 1.6432e+01}, "entropy_coef": {"n": 1, "mean": 1.2756e-01}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.8020e-01, "std": 2.6111e-01, "min_value": 1.4153e-03, "max_value": 9.9997e-01}, "num_gradient_steps": 0, "step_time": 9.9368e+00, "total_time": 2.1347e+03, "__timestamp": "2024-10-09 18:32:59.767494"}, {"step": 230000, "num_env_steps": 230000, "scores": {"n": 1, "mean": 4.8848e+03}, "actor_loss": {"n": 1, "mean": -2.6674e+02}, "entropy_coef_loss": {"n": 1, "mean": 6.1386e-01}, "critic_loss": {"n": 1, "mean": 1.8853e+01}, "entropy_coef": {"n": 1, "mean": 1.2511e-01}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.7010e-01, "std": 2.6488e-01, "min_value": 8.6054e-04, "max_value": 9.9988e-01}, "num_gradient_steps": 0, "step_time": 1.0027e+01, "total_time": 2.1447e+03, "__timestamp": "2024-10-09 18:33:09.794940"}, {"step": 231000, "num_env_steps": 231000, "scores": {"n": 1, "mean": 5.0384e+03}, "actor_loss": {"n": 1, "mean": -2.6963e+02}, "entropy_coef_loss": {"n": 1, "mean": -1.4721e-01}, "critic_loss": {"n": 1, "mean": 4.4014e+02}, "entropy_coef": {"n": 1, "mean": 1.2359e-01}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.6191e-01, "std": 2.7258e-01, "min_value": 1.0313e-04, "max_value": 9.9984e-01}, "num_gradient_steps": 0, "step_time": 1.0280e+01, "total_time": 2.1550e+03, "__timestamp": "2024-10-09 18:33:20.075399"}, {"step": 232000, "num_env_steps": 232000, "scores": {"n": 1, "mean": 5.0112e+03}, "actor_loss": {"n": 1, "mean": -2.7604e+02}, "entropy_coef_loss": {"n": 1, "mean": -4.0252e-01}, "critic_loss": {"n": 1, "mean": 1.6091e+01}, "entropy_coef": {"n": 1, "mean": 1.2346e-01}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.6510e-01, "std": 2.6619e-01, "min_value": 8.3005e-04, "max_value": 9.9979e-01}, "num_gradient_steps": 0, "step_time": 1.0223e+01, "total_time": 2.1652e+03, "__timestamp": "2024-10-09 18:33:30.299167"}, {"step": 233000, "num_env_steps": 233000, "scores": {"n": 1, "mean": 4.8860e+03}, "actor_loss": {"n": 1, "mean": -2.6967e+02}, "entropy_coef_loss": {"n": 1, "mean": 7.5684e-01}, "critic_loss": {"n": 1, "mean": 2.1720e+01}, "entropy_coef": {"n": 1, "mean": 1.2554e-01}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.7334e-01, "std": 2.6395e-01, "min_value": 6.9914e-04, "max_value": 9.9999e-01}, "num_gradient_steps": 0, "step_time": 1.0113e+01, "total_time": 2.1753e+03, "__timestamp": "2024-10-09 18:33:40.411988"}, {"step": 234000, "num_env_steps": 234000, "scores": {"n": 1, "mean": 4.9839e+03}, "actor_loss": {"n": 1, "mean": -2.7349e+02}, "entropy_coef_loss": {"n": 1, "mean": -3.5102e-01}, "critic_loss": {"n": 1, "mean": 4.2117e+02}, "entropy_coef": {"n": 1, "mean": 1.2645e-01}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.7009e-01, "std": 2.6795e-01, "min_value": 2.9206e-05, "max_value": 9.9993e-01}, "num_gradient_steps": 0, "step_time": 1.0171e+01, "total_time": 2.1855e+03, "__timestamp": "2024-10-09 18:33:50.581605"}, {"step": 235000, "num_env_steps": 235000, "scores": {"n": 1, "mean": 5.0976e+03}, "actor_loss": {"n": 1, "mean": -2.7579e+02}, "entropy_coef_loss": {"n": 1, "mean": -2.1000e-02}, "critic_loss": {"n": 1, "mean": 3.5638e+02}, "entropy_coef": {"n": 1, "mean": 1.2603e-01}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.6959e-01, "std": 2.6465e-01, "min_value": 3.2157e-04, "max_value": 9.9993e-01}, "num_gradient_steps": 0, "step_time": 1.0004e+01, "total_time": 2.1955e+03, "__timestamp": "2024-10-09 18:34:00.586971"}, {"step": 236000, "num_env_steps": 236000, "scores": {"n": 1, "mean": 4.9436e+03}, "actor_loss": {"n": 1, "mean": -2.7039e+02}, "entropy_coef_loss": {"n": 1, "mean": 3.3229e-01}, "critic_loss": {"n": 1, "mean": 1.4756e+01}, "entropy_coef": {"n": 1, "mean": 1.2541e-01}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.6785e-01, "std": 2.6668e-01, "min_value": 3.5685e-04, "max_value": 9.9999e-01}, "num_gradient_steps": 0, "step_time": 9.6683e+00, "total_time": 2.2051e+03, "__timestamp": "2024-10-09 18:34:10.254243"}, {"step": 237000, "num_env_steps": 237000, "scores": {"n": 1, "mean": 4.6497e+03}, "actor_loss": {"n": 1, "mean": -2.7840e+02}, "entropy_coef_loss": {"n": 1, "mean": 1.0436e+00}, "critic_loss": {"n": 1, "mean": 1.7302e+01}, "entropy_coef": {"n": 1, "mean": 1.2732e-01}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.6675e-01, "std": 2.6568e-01, "min_value": 1.9804e-04, "max_value": 9.9980e-01}, "num_gradient_steps": 0, "step_time": 9.6782e+00, "total_time": 2.2148e+03, "__timestamp": "2024-10-09 18:34:19.933478"}, {"step": 238000, "num_env_steps": 238000, "scores": {"n": 1, "mean": 5.2002e+03}, "actor_loss": {"n": 1, "mean": -2.7126e+02}, "entropy_coef_loss": {"n": 1, "mean": -6.1077e-01}, "critic_loss": {"n": 1, "mean": 1.5406e+01}, "entropy_coef": {"n": 1, "mean": 1.2684e-01}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.7393e-01, "std": 2.6481e-01, "min_value": 3.6672e-04, "max_value": 9.9978e-01}, "num_gradient_steps": 0, "step_time": 9.7538e+00, "total_time": 2.2246e+03, "__timestamp": "2024-10-09 18:34:29.687323"}, {"step": 239000, "num_env_steps": 239000, "scores": {"n": 1, "mean": 4.9500e+03}, "actor_loss": {"n": 1, "mean": -2.7539e+02}, "entropy_coef_loss": {"n": 1, "mean": 3.8614e-01}, "critic_loss": {"n": 1, "mean": 1.7081e+01}, "entropy_coef": {"n": 1, "mean": 1.2762e-01}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.7411e-01, "std": 2.6466e-01, "min_value": 6.7949e-06, "max_value": 9.9967e-01}, "num_gradient_steps": 0, "step_time": 9.6366e+00, "total_time": 2.2342e+03, "__timestamp": "2024-10-09 18:34:39.322965"}, {"step": 240000, "num_env_steps": 240000, "scores": {"n": 1, "mean": 5.1462e+03}, "actor_loss": {"n": 1, "mean": -2.6516e+02}, "entropy_coef_loss": {"n": 1, "mean": 4.6367e-01}, "critic_loss": {"n": 1, "mean": 1.4451e+01}, "entropy_coef": {"n": 1, "mean": 1.2895e-01}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.7833e-01, "std": 2.6190e-01, "min_value": 6.7145e-04, "max_value": 9.9982e-01}, "num_gradient_steps": 0, "step_time": 9.6649e+00, "total_time": 2.2439e+03, "__timestamp": "2024-10-09 18:34:48.988873"}, {"step": 241000, "num_env_steps": 241000, "scores": {"n": 1, "mean": 4.9643e+03}, "actor_loss": {"n": 1, "mean": -2.8109e+02}, "entropy_coef_loss": {"n": 1, "mean": 1.3031e+00}, "critic_loss": {"n": 1, "mean": 1.7941e+01}, "entropy_coef": {"n": 1, "mean": 1.2635e-01}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.7497e-01, "std": 2.6404e-01, "min_value": 3.5800e-04, "max_value": 9.9992e-01}, "num_gradient_steps": 0, "step_time": 9.6591e+00, "total_time": 2.2535e+03, "__timestamp": "2024-10-09 18:34:58.646971"}, {"step": 242000, "num_env_steps": 242000, "scores": {"n": 1, "mean": 4.9979e+03}, "actor_loss": {"n": 1, "mean": -2.7654e+02}, "entropy_coef_loss": {"n": 1, "mean": -7.0968e-01}, "critic_loss": {"n": 1, "mean": 1.4663e+01}, "entropy_coef": {"n": 1, "mean": 1.3062e-01}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.7973e-01, "std": 2.6200e-01, "min_value": 3.3742e-04, "max_value": 9.9986e-01}, "num_gradient_steps": 0, "step_time": 9.8467e+00, "total_time": 2.2634e+03, "__timestamp": "2024-10-09 18:35:08.494696"}, {"step": 243000, "num_env_steps": 243000, "scores": {"n": 1, "mean": 4.9191e+03}, "actor_loss": {"n": 1, "mean": -2.8251e+02}, "entropy_coef_loss": {"n": 1, "mean": 1.1164e+00}, "critic_loss": {"n": 1, "mean": 3.5635e+01}, "entropy_coef": {"n": 1, "mean": 1.3294e-01}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.7515e-01, "std": 2.6130e-01, "min_value": 1.0818e-04, "max_value": 9.9975e-01}, "num_gradient_steps": 0, "step_time": 9.6377e+00, "total_time": 2.2730e+03, "__timestamp": "2024-10-09 18:35:18.131361"}, {"step": 244000, "num_env_steps": 244000, "scores": {"n": 1, "mean": 5.0486e+03}, "actor_loss": {"n": 1, "mean": -2.7747e+02}, "entropy_coef_loss": {"n": 1, "mean": 6.4283e-01}, "critic_loss": {"n": 1, "mean": 1.8413e+01}, "entropy_coef": {"n": 1, "mean": 1.3018e-01}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.7210e-01, "std": 2.6496e-01, "min_value": 2.3823e-04, "max_value": 9.9986e-01}, "num_gradient_steps": 0, "step_time": 9.5884e+00, "total_time": 2.2826e+03, "__timestamp": "2024-10-09 18:35:27.720760"}, {"step": 245000, "num_env_steps": 245000, "scores": {"n": 1, "mean": 5.1251e+03}, "actor_loss": {"n": 1, "mean": -2.7676e+02}, "entropy_coef_loss": {"n": 1, "mean": -7.0065e-01}, "critic_loss": {"n": 1, "mean": 1.7063e+01}, "entropy_coef": {"n": 1, "mean": 1.2965e-01}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.7704e-01, "std": 2.6098e-01, "min_value": 4.0495e-04, "max_value": 9.9998e-01}, "num_gradient_steps": 0, "step_time": 9.6595e+00, "total_time": 2.2923e+03, "__timestamp": "2024-10-09 18:35:37.379250"}, {"step": 246000, "num_env_steps": 246000, "scores": {"n": 1, "mean": 5.0670e+03}, "actor_loss": {"n": 1, "mean": -2.7674e+02}, "entropy_coef_loss": {"n": 1, "mean": 2.9431e-01}, "critic_loss": {"n": 1, "mean": 2.7792e+02}, "entropy_coef": {"n": 1, "mean": 1.3273e-01}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.7406e-01, "std": 2.6338e-01, "min_value": 2.8306e-04, "max_value": 9.9981e-01}, "num_gradient_steps": 0, "step_time": 9.6045e+00, "total_time": 2.3019e+03, "__timestamp": "2024-10-09 18:35:46.984731"}, {"step": 247000, "num_env_steps": 247000, "scores": {"n": 1, "mean": 4.8136e+03}, "actor_loss": {"n": 1, "mean": -2.7124e+02}, "entropy_coef_loss": {"n": 1, "mean": -6.7359e-01}, "critic_loss": {"n": 1, "mean": 1.6155e+01}, "entropy_coef": {"n": 1, "mean": 1.3115e-01}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.6721e-01, "std": 2.6708e-01, "min_value": 1.3185e-04, "max_value": 9.9984e-01}, "num_gradient_steps": 0, "step_time": 9.6308e+00, "total_time": 2.3115e+03, "__timestamp": "2024-10-09 18:35:56.615549"}, {"step": 248000, "num_env_steps": 248000, "scores": {"n": 1, "mean": 5.2078e+03}, "actor_loss": {"n": 1, "mean": -2.8172e+02}, "entropy_coef_loss": {"n": 1, "mean": 7.5131e-02}, "critic_loss": {"n": 1, "mean": 1.4384e+01}, "entropy_coef": {"n": 1, "mean": 1.2919e-01}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.7394e-01, "std": 2.6340e-01, "min_value": 2.1011e-05, "max_value": 9.9999e-01}, "num_gradient_steps": 0, "step_time": 9.6458e+00, "total_time": 2.3212e+03, "__timestamp": "2024-10-09 18:36:06.261386"}, {"step": 249000, "num_env_steps": 249000, "scores": {"n": 1, "mean": 4.9975e+03}, "actor_loss": {"n": 1, "mean": -2.7778e+02}, "entropy_coef_loss": {"n": 1, "mean": -4.6121e-01}, "critic_loss": {"n": 1, "mean": 3.8585e+02}, "entropy_coef": {"n": 1, "mean": 1.2794e-01}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.6498e-01, "std": 2.6846e-01, "min_value": 1.7405e-05, "max_value": 9.9992e-01}, "num_gradient_steps": 0, "step_time": 1.0226e+01, "total_time": 2.3314e+03, "__timestamp": "2024-10-09 18:36:16.487315"}, {"step": 250000, "num_env_steps": 250000, "scores": {"n": 1, "mean": 5.0509e+03}, "actor_loss": {"n": 1, "mean": -2.7376e+02}, "entropy_coef_loss": {"n": 1, "mean": -4.9017e-01}, "critic_loss": {"n": 1, "mean": 1.8571e+01}, "entropy_coef": {"n": 1, "mean": 1.3212e-01}, "action_stds": null, "action_magnitude": {"n": 6000, "mean": 7.7301e-01, "std": 2.6595e-01, "min_value": 3.3446e-04, "max_value": 9.9972e-01}, "num_gradient_steps": 0, "step_time": 1.0977e+01, "total_time": 2.3424e+03, "__timestamp": "2024-10-09 18:36:27.462856"}]}}