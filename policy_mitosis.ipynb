{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-03T22:32:34.541824Z",
     "start_time": "2024-05-03T22:32:34.248378Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import time\n",
    "from typing import Any, Iterable\n",
    "\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.distributions as dist\n",
    "from gymnasium.vector import VectorEnv\n",
    "from gymnasium.wrappers import RescaleAction, ClipAction\n",
    "from torch import optim, nn\n",
    "\n",
    "from src.datetime import get_current_timestamp\n",
    "from src.model_db.tiny_model_db import TinyModelDB\n",
    "from src.module_analysis import count_parameters\n",
    "from src.networks.core.seq_net import SeqNet\n",
    "from src.networks.core.tensor_shape import TensorShape\n",
    "from src.networks.core.torch_wrappers.torch_net import TorchNet\n",
    "from src.reinforcement_learning.algorithms.ppo.ppo import PPO, PPOLoggingConfig\n",
    "from src.reinforcement_learning.algorithms.policy_mitosis.policy_mitosis import PolicyMitosis, PolicyWithEnvAndInfo\n",
    "from src.reinforcement_learning.core.callback import Callback\n",
    "from src.reinforcement_learning.core.generalized_advantage_estimate import compute_gae_and_returns\n",
    "from src.reinforcement_learning.core.normalization import NormalizationType\n",
    "from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n",
    "from src.reinforcement_learning.core.policy_info import PolicyInfo\n",
    "from src.reinforcement_learning.gym.envs.parallelize_env import parallelize_env_async\n",
    "from src.reinforcement_learning.gym.envs.transform_reward_wrapper import TransformRewardWrapper\n",
    "from src.stopwatch import Stopwatch\n",
    "from src.summary_statistics import format_summary_statics\n",
    "from src.torch_device import set_default_torch_device\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting mitosis with id 2024-05-03_19.31.53\n",
      "policy selection probs = \n",
      "\t2024-05-03_19.31.56~YOi2Kr: p = 0.030967, score = 9.324106646821708, steps = 100000\n",
      "\t2024-05-03_19.41.26~ONGcgY: p = 0.023469, score = 9.019118288658124, steps = 100000\n",
      "\t2024-05-03_19.50.38~rpp1TN: p = 0.029827, score = 9.28283808761468, steps = 100000\n",
      "\t2024-05-03_19.59.45~iOUmuV: p = 0.009948, score = 8.074939831743997, steps = 100000\n",
      "\t2024-05-03_20.08.31~qVIc0m: p = 0.028977, score = 9.251017367165009, steps = 100000\n",
      "\t2024-05-03_20.23.19~jkSCqb: p = 0.054721, score = 9.950350163271155, steps = 200000\n",
      "\t2024-05-03_20.32.46~UETzfs: p = 0.102401, score = 10.639669612283704, steps = 300000\n",
      "\t2024-05-03_20.42.03~AAbsq9: p = 0.092334, score = 10.525839112620446, steps = 300000\n",
      "\t2024-05-03_20.51.29~B2PjVU: p = 0.021362, score = 8.915683225407209, steps = 100000\n",
      "\t2024-05-03_21.00.17~O81lZo: p = 0.046211, score = 9.764420465595782, steps = 200000\n",
      "\t2024-05-03_21.09.57~l028kP: p = 0.194829, score = 11.347217090925172, steps = 400000\n",
      "\t2024-05-03_21.19.14~Ha74nA: p = 0.130451, score = 10.905983823288127, steps = 300000\n",
      "\t2024-05-03_21.30.22~qZu9T3: p = 0.234504, score = 11.55110200337021, steps = 400000\n",
      "Starting PPO with policy (policy_id = 2024-05-03_21.43.20~RfUGC7, parent_id = 2024-05-03_21.09.57~l028kP, num_parameters = 1639186, previous_steps = 400000, previous_score =    95.916) for 100_000 steps\n",
      "  2500: score =    96.703, time = 14.33\n",
      "  5000: score =    97.918, time = 13.50\n",
      "  7500: score =   101.132, time = 13.71\n",
      " 10000: score =    99.150, time = 13.76\n",
      " 12500: score =    99.056, time = 13.96\n",
      " 15000: score =    99.625, time = 13.55\n",
      " 17500: score =   100.593, time = 13.59\n",
      " 20000: score =   100.445, time = 13.86\n",
      " 22500: score =    99.625, time = 13.93\n",
      " 25000: score =    99.469, time = 14.00\n",
      " 27500: score =   100.922, time = 14.07\n",
      " 30000: score =   102.046, time = 14.07\n",
      " 32500: score =   102.740, time = 14.11\n",
      " 35000: score =   100.358, time = 13.76\n",
      " 37500: score =   102.266, time = 13.86\n",
      " 40000: score =   104.176, time = 14.31\n",
      " 42500: score =   105.014, time = 14.12\n",
      " 45000: score =   104.979, time = 13.26\n",
      " 47500: score =   104.837, time = 15.22\n",
      " 50000: score =   103.486, time = 14.86\n",
      " 52500: score =   103.806, time = 13.91\n",
      " 55000: score =   100.340, time = 17.01\n",
      " 57500: score =   101.324, time = 14.05\n",
      " 60000: score =   101.277, time = 13.68\n",
      " 62500: score =   101.932, time = 13.79\n",
      " 65000: score =   100.323, time = 12.83\n",
      " 67500: score =   101.268, time = 13.53\n",
      " 70000: score =    99.765, time = 13.37\n",
      " 72500: score =   107.284, time = 13.69\n",
      " 75000: score =   104.727, time = 14.28\n",
      " 77500: score =   111.343, time = 13.47\n",
      " 80000: score =   101.822, time = 13.62\n",
      " 82500: score =   110.688, time = 13.64\n",
      " 85000: score =   105.898, time = 13.74\n",
      " 87500: score =   106.114, time = 13.64\n",
      " 90000: score =   110.274, time = 13.64\n",
      " 92500: score =   110.430, time = 14.17\n",
      " 95000: score =   107.058, time = 13.61\n",
      " 97500: score =   105.731, time = 14.03\n",
      "100000: score =   109.038, time = 13.61\n",
      "Training finished for policy (policy_id = 2024-05-03_21.43.20~RfUGC7, parent_id = 2024-05-03_21.09.57~l028kP, num_parameters = 1639186, previous_steps = 400000, previous_score =    95.916), end score =   109.038, time = 557.74\n",
      "policy selection probs = \n",
      "\t2024-05-03_19.31.56~YOi2Kr: p = 0.025330, score = 7.538385176732713, steps = 100000\n",
      "\t2024-05-03_19.41.26~ONGcgY: p = 0.020244, score = 7.291807160699392, steps = 100000\n",
      "\t2024-05-03_19.50.38~rpp1TN: p = 0.024574, score = 7.505020232853891, steps = 100000\n",
      "\t2024-05-03_19.59.45~iOUmuV: p = 0.010114, score = 6.528454578688977, steps = 100000\n",
      "\t2024-05-03_20.08.31~qVIc0m: p = 0.024006, score = 7.479293709505669, steps = 100000\n",
      "\t2024-05-03_20.23.19~jkSCqb: p = 0.040137, score = 8.04469264620344, steps = 200000\n",
      "\t2024-05-03_20.32.46~UETzfs: p = 0.066615, score = 8.601995958284393, steps = 300000\n",
      "\t2024-05-03_20.42.03~AAbsq9: p = 0.061268, score = 8.509965892153168, steps = 300000\n",
      "\t2024-05-03_20.51.29~B2PjVU: p = 0.018762, score = 7.208181632045568, steps = 100000\n",
      "\t2024-05-03_21.00.17~O81lZo: p = 0.035010, score = 7.894371577391107, steps = 200000\n",
      "\t2024-05-03_21.09.57~l028kP: p = 0.112052, score = 9.174036329212964, steps = 400000\n",
      "\t2024-05-03_21.19.14~Ha74nA: p = 0.081017, score = 8.817306569438045, steps = 300000\n",
      "\t2024-05-03_21.30.22~qZu9T3: p = 0.130167, score = 9.33887389059575, steps = 400000\n",
      "\t2024-05-03_21.43.20~RfUGC7: p = 0.350704, score = 10.429113563837605, steps = 500000\n",
      "Starting PPO with policy (policy_id = 2024-05-03_21.52.38~IWwG2v, parent_id = 2024-05-03_20.42.03~AAbsq9, num_parameters = 1639186, previous_steps = 300000, previous_score =    88.973) for 100_000 steps\n",
      "  2500: score =    88.694, time = 14.45\n",
      "  5000: score =    87.807, time = 14.31\n",
      "  7500: score =    86.479, time = 14.85\n",
      " 10000: score =    87.521, time = 14.21\n",
      " 12500: score =    88.551, time = 14.61\n",
      " 15000: score =    87.158, time = 14.28\n",
      " 17500: score =    87.055, time = 13.82\n",
      " 20000: score =    86.807, time = 14.03\n",
      " 22500: score =    88.732, time = 13.87\n",
      " 25000: score =    88.863, time = 13.86\n",
      " 27500: score =    87.421, time = 13.85\n",
      " 30000: score =    87.064, time = 13.93\n",
      " 32500: score =    88.623, time = 13.91\n",
      " 35000: score =    89.854, time = 13.84\n",
      " 37500: score =    88.637, time = 13.93\n",
      " 40000: score =    85.906, time = 13.89\n",
      " 42500: score =    87.299, time = 14.07\n",
      " 45000: score =    88.822, time = 13.87\n",
      " 47500: score =    87.342, time = 13.64\n",
      " 50000: score =    88.123, time = 13.70\n",
      " 52500: score =    89.004, time = 13.57\n",
      " 55000: score =    87.307, time = 13.47\n",
      " 57500: score =    89.909, time = 13.65\n",
      " 60000: score =    89.644, time = 13.85\n",
      " 62500: score =    89.645, time = 13.71\n",
      " 65000: score =    91.802, time = 13.75\n",
      " 67500: score =    92.841, time = 13.73\n",
      " 70000: score =    91.382, time = 13.66\n",
      " 72500: score =    90.899, time = 13.58\n",
      " 75000: score =    91.774, time = 13.71\n",
      " 77500: score =    90.582, time = 13.68\n",
      " 80000: score =    95.467, time = 13.85\n",
      " 82500: score =    93.781, time = 13.79\n",
      " 85000: score =    93.483, time = 13.62\n",
      " 87500: score =    92.890, time = 13.83\n",
      " 90000: score =    91.804, time = 13.98\n",
      " 92500: score =    93.136, time = 13.91\n",
      " 95000: score =    91.617, time = 13.86\n",
      " 97500: score =    93.061, time = 13.74\n",
      "100000: score =    91.264, time = 13.86\n",
      "Training finished for policy (policy_id = 2024-05-03_21.52.38~IWwG2v, parent_id = 2024-05-03_20.42.03~AAbsq9, num_parameters = 1639186, previous_steps = 300000, previous_score =    88.973), end score =    91.264, time = 556.40\n",
      "Starting PPO with policy (policy_id = 2024-05-03_22.01.54~ACeu6l, parent_id = None, num_parameters = 1639186, previous_steps = 0, previous_score = -1000000.000) for 100_000 steps\n",
      "  2500: score =    19.410, time = 12.09\n",
      "  5000: score =    18.886, time = 12.61\n",
      "  7500: score =    26.103, time = 13.08\n",
      " 10000: score =    37.163, time = 13.26\n",
      " 12500: score =    45.700, time = 13.40\n",
      " 15000: score =    47.734, time = 13.31\n",
      " 17500: score =    49.004, time = 13.11\n",
      " 20000: score =    50.365, time = 13.38\n",
      " 22500: score =    51.563, time = 13.20\n",
      " 25000: score =    53.496, time = 13.34\n",
      " 27500: score =    55.654, time = 13.32\n",
      " 30000: score =    56.631, time = 13.19\n",
      " 32500: score =    58.737, time = 13.25\n",
      " 35000: score =    59.854, time = 13.72\n",
      " 37500: score =    60.918, time = 13.31\n",
      " 40000: score =    61.433, time = 13.38\n",
      " 42500: score =    63.771, time = 13.44\n",
      " 45000: score =    65.621, time = 13.33\n",
      " 47500: score =    67.223, time = 13.38\n",
      " 50000: score =    67.375, time = 13.55\n",
      " 52500: score =    69.667, time = 13.26\n",
      " 55000: score =    70.543, time = 13.37\n",
      " 57500: score =    71.493, time = 13.10\n",
      " 60000: score =    72.105, time = 13.32\n",
      " 62500: score =    73.908, time = 13.34\n",
      " 65000: score =    75.134, time = 13.67\n",
      " 67500: score =    74.749, time = 13.16\n",
      " 70000: score =    76.736, time = 13.29\n",
      " 72500: score =    77.560, time = 13.62\n",
      " 75000: score =    79.585, time = 13.63\n",
      " 77500: score =    79.013, time = 13.48\n",
      " 80000: score =    81.172, time = 13.43\n",
      " 82500: score =    82.100, time = 13.50\n",
      " 85000: score =    83.022, time = 13.38\n",
      " 87500: score =    83.037, time = 13.45\n",
      " 90000: score =    83.983, time = 13.39\n",
      " 92500: score =    84.981, time = 13.34\n",
      " 95000: score =    84.855, time = 13.54\n",
      " 97500: score =    87.288, time = 13.65\n",
      "100000: score =    88.281, time = 13.60\n",
      "Training finished for policy (policy_id = 2024-05-03_22.01.54~ACeu6l, parent_id = None, num_parameters = 1639186, previous_steps = 0, previous_score = -1000000.000), end score =    88.281, time = 533.86\n",
      "policy selection probs = \n",
      "\t2024-05-03_19.31.56~YOi2Kr: p = 0.020584, score = 7.961085752677009, steps = 100000\n",
      "\t2024-05-03_19.41.26~ONGcgY: p = 0.016245, score = 7.7006813445253615, steps = 100000\n",
      "\t2024-05-03_19.50.38~rpp1TN: p = 0.019935, score = 7.925849933184474, steps = 100000\n",
      "\t2024-05-03_19.59.45~iOUmuV: p = 0.007806, score = 6.894525221902524, steps = 100000\n",
      "\t2024-05-03_20.08.31~qVIc0m: p = 0.019449, score = 7.898680844090221, steps = 100000\n",
      "\t2024-05-03_20.23.19~jkSCqb: p = 0.033469, score = 8.495783448162022, steps = 200000\n",
      "\t2024-05-03_20.32.46~UETzfs: p = 0.057149, score = 9.0843364809019, steps = 300000\n",
      "\t2024-05-03_20.42.03~AAbsq9: p = 0.052316, score = 8.987146004278793, steps = 300000\n",
      "\t2024-05-03_20.51.29~B2PjVU: p = 0.014992, score = 7.612366673794436, steps = 100000\n",
      "\t2024-05-03_21.00.17~O81lZo: p = 0.028971, score = 8.337033412021293, steps = 200000\n",
      "\t2024-05-03_21.09.57~l028kP: p = 0.098974, score = 9.688452924966295, steps = 400000\n",
      "\t2024-05-03_21.19.14~Ha74nA: p = 0.070272, score = 9.311720224060332, steps = 300000\n",
      "\t2024-05-03_21.30.22~qZu9T3: p = 0.115944, score = 9.86253343832092, steps = 400000\n",
      "\t2024-05-03_21.43.20~RfUGC7: p = 0.330238, score = 11.013906222566316, steps = 500000\n",
      "\t2024-05-03_21.52.38~IWwG2v: p = 0.064562, score = 9.218494492958392, steps = 400000\n",
      "\t2024-05-03_22.01.54~ACeu6l: p = 0.049094, score = 8.917220712181823, steps = 100000\n",
      "Starting PPO with policy (policy_id = 2024-05-03_22.10.48~pYUxFh, parent_id = 2024-05-03_20.08.31~qVIc0m, num_parameters = 1639186, previous_steps = 100000, previous_score =    78.197) for 100_000 steps\n",
      "  2500: score =    79.546, time = 13.43\n",
      "  5000: score =    81.739, time = 13.97\n",
      "  7500: score =    81.893, time = 15.09\n",
      " 10000: score =    82.681, time = 14.68\n",
      " 12500: score =    84.299, time = 13.98\n",
      " 15000: score =    84.518, time = 14.42\n",
      " 17500: score =    82.450, time = 16.03\n",
      " 20000: score =    81.300, time = 14.77\n",
      " 22500: score =    85.944, time = 13.85\n",
      " 25000: score =    78.833, time = 13.88\n",
      " 27500: score =    82.535, time = 13.72\n",
      " 30000: score =    73.717, time = 13.65\n",
      " 32500: score =    78.273, time = 14.05\n",
      " 35000: score =    84.168, time = 13.96\n",
      " 37500: score =    84.634, time = 14.39\n",
      " 40000: score =    84.484, time = 14.19\n",
      " 42500: score =    85.669, time = 13.98\n",
      " 45000: score =    85.030, time = 14.04\n",
      " 47500: score =    83.038, time = 13.79\n",
      " 50000: score =    86.629, time = 13.87\n",
      " 52500: score =    81.171, time = 13.92\n",
      " 55000: score =    87.504, time = 14.20\n",
      " 57500: score =    87.992, time = 13.97\n",
      " 60000: score =    88.807, time = 13.95\n",
      " 62500: score =    89.093, time = 14.08\n",
      " 65000: score =    89.823, time = 13.98\n",
      " 67500: score =    87.676, time = 13.96\n",
      " 70000: score =    88.560, time = 14.08\n",
      " 72500: score =    90.816, time = 13.92\n",
      " 75000: score =    90.463, time = 14.03\n",
      " 77500: score =    92.737, time = 14.12\n",
      " 80000: score =    92.954, time = 13.74\n",
      " 82500: score =    87.134, time = 13.62\n",
      " 85000: score =    90.462, time = 13.91\n",
      " 87500: score =    84.611, time = 13.97\n",
      " 90000: score =    89.012, time = 13.83\n",
      " 92500: score =    89.875, time = 13.73\n",
      " 95000: score =    93.941, time = 13.80\n",
      " 97500: score =    91.738, time = 14.01\n",
      "100000: score =    92.164, time = 14.86\n",
      "Training finished for policy (policy_id = 2024-05-03_22.10.48~pYUxFh, parent_id = 2024-05-03_20.08.31~qVIc0m, num_parameters = 1639186, previous_steps = 100000, previous_score =    78.197), end score =    92.164, time = 564.15\n",
      "policy selection probs = \n",
      "\t2024-05-03_19.31.56~YOi2Kr: p = 0.018667, score = 8.112660364782622, steps = 100000\n",
      "\t2024-05-03_19.41.26~ONGcgY: p = 0.014666, score = 7.847298002605306, steps = 100000\n",
      "\t2024-05-03_19.50.38~rpp1TN: p = 0.018067, score = 8.076753675029707, steps = 100000\n",
      "\t2024-05-03_19.59.45~iOUmuV: p = 0.006950, score = 7.025793119099942, steps = 100000\n",
      "\t2024-05-03_20.08.31~qVIc0m: p = 0.017618, score = 8.04906730170204, steps = 100000\n",
      "\t2024-05-03_20.23.19~jkSCqb: p = 0.030634, score = 8.657538404796602, steps = 200000\n",
      "\t2024-05-03_20.32.46~UETzfs: p = 0.052843, score = 9.257297157511438, steps = 300000\n",
      "\t2024-05-03_20.42.03~AAbsq9: p = 0.048293, score = 9.158256228669606, steps = 300000\n",
      "\t2024-05-03_20.51.29~B2PjVU: p = 0.013514, score = 7.757301870026695, steps = 100000\n",
      "\t2024-05-03_21.00.17~O81lZo: p = 0.026444, score = 8.495765856915979, steps = 200000\n",
      "\t2024-05-03_21.09.57~l028kP: p = 0.092479, score = 9.872915640182175, steps = 400000\n",
      "\t2024-05-03_21.19.14~Ha74nA: p = 0.065234, score = 9.489010159735667, steps = 300000\n",
      "\t2024-05-03_21.30.22~qZu9T3: p = 0.108663, score = 10.050310548973124, steps = 400000\n",
      "\t2024-05-03_21.43.20~RfUGC7: p = 0.315729, score = 11.223604825912187, steps = 500000\n",
      "\t2024-05-03_21.52.38~IWwG2v: p = 0.059837, score = 9.394009462948263, steps = 400000\n",
      "\t2024-05-03_22.01.54~ACeu6l: p = 0.045264, score = 9.086999598190504, steps = 100000\n",
      "\t2024-05-03_22.10.48~pYUxFh: p = 0.065097, score = 9.486689766230976, steps = 200000\n",
      "Starting PPO with policy (policy_id = 2024-05-03_22.20.12~h4k0Gh, parent_id = 2024-05-03_21.43.20~RfUGC7, num_parameters = 1639186, previous_steps = 500000, previous_score =   109.038) for 100_000 steps\n",
      "  2500: score =   109.282, time = 13.85\n",
      "  5000: score =   107.978, time = 14.20\n",
      "  7500: score =   110.461, time = 14.00\n",
      " 10000: score =   104.983, time = 13.95\n",
      " 12500: score =   109.321, time = 13.82\n",
      " 15000: score =   109.820, time = 13.85\n",
      " 17500: score =   109.131, time = 13.81\n",
      " 20000: score =   103.913, time = 13.97\n",
      " 22500: score =   111.150, time = 14.01\n",
      " 25000: score =   107.694, time = 13.83\n",
      " 27500: score =   106.147, time = 13.81\n",
      " 30000: score =   113.278, time = 13.81\n",
      " 32500: score =   100.627, time = 13.84\n",
      " 35000: score =   109.944, time = 14.06\n",
      " 37500: score =   101.971, time = 13.94\n",
      " 40000: score =   109.932, time = 13.99\n",
      " 42500: score =   114.117, time = 13.98\n",
      " 45000: score =   103.645, time = 13.82\n",
      " 47500: score =   115.655, time = 13.98\n",
      " 50000: score =    93.815, time = 13.92\n",
      " 52500: score =   115.029, time = 13.79\n",
      " 55000: score =    94.652, time = 13.84\n",
      " 57500: score =   115.564, time = 13.72\n",
      " 60000: score =   101.308, time = 13.83\n",
      " 62500: score =   115.889, time = 13.70\n",
      " 65000: score =   101.754, time = 14.51\n",
      " 67500: score =   115.769, time = 13.76\n",
      " 70000: score =    92.745, time = 13.87\n",
      " 72500: score =   113.449, time = 13.75\n",
      " 75000: score =   102.511, time = 13.71\n",
      " 77500: score =   120.135, time = 13.85\n",
      " 80000: score =   109.413, time = 13.88\n",
      " 82500: score =   117.448, time = 13.60\n",
      " 85000: score =   104.155, time = 13.71\n",
      " 87500: score =   112.944, time = 14.10\n",
      " 90000: score =    91.086, time = 14.04\n",
      " 92500: score =   112.107, time = 13.92\n",
      " 95000: score =   110.499, time = 13.71\n",
      " 97500: score =   121.225, time = 14.01\n",
      "100000: score =   108.059, time = 13.81\n",
      "Training finished for policy (policy_id = 2024-05-03_22.20.12~h4k0Gh, parent_id = 2024-05-03_21.43.20~RfUGC7, num_parameters = 1639186, previous_steps = 500000, previous_score =   109.038), end score =   108.059, time = 556.11\n",
      "policy selection probs = \n",
      "\t2024-05-03_19.31.56~YOi2Kr: p = 0.017070, score = 7.38357464979292, steps = 100000\n",
      "\t2024-05-03_19.41.26~ONGcgY: p = 0.013705, score = 7.142060433459262, steps = 100000\n",
      "\t2024-05-03_19.50.38~rpp1TN: p = 0.016571, score = 7.350894898355463, steps = 100000\n",
      "\t2024-05-03_19.59.45~iOUmuV: p = 0.006945, score = 6.394384287806416, steps = 100000\n",
      "\t2024-05-03_20.08.31~qVIc0m: p = 0.016195, score = 7.3256967025657955, steps = 100000\n",
      "\t2024-05-03_20.23.19~jkSCqb: p = 0.026794, score = 7.87948443802228, steps = 200000\n",
      "\t2024-05-03_20.32.46~UETzfs: p = 0.044009, score = 8.42534280302427, steps = 300000\n",
      "\t2024-05-03_20.42.03~AAbsq9: p = 0.040547, score = 8.335202693786739, steps = 300000\n",
      "\t2024-05-03_20.51.29~B2PjVU: p = 0.012722, score = 7.060152263610143, steps = 100000\n",
      "\t2024-05-03_21.00.17~O81lZo: p = 0.023437, score = 7.732250407524839, steps = 200000\n",
      "\t2024-05-03_21.09.57~l028kP: p = 0.073241, score = 8.98563558223683, steps = 400000\n",
      "\t2024-05-03_21.19.14~Ha74nA: p = 0.053310, score = 8.636231731232971, steps = 300000\n",
      "\t2024-05-03_21.30.22~qZu9T3: p = 0.084820, score = 9.147087990282545, steps = 400000\n",
      "\t2024-05-03_21.43.20~RfUGC7: p = 0.223924, score = 10.214938176340038, steps = 500000\n",
      "\t2024-05-03_21.52.38~IWwG2v: p = 0.049280, score = 8.549768757932975, steps = 400000\n",
      "\t2024-05-03_22.01.54~ACeu6l: p = 0.038225, score = 8.270349904839835, steps = 100000\n",
      "\t2024-05-03_22.10.48~pYUxFh: p = 0.053207, score = 8.634119871757978, steps = 200000\n",
      "\t2024-05-03_22.20.12~h4k0Gh: p = 0.205998, score = 10.123156962922698, steps = 600000\n",
      "Starting PPO with policy (policy_id = 2024-05-03_22.29.29~Rs0F3r, parent_id = 2024-05-03_20.23.19~jkSCqb, num_parameters = 1639186, previous_steps = 200000, previous_score =    84.109) for 100_000 steps\n",
      "  2500: score =    84.285, time = 13.56\n",
      "  5000: score =    84.564, time = 14.21\n",
      "  7500: score =    84.968, time = 14.45\n",
      " 10000: score =    84.735, time = 14.12\n",
      " 12500: score =    85.217, time = 14.24\n",
      " 15000: score =    84.882, time = 14.26\n",
      " 17500: score =    85.751, time = 14.16\n",
      " 20000: score =    85.122, time = 14.19\n",
      " 22500: score =    85.851, time = 14.23\n",
      " 25000: score =    87.067, time = 14.29\n",
      " 27500: score =    87.249, time = 13.98\n",
      " 30000: score =    86.765, time = 14.13\n",
      " 32500: score =    86.467, time = 14.01\n",
      " 35000: score =    85.951, time = 14.14\n",
      " 37500: score =    86.985, time = 14.32\n",
      " 40000: score =    89.270, time = 14.06\n",
      " 42500: score =    88.319, time = 14.25\n",
      " 45000: score =    89.666, time = 13.91\n",
      " 47500: score =    88.928, time = 13.95\n",
      " 50000: score =    91.597, time = 14.06\n",
      " 52500: score =    91.877, time = 13.98\n",
      " 55000: score =    90.955, time = 14.05\n",
      " 57500: score =    92.773, time = 13.92\n",
      " 60000: score =    91.781, time = 13.93\n",
      " 62500: score =    89.410, time = 13.93\n",
      " 65000: score =    86.820, time = 13.92\n",
      " 67500: score =    90.227, time = 13.95\n",
      " 70000: score =    91.394, time = 13.95\n",
      " 72500: score =    92.175, time = 14.02\n",
      " 75000: score =    90.024, time = 13.97\n",
      " 77500: score =    92.443, time = 14.06\n",
      " 80000: score =    91.572, time = 13.93\n",
      " 82500: score =    89.872, time = 14.23\n",
      " 85000: score =    90.215, time = 14.07\n",
      " 87500: score =    89.786, time = 14.08\n",
      " 90000: score =    91.140, time = 13.94\n",
      " 92500: score =    91.738, time = 14.11\n",
      " 95000: score =    93.016, time = 13.89\n",
      " 97500: score =    92.525, time = 14.02\n",
      "100000: score =    91.502, time = 14.12\n",
      "Training finished for policy (policy_id = 2024-05-03_22.29.29~Rs0F3r, parent_id = 2024-05-03_20.23.19~jkSCqb, num_parameters = 1639186, previous_steps = 200000, previous_score =    84.109), end score =    91.502, time = 563.22\n",
      "policy selection probs = \n",
      "\t2024-05-03_19.31.56~YOi2Kr: p = 0.015648, score = 7.558326425997325, steps = 100000\n",
      "\t2024-05-03_19.41.26~ONGcgY: p = 0.012498, score = 7.311096138480705, steps = 100000\n",
      "\t2024-05-03_19.50.38~rpp1TN: p = 0.015179, score = 7.524873222014118, steps = 100000\n",
      "\t2024-05-03_19.59.45~iOUmuV: p = 0.006233, score = 6.5457242640412385, steps = 100000\n",
      "\t2024-05-03_20.08.31~qVIc0m: p = 0.014828, score = 7.499078644433753, steps = 100000\n",
      "\t2024-05-03_20.23.19~jkSCqb: p = 0.024825, score = 8.065973227860407, steps = 200000\n",
      "\t2024-05-03_20.32.46~UETzfs: p = 0.041258, score = 8.62475077135852, steps = 300000\n",
      "\t2024-05-03_20.42.03~AAbsq9: p = 0.037938, score = 8.532477258594426, steps = 300000\n",
      "\t2024-05-03_20.51.29~B2PjVU: p = 0.011581, score = 7.22724939567124, steps = 100000\n",
      "\t2024-05-03_21.00.17~O81lZo: p = 0.021646, score = 7.915254515543181, steps = 200000\n",
      "\t2024-05-03_21.09.57~l028kP: p = 0.069494, score = 9.198304357565785, steps = 400000\n",
      "\t2024-05-03_21.19.14~Ha74nA: p = 0.050204, score = 8.84063094249958, steps = 300000\n",
      "\t2024-05-03_21.30.22~qZu9T3: p = 0.080761, score = 9.363577962852224, steps = 400000\n",
      "\t2024-05-03_21.43.20~RfUGC7: p = 0.218163, score = 10.4567016411658, steps = 500000\n",
      "\t2024-05-03_21.52.38~IWwG2v: p = 0.046322, score = 8.752121594797382, steps = 400000\n",
      "\t2024-05-03_22.01.54~ACeu6l: p = 0.035716, score = 8.466089557278131, steps = 100000\n",
      "\t2024-05-03_22.10.48~pYUxFh: p = 0.050105, score = 8.83846910029781, steps = 200000\n",
      "\t2024-05-03_22.20.12~h4k0Gh: p = 0.200303, score = 10.362748183161305, steps = 600000\n",
      "\t2024-05-03_22.29.29~Rs0F3r: p = 0.047297, score = 8.77502491607195, steps = 300000\n",
      "Starting PPO with policy (policy_id = 2024-05-03_22.38.52~Xu8Xy5, parent_id = 2024-05-03_21.19.14~Ha74nA, num_parameters = 1639186, previous_steps = 300000, previous_score =    92.187) for 100_000 steps\n",
      "  2500: score =    90.431, time = 13.16\n",
      "  5000: score =    91.522, time = 13.64\n",
      "  7500: score =    91.880, time = 13.73\n",
      " 10000: score =    91.922, time = 13.89\n",
      " 12500: score =    90.618, time = 13.86\n",
      " 15000: score =    89.872, time = 13.97\n",
      " 17500: score =    91.411, time = 13.96\n",
      " 20000: score =    95.153, time = 13.83\n",
      " 22500: score =    96.067, time = 13.81\n",
      " 25000: score =    94.843, time = 13.85\n",
      " 27500: score =    96.269, time = 13.73\n",
      " 30000: score =    95.303, time = 13.88\n",
      " 32500: score =    92.816, time = 13.81\n",
      " 35000: score =    94.186, time = 13.80\n",
      " 37500: score =    94.154, time = 13.74\n",
      " 40000: score =    93.502, time = 13.86\n",
      " 42500: score =    93.803, time = 13.72\n",
      " 45000: score =    94.804, time = 13.85\n",
      " 47500: score =    91.104, time = 13.75\n",
      " 50000: score =    95.241, time = 13.85\n",
      " 52500: score =    95.011, time = 13.80\n",
      " 55000: score =    94.344, time = 13.73\n",
      " 57500: score =    93.769, time = 13.94\n",
      " 60000: score =    97.525, time = 13.75\n",
      " 62500: score =    95.639, time = 13.61\n",
      " 65000: score =    94.515, time = 13.69\n",
      " 67500: score =    93.670, time = 13.86\n",
      " 70000: score =    96.825, time = 13.80\n",
      " 72500: score =    97.594, time = 14.04\n",
      " 75000: score =    96.407, time = 14.08\n",
      " 77500: score =    94.924, time = 13.81\n",
      " 80000: score =    91.987, time = 13.95\n",
      " 82500: score =    98.179, time = 14.07\n",
      " 85000: score =    97.953, time = 13.91\n",
      " 87500: score =   101.106, time = 14.19\n",
      " 90000: score =    98.115, time = 13.79\n",
      " 92500: score =   102.160, time = 14.00\n",
      " 95000: score =    97.691, time = 14.03\n",
      " 97500: score =    96.222, time = 13.73\n",
      "100000: score =    98.112, time = 13.82\n",
      "Training finished for policy (policy_id = 2024-05-03_22.38.52~Xu8Xy5, parent_id = 2024-05-03_21.19.14~Ha74nA, num_parameters = 1639186, previous_steps = 300000, previous_score =    92.187), end score =    98.112, time = 554.04\n",
      "policy selection probs = \n",
      "\t2024-05-03_19.31.56~YOi2Kr: p = 0.014398, score = 7.569502645768518, steps = 100000\n",
      "\t2024-05-03_19.41.26~ONGcgY: p = 0.011496, score = 7.321906787903167, steps = 100000\n",
      "\t2024-05-03_19.50.38~rpp1TN: p = 0.013966, score = 7.535999975760864, steps = 100000\n",
      "\t2024-05-03_19.59.45~iOUmuV: p = 0.005727, score = 6.555403186174706, steps = 100000\n",
      "\t2024-05-03_20.08.31~qVIc0m: p = 0.013642, score = 7.510167256685716, steps = 100000\n",
      "\t2024-05-03_20.23.19~jkSCqb: p = 0.022858, score = 8.077900086318527, steps = 200000\n",
      "\t2024-05-03_20.32.46~UETzfs: p = 0.038017, score = 8.637503873653882, steps = 300000\n",
      "\t2024-05-03_20.42.03~AAbsq9: p = 0.034953, score = 8.545093919434418, steps = 300000\n",
      "\t2024-05-03_20.51.29~B2PjVU: p = 0.010651, score = 7.237936063993664, steps = 100000\n",
      "\t2024-05-03_21.00.17~O81lZo: p = 0.019927, score = 7.926958511775252, steps = 200000\n",
      "\t2024-05-03_21.09.57~l028kP: p = 0.064085, score = 9.211905552490217, steps = 400000\n",
      "\t2024-05-03_21.19.14~Ha74nA: p = 0.046273, score = 8.853703258877653, steps = 300000\n",
      "\t2024-05-03_21.30.22~qZu9T3: p = 0.074491, score = 9.377423541788534, steps = 400000\n",
      "\t2024-05-03_21.43.20~RfUGC7: p = 0.201522, score = 10.472163581949609, steps = 500000\n",
      "\t2024-05-03_21.52.38~IWwG2v: p = 0.042691, score = 8.765063035652757, steps = 400000\n",
      "\t2024-05-03_22.01.54~ACeu6l: p = 0.032903, score = 8.47860805306171, steps = 100000\n",
      "\t2024-05-03_22.10.48~pYUxFh: p = 0.046182, score = 8.851538220039195, steps = 200000\n",
      "\t2024-05-03_22.20.12~h4k0Gh: p = 0.185000, score = 10.378071198416398, steps = 600000\n",
      "\t2024-05-03_22.29.29~Rs0F3r: p = 0.043590, score = 8.788000223227563, steps = 300000\n",
      "\t2024-05-03_22.38.52~Xu8Xy5: p = 0.077625, score = 9.422759947396386, steps = 400000\n",
      "Starting PPO with policy (policy_id = 2024-05-03_22.48.06~ZTYgTN, parent_id = 2024-05-03_21.43.20~RfUGC7, num_parameters = 1639186, previous_steps = 500000, previous_score =   109.038) for 100_000 steps\n",
      "  2500: score =   111.063, time = 13.18\n",
      "  5000: score =   109.236, time = 13.68\n",
      "  7500: score =   111.747, time = 13.78\n",
      " 10000: score =   115.146, time = 13.74\n",
      " 12500: score =   114.108, time = 13.63\n",
      " 15000: score =   108.471, time = 13.89\n",
      " 17500: score =   116.012, time = 13.88\n",
      " 20000: score =   108.484, time = 13.57\n",
      " 22500: score =   115.551, time = 13.74\n",
      " 25000: score =   100.324, time = 13.82\n",
      " 27500: score =   115.256, time = 13.95\n",
      " 30000: score =   103.869, time = 13.77\n",
      " 32500: score =   113.566, time = 13.91\n",
      " 35000: score =   106.932, time = 13.82\n",
      " 37500: score =   118.476, time = 13.61\n",
      " 40000: score =   108.075, time = 13.87\n",
      " 42500: score =   112.565, time = 13.60\n",
      " 45000: score =   106.842, time = 13.81\n",
      " 47500: score =   115.099, time = 13.85\n",
      " 50000: score =   107.514, time = 13.81\n",
      " 52500: score =   125.364, time = 13.93\n",
      " 55000: score =   108.727, time = 14.12\n",
      " 57500: score =   120.207, time = 13.86\n",
      " 60000: score =   118.928, time = 13.70\n",
      " 62500: score =   115.427, time = 13.71\n",
      " 65000: score =   110.296, time = 13.81\n",
      " 67500: score =   112.804, time = 13.70\n",
      " 70000: score =   112.964, time = 13.65\n",
      " 72500: score =   121.870, time = 13.73\n",
      " 75000: score =   102.931, time = 13.95\n",
      " 77500: score =   120.589, time = 13.81\n",
      " 80000: score =   120.901, time = 13.78\n",
      " 82500: score =   124.019, time = 13.87\n",
      " 85000: score =   122.379, time = 13.56\n",
      " 87500: score =   121.680, time = 13.66\n",
      " 90000: score =   121.980, time = 13.64\n",
      " 92500: score =   127.263, time = 13.83\n",
      " 95000: score =   116.061, time = 13.91\n",
      " 97500: score =   123.005, time = 13.48\n",
      "100000: score =   119.155, time = 13.68\n",
      "Training finished for policy (policy_id = 2024-05-03_22.48.06~ZTYgTN, parent_id = 2024-05-03_21.43.20~RfUGC7, num_parameters = 1639186, previous_steps = 500000, previous_score =   109.038), end score =   119.155, time = 550.78\n",
      "policy selection probs = \n",
      "\t2024-05-03_19.31.56~YOi2Kr: p = 0.013125, score = 6.510287522945482, steps = 100000\n",
      "\t2024-05-03_19.41.26~ONGcgY: p = 0.010815, score = 6.297338231607977, steps = 100000\n",
      "\t2024-05-03_19.50.38~rpp1TN: p = 0.012785, score = 6.481472946249599, steps = 100000\n",
      "\t2024-05-03_19.59.45~iOUmuV: p = 0.005939, score = 5.638092959078063, steps = 100000\n",
      "\t2024-05-03_20.08.31~qVIc0m: p = 0.012530, score = 6.459255049440658, steps = 100000\n",
      "\t2024-05-03_20.23.19~jkSCqb: p = 0.019531, score = 6.947543927864025, steps = 200000\n",
      "\t2024-05-03_20.32.46~UETzfs: p = 0.030251, score = 7.428841276576757, steps = 300000\n",
      "\t2024-05-03_20.42.03~AAbsq9: p = 0.028143, score = 7.349362425705722, steps = 300000\n",
      "\t2024-05-03_20.51.29~B2PjVU: p = 0.010127, score = 6.225117693252483, steps = 100000\n",
      "\t2024-05-03_21.00.17~O81lZo: p = 0.017357, score = 6.817723899332539, steps = 200000\n",
      "\t2024-05-03_21.09.57~l028kP: p = 0.047401, score = 7.922865819256267, steps = 400000\n",
      "\t2024-05-03_21.19.14~Ha74nA: p = 0.035823, score = 7.614787464319703, steps = 300000\n",
      "\t2024-05-03_21.30.22~qZu9T3: p = 0.053951, score = 8.065222556677348, steps = 400000\n",
      "\t2024-05-03_21.43.20~RfUGC7: p = 0.126979, score = 9.0067735089468, steps = 500000\n",
      "\t2024-05-03_21.52.38~IWwG2v: p = 0.033424, score = 7.538550838705372, steps = 400000\n",
      "\t2024-05-03_22.01.54~ACeu6l: p = 0.026717, score = 7.292180055006581, steps = 100000\n",
      "\t2024-05-03_22.10.48~pYUxFh: p = 0.035762, score = 7.612925383546855, steps = 200000\n",
      "\t2024-05-03_22.20.12~h4k0Gh: p = 0.117973, score = 8.925847654344862, steps = 600000\n",
      "\t2024-05-03_22.29.29~Rs0F3r: p = 0.034029, score = 7.558278381328427, steps = 300000\n",
      "\t2024-05-03_22.38.52~Xu8Xy5: p = 0.055897, score = 8.104214951498559, steps = 400000\n",
      "\t2024-05-03_22.48.06~ZTYgTN: p = 0.271441, score = 9.84246830684676, steps = 600000\n",
      "Starting PPO with policy (policy_id = 2024-05-03_22.57.17~SjuQMY, parent_id = 2024-05-03_20.42.03~AAbsq9, num_parameters = 1639186, previous_steps = 300000, previous_score =    88.973) for 100_000 steps\n",
      "  2500: score =    90.844, time = 13.37\n",
      "  5000: score =    89.836, time = 13.99\n",
      "  7500: score =    88.437, time = 14.06\n",
      " 10000: score =    89.410, time = 14.15\n",
      " 12500: score =    88.565, time = 14.25\n",
      " 15000: score =    88.843, time = 14.23\n",
      " 17500: score =    88.621, time = 14.21\n",
      " 20000: score =    89.161, time = 14.11\n",
      " 22500: score =    89.071, time = 14.24\n",
      " 25000: score =    88.433, time = 14.07\n",
      " 27500: score =    89.208, time = 14.06\n",
      " 30000: score =    88.442, time = 14.13\n",
      " 32500: score =    87.863, time = 14.08\n",
      " 35000: score =    89.398, time = 14.20\n",
      " 37500: score =    88.023, time = 14.17\n",
      " 40000: score =    90.668, time = 14.03\n",
      " 42500: score =    90.165, time = 14.19\n",
      " 45000: score =    90.682, time = 14.12\n",
      " 47500: score =    91.633, time = 14.06\n",
      " 50000: score =    91.001, time = 13.91\n",
      " 52500: score =    89.383, time = 13.93\n",
      " 55000: score =    91.833, time = 14.23\n",
      " 57500: score =    91.014, time = 14.09\n",
      " 60000: score =    92.815, time = 14.00\n",
      " 62500: score =    91.843, time = 14.15\n",
      " 65000: score =    89.917, time = 14.09\n",
      " 67500: score =    88.625, time = 14.21\n",
      " 70000: score =    89.462, time = 14.05\n",
      " 72500: score =    87.385, time = 13.98\n",
      " 75000: score =    90.391, time = 14.11\n",
      " 77500: score =    90.820, time = 13.96\n",
      " 80000: score =    89.256, time = 14.22\n",
      " 82500: score =    90.830, time = 14.27\n",
      " 85000: score =    93.454, time = 14.19\n",
      " 87500: score =    94.401, time = 14.16\n",
      " 90000: score =    94.135, time = 14.14\n",
      " 92500: score =    93.194, time = 14.25\n",
      " 95000: score =    93.977, time = 14.19\n",
      " 97500: score =    94.539, time = 14.40\n",
      "100000: score =    94.818, time = 14.18\n",
      "Training finished for policy (policy_id = 2024-05-03_22.57.17~SjuQMY, parent_id = 2024-05-03_20.42.03~AAbsq9, num_parameters = 1639186, previous_steps = 300000, previous_score =    88.973), end score =    94.818, time = 565.07\n",
      "policy selection probs = \n",
      "\t2024-05-03_19.31.56~YOi2Kr: p = 0.012149, score = 6.636838589750912, steps = 100000\n",
      "\t2024-05-03_19.41.26~ONGcgY: p = 0.009973, score = 6.419749856046347, steps = 100000\n",
      "\t2024-05-03_19.50.38~rpp1TN: p = 0.011829, score = 6.6074638971757285, steps = 100000\n",
      "\t2024-05-03_19.59.45~iOUmuV: p = 0.005414, score = 5.747689758943624, steps = 100000\n",
      "\t2024-05-03_20.08.31~qVIc0m: p = 0.011588, score = 6.584814114903445, steps = 100000\n",
      "\t2024-05-03_20.23.19~jkSCqb: p = 0.018219, score = 7.082594659901585, steps = 200000\n",
      "\t2024-05-03_20.32.46~UETzfs: p = 0.028461, score = 7.57324776943372, steps = 300000\n",
      "\t2024-05-03_20.42.03~AAbsq9: p = 0.026440, score = 7.492223958631077, steps = 300000\n",
      "\t2024-05-03_20.51.29~B2PjVU: p = 0.009327, score = 6.3461254494067045, steps = 100000\n",
      "\t2024-05-03_21.00.17~O81lZo: p = 0.016154, score = 6.950251107939611, steps = 200000\n",
      "\t2024-05-03_21.09.57~l028kP: p = 0.044987, score = 8.076875472140157, steps = 400000\n",
      "\t2024-05-03_21.19.14~Ha74nA: p = 0.033813, score = 7.762808496218811, steps = 300000\n",
      "\t2024-05-03_21.30.22~qZu9T3: p = 0.051331, score = 8.22199942943042, steps = 400000\n",
      "\t2024-05-03_21.43.20~RfUGC7: p = 0.122841, score = 9.18185284177424, steps = 500000\n",
      "\t2024-05-03_21.52.38~IWwG2v: p = 0.031507, score = 7.6850899350882464, steps = 400000\n",
      "\t2024-05-03_22.01.54~ACeu6l: p = 0.025075, score = 7.433930041016544, steps = 100000\n",
      "\t2024-05-03_22.10.48~pYUxFh: p = 0.033755, score = 7.760910219147804, steps = 200000\n",
      "\t2024-05-03_22.20.12~h4k0Gh: p = 0.113965, score = 9.099353899471348, steps = 600000\n",
      "\t2024-05-03_22.29.29~Rs0F3r: p = 0.032088, score = 7.705200954102414, steps = 300000\n",
      "\t2024-05-03_22.38.52~Xu8Xy5: p = 0.053220, score = 8.261749782966131, steps = 400000\n",
      "\t2024-05-03_22.48.06~ZTYgTN: p = 0.266503, score = 10.033792401188226, steps = 600000\n",
      "\t2024-05-03_22.57.17~SjuQMY: p = 0.041360, score = 7.984415064061322, steps = 400000\n",
      "Starting PPO with policy (policy_id = 2024-05-03_23.06.42~60oZB5, parent_id = 2024-05-03_20.42.03~AAbsq9, num_parameters = 1639186, previous_steps = 300000, previous_score =    88.973) for 100_000 steps\n",
      "  2500: score =    88.592, time = 13.35\n",
      "  5000: score =    88.221, time = 13.79\n",
      "  7500: score =    89.251, time = 13.99\n",
      " 10000: score =    89.027, time = 14.23\n",
      " 12500: score =    87.884, time = 13.99\n",
      " 15000: score =    86.646, time = 13.98\n",
      " 17500: score =    86.170, time = 13.84\n",
      " 20000: score =    79.884, time = 13.68\n",
      " 22500: score =    88.147, time = 13.97\n",
      " 25000: score =    86.683, time = 14.20\n",
      " 27500: score =    85.606, time = 14.15\n",
      " 30000: score =    86.947, time = 14.47\n",
      " 32500: score =    86.615, time = 14.24\n",
      " 35000: score =    85.294, time = 14.03\n",
      " 37500: score =    86.976, time = 14.20\n",
      " 40000: score =    86.972, time = 14.06\n",
      " 42500: score =    89.244, time = 14.04\n",
      " 45000: score =    89.154, time = 13.89\n",
      " 47500: score =    90.259, time = 14.30\n",
      " 50000: score =    91.592, time = 14.21\n",
      " 52500: score =    90.458, time = 14.17\n",
      " 55000: score =    90.667, time = 14.33\n",
      " 57500: score =    90.370, time = 14.32\n",
      " 60000: score =    87.868, time = 13.82\n",
      " 62500: score =    87.497, time = 13.80\n",
      " 65000: score =    89.073, time = 13.85\n",
      " 67500: score =    88.234, time = 14.19\n",
      " 70000: score =    85.306, time = 14.38\n",
      " 72500: score =    87.547, time = 14.48\n",
      " 75000: score =    87.348, time = 14.19\n",
      " 77500: score =    89.151, time = 14.10\n",
      " 80000: score =    88.694, time = 14.31\n",
      " 82500: score =    87.324, time = 14.13\n",
      " 85000: score =    87.832, time = 13.98\n",
      " 87500: score =    88.388, time = 14.21\n",
      " 90000: score =    86.775, time = 14.22\n",
      " 92500: score =    88.611, time = 14.25\n",
      " 95000: score =    92.286, time = 14.02\n",
      " 97500: score =    91.380, time = 14.05\n",
      "100000: score =    89.709, time = 14.19\n",
      "Training finished for policy (policy_id = 2024-05-03_23.06.42~60oZB5, parent_id = 2024-05-03_20.42.03~AAbsq9, num_parameters = 1639186, previous_steps = 300000, previous_score =    88.973), end score =    89.709, time = 564.16\n",
      "policy selection probs = \n",
      "\t2024-05-03_19.31.56~YOi2Kr: p = 0.011349, score = 6.785935925165056, steps = 100000\n",
      "\t2024-05-03_19.41.26~ONGcgY: p = 0.009275, score = 6.563970268313111, steps = 100000\n",
      "\t2024-05-03_19.50.38~rpp1TN: p = 0.011043, score = 6.755901326772918, steps = 100000\n",
      "\t2024-05-03_19.59.45~iOUmuV: p = 0.004966, score = 5.876812264524676, steps = 100000\n",
      "\t2024-05-03_20.08.31~qVIc0m: p = 0.010813, score = 6.7327427145601675, steps = 100000\n",
      "\t2024-05-03_20.23.19~jkSCqb: p = 0.017175, score = 7.241705956240857, steps = 200000\n",
      "\t2024-05-03_20.32.46~UETzfs: p = 0.027100, score = 7.743381643805382, steps = 300000\n",
      "\t2024-05-03_20.42.03~AAbsq9: p = 0.025134, score = 7.660537623857615, steps = 300000\n",
      "\t2024-05-03_20.51.29~B2PjVU: p = 0.008662, score = 6.488691880986283, steps = 100000\n",
      "\t2024-05-03_21.00.17~O81lZo: p = 0.015187, score = 7.10638929129897, steps = 200000\n",
      "\t2024-05-03_21.09.57~l028kP: p = 0.043278, score = 8.25832340025877, steps = 400000\n",
      "\t2024-05-03_21.19.14~Ha74nA: p = 0.032321, score = 7.937200873924646, steps = 300000\n",
      "\t2024-05-03_21.30.22~qZu9T3: p = 0.049529, score = 8.40670758379141, steps = 400000\n",
      "\t2024-05-03_21.43.20~RfUGC7: p = 0.120874, score = 9.388124212451753, steps = 500000\n",
      "\t2024-05-03_21.52.38~IWwG2v: p = 0.030069, score = 7.857736356459587, steps = 400000\n",
      "\t2024-05-03_22.01.54~ACeu6l: p = 0.023808, score = 7.60093412673928, steps = 100000\n",
      "\t2024-05-03_22.10.48~pYUxFh: p = 0.032264, score = 7.935259951842864, steps = 200000\n",
      "\t2024-05-03_22.20.12~h4k0Gh: p = 0.111951, score = 9.303771922006442, steps = 600000\n",
      "\t2024-05-03_22.29.29~Rs0F3r: p = 0.030636, score = 7.878299171808248, steps = 300000\n",
      "\t2024-05-03_22.38.52~Xu8Xy5: p = 0.051393, score = 8.447350933550219, steps = 400000\n",
      "\t2024-05-03_22.48.06~ZTYgTN: p = 0.266836, score = 10.259202691175707, steps = 600000\n",
      "\t2024-05-03_22.57.17~SjuQMY: p = 0.039714, score = 8.163785858573409, steps = 400000\n",
      "\t2024-05-03_23.06.42~60oZB5: p = 0.026623, score = 7.723874109603058, steps = 400000\n",
      "Starting PPO with policy (policy_id = 2024-05-03_23.16.07~Ntmb7N, parent_id = 2024-05-03_22.20.12~h4k0Gh, num_parameters = 1639186, previous_steps = 600000, previous_score =   108.059) for 100_000 steps\n",
      "  2500: score =   118.558, time = 13.45\n",
      "  5000: score =   122.811, time = 13.67\n",
      "  7500: score =   121.397, time = 13.91\n",
      " 10000: score =   120.414, time = 13.75\n",
      " 12500: score =   118.904, time = 13.80\n",
      " 15000: score =   114.284, time = 13.93\n",
      " 17500: score =   121.429, time = 14.05\n",
      " 20000: score =   121.417, time = 13.88\n",
      " 22500: score =   125.844, time = 13.89\n",
      " 25000: score =   126.796, time = 14.03\n",
      " 27500: score =   127.007, time = 14.03\n",
      " 30000: score =   120.806, time = 13.89\n",
      " 32500: score =   117.619, time = 13.87\n",
      " 35000: score =   125.965, time = 13.87\n",
      " 37500: score =   121.705, time = 14.04\n",
      " 40000: score =   117.283, time = 13.88\n",
      " 42500: score =   121.097, time = 13.74\n",
      " 45000: score =   122.497, time = 13.90\n",
      " 47500: score =   125.010, time = 13.70\n",
      " 50000: score =   128.467, time = 14.28\n",
      " 52500: score =   129.817, time = 14.32\n",
      " 55000: score =   115.081, time = 13.96\n",
      " 57500: score =   122.113, time = 13.93\n",
      " 60000: score =   101.441, time = 13.89\n",
      " 62500: score =   119.351, time = 13.76\n",
      " 65000: score =    89.833, time = 13.71\n",
      " 67500: score =   124.661, time = 13.86\n",
      " 70000: score =   103.858, time = 13.98\n",
      " 72500: score =   119.462, time = 13.94\n",
      " 75000: score =    97.066, time = 13.76\n",
      " 77500: score =   120.683, time = 13.86\n",
      " 80000: score =   107.513, time = 13.83\n",
      " 82500: score =   123.851, time = 14.01\n",
      " 85000: score =   115.854, time = 13.70\n",
      " 87500: score =   122.622, time = 13.91\n",
      " 90000: score =   123.021, time = 13.96\n",
      " 92500: score =   114.214, time = 13.75\n",
      " 95000: score =   126.249, time = 13.74\n",
      " 97500: score =   120.978, time = 13.90\n",
      "100000: score =   119.193, time = 13.92\n",
      "Training finished for policy (policy_id = 2024-05-03_23.16.07~Ntmb7N, parent_id = 2024-05-03_22.20.12~h4k0Gh, num_parameters = 1639186, previous_steps = 600000, previous_score =   108.059), end score =   119.193, time = 555.80\n",
      "policy selection probs = \n",
      "\t2024-05-03_19.31.56~YOi2Kr: p = 0.010830, score = 6.165085565760587, steps = 100000\n",
      "\t2024-05-03_19.41.26~ONGcgY: p = 0.009016, score = 5.963427713071798, steps = 100000\n",
      "\t2024-05-03_19.50.38~rpp1TN: p = 0.010564, score = 6.137798855266591, steps = 100000\n",
      "\t2024-05-03_19.59.45~iOUmuV: p = 0.005111, score = 5.339138309624492, steps = 100000\n",
      "\t2024-05-03_20.08.31~qVIc0m: p = 0.010364, score = 6.116759041827386, steps = 100000\n",
      "\t2024-05-03_20.23.19~jkSCqb: p = 0.015780, score = 6.57915685539236, steps = 200000\n",
      "\t2024-05-03_20.32.46~UETzfs: p = 0.023881, score = 7.034933858624504, steps = 300000\n",
      "\t2024-05-03_20.42.03~AAbsq9: p = 0.022301, score = 6.95966930009905, steps = 300000\n",
      "\t2024-05-03_20.51.29~B2PjVU: p = 0.008472, score = 5.895036601773312, steps = 100000\n",
      "\t2024-05-03_21.00.17~O81lZo: p = 0.014111, score = 6.456220413457153, steps = 200000\n",
      "\t2024-05-03_21.09.57~l028kP: p = 0.036539, score = 7.502763208168645, steps = 400000\n",
      "\t2024-05-03_21.19.14~Ha74nA: p = 0.028027, score = 7.211020422239683, steps = 300000\n",
      "\t2024-05-03_21.30.22~qZu9T3: p = 0.041303, score = 7.637571611633198, steps = 400000\n",
      "\t2024-05-03_21.43.20~RfUGC7: p = 0.092898, score = 8.529197698008913, steps = 500000\n",
      "\t2024-05-03_21.52.38~IWwG2v: p = 0.026246, score = 7.138826172984073, steps = 400000\n",
      "\t2024-05-03_22.01.54~ACeu6l: p = 0.021230, score = 6.905518971565827, steps = 100000\n",
      "\t2024-05-03_22.10.48~pYUxFh: p = 0.027982, score = 7.209257076572612, steps = 200000\n",
      "\t2024-05-03_22.20.12~h4k0Gh: p = 0.086646, score = 8.452562861783196, steps = 600000\n",
      "\t2024-05-03_22.29.29~Rs0F3r: p = 0.026696, score = 7.157507680958132, steps = 300000\n",
      "\t2024-05-03_22.38.52~Xu8Xy5: p = 0.042713, score = 7.6744964708870205, steps = 400000\n",
      "\t2024-05-03_22.48.06~ZTYgTN: p = 0.190745, score = 9.320580554412043, steps = 600000\n",
      "\t2024-05-03_22.57.17~SjuQMY: p = 0.033794, score = 7.416874976966, steps = 400000\n",
      "\t2024-05-03_23.06.42~60oZB5: p = 0.023499, score = 7.017211083334461, steps = 400000\n",
      "\t2024-05-03_23.16.07~Ntmb7N: p = 0.191252, score = 9.323503402594305, steps = 700000\n",
      "Starting PPO with policy (policy_id = 2024-05-03_23.25.23~F54ySp, parent_id = 2024-05-03_22.48.06~ZTYgTN, num_parameters = 1639186, previous_steps = 600000, previous_score =   119.155) for 100_000 steps\n",
      "  2500: score =   122.433, time = 13.20\n",
      "  5000: score =   122.106, time = 13.69\n",
      "  7500: score =   121.841, time = 13.71\n",
      " 10000: score =   126.482, time = 13.91\n",
      " 12500: score =   114.725, time = 13.78\n",
      " 15000: score =   127.345, time = 13.86\n",
      " 17500: score =   122.523, time = 13.96\n",
      " 20000: score =   112.921, time = 13.66\n",
      " 22500: score =   128.032, time = 13.96\n",
      " 25000: score =   111.144, time = 13.67\n",
      " 27500: score =   121.162, time = 13.73\n",
      " 30000: score =   109.319, time = 13.81\n",
      " 32500: score =   115.957, time = 13.81\n",
      " 35000: score =   109.576, time = 13.79\n",
      " 37500: score =   126.742, time = 13.75\n",
      " 40000: score =   120.150, time = 13.78\n",
      " 42500: score =   123.879, time = 13.87\n",
      " 45000: score =   118.626, time = 13.74\n",
      " 47500: score =   123.786, time = 13.80\n",
      " 50000: score =   132.350, time = 13.81\n",
      " 52500: score =   133.747, time = 13.68\n",
      " 55000: score =   130.065, time = 13.87\n",
      " 57500: score =   127.397, time = 13.72\n",
      " 60000: score =   132.123, time = 13.84\n",
      " 62500: score =   125.877, time = 13.73\n",
      " 65000: score =   114.511, time = 13.69\n",
      " 67500: score =   124.834, time = 13.51\n",
      " 70000: score =   104.013, time = 13.76\n",
      " 72500: score =   126.739, time = 13.65\n",
      " 75000: score =    90.240, time = 13.60\n",
      " 77500: score =   121.222, time = 13.72\n",
      " 80000: score =   117.811, time = 13.67\n",
      " 82500: score =   113.425, time = 13.76\n",
      " 85000: score =   134.271, time = 13.65\n",
      " 87500: score =   124.942, time = 13.83\n",
      " 90000: score =   121.453, time = 13.66\n",
      " 92500: score =   138.005, time = 13.87\n",
      " 95000: score =   117.391, time = 13.78\n",
      " 97500: score =   136.308, time = 13.66\n",
      "100000: score =   128.320, time = 13.79\n",
      "Training finished for policy (policy_id = 2024-05-03_23.25.23~F54ySp, parent_id = 2024-05-03_22.48.06~ZTYgTN, num_parameters = 1639186, previous_steps = 600000, previous_score =   119.155), end score =   128.320, time = 550.28\n",
      "policy selection probs = \n",
      "\t2024-05-03_19.31.56~YOi2Kr: p = 0.010290, score = 5.439928731783623, steps = 100000\n",
      "\t2024-05-03_19.41.26~ONGcgY: p = 0.008753, score = 5.261990512576411, steps = 100000\n",
      "\t2024-05-03_19.50.38~rpp1TN: p = 0.010067, score = 5.415851570351097, steps = 100000\n",
      "\t2024-05-03_19.59.45~iOUmuV: p = 0.005305, score = 4.711132000308206, steps = 100000\n",
      "\t2024-05-03_20.08.31~qVIc0m: p = 0.009898, score = 5.39728652621368, steps = 100000\n",
      "\t2024-05-03_20.23.19~jkSCqb: p = 0.014343, score = 5.805295648665447, steps = 200000\n",
      "\t2024-05-03_20.32.46~UETzfs: p = 0.020674, score = 6.20746272140467, steps = 300000\n",
      "\t2024-05-03_20.42.03~AAbsq9: p = 0.019463, score = 6.1410510179432425, steps = 300000\n",
      "\t2024-05-03_20.51.29~B2PjVU: p = 0.008286, score = 5.20164377977233, steps = 100000\n",
      "\t2024-05-03_21.00.17~O81lZo: p = 0.012996, score = 5.696819379271759, steps = 200000\n",
      "\t2024-05-03_21.09.57~l028kP: p = 0.030089, score = 6.620264505420598, steps = 400000\n",
      "\t2024-05-03_21.19.14~Ha74nA: p = 0.023811, score = 6.362837427314869, steps = 300000\n",
      "\t2024-05-03_21.30.22~qZu9T3: p = 0.033525, score = 6.739216318736141, steps = 400000\n",
      "\t2024-05-03_21.43.20~RfUGC7: p = 0.068548, score = 7.525966529020473, steps = 500000\n",
      "\t2024-05-03_21.52.38~IWwG2v: p = 0.022471, score = 6.2991348936507325, steps = 400000\n",
      "\t2024-05-03_22.01.54~ACeu6l: p = 0.018636, score = 6.093270022062277, steps = 100000\n",
      "\t2024-05-03_22.10.48~pYUxFh: p = 0.023777, score = 6.361281491933917, steps = 200000\n",
      "\t2024-05-03_22.20.12~h4k0Gh: p = 0.064461, score = 7.458345724249311, steps = 600000\n",
      "\t2024-05-03_22.29.29~Rs0F3r: p = 0.022810, score = 6.315619023659494, steps = 300000\n",
      "\t2024-05-03_22.38.52~Xu8Xy5: p = 0.034533, score = 6.771797959433476, steps = 400000\n",
      "\t2024-05-03_22.48.06~ZTYgTN: p = 0.129327, score = 8.224264434616089, steps = 600000\n",
      "\t2024-05-03_22.57.17~SjuQMY: p = 0.028086, score = 6.544478719212504, steps = 400000\n",
      "\t2024-05-03_23.06.42~60oZB5: p = 0.020382, score = 6.191824554913894, steps = 400000\n",
      "\t2024-05-03_23.16.07~Ntmb7N: p = 0.129631, score = 8.226843488164613, steps = 700000\n",
      "\t2024-05-03_23.25.23~F54ySp: p = 0.229837, score = 8.856789021729677, steps = 700000\n",
      "Starting PPO with policy (policy_id = 2024-05-03_23.34.33~z9rEfe, parent_id = 2024-05-03_23.16.07~Ntmb7N, num_parameters = 1639186, previous_steps = 700000, previous_score =   119.193) for 100_000 steps\n",
      "  2500: score =   119.499, time = 13.02\n",
      "  5000: score =   120.253, time = 13.74\n",
      "  7500: score =   129.264, time = 13.71\n",
      " 10000: score =    91.474, time = 13.64\n",
      " 12500: score =   129.829, time = 13.70\n",
      " 15000: score =   112.065, time = 13.79\n",
      " 17500: score =   125.032, time = 13.98\n",
      " 20000: score =   122.108, time = 13.73\n",
      " 22500: score =   120.306, time = 13.90\n",
      " 25000: score =   118.909, time = 13.88\n",
      " 27500: score =   111.106, time = 13.77\n",
      " 30000: score =   125.138, time = 13.73\n",
      " 32500: score =   121.290, time = 13.80\n",
      " 35000: score =   123.307, time = 13.73\n",
      " 37500: score =   127.897, time = 13.69\n",
      " 40000: score =   129.083, time = 13.86\n",
      " 42500: score =   129.777, time = 13.96\n",
      " 45000: score =   128.833, time = 13.91\n",
      " 47500: score =   125.438, time = 13.77\n",
      " 50000: score =   118.527, time = 13.79\n",
      " 52500: score =   118.188, time = 13.85\n",
      " 55000: score =   126.878, time = 13.75\n",
      " 57500: score =   122.156, time = 13.80\n",
      " 60000: score =   135.335, time = 13.89\n",
      " 62500: score =   104.461, time = 13.56\n",
      " 65000: score =   135.796, time = 13.73\n",
      " 67500: score =   106.763, time = 13.89\n",
      " 70000: score =   127.069, time = 13.75\n",
      " 72500: score =   127.478, time = 13.83\n",
      " 75000: score =   131.595, time = 13.89\n",
      " 77500: score =   125.440, time = 14.03\n",
      " 80000: score =   127.495, time = 14.03\n",
      " 82500: score =   119.272, time = 13.88\n",
      " 85000: score =   120.597, time = 13.74\n",
      " 87500: score =   127.843, time = 13.93\n",
      " 90000: score =    99.310, time = 13.79\n",
      " 92500: score =   120.761, time = 13.69\n",
      " 95000: score =   121.977, time = 13.81\n",
      " 97500: score =   131.614, time = 13.84\n",
      "100000: score =   125.265, time = 13.71\n",
      "Training finished for policy (policy_id = 2024-05-03_23.34.33~z9rEfe, parent_id = 2024-05-03_23.16.07~Ntmb7N, num_parameters = 1639186, previous_steps = 700000, previous_score =   119.193), end score =   125.265, time = 552.10\n",
      "policy selection probs = \n",
      "\t2024-05-03_19.31.56~YOi2Kr: p = 0.009901, score = 5.075088621657356, steps = 100000\n",
      "\t2024-05-03_19.41.26~ONGcgY: p = 0.008514, score = 4.909084198404479, steps = 100000\n",
      "\t2024-05-03_19.50.38~rpp1TN: p = 0.009701, score = 5.052626245024721, steps = 100000\n",
      "\t2024-05-03_19.59.45~iOUmuV: p = 0.005336, score = 4.39517015548303, steps = 100000\n",
      "\t2024-05-03_20.08.31~qVIc0m: p = 0.009550, score = 5.035306304101251, steps = 100000\n",
      "\t2024-05-03_20.23.19~jkSCqb: p = 0.013498, score = 5.4159514479960755, steps = 200000\n",
      "\t2024-05-03_20.32.46~UETzfs: p = 0.018985, score = 5.791146351366597, steps = 300000\n",
      "\t2024-05-03_20.42.03~AAbsq9: p = 0.017945, score = 5.72918868662501, steps = 300000\n",
      "\t2024-05-03_20.51.29~B2PjVU: p = 0.008090, score = 4.852784744476197, steps = 100000\n",
      "\t2024-05-03_21.00.17~O81lZo: p = 0.012312, score = 5.314750364734965, steps = 200000\n",
      "\t2024-05-03_21.09.57~l028kP: p = 0.026943, score = 6.176262727031355, steps = 400000\n",
      "\t2024-05-03_21.19.14~Ha74nA: p = 0.021659, score = 5.936100530168799, steps = 300000\n",
      "\t2024-05-03_21.30.22~qZu9T3: p = 0.029803, score = 6.287236790120833, steps = 400000\n",
      "\t2024-05-03_21.43.20~RfUGC7: p = 0.058084, score = 7.021221964774288, steps = 500000\n",
      "\t2024-05-03_21.52.38~IWwG2v: p = 0.020520, score = 5.876670339129587, steps = 400000\n",
      "\t2024-05-03_22.01.54~ACeu6l: p = 0.017232, score = 5.684612222394855, steps = 100000\n",
      "\t2024-05-03_22.10.48~pYUxFh: p = 0.021630, score = 5.934648946823274, steps = 200000\n",
      "\t2024-05-03_22.20.12~h4k0Gh: p = 0.054846, score = 6.9581362896116055, steps = 600000\n",
      "\t2024-05-03_22.29.29~Rs0F3r: p = 0.020809, score = 5.8920489267490535, steps = 300000\n",
      "\t2024-05-03_22.38.52~Xu8Xy5: p = 0.030638, score = 6.317633275466655, steps = 400000\n",
      "\t2024-05-03_22.48.06~ZTYgTN: p = 0.105017, score = 7.672687072122027, steps = 600000\n",
      "\t2024-05-03_22.57.17~SjuQMY: p = 0.025266, score = 6.1055596718569625, steps = 400000\n",
      "\t2024-05-03_23.06.42~60oZB5: p = 0.018735, score = 5.776556990966116, steps = 400000\n",
      "\t2024-05-03_23.16.07~Ntmb7N: p = 0.105247, score = 7.675093156091894, steps = 700000\n",
      "\t2024-05-03_23.25.23~F54ySp: p = 0.179573, score = 8.262790085094068, steps = 700000\n",
      "\t2024-05-03_23.34.33~z9rEfe: p = 0.150166, score = 8.066062838123159, steps = 800000\n",
      "Starting PPO with policy (policy_id = 2024-05-03_23.43.45~3uRz5g, parent_id = 2024-05-03_23.16.07~Ntmb7N, num_parameters = 1639186, previous_steps = 700000, previous_score =   119.193) for 100_000 steps\n",
      "  2500: score =   119.135, time = 12.97\n",
      "  5000: score =   116.342, time = 13.86\n",
      "  7500: score =   120.552, time = 13.96\n",
      " 10000: score =   107.712, time = 13.56\n",
      " 12500: score =   125.569, time = 13.79\n",
      " 15000: score =   100.998, time = 13.83\n",
      " 17500: score =   129.237, time = 13.77\n",
      " 20000: score =   106.903, time = 13.64\n",
      " 22500: score =   127.390, time = 13.82\n",
      " 25000: score =   107.653, time = 13.92\n",
      " 27500: score =   124.528, time = 13.83\n",
      " 30000: score =   124.790, time = 13.70\n",
      " 32500: score =   132.688, time = 13.86\n",
      " 35000: score =   129.450, time = 13.83\n",
      " 37500: score =   124.969, time = 13.77\n",
      " 40000: score =   128.429, time = 13.91\n",
      " 42500: score =   120.254, time = 13.89\n",
      " 45000: score =   118.294, time = 13.59\n",
      " 47500: score =   128.034, time = 13.73\n",
      " 50000: score =   114.454, time = 13.83\n",
      " 52500: score =   127.837, time = 13.76\n",
      " 55000: score =    99.451, time = 13.78\n",
      " 57500: score =   127.714, time = 13.68\n",
      " 60000: score =   108.409, time = 13.87\n",
      " 62500: score =   128.123, time = 13.98\n",
      " 65000: score =   107.329, time = 13.76\n",
      " 67500: score =   128.190, time = 13.70\n",
      " 70000: score =   122.128, time = 13.71\n",
      " 72500: score =   128.992, time = 14.03\n",
      " 75000: score =   110.006, time = 13.73\n",
      " 77500: score =   131.600, time = 13.80\n",
      " 80000: score =   106.879, time = 13.87\n",
      " 82500: score =   131.053, time = 13.92\n",
      " 85000: score =   106.073, time = 14.13\n",
      " 87500: score =   132.030, time = 13.74\n",
      " 90000: score =   120.947, time = 13.90\n",
      " 92500: score =   131.399, time = 13.83\n",
      " 95000: score =   125.367, time = 13.87\n",
      " 97500: score =   125.850, time = 13.67\n",
      "100000: score =   131.105, time = 13.86\n",
      "Training finished for policy (policy_id = 2024-05-03_23.43.45~3uRz5g, parent_id = 2024-05-03_23.16.07~Ntmb7N, num_parameters = 1639186, previous_steps = 700000, previous_score =   119.193), end score =   131.105, time = 552.38\n",
      "policy selection probs = \n",
      "\t2024-05-03_19.31.56~YOi2Kr: p = 0.009505, score = 4.696720132782506, steps = 100000\n",
      "\t2024-05-03_19.41.26~ONGcgY: p = 0.008266, score = 4.543092014153097, steps = 100000\n",
      "\t2024-05-03_19.50.38~rpp1TN: p = 0.009327, score = 4.6759324176457815, steps = 100000\n",
      "\t2024-05-03_19.59.45~iOUmuV: p = 0.005364, score = 4.067492352383924, steps = 100000\n",
      "\t2024-05-03_20.08.31~qVIc0m: p = 0.009192, score = 4.659903748730184, steps = 100000\n",
      "\t2024-05-03_20.23.19~jkSCqb: p = 0.012662, score = 5.012170249683006, steps = 200000\n",
      "\t2024-05-03_20.32.46~UETzfs: p = 0.017361, score = 5.359392847699874, steps = 300000\n",
      "\t2024-05-03_20.42.03~AAbsq9: p = 0.016479, score = 5.302054378745814, steps = 300000\n",
      "\t2024-05-03_20.51.29~B2PjVU: p = 0.007883, score = 4.490989913393471, steps = 100000\n",
      "\t2024-05-03_21.00.17~O81lZo: p = 0.011628, score = 4.918514118599203, steps = 200000\n",
      "\t2024-05-03_21.09.57~l028kP: p = 0.024004, score = 5.715797231916954, steps = 400000\n",
      "\t2024-05-03_21.19.14~Ha74nA: p = 0.019613, score = 5.49354010317951, steps = 300000\n",
      "\t2024-05-03_21.30.22~qZu9T3: p = 0.026353, score = 5.818497727452107, steps = 400000\n",
      "\t2024-05-03_21.43.20~RfUGC7: p = 0.048867, score = 6.49776132341134, steps = 500000\n",
      "\t2024-05-03_21.52.38~IWwG2v: p = 0.018656, score = 5.438540674488189, steps = 400000\n",
      "\t2024-05-03_22.01.54~ACeu6l: p = 0.015873, score = 5.26080127114399, steps = 100000\n",
      "\t2024-05-03_22.10.48~pYUxFh: p = 0.019589, score = 5.492196741273621, steps = 200000\n",
      "\t2024-05-03_22.20.12~h4k0Gh: p = 0.046341, score = 6.4393789417988625, steps = 600000\n",
      "\t2024-05-03_22.29.29~Rs0F3r: p = 0.018899, score = 5.452772725880922, steps = 300000\n",
      "\t2024-05-03_22.38.52~Xu8Xy5: p = 0.027036, score = 5.846628031242335, steps = 400000\n",
      "\t2024-05-03_22.48.06~ZTYgTN: p = 0.084537, score = 7.1006570585573865, steps = 600000\n",
      "\t2024-05-03_22.57.17~SjuQMY: p = 0.022618, score = 5.650365376940132, steps = 400000\n",
      "\t2024-05-03_23.06.42~60oZB5: p = 0.017149, score = 5.345891183428447, steps = 400000\n",
      "\t2024-05-03_23.16.07~Ntmb7N: p = 0.084708, score = 7.102883759185669, steps = 700000\n",
      "\t2024-05-03_23.25.23~F54ySp: p = 0.138886, score = 7.646765492923269, steps = 700000\n",
      "\t2024-05-03_23.34.33~z9rEfe: p = 0.117701, score = 7.464705061983758, steps = 800000\n",
      "\t2024-05-03_23.43.45~3uRz5g: p = 0.161503, score = 7.8127252947922115, steps = 800000\n",
      "Starting PPO with policy (policy_id = 2024-05-03_23.52.58~bSXC4u, parent_id = 2024-05-03_21.43.20~RfUGC7, num_parameters = 1639186, previous_steps = 500000, previous_score =   109.038) for 100_000 steps\n",
      "  2500: score =   109.994, time = 13.11\n",
      "  5000: score =    97.926, time = 13.63\n",
      "  7500: score =   107.296, time = 13.83\n",
      " 10000: score =    96.155, time = 13.71\n",
      " 12500: score =   109.697, time = 13.79\n",
      " 15000: score =   103.908, time = 13.78\n",
      " 17500: score =   107.841, time = 13.85\n",
      " 20000: score =   104.410, time = 13.80\n",
      " 22500: score =   108.059, time = 13.85\n",
      " 25000: score =   110.557, time = 13.78\n",
      " 27500: score =   110.282, time = 13.80\n",
      " 30000: score =   107.505, time = 13.83\n",
      " 32500: score =    99.580, time = 13.77\n",
      " 35000: score =   112.357, time = 13.66\n",
      " 37500: score =   109.103, time = 13.82\n",
      " 40000: score =   107.397, time = 13.76\n",
      " 42500: score =   110.101, time = 13.83\n",
      " 45000: score =   111.312, time = 13.82\n",
      " 47500: score =   111.113, time = 13.77\n",
      " 50000: score =   111.980, time = 13.88\n",
      " 52500: score =   113.445, time = 13.84\n",
      " 55000: score =   116.204, time = 13.84\n",
      " 57500: score =   110.714, time = 13.83\n",
      " 60000: score =   105.865, time = 13.93\n",
      " 62500: score =   110.732, time = 13.70\n",
      " 65000: score =   114.565, time = 13.97\n",
      " 67500: score =   111.245, time = 13.99\n",
      " 70000: score =   108.564, time = 13.91\n",
      " 72500: score =   112.673, time = 13.75\n",
      " 75000: score =   113.057, time = 13.82\n",
      " 77500: score =   115.645, time = 13.87\n",
      " 80000: score =   107.536, time = 13.71\n",
      " 82500: score =   120.213, time = 13.78\n",
      " 85000: score =   113.949, time = 13.71\n",
      " 87500: score =   118.612, time = 13.77\n",
      " 90000: score =   110.875, time = 13.81\n",
      " 92500: score =   109.456, time = 13.64\n",
      " 95000: score =   117.027, time = 13.88\n",
      " 97500: score =   113.815, time = 13.80\n",
      "100000: score =   117.928, time = 13.73\n",
      "Training finished for policy (policy_id = 2024-05-03_23.52.58~bSXC4u, parent_id = 2024-05-03_21.43.20~RfUGC7, num_parameters = 1639186, previous_steps = 500000, previous_score =   109.038), end score =   117.928, time = 552.00\n",
      "policy selection probs = \n",
      "\t2024-05-03_19.31.56~YOi2Kr: p = 0.009027, score = 4.634557204147809, steps = 100000\n",
      "\t2024-05-03_19.41.26~ONGcgY: p = 0.007865, score = 4.482962413778261, steps = 100000\n",
      "\t2024-05-03_19.50.38~rpp1TN: p = 0.008860, score = 4.614044622554491, steps = 100000\n",
      "\t2024-05-03_19.59.45~iOUmuV: p = 0.005133, score = 4.013657499619636, steps = 100000\n",
      "\t2024-05-03_20.08.31~qVIc0m: p = 0.008734, score = 4.598228099343501, steps = 100000\n",
      "\t2024-05-03_20.23.19~jkSCqb: p = 0.011979, score = 4.945832215325526, steps = 200000\n",
      "\t2024-05-03_20.32.46~UETzfs: p = 0.016357, score = 5.288459186400473, steps = 300000\n",
      "\t2024-05-03_20.42.03~AAbsq9: p = 0.015537, score = 5.231879614517742, steps = 300000\n",
      "\t2024-05-03_20.51.29~B2PjVU: p = 0.007506, score = 4.431549904708085, steps = 100000\n",
      "\t2024-05-03_21.00.17~O81lZo: p = 0.011014, score = 4.853415659781285, steps = 200000\n",
      "\t2024-05-03_21.09.57~l028kP: p = 0.022519, score = 5.640146419142732, steps = 400000\n",
      "\t2024-05-03_21.19.14~Ha74nA: p = 0.018449, score = 5.420830950466279, steps = 300000\n",
      "\t2024-05-03_21.30.22~qZu9T3: p = 0.024692, score = 5.741487633436037, steps = 400000\n",
      "\t2024-05-03_21.43.20~RfUGC7: p = 0.045415, score = 6.411760909928493, steps = 500000\n",
      "\t2024-05-03_21.52.38~IWwG2v: p = 0.017561, score = 5.366559460733216, steps = 400000\n",
      "\t2024-05-03_22.01.54~ACeu6l: p = 0.014972, score = 5.191172507936057, steps = 100000\n",
      "\t2024-05-03_22.10.48~pYUxFh: p = 0.018426, score = 5.419505368480829, steps = 200000\n",
      "\t2024-05-03_22.20.12~h4k0Gh: p = 0.043097, score = 6.354151241979826, steps = 600000\n",
      "\t2024-05-03_22.29.29~Rs0F3r: p = 0.017786, score = 5.380603145357217, steps = 300000\n",
      "\t2024-05-03_22.38.52~Xu8Xy5: p = 0.025323, score = 5.769245621649107, steps = 400000\n",
      "\t2024-05-03_22.48.06~ZTYgTN: p = 0.077997, score = 7.006677084125941, steps = 600000\n",
      "\t2024-05-03_22.57.17~SjuQMY: p = 0.021235, score = 5.575580580367934, steps = 400000\n",
      "\t2024-05-03_23.06.42~60oZB5: p = 0.016160, score = 5.2751362219384506, steps = 400000\n",
      "\t2024-05-03_23.16.07~Ntmb7N: p = 0.078153, score = 7.008874313500171, steps = 700000\n",
      "\t2024-05-03_23.25.23~F54ySp: p = 0.127302, score = 7.545557559688116, steps = 700000\n",
      "\t2024-05-03_23.34.33~z9rEfe: p = 0.108120, score = 7.365906769786551, steps = 800000\n",
      "\t2024-05-03_23.43.45~3uRz5g: p = 0.147737, score = 7.709320818644528, steps = 800000\n",
      "\t2024-05-03_23.52.58~bSXC4u: p = 0.073044, score = 6.934514044200987, steps = 600000\n",
      "Starting PPO with policy (policy_id = 2024-05-04_00.02.10~DQW8KB, parent_id = 2024-05-03_23.52.58~bSXC4u, num_parameters = 1639186, previous_steps = 600000, previous_score =   117.928) for 100_000 steps\n",
      "  2500: score =   111.052, time = 13.25\n",
      "  5000: score =   118.919, time = 13.73\n",
      "  7500: score =   117.031, time = 13.83\n",
      " 10000: score =   128.856, time = 13.64\n",
      " 12500: score =   121.221, time = 13.74\n",
      " 15000: score =   114.218, time = 13.81\n",
      " 17500: score =   125.926, time = 13.89\n",
      " 20000: score =   126.796, time = 13.71\n",
      " 22500: score =   108.054, time = 13.80\n",
      " 25000: score =   128.121, time = 13.95\n",
      " 27500: score =   103.386, time = 13.73\n",
      " 30000: score =   119.370, time = 13.78\n",
      " 32500: score =   116.008, time = 13.75\n",
      " 35000: score =   118.903, time = 13.84\n",
      " 37500: score =   128.395, time = 13.89\n",
      " 40000: score =   105.033, time = 13.77\n",
      " 42500: score =   127.609, time = 13.89\n",
      " 45000: score =   112.196, time = 13.83\n",
      " 47500: score =   122.764, time = 13.96\n",
      " 50000: score =   109.991, time = 13.74\n",
      " 52500: score =   128.885, time = 13.58\n",
      " 55000: score =   107.031, time = 13.74\n",
      " 57500: score =   121.866, time = 13.64\n",
      " 60000: score =   108.048, time = 13.92\n",
      " 62500: score =   123.301, time = 13.74\n",
      " 65000: score =   121.190, time = 13.87\n",
      " 67500: score =   117.586, time = 13.65\n",
      " 70000: score =   123.581, time = 13.97\n",
      " 72500: score =   120.807, time = 14.01\n",
      " 75000: score =   125.433, time = 13.80\n",
      " 77500: score =   125.031, time = 13.77\n",
      " 80000: score =   124.647, time = 13.70\n",
      " 82500: score =   128.772, time = 13.53\n",
      " 85000: score =   130.230, time = 13.79\n",
      " 87500: score =   135.553, time = 13.67\n",
      " 90000: score =   129.143, time = 14.20\n",
      " 92500: score =   124.352, time = 13.49\n",
      " 95000: score =   108.486, time = 13.75\n",
      " 97500: score =   126.425, time = 13.63\n",
      "100000: score =   106.870, time = 13.59\n",
      "Training finished for policy (policy_id = 2024-05-04_00.02.10~DQW8KB, parent_id = 2024-05-03_23.52.58~bSXC4u, num_parameters = 1639186, previous_steps = 600000, previous_score =   117.928), end score =   106.870, time = 551.20\n",
      "policy selection probs = \n",
      "\t2024-05-03_19.31.56~YOi2Kr: p = 0.008509, score = 4.684253448954495, steps = 100000\n",
      "\t2024-05-03_19.41.26~ONGcgY: p = 0.007402, score = 4.5310331113143505, steps = 100000\n",
      "\t2024-05-03_19.50.38~rpp1TN: p = 0.008350, score = 4.663520911444878, steps = 100000\n",
      "\t2024-05-03_19.59.45~iOUmuV: p = 0.004809, score = 4.056695851912012, steps = 100000\n",
      "\t2024-05-03_20.08.31~qVIc0m: p = 0.008229, score = 4.647534788038041, steps = 100000\n",
      "\t2024-05-03_20.23.19~jkSCqb: p = 0.011326, score = 4.998866254548439, steps = 200000\n",
      "\t2024-05-03_20.32.46~UETzfs: p = 0.015517, score = 5.345167206347299, steps = 300000\n",
      "\t2024-05-03_20.42.03~AAbsq9: p = 0.014731, score = 5.287980933083728, steps = 300000\n",
      "\t2024-05-03_20.51.29~B2PjVU: p = 0.007061, score = 4.4790693071529, steps = 100000\n",
      "\t2024-05-03_21.00.17~O81lZo: p = 0.010404, score = 4.905458718514323, steps = 200000\n",
      "\t2024-05-03_21.09.57~l028kP: p = 0.021436, score = 5.700625572780195, steps = 400000\n",
      "\t2024-05-03_21.19.14~Ha74nA: p = 0.017524, score = 5.478958389637582, steps = 300000\n",
      "\t2024-05-03_21.30.22~qZu9T3: p = 0.023528, score = 5.803053466463286, steps = 400000\n",
      "\t2024-05-03_21.43.20~RfUGC7: p = 0.043556, score = 6.480514067088052, steps = 500000\n",
      "\t2024-05-03_21.52.38~IWwG2v: p = 0.016671, score = 5.4241049480327455, steps = 400000\n",
      "\t2024-05-03_22.01.54~ACeu6l: p = 0.014190, score = 5.246837325182726, steps = 100000\n",
      "\t2024-05-03_22.10.48~pYUxFh: p = 0.017502, score = 5.477618593468565, steps = 200000\n",
      "\t2024-05-03_22.20.12~h4k0Gh: p = 0.041310, score = 6.422286652063344, steps = 600000\n",
      "\t2024-05-03_22.29.29~Rs0F3r: p = 0.016888, score = 5.438299222747303, steps = 300000\n",
      "\t2024-05-03_22.38.52~Xu8Xy5: p = 0.024135, score = 5.831109102912597, steps = 400000\n",
      "\t2024-05-03_22.48.06~ZTYgTN: p = 0.075240, score = 7.081809513032521, steps = 600000\n",
      "\t2024-05-03_22.57.17~SjuQMY: p = 0.020201, score = 5.635367396077832, steps = 400000\n",
      "\t2024-05-03_23.06.42~60oZB5: p = 0.015328, score = 5.331701380059585, steps = 400000\n",
      "\t2024-05-03_23.16.07~Ntmb7N: p = 0.075392, score = 7.084030303244188, steps = 700000\n",
      "\t2024-05-03_23.25.23~F54ySp: p = 0.123449, score = 7.626468390900555, steps = 700000\n",
      "\t2024-05-03_23.34.33~z9rEfe: p = 0.104664, score = 7.444891209923986, steps = 800000\n",
      "\t2024-05-03_23.43.45~3uRz5g: p = 0.143495, score = 7.791987679321908, steps = 800000\n",
      "\t2024-05-03_23.52.58~bSXC4u: p = 0.070413, score = 7.008872670575819, steps = 600000\n",
      "\t2024-05-04_00.02.10~DQW8KB: p = 0.038742, score = 6.351665694233134, steps = 700000\n",
      "Starting PPO with policy (policy_id = 2024-05-04_00.11.21~MQ4D7Q, parent_id = 2024-05-03_23.25.23~F54ySp, num_parameters = 1639186, previous_steps = 700000, previous_score =   128.320) for 100_000 steps\n",
      "  2500: score =   127.286, time = 12.74\n",
      "  5000: score =   134.203, time = 13.26\n",
      "  7500: score =   128.589, time = 13.70\n",
      " 10000: score =   125.322, time = 13.31\n",
      " 12500: score =   127.394, time = 14.06\n",
      " 15000: score =   119.213, time = 13.42\n",
      " 17500: score =   130.361, time = 13.46\n",
      " 20000: score =   120.970, time = 13.56\n",
      " 22500: score =   131.150, time = 13.52\n",
      " 25000: score =   106.330, time = 13.36\n",
      " 27500: score =   126.176, time = 13.35\n",
      " 30000: score =   122.861, time = 13.54\n",
      " 32500: score =   125.762, time = 13.57\n",
      " 35000: score =   129.312, time = 13.51\n",
      " 37500: score =   140.385, time = 13.64\n",
      " 40000: score =   141.371, time = 13.56\n",
      " 42500: score =   137.180, time = 13.60\n",
      " 45000: score =   128.661, time = 13.63\n",
      " 47500: score =   135.110, time = 13.47\n",
      " 50000: score =   139.239, time = 13.91\n",
      " 52500: score =   134.294, time = 13.61\n",
      " 55000: score =   127.003, time = 13.65\n",
      " 57500: score =   135.414, time = 13.35\n",
      " 60000: score =   128.273, time = 13.52\n",
      " 62500: score =   129.872, time = 13.50\n",
      " 65000: score =   126.697, time = 13.23\n",
      " 67500: score =   131.480, time = 13.74\n",
      " 70000: score =   126.130, time = 13.51\n",
      " 72500: score =   130.879, time = 13.51\n",
      " 75000: score =   128.109, time = 13.68\n",
      " 77500: score =   133.482, time = 13.59\n",
      " 80000: score =   135.232, time = 13.67\n",
      " 82500: score =   143.084, time = 13.48\n",
      " 85000: score =   138.870, time = 13.63\n",
      " 87500: score =   139.634, time = 13.51\n",
      " 90000: score =   130.449, time = 13.48\n",
      " 92500: score =   141.397, time = 13.50\n",
      " 95000: score =   129.910, time = 13.43\n",
      " 97500: score =   132.749, time = 13.54\n",
      "100000: score =   113.217, time = 13.45\n",
      "Training finished for policy (policy_id = 2024-05-04_00.11.21~MQ4D7Q, parent_id = 2024-05-03_23.25.23~F54ySp, num_parameters = 1639186, previous_steps = 700000, previous_score =   128.320), end score =   113.217, time = 541.38\n",
      "policy selection probs = \n",
      "\t2024-05-03_19.31.56~YOi2Kr: p = 0.008058, score = 4.687492398255874, steps = 100000\n",
      "\t2024-05-03_19.41.26~ONGcgY: p = 0.007010, score = 4.534166115685345, steps = 100000\n",
      "\t2024-05-03_19.50.38~rpp1TN: p = 0.007907, score = 4.6667455251347, steps = 100000\n",
      "\t2024-05-03_19.59.45~iOUmuV: p = 0.004553, score = 4.059500873531496, steps = 100000\n",
      "\t2024-05-03_20.08.31~qVIc0m: p = 0.007793, score = 4.6507483480468865, steps = 100000\n",
      "\t2024-05-03_20.23.19~jkSCqb: p = 0.010728, score = 5.002322744368919, steps = 200000\n",
      "\t2024-05-03_20.32.46~UETzfs: p = 0.014701, score = 5.348863147606118, steps = 300000\n",
      "\t2024-05-03_20.42.03~AAbsq9: p = 0.013956, score = 5.291637332622216, steps = 300000\n",
      "\t2024-05-03_20.51.29~B2PjVU: p = 0.006686, score = 4.482166380904635, steps = 100000\n",
      "\t2024-05-03_21.00.17~O81lZo: p = 0.009854, score = 4.908850621250249, steps = 200000\n",
      "\t2024-05-03_21.09.57~l028kP: p = 0.020313, score = 5.704567297415207, steps = 400000\n",
      "\t2024-05-03_21.19.14~Ha74nA: p = 0.016604, score = 5.482746841445707, steps = 300000\n",
      "\t2024-05-03_21.30.22~qZu9T3: p = 0.022297, score = 5.807066015352002, steps = 400000\n",
      "\t2024-05-03_21.43.20~RfUGC7: p = 0.041296, score = 6.484995049327572, steps = 500000\n",
      "\t2024-05-03_21.52.38~IWwG2v: p = 0.015795, score = 5.427855471168073, steps = 400000\n",
      "\t2024-05-03_22.01.54~ACeu6l: p = 0.013443, score = 5.250465275778065, steps = 100000\n",
      "\t2024-05-03_22.10.48~pYUxFh: p = 0.016583, score = 5.481406118868263, steps = 200000\n",
      "\t2024-05-03_22.20.12~h4k0Gh: p = 0.039165, score = 6.426727372680117, steps = 600000\n",
      "\t2024-05-03_22.29.29~Rs0F3r: p = 0.016001, score = 5.442059560581316, steps = 300000\n",
      "\t2024-05-03_22.38.52~Xu8Xy5: p = 0.022873, score = 5.835141051004425, steps = 400000\n",
      "\t2024-05-03_22.48.06~ZTYgTN: p = 0.071362, score = 7.086706263864793, steps = 600000\n",
      "\t2024-05-03_22.57.17~SjuQMY: p = 0.019142, score = 5.639263997636532, steps = 400000\n",
      "\t2024-05-03_23.06.42~60oZB5: p = 0.014522, score = 5.335388010308844, steps = 400000\n",
      "\t2024-05-03_23.16.07~Ntmb7N: p = 0.071506, score = 7.088928589652402, steps = 700000\n",
      "\t2024-05-03_23.25.23~F54ySp: p = 0.117126, score = 7.631741748701511, steps = 700000\n",
      "\t2024-05-03_23.34.33~z9rEfe: p = 0.099292, score = 7.450039015320513, steps = 800000\n",
      "\t2024-05-03_23.43.45~3uRz5g: p = 0.136160, score = 7.797375486221197, steps = 800000\n",
      "\t2024-05-03_23.52.58~bSXC4u: p = 0.066781, score = 7.013718988881863, steps = 600000\n",
      "\t2024-05-04_00.02.10~DQW8KB: p = 0.036728, score = 6.356057583653106, steps = 700000\n",
      "\t2024-05-04_00.11.21~MQ4D7Q: p = 0.051765, score = 6.733544496583319, steps = 800000\n",
      "Starting PPO with policy (policy_id = 2024-05-04_00.20.23~MV6RVg, parent_id = 2024-05-03_23.43.45~3uRz5g, num_parameters = 1639186, previous_steps = 800000, previous_score =   131.105) for 100_000 steps\n",
      "  2500: score =   131.960, time = 13.15\n",
      "  5000: score =   134.048, time = 13.53\n",
      "  7500: score =   127.116, time = 14.50\n",
      " 10000: score =   139.508, time = 14.54\n",
      " 12500: score =   133.597, time = 13.83\n",
      " 15000: score =   124.897, time = 13.85\n",
      " 17500: score =   137.648, time = 13.93\n",
      " 20000: score =   124.432, time = 13.81\n",
      " 22500: score =   133.614, time = 13.85\n",
      " 25000: score =    95.729, time = 14.04\n",
      " 27500: score =   130.307, time = 13.95\n",
      " 30000: score =   125.757, time = 13.79\n",
      " 32500: score =   139.663, time = 14.07\n",
      " 35000: score =   137.022, time = 14.04\n",
      " 37500: score =   115.761, time = 13.83\n",
      " 40000: score =   134.166, time = 13.79\n",
      " 42500: score =   126.489, time = 13.97\n",
      " 45000: score =   125.131, time = 13.86\n",
      " 47500: score =   138.907, time = 14.01\n",
      " 50000: score =   135.497, time = 13.95\n",
      " 52500: score =   136.030, time = 13.77\n",
      " 55000: score =   132.411, time = 13.75\n",
      " 57500: score =   133.708, time = 13.72\n",
      " 60000: score =   133.030, time = 13.96\n",
      " 62500: score =   137.580, time = 13.90\n",
      " 65000: score =   115.023, time = 14.02\n",
      " 67500: score =   140.915, time = 13.98\n",
      " 70000: score =   104.383, time = 13.83\n",
      " 72500: score =   139.625, time = 13.89\n",
      " 75000: score =   116.585, time = 13.78\n",
      " 77500: score =   141.867, time = 13.93\n",
      " 80000: score =   108.981, time = 13.92\n",
      " 82500: score =   140.786, time = 13.91\n",
      " 85000: score =   113.046, time = 13.85\n",
      " 87500: score =   140.679, time = 13.96\n",
      " 90000: score =   119.724, time = 13.99\n",
      " 92500: score =   144.977, time = 13.74\n",
      " 95000: score =   130.251, time = 13.64\n",
      " 97500: score =   138.518, time = 13.71\n",
      "100000: score =   146.810, time = 13.74\n",
      "Training finished for policy (policy_id = 2024-05-04_00.20.23~MV6RVg, parent_id = 2024-05-03_23.43.45~3uRz5g, num_parameters = 1639186, previous_steps = 800000, previous_score =   131.105), end score =   146.810, time = 555.96\n",
      "policy selection probs = \n",
      "\t2024-05-03_19.31.56~YOi2Kr: p = 0.007677, score = 4.206996390849505, steps = 100000\n",
      "\t2024-05-03_19.41.26~ONGcgY: p = 0.006774, score = 4.0693869693096225, steps = 100000\n",
      "\t2024-05-03_19.50.38~rpp1TN: p = 0.007548, score = 4.188376196313367, steps = 100000\n",
      "\t2024-05-03_19.59.45~iOUmuV: p = 0.004599, score = 3.6433777535195424, steps = 100000\n",
      "\t2024-05-03_20.08.31~qVIc0m: p = 0.007450, score = 4.174018825558536, steps = 100000\n",
      "\t2024-05-03_20.23.19~jkSCqb: p = 0.009925, score = 4.489554743439111, steps = 200000\n",
      "\t2024-05-03_20.32.46~UETzfs: p = 0.013168, score = 4.800572682635106, steps = 300000\n",
      "\t2024-05-03_20.42.03~AAbsq9: p = 0.012568, score = 4.749212855963114, steps = 300000\n",
      "\t2024-05-03_20.51.29~B2PjVU: p = 0.006493, score = 4.022717518362039, steps = 100000\n",
      "\t2024-05-03_21.00.17~O81lZo: p = 0.009196, score = 4.405664072010694, steps = 200000\n",
      "\t2024-05-03_21.09.57~l028kP: p = 0.017602, score = 5.119815029569647, steps = 400000\n",
      "\t2024-05-03_21.19.14~Ha74nA: p = 0.014688, score = 4.9207324970779664, steps = 300000\n",
      "\t2024-05-03_21.30.22~qZu9T3: p = 0.019138, score = 5.211807015857933, steps = 400000\n",
      "\t2024-05-03_21.43.20~RfUGC7: p = 0.033274, score = 5.820244269057214, steps = 500000\n",
      "\t2024-05-03_21.52.38~IWwG2v: p = 0.014045, score = 4.871467820567192, steps = 400000\n",
      "\t2024-05-03_22.01.54~ACeu6l: p = 0.012152, score = 4.712261181201649, steps = 100000\n",
      "\t2024-05-03_22.10.48~pYUxFh: p = 0.014672, score = 4.91952920658377, steps = 200000\n",
      "\t2024-05-03_22.20.12~h4k0Gh: p = 0.031729, score = 5.7679493777737125, steps = 600000\n",
      "\t2024-05-03_22.29.29~Rs0F3r: p = 0.014209, score = 4.884215905858819, steps = 300000\n",
      "\t2024-05-03_22.38.52~Xu8Xy5: p = 0.019581, score = 5.237004192435043, steps = 400000\n",
      "\t2024-05-03_22.48.06~ZTYgTN: p = 0.054365, score = 6.360276485180624, steps = 600000\n",
      "\t2024-05-03_22.57.17~SjuQMY: p = 0.016689, score = 5.061205708606979, steps = 400000\n",
      "\t2024-05-03_23.06.42~60oZB5: p = 0.013024, score = 4.78847882750759, steps = 400000\n",
      "\t2024-05-03_23.16.07~Ntmb7N: p = 0.054464, score = 6.362271009282945, steps = 700000\n",
      "\t2024-05-03_23.25.23~F54ySp: p = 0.084810, score = 6.849442572883754, steps = 700000\n",
      "\t2024-05-03_23.34.33~z9rEfe: p = 0.073125, score = 6.686365456465223, steps = 800000\n",
      "\t2024-05-03_23.43.45~3uRz5g: p = 0.097082, score = 6.998097861627796, steps = 800000\n",
      "\t2024-05-03_23.52.58~bSXC4u: p = 0.051222, score = 6.294770842431128, steps = 600000\n",
      "\t2024-05-04_00.02.10~DQW8KB: p = 0.029952, score = 5.704523664808428, steps = 700000\n",
      "\t2024-05-04_00.11.21~MQ4D7Q: p = 0.040755, score = 6.043315911358251, steps = 800000\n",
      "\t2024-05-04_00.20.23~MV6RVg: p = 0.208026, score = 7.836413759743161, steps = 900000\n",
      "Starting PPO with policy (policy_id = 2024-05-04_00.29.39~iFr1CD, parent_id = 2024-05-03_22.57.17~SjuQMY, num_parameters = 1639186, previous_steps = 400000, previous_score =    94.818) for 100_000 steps\n",
      "  2500: score =    90.836, time = 13.55\n",
      "  5000: score =    94.932, time = 14.17\n",
      "  7500: score =    96.439, time = 14.31\n",
      " 10000: score =    92.901, time = 14.18\n",
      " 12500: score =    93.019, time = 14.10\n",
      " 15000: score =    91.569, time = 14.25\n",
      " 17500: score =    92.186, time = 13.66\n",
      " 20000: score =    94.061, time = 13.85\n",
      " 22500: score =    96.670, time = 13.98\n",
      " 25000: score =    95.287, time = 13.93\n",
      " 27500: score =    95.656, time = 13.96\n",
      " 30000: score =    95.040, time = 13.97\n",
      "keyboard interrupt\n",
      "closing envs\n",
      "envs closed\n",
      "model db closed\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "def init_policy():\n",
    "    class A2CNetwork(nn.Module):\n",
    "\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "            \n",
    "            in_size = 376\n",
    "            shared_out_sizes = []\n",
    "            actor_out_sizes = [512, 512, 256, 256, 256, 256, 256, 256, 17]\n",
    "            critic_out_sizes = [512, 512, 256, 256, 256, 1]\n",
    "            \n",
    "            hidden_activation_function = nn.ELU()\n",
    "            actor_out_activation_function = nn.Tanh()\n",
    "            critic_out_activation_function = nn.Identity()\n",
    "            \n",
    "            self.has_shared = len(shared_out_sizes) > 0\n",
    "            \n",
    "            if self.has_shared:\n",
    "                self.shared = SeqNet.from_layer_provider(\n",
    "                    layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n",
    "                        nn.Linear(in_features, out_features),\n",
    "                        hidden_activation_function\n",
    "                    ),\n",
    "                    in_size=in_size,\n",
    "                    out_sizes=shared_out_sizes\n",
    "                )\n",
    "            else:\n",
    "                self.shared = TorchNet(nn.Identity(), in_shape=TensorShape(features=in_size), out_shape=TensorShape(features=in_size))\n",
    "\n",
    "            self.actor = SeqNet.from_layer_provider(\n",
    "                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n",
    "                    nn.Linear(in_features, out_features),\n",
    "                    actor_out_activation_function if is_last_layer else hidden_activation_function\n",
    "                ),\n",
    "                in_size=self.shared.out_shape.get_definite_features(),\n",
    "                out_sizes=actor_out_sizes\n",
    "            )\n",
    "\n",
    "            self.critic = SeqNet.from_layer_provider(\n",
    "                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n",
    "                    nn.Linear(in_features, out_features),\n",
    "                    critic_out_activation_function if is_last_layer else hidden_activation_function\n",
    "                ),\n",
    "                in_size=self.shared.out_shape.get_definite_features(),\n",
    "                out_sizes=critic_out_sizes\n",
    "            )\n",
    "\n",
    "        def forward(self, x: torch.Tensor):\n",
    "            if self.has_shared:\n",
    "                shared_out = self.shared(x)\n",
    "            else:\n",
    "                shared_out = x\n",
    "\n",
    "            return self.actor(shared_out), self.critic(shared_out)\n",
    "\n",
    "    return ActorCriticPolicy(A2CNetwork(), lambda action_logits: dist.Normal(loc=action_logits, scale=policy_action_std))\n",
    "\n",
    "def wrap_env(_env: VectorEnv):\n",
    "    _env = TransformRewardWrapper(_env, lambda _reward: 0.01 * _reward) \n",
    "    _env = RescaleAction(_env, min_action=-1.0, max_action=1.0)\n",
    "    _env = ClipAction(_env)\n",
    "    return _env\n",
    "\n",
    "def train_func(policy_with_env_and_info: PolicyWithEnvAndInfo) -> tuple[int, float]:\n",
    "    policy = policy_with_env_and_info['policy']\n",
    "    env = policy_with_env_and_info['env']\n",
    "    \n",
    "    \n",
    "    # todo: ems\n",
    "    score = 0.0\n",
    "    rollout_stopwatch = Stopwatch()\n",
    "    def on_rollout_done(rl: PPO, step: int, info: dict[str, Any]):   \n",
    "        \n",
    "        if 'raw_rewards' in info['rollout']:\n",
    "            raw_rewards = info['rollout']['raw_rewards']\n",
    "            _, gamma_1_returns = compute_gae_and_returns(\n",
    "                value_estimates=np.zeros_like(rl.buffer.rewards[:len(raw_rewards)]),\n",
    "                rewards=raw_rewards,\n",
    "                episode_starts=rl.buffer.episode_starts[:len(raw_rewards)],\n",
    "                last_values=np.zeros_like(rl.buffer.rewards[0], dtype=float),\n",
    "                last_dones=np.zeros_like(rl.buffer.episode_starts[0], dtype=bool),\n",
    "                gamma=1.0,\n",
    "                gae_lambda=1.0,\n",
    "                normalize_rewards=None,\n",
    "                normalize_advantages=None,\n",
    "            )\n",
    "        else:\n",
    "            _, gamma_1_returns = rl.buffer.compute_gae_and_returns(\n",
    "                last_values=torch.zeros_like(rl.buffer.value_estimates[0]),\n",
    "                last_dones=np.zeros_like(rl.buffer.episode_starts[0], dtype=bool),\n",
    "                gamma=1.0,\n",
    "                gae_lambda=1.0,\n",
    "                normalize_advantages=None,\n",
    "                normalize_rewards=None,\n",
    "            )\n",
    "        \n",
    "        episode_scores = gamma_1_returns[\n",
    "            rl.buffer.episode_starts[:rl.buffer.pos]\n",
    "        ]\n",
    "        \n",
    "        nonlocal score\n",
    "        score = episode_scores.mean()\n",
    "        \n",
    "        rollout_time = rollout_stopwatch.reset()\n",
    "        \n",
    "        resets = format_summary_statics(\n",
    "            rl.buffer.episode_starts.astype(int).sum(axis=0), \n",
    "            mean_format='.2f',\n",
    "            std_format=None,\n",
    "            min_value_format='1d',\n",
    "            max_value_format=None,\n",
    "        )\n",
    "        print(f'{step:>6}: {score = :9.3f}, time = {rollout_time:5.2f}, {resets = :s}')\n",
    "    \n",
    "    policy_info_str = ('('\n",
    "          f'policy_id = {policy_with_env_and_info[\"policy_id\"]}, '\n",
    "          f'parent_id = {policy_with_env_and_info[\"parent_policy_id\"]}, '\n",
    "          f'num_parameters = {count_parameters(policy)}, '\n",
    "          f'previous_steps = {policy_with_env_and_info[\"policy_info\"][\"steps_trained\"]}, '\n",
    "          f'previous_score = {policy_with_env_and_info[\"policy_info\"][\"score\"]:9.3f}'\n",
    "          ')')\n",
    "    \n",
    "    print(f'Starting PPO with policy {policy_info_str:s} for {steps_per_iteration:_} steps')\n",
    "    mitosis_iteration_stopwatch = Stopwatch()\n",
    "    PPO(\n",
    "        env=env,\n",
    "        policy=policy.to(device),\n",
    "        policy_optimizer=lambda pol: optim.Adam(pol.parameters(), lr=1e-5),\n",
    "        buffer_size=2500,\n",
    "        gamma=0.995,\n",
    "        gae_lambda=1.0,\n",
    "        normalize_rewards=None,\n",
    "        normalize_advantages=NormalizationType.Std,\n",
    "        weigh_actor_objective=lambda obj: 1.0 * obj,\n",
    "        weigh_critic_objective=lambda obj: 0.5 * obj,\n",
    "        ppo_max_epochs=10,\n",
    "        ppo_kl_target=0.01,\n",
    "        ppo_batch_size=500,\n",
    "        action_ratio_clip_range=0.05,\n",
    "        grad_norm_clip_value=2.0,\n",
    "        callback=Callback(on_rollout_done=on_rollout_done),\n",
    "        logging_config=PPOLoggingConfig(log_rollout_infos=True)\n",
    "    ).train(steps_per_iteration)\n",
    "    \n",
    "    \n",
    "    print(f'Training finished for policy {policy_info_str:s}, end score = {score:9.3f}, time = {mitosis_iteration_stopwatch.time_passed():6.2f}')\n",
    "    \n",
    "    return steps_per_iteration, score\n",
    "\n",
    "def select_policy_selection_scores(policy_infos: Iterable[PolicyInfo]) -> np.ndarray:\n",
    "    scores = np.array([policy_info['score'] for policy_info in policy_infos])\n",
    "    return scores / scores.std()\n",
    "\n",
    "device = set_default_torch_device(\"cuda:0\") if True else set_default_torch_device('cpu')\n",
    "\n",
    "policy_action_std = 0.15\n",
    "steps_per_iteration = 100_000\n",
    "\n",
    "env_name = 'Humanoid-v4'\n",
    "env_kwargs = {'forward_reward_weight': 1.25, 'healthy_reward': 0.5, 'ctrl_cost_weight': 0.001 }\n",
    "num_envs = 32\n",
    "\n",
    "# mitosis_id = get_current_timestamp()\n",
    "mitosis_id = '2024-05-03_19.31.53'\n",
    "policy_db = TinyModelDB[PolicyInfo](base_path=f'E:/saved_models/rl/{env_name}/mitosis-{mitosis_id}')\n",
    "\n",
    "unwrapped_env = parallelize_env_async(lambda: gym.make(env_name, **env_kwargs), num_envs)\n",
    "try:\n",
    "    print(f'Starting mitosis with id {mitosis_id}')\n",
    "    PolicyMitosis(\n",
    "        policy_db=policy_db,\n",
    "        policy_train_function=train_func,\n",
    "        env=unwrapped_env,\n",
    "        new_init_policy_function=init_policy,\n",
    "        new_wrap_env_function=wrap_env,\n",
    "        select_policy_selection_scores=select_policy_selection_scores,\n",
    "        policy_selection_temperature=1.1,\n",
    "        min_base_ancestors=5,\n",
    "        _globals=globals(),\n",
    "        rng_seed=None,\n",
    "    ).train(1000)\n",
    "except KeyboardInterrupt:\n",
    "    print('keyboard interrupt')\n",
    "finally:\n",
    "    print('closing envs')\n",
    "    time.sleep(2.5)\n",
    "    unwrapped_env.close()\n",
    "    print('envs closed')\n",
    "    policy_db.close()\n",
    "    print('model db closed')\n",
    "    \n",
    "\n",
    "print('done')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-03T22:32:34.247375Z",
     "start_time": "2024-05-03T19:43:17.779727Z"
    }
   },
   "id": "8c51ce897912a70",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "5f8e85263282473c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
