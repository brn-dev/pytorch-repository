{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-17T16:16:59.862463Z",
     "start_time": "2024-05-17T16:16:59.846803Z"
    }
   },
   "outputs": [],
   "source": [
    "from tmp_mp import main"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08201789855957031: 3\n",
      "0.08501863479614258: 5\n",
      "0.08701920509338379: 7\n",
      "3.0842227935791016: 3\n",
      "5.086192607879639: 5\n",
      "6.08526086807251: 3\n",
      "7.087646961212158: 7\n",
      "9.086596965789795: 3\n",
      "10.08682370185852: 5\n",
      "12.08789610862732: 3\n",
      "14.088351011276245: 7\n"
     ]
    }
   ],
   "source": [
    "main()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-17T16:17:15.230794Z",
     "start_time": "2024-05-17T16:17:01.129793Z"
    }
   },
   "id": "83a784f8b65b74f8",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -713     |\n",
      "| time/              |          |\n",
      "|    fps             | 2055     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 3        |\n",
      "|    total_timesteps | 8192     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | -701        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1157        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 14          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024106132 |\n",
      "|    clip_fraction        | 0.399       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -18.8       |\n",
      "|    explained_variance   | -0.00688    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 35.4        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0515     |\n",
      "|    std                  | 0.969       |\n",
      "|    value_loss           | 112         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | -681        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1008        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 24          |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035981067 |\n",
      "|    clip_fraction        | 0.524       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -18.9       |\n",
      "|    explained_variance   | 0.293       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 36.8        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.103      |\n",
      "|    std                  | 0.954       |\n",
      "|    value_loss           | 88.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | -648        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 948         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 34          |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019304514 |\n",
      "|    clip_fraction        | 0.253       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -18.7       |\n",
      "|    explained_variance   | 0.155       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 27.9        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0435     |\n",
      "|    std                  | 0.937       |\n",
      "|    value_loss           | 78.2        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | -642       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 914        |\n",
      "|    iterations           | 5          |\n",
      "|    time_elapsed         | 44         |\n",
      "|    total_timesteps      | 40960      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01131996 |\n",
      "|    clip_fraction        | 0.131      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -18.6      |\n",
      "|    explained_variance   | 0.186      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 30.3       |\n",
      "|    n_updates            | 40         |\n",
      "|    policy_gradient_loss | -0.0205    |\n",
      "|    std                  | 0.932      |\n",
      "|    value_loss           | 61         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | -636       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 894        |\n",
      "|    iterations           | 6          |\n",
      "|    time_elapsed         | 54         |\n",
      "|    total_timesteps      | 49152      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01044782 |\n",
      "|    clip_fraction        | 0.0928     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -18.6      |\n",
      "|    explained_variance   | 0.259      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 26.9       |\n",
      "|    n_updates            | 50         |\n",
      "|    policy_gradient_loss | -0.0153    |\n",
      "|    std                  | 0.926      |\n",
      "|    value_loss           | 51.2       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | -631        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 880         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 65          |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011939176 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -18.5       |\n",
      "|    explained_variance   | 0.296       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 18.3        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.02       |\n",
      "|    std                  | 0.916       |\n",
      "|    value_loss           | 51.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | -606        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 870         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 75          |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021661524 |\n",
      "|    clip_fraction        | 0.296       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -18.5       |\n",
      "|    explained_variance   | 0.204       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 18.6        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0386     |\n",
      "|    std                  | 0.919       |\n",
      "|    value_loss           | 36          |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[2], line 10\u001B[0m\n\u001B[0;32m      7\u001B[0m vec_env \u001B[38;5;241m=\u001B[39m make_vec_env(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mHalfCheetah-v4\u001B[39m\u001B[38;5;124m\"\u001B[39m, n_envs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m4\u001B[39m)\n\u001B[0;32m      9\u001B[0m model \u001B[38;5;241m=\u001B[39m PPO(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMlpPolicy\u001B[39m\u001B[38;5;124m\"\u001B[39m, vec_env, use_sde\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m)\n\u001B[1;32m---> 10\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlearn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtotal_timesteps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m250000\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m     11\u001B[0m model\u001B[38;5;241m.\u001B[39msave(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mppo_cartpole\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     13\u001B[0m \u001B[38;5;28;01mdel\u001B[39;00m model \u001B[38;5;66;03m# remove to demonstrate saving and loading\u001B[39;00m\n",
      "File \u001B[1;32m~\\Git\\stable-baselines3\\stable_baselines3\\ppo\\ppo.py:315\u001B[0m, in \u001B[0;36mPPO.learn\u001B[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001B[0m\n\u001B[0;32m    306\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mlearn\u001B[39m(\n\u001B[0;32m    307\u001B[0m     \u001B[38;5;28mself\u001B[39m: SelfPPO,\n\u001B[0;32m    308\u001B[0m     total_timesteps: \u001B[38;5;28mint\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    313\u001B[0m     progress_bar: \u001B[38;5;28mbool\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[0;32m    314\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m SelfPPO:\n\u001B[1;32m--> 315\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlearn\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    316\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtotal_timesteps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtotal_timesteps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    317\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcallback\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallback\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    318\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlog_interval\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlog_interval\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    319\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtb_log_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtb_log_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    320\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreset_num_timesteps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreset_num_timesteps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    321\u001B[0m \u001B[43m        \u001B[49m\u001B[43mprogress_bar\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mprogress_bar\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    322\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Git\\stable-baselines3\\stable_baselines3\\common\\on_policy_algorithm.py:313\u001B[0m, in \u001B[0;36mOnPolicyAlgorithm.learn\u001B[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001B[0m\n\u001B[0;32m    310\u001B[0m         \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mep_info_buffer \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    311\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dump_logs(iteration)\n\u001B[1;32m--> 313\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    315\u001B[0m callback\u001B[38;5;241m.\u001B[39mon_training_end()\n\u001B[0;32m    317\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\n",
      "File \u001B[1;32m~\\Git\\stable-baselines3\\stable_baselines3\\ppo\\ppo.py:279\u001B[0m, in \u001B[0;36mPPO.train\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    277\u001B[0m \u001B[38;5;66;03m# Optimization step\u001B[39;00m\n\u001B[0;32m    278\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpolicy\u001B[38;5;241m.\u001B[39moptimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[1;32m--> 279\u001B[0m \u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    280\u001B[0m \u001B[38;5;66;03m# Clip grad norm\u001B[39;00m\n\u001B[0;32m    281\u001B[0m th\u001B[38;5;241m.\u001B[39mnn\u001B[38;5;241m.\u001B[39mutils\u001B[38;5;241m.\u001B[39mclip_grad_norm_(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpolicy\u001B[38;5;241m.\u001B[39mparameters(), \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmax_grad_norm)\n",
      "File \u001B[1;32mC:\\Program Files\\Python311\\Lib\\site-packages\\torch\\_tensor.py:492\u001B[0m, in \u001B[0;36mTensor.backward\u001B[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[0;32m    482\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    483\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[0;32m    484\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[0;32m    485\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    490\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[0;32m    491\u001B[0m     )\n\u001B[1;32m--> 492\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    493\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\n\u001B[0;32m    494\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\Program Files\\Python311\\Lib\\site-packages\\torch\\autograd\\__init__.py:251\u001B[0m, in \u001B[0;36mbackward\u001B[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[0;32m    246\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[0;32m    248\u001B[0m \u001B[38;5;66;03m# The reason we repeat the same comment below is that\u001B[39;00m\n\u001B[0;32m    249\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[0;32m    250\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[1;32m--> 251\u001B[0m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[0;32m    252\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    253\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    254\u001B[0m \u001B[43m    \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    255\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    256\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    257\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    258\u001B[0m \u001B[43m    \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    259\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "\n",
    "# Parallel environments\n",
    "vec_env = make_vec_env(\"HalfCheetah-v4\", n_envs=4)\n",
    "\n",
    "model = PPO(\"MlpPolicy\", vec_env, use_sde=True, verbose=2)\n",
    "model.learn(total_timesteps=250000)\n",
    "model.save(\"ppo_cartpole\")\n",
    "\n",
    "del model # remove to demonstrate saving and loading\n",
    "\n",
    "model = PPO.load(\"ppo_cartpole\")\n",
    "\n",
    "obs = vec_env.reset()\n",
    "while True:\n",
    "    action, _states = model.predict(obs)\n",
    "    obs, rewards, dones, info = vec_env.step(action)\n",
    "    vec_env.render(\"human\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-22T10:51:24.817944Z",
     "start_time": "2024-05-22T10:50:08.378272Z"
    }
   },
   "id": "6d26ca5d3fba5ab7",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "8f542b5b7a30c20d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
