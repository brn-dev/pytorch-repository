{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4de06880-6b03-4d58-9afc-5bd1d6263d6c",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-04-05T18:00:52.214230Z",
     "start_time": "2024-04-05T18:00:50.421039Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c2f3051-d357-447d-87b5-a4cdd1caa627",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T17:33:31.624055Z",
     "start_time": "2024-03-28T17:33:31.537695Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1390\n",
      "ModulatedDenseSkipNet(\n",
      "  (layers): NetList(\n",
      "    (0): TorchNet(\n",
      "      (torch_module): Sequential(\n",
      "        (0): Linear(in_features=3, out_features=11, bias=True)\n",
      "        (1): CELU(alpha=1.0)\n",
      "      )\n",
      "    )\n",
      "    (1): TorchNet(\n",
      "      (torch_module): Sequential(\n",
      "        (0): Linear(in_features=13, out_features=23, bias=True)\n",
      "        (1): CELU(alpha=1.0)\n",
      "      )\n",
      "    )\n",
      "    (2): TorchNet(\n",
      "      (torch_module): Sequential(\n",
      "        (0): Linear(in_features=27, out_features=17, bias=True)\n",
      "        (1): CELU(alpha=1.0)\n",
      "      )\n",
      "    )\n",
      "    (3): TorchNet(\n",
      "      (torch_module): Sequential(\n",
      "        (0): Linear(in_features=23, out_features=13, bias=True)\n",
      "        (1): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (connection_modulators[0][0]): TorchNet(\n",
      "    (torch_module): Identity()\n",
      "  )\n",
      "  (connection_modulators[1][0]): TorchNet(\n",
      "    (torch_module): Linear(in_features=3, out_features=2, bias=True)\n",
      "  )\n",
      "  (connection_modulators[1][1]): TorchNet(\n",
      "    (torch_module): Identity()\n",
      "  )\n",
      "  (connection_modulators[2][0]): TorchNet(\n",
      "    (torch_module): Linear(in_features=3, out_features=2, bias=True)\n",
      "  )\n",
      "  (connection_modulators[2][1]): TorchNet(\n",
      "    (torch_module): Linear(in_features=11, out_features=2, bias=True)\n",
      "  )\n",
      "  (connection_modulators[2][2]): TorchNet(\n",
      "    (torch_module): Identity()\n",
      "  )\n",
      "  (connection_modulators[3][0]): TorchNet(\n",
      "    (torch_module): Linear(in_features=3, out_features=2, bias=True)\n",
      "  )\n",
      "  (connection_modulators[3][1]): TorchNet(\n",
      "    (torch_module): Linear(in_features=11, out_features=2, bias=True)\n",
      "  )\n",
      "  (connection_modulators[3][2]): TorchNet(\n",
      "    (torch_module): Linear(in_features=23, out_features=2, bias=True)\n",
      "  )\n",
      "  (connection_modulators[3][3]): TorchNet(\n",
      "    (torch_module): Identity()\n",
      "  )\n",
      "  (connection_modulators[4][0]): TorchNet(\n",
      "    (torch_module): Linear(in_features=3, out_features=2, bias=True)\n",
      "  )\n",
      "  (connection_modulators[4][1]): TorchNet(\n",
      "    (torch_module): Linear(in_features=11, out_features=2, bias=True)\n",
      "  )\n",
      "  (connection_modulators[4][2]): TorchNet(\n",
      "    (torch_module): Linear(in_features=23, out_features=2, bias=True)\n",
      "  )\n",
      "  (connection_modulators[4][3]): TorchNet(\n",
      "    (torch_module): Linear(in_features=17, out_features=2, bias=True)\n",
      "  )\n",
      "  (connection_modulators[4][4]): TorchNet(\n",
      "    (torch_module): Identity()\n",
      "  )\n",
      ")\n",
      "torch.Size([111, 5, 19, 21])\n"
     ]
    }
   ],
   "source": [
    "from src.networks.core.tensor_shape import TensorShape\n",
    "from src.networks.skip_nets.modulated_additive_skip_net import ModulatedAdditiveSkipNet\n",
    "from src.networks.core.net import Net\n",
    "from src.networks.skip_nets.modulated_dense_skip_net import ModulatedDenseSkipNet\n",
    "from src.networks.core.parallel_net import ParallelNet\n",
    "from src.module_analysis import count_parameters\n",
    "from src.networks.skip_nets.dense_skip_net import DenseSkipNet\n",
    "from src.networks.core.layer_connections import LayerConnections\n",
    "from src.networks.skip_nets.additive_skip_net import AdditiveSkipNet\n",
    "\n",
    "def create_mod_dense(from_idx: int, to_idx: int, num_f: int):\n",
    "    if from_idx != to_idx:\n",
    "        return Net.as_net(create_ones_linear(num_f, 2))\n",
    "    else:\n",
    "        return Net.as_net(nn.Identity())\n",
    "\n",
    "def create_mod_additive(from_idx: int, to_idx: int, num_f: int):\n",
    "    if from_idx != to_idx:\n",
    "        return Net.as_net(create_ones_linear(num_f, num_f))\n",
    "    else:\n",
    "        return Net.as_net(nn.Identity())\n",
    "\n",
    "def create_ones_linear(in_features, out_features):\n",
    "    l = nn.Linear(in_features, out_features)\n",
    "    l.weight.data[:] = 1.0\n",
    "    l.bias.data[:] = 0.0\n",
    "    return l\n",
    "\n",
    "def create_layer(i, is_last, in_features, out_features):\n",
    "    return nn.Sequential(\n",
    "        create_ones_linear(in_features, out_features),\n",
    "        nn.CELU() if not is_last else nn.Identity(),\n",
    "    )\n",
    "\n",
    "num_features=3\n",
    "# net = AdditiveSkipNet.from_layer_provider(\n",
    "#     layer_provider=create_layer,\n",
    "#     num_layers=4,\n",
    "#     num_features=num_features,\n",
    "#     layer_connections='full',\n",
    "#     initial_direct_connection_weight=1.0,\n",
    "#     initial_skip_connection_weight=0.01,\n",
    "#     return_dense=False,\n",
    "#     weights_trainable=False,\n",
    "# )\n",
    "# net = DenseSkipNet.from_layer_provider(\n",
    "#     layer_provider=create_layer,\n",
    "#     num_layers=10,\n",
    "#     num_features=num_features,\n",
    "#     layer_connections='full'\n",
    "# )\n",
    "# net = ParallelNet.from_layer_provider(create_layer, in_size=num_features, out_sizes=[5, 7, 11, 13])\n",
    "net = ModulatedDenseSkipNet.from_layer_provider(\n",
    "    layer_provider=create_layer,\n",
    "    modulator_provider=create_mod_dense,\n",
    "    in_size=num_features,\n",
    "    layer_out_sizes=[11, 23, 17, 13],\n",
    ")\n",
    "# net = ModulatedAdditiveSkipNet.from_layer_provider(\n",
    "#     layer_provider=create_layer,\n",
    "#     modulator_provider=create_mod_additive,\n",
    "#     num_features=num_features,\n",
    "#     num_layers=4,\n",
    "#     # return_dense=True,\n",
    "# )\n",
    "print(net.count_parameters())\n",
    "print(net)\n",
    "\n",
    "out = net(torch.ones(111, 5, 19, num_features))\n",
    "print(out.shape)\n",
    "# print(out)\n",
    "# print(net.forward_shape(TensorShape(features=num_features, s_0=111, s_1=5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5a5e3e1d339c766",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-28T17:33:31.692766Z",
     "start_time": "2024-03-28T17:33:31.625045Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "468"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "90 * 3 + 3 * 3 * 18 + 3 * 3 * 3 + 3 * 3 * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33dd5e90",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-28T17:33:31.766826Z",
     "start_time": "2024-03-28T17:33:31.693749Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "804"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3 * (90 + 18 + 3 + 1) + 468"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c8e263e",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-28T17:33:31.842571Z",
     "start_time": "2024-03-28T17:33:31.767820Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "804"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "804"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77e0603b",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-28T17:33:31.912911Z",
     "start_time": "2024-03-28T17:33:31.843567Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Conv2dNet(2, 3, kernel_size=(4, 4), stride=(1, 1), padding=same)"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.networks.core.torch_wrappers.conv_net import Conv2dNet\n",
    "\n",
    "conv = Conv2dNet(2, 3, 4, padding='same')\n",
    "conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db8955ea",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-28T17:33:31.984662Z",
     "start_time": "2024-03-28T17:33:31.913906Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([ 0.4794, -0.7732, -0.1890], grad_fn=<ViewBackward0>)"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.networks.core.torch_wrappers.linear_net import LinearNet\n",
    "\n",
    "lin = LinearNet(2, 3)\n",
    "lin(torch.ones(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96091cdd",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-28T17:33:32.055886Z",
     "start_time": "2024-03-28T17:33:31.985660Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[ 0.1577, -0.4909, -0.1444,  ...,  0.1137, -0.1642,  0.0041],\n         [ 0.1577, -0.4909, -0.1444,  ...,  0.1137, -0.1642,  0.0041],\n         [ 0.1577, -0.4909, -0.1444,  ...,  0.1137, -0.1642,  0.0041],\n         ...,\n         [ 0.1577, -0.4909, -0.1444,  ...,  0.1137, -0.1642,  0.0041],\n         [ 0.1577, -0.4909, -0.1444,  ...,  0.1137, -0.1642,  0.0041],\n         [ 0.1577, -0.4909, -0.1444,  ...,  0.1137, -0.1642,  0.0041]],\n\n        [[ 0.1577, -0.4909, -0.1444,  ...,  0.1137, -0.1642,  0.0041],\n         [ 0.1577, -0.4909, -0.1444,  ...,  0.1137, -0.1642,  0.0041],\n         [ 0.1577, -0.4909, -0.1444,  ...,  0.1137, -0.1642,  0.0041],\n         ...,\n         [ 0.1577, -0.4909, -0.1444,  ...,  0.1137, -0.1642,  0.0041],\n         [ 0.1577, -0.4909, -0.1444,  ...,  0.1137, -0.1642,  0.0041],\n         [ 0.1577, -0.4909, -0.1444,  ...,  0.1137, -0.1642,  0.0041]],\n\n        [[ 0.1577, -0.4909, -0.1444,  ...,  0.1137, -0.1642,  0.0041],\n         [ 0.1577, -0.4909, -0.1444,  ...,  0.1137, -0.1642,  0.0041],\n         [ 0.1577, -0.4909, -0.1444,  ...,  0.1137, -0.1642,  0.0041],\n         ...,\n         [ 0.1577, -0.4909, -0.1444,  ...,  0.1137, -0.1642,  0.0041],\n         [ 0.1577, -0.4909, -0.1444,  ...,  0.1137, -0.1642,  0.0041],\n         [ 0.1577, -0.4909, -0.1444,  ...,  0.1137, -0.1642,  0.0041]],\n\n        ...,\n\n        [[ 0.1577, -0.4909, -0.1444,  ...,  0.1137, -0.1642,  0.0041],\n         [ 0.1577, -0.4909, -0.1444,  ...,  0.1137, -0.1642,  0.0041],\n         [ 0.1577, -0.4909, -0.1444,  ...,  0.1137, -0.1642,  0.0041],\n         ...,\n         [ 0.1577, -0.4909, -0.1444,  ...,  0.1137, -0.1642,  0.0041],\n         [ 0.1577, -0.4909, -0.1444,  ...,  0.1137, -0.1642,  0.0041],\n         [ 0.1577, -0.4909, -0.1444,  ...,  0.1137, -0.1642,  0.0041]],\n\n        [[ 0.1577, -0.4909, -0.1444,  ...,  0.1137, -0.1642,  0.0041],\n         [ 0.1577, -0.4909, -0.1444,  ...,  0.1137, -0.1642,  0.0041],\n         [ 0.1577, -0.4909, -0.1444,  ...,  0.1137, -0.1642,  0.0041],\n         ...,\n         [ 0.1577, -0.4909, -0.1444,  ...,  0.1137, -0.1642,  0.0041],\n         [ 0.1577, -0.4909, -0.1444,  ...,  0.1137, -0.1642,  0.0041],\n         [ 0.1577, -0.4909, -0.1444,  ...,  0.1137, -0.1642,  0.0041]],\n\n        [[ 0.1577, -0.4909, -0.1444,  ...,  0.1137, -0.1642,  0.0041],\n         [ 0.1577, -0.4909, -0.1444,  ...,  0.1137, -0.1642,  0.0041],\n         [ 0.1577, -0.4909, -0.1444,  ...,  0.1137, -0.1642,  0.0041],\n         ...,\n         [ 0.1577, -0.4909, -0.1444,  ...,  0.1137, -0.1642,  0.0041],\n         [ 0.1577, -0.4909, -0.1444,  ...,  0.1137, -0.1642,  0.0041],\n         [ 0.1577, -0.4909, -0.1444,  ...,  0.1137, -0.1642,  0.0041]]],\n       grad_fn=<ViewBackward0>)"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.networks.multihead_self_attention import MultiheadSelfAttention\n",
    "\n",
    "mhsa = MultiheadSelfAttention(10, 5)\n",
    "mhsa.forward_shape(TensorShape(features=10, s_0=None))\n",
    "mhsa(torch.ones(123, 9, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ccaa81c5-426a-443d-bb96-696abbdd298d",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-03-28T17:33:32.131054Z",
     "start_time": "2024-03-28T17:33:32.056844Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 0,  0],\n       [ 0, 12],\n       [ 1,  1],\n       [ 1,  2],\n       [ 1,  3],\n       [ 1,  4],\n       [ 1,  5],\n       [ 1,  6],\n       [ 1,  7],\n       [ 1,  8],\n       [ 1,  9],\n       [ 1, 10],\n       [ 1, 11],\n       [ 1, 12],\n       [ 2,  2],\n       [ 2,  3],\n       [ 2,  4],\n       [ 2,  5],\n       [ 2,  6],\n       [ 2,  7],\n       [ 2,  8],\n       [ 2,  9],\n       [ 2, 10],\n       [ 2, 11],\n       [ 2, 12],\n       [ 3,  3],\n       [ 3, 12],\n       [ 4,  4],\n       [ 4, 12],\n       [ 5,  5],\n       [ 5, 12],\n       [ 6,  6],\n       [ 6,  7],\n       [ 6,  8],\n       [ 6,  9],\n       [ 6, 10],\n       [ 6, 11],\n       [ 6, 12],\n       [ 7,  7],\n       [ 7, 12],\n       [ 8,  8],\n       [ 8, 12],\n       [ 9,  9],\n       [ 9, 12],\n       [10, 10],\n       [10, 12],\n       [11, 11],\n       [11, 12],\n       [12, 12]], dtype=int32)"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.networks.core.layer_connections import *\n",
    "from src.integer_sequences import *\n",
    "\n",
    "(LayerConnectionsBuilder(12)\n",
    "    .sequential()\n",
    "    .every_step_receives(factorial).every_step_to_output().to_np())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d842097-67d7-41d2-ad5c-ab3c75eef202",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-07T16:58:55.887391Z",
     "start_time": "2024-04-07T16:52:21.808127Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "using device cuda:0\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'imageio'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[2], line 19\u001B[0m\n\u001B[0;32m     16\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124musing device \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdevice\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m     18\u001B[0m \u001B[38;5;66;03m# env = gym.make(\"BipedalWalker-v3\", max_episode_steps=3000)\u001B[39;00m\n\u001B[1;32m---> 19\u001B[0m env \u001B[38;5;241m=\u001B[39m \u001B[43mgym\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmake\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mAnt-v4\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m     21\u001B[0m \u001B[38;5;28mprint\u001B[39m(env)\n\u001B[0;32m     23\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21minit_network\u001B[39m(out_size: \u001B[38;5;28mint\u001B[39m, is_actor: \u001B[38;5;28mbool\u001B[39m):\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gymnasium\\envs\\registration.py:802\u001B[0m, in \u001B[0;36mmake\u001B[1;34m(id, max_episode_steps, autoreset, apply_api_compatibility, disable_env_checker, **kwargs)\u001B[0m\n\u001B[0;32m    799\u001B[0m     render_mode \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    801\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 802\u001B[0m     env \u001B[38;5;241m=\u001B[39m \u001B[43menv_creator\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43menv_spec_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    803\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    804\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[0;32m    805\u001B[0m         \u001B[38;5;28mstr\u001B[39m(e)\u001B[38;5;241m.\u001B[39mfind(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgot an unexpected keyword argument \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrender_mode\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m    806\u001B[0m         \u001B[38;5;129;01mand\u001B[39;00m apply_human_rendering\n\u001B[0;32m    807\u001B[0m     ):\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gymnasium\\envs\\mujoco\\ant_v4.py:266\u001B[0m, in \u001B[0;36mAntEnv.__init__\u001B[1;34m(self, xml_file, ctrl_cost_weight, use_contact_forces, contact_cost_weight, healthy_reward, terminate_when_unhealthy, healthy_z_range, contact_force_range, reset_noise_scale, exclude_current_positions_from_observation, **kwargs)\u001B[0m\n\u001B[0;32m    260\u001B[0m     obs_shape \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m84\u001B[39m\n\u001B[0;32m    262\u001B[0m observation_space \u001B[38;5;241m=\u001B[39m Box(\n\u001B[0;32m    263\u001B[0m     low\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39mnp\u001B[38;5;241m.\u001B[39minf, high\u001B[38;5;241m=\u001B[39mnp\u001B[38;5;241m.\u001B[39minf, shape\u001B[38;5;241m=\u001B[39m(obs_shape,), dtype\u001B[38;5;241m=\u001B[39mnp\u001B[38;5;241m.\u001B[39mfloat64\n\u001B[0;32m    264\u001B[0m )\n\u001B[1;32m--> 266\u001B[0m \u001B[43mMujocoEnv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__init__\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[0;32m    267\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    268\u001B[0m \u001B[43m    \u001B[49m\u001B[43mxml_file\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    269\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m5\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    270\u001B[0m \u001B[43m    \u001B[49m\u001B[43mobservation_space\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mobservation_space\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    271\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdefault_camera_config\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mDEFAULT_CAMERA_CONFIG\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    272\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    273\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gymnasium\\envs\\mujoco\\mujoco_env.py:371\u001B[0m, in \u001B[0;36mMujocoEnv.__init__\u001B[1;34m(self, model_path, frame_skip, observation_space, render_mode, width, height, camera_id, camera_name, default_camera_config)\u001B[0m\n\u001B[0;32m    355\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m error\u001B[38;5;241m.\u001B[39mDependencyNotInstalled(\n\u001B[0;32m    356\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mMUJOCO_IMPORT_ERROR\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    357\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m(HINT: you need to install mujoco, run `pip install gymnasium[mujoco]`.)\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    358\u001B[0m     )\n\u001B[0;32m    360\u001B[0m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m(\n\u001B[0;32m    361\u001B[0m     model_path,\n\u001B[0;32m    362\u001B[0m     frame_skip,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    368\u001B[0m     camera_name,\n\u001B[0;32m    369\u001B[0m )\n\u001B[1;32m--> 371\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mgymnasium\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01menvs\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmujoco\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmujoco_rendering\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m MujocoRenderer\n\u001B[0;32m    373\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmujoco_renderer \u001B[38;5;241m=\u001B[39m MujocoRenderer(\n\u001B[0;32m    374\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdata, default_camera_config\n\u001B[0;32m    375\u001B[0m )\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gymnasium\\envs\\mujoco\\mujoco_rendering.py:7\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtyping\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Optional\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mglfw\u001B[39;00m\n\u001B[1;32m----> 7\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mimageio\u001B[39;00m\n\u001B[0;32m      8\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mmujoco\u001B[39;00m\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnp\u001B[39;00m\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'imageio'"
     ]
    }
   ],
   "source": [
    "from gymnasium.wrappers import TimeLimit\n",
    "from src.torch_device import set_default_torch_device\n",
    "from torch.distributions import Normal\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.distributions import Categorical\n",
    "from torch import optim, nn\n",
    "from src.reinforcement_learning.a2c.episodic.a2c import A2C\n",
    "from src.networks.core.seq_net import SeqNet\n",
    "import gymnasium as gym\n",
    "\n",
    "device = set_default_torch_device(\"cuda:0\")\n",
    "print(f'using device {device}')\n",
    "\n",
    "env = gym.make(\"BipedalWalker-v3\", max_episode_steps=3000)\n",
    "\n",
    "print(env)\n",
    "\n",
    "def init_network(out_size: int, is_actor: bool):\n",
    "    return SeqNet.from_layer_provider(\n",
    "        layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n",
    "            nn.Linear(in_features, out_features),\n",
    "            nn.CELU() if not is_last_layer else (nn.Tanh() if is_actor else nn.Identity())\n",
    "        ),\n",
    "        in_size=24,\n",
    "        out_sizes=[32, 32, 32, out_size]\n",
    "    )\n",
    "\n",
    "def select_action(logits: torch.Tensor):\n",
    "    dist = Normal(loc=logits, scale=0.15)\n",
    "    \n",
    "    action = dist.sample()\n",
    "    \n",
    "    return action.detach().cpu().numpy(), dist.log_prob(action)\n",
    "\n",
    "actor = init_network(4, True)\n",
    "critic = init_network(1, False)\n",
    "\n",
    "A2C(\n",
    "    env=env,\n",
    "    actor_network=actor,\n",
    "    actor_network_optimizer=optim.Adam(actor.parameters()),\n",
    "    critic_network=critic,\n",
    "    critic_network_optimizer=optim.Adam(critic.parameters()),\n",
    "    critic_loss=nn.MSELoss(),\n",
    "    select_action=select_action,\n",
    "    gamma=0.9,\n",
    "    on_episode_done=lambda a2c, info: print(f'{info[\"i_episode\"]:>4}: {info[\"episode_cumulative_reward\"]:> 8.1f}, {info[\"end_timestep\"]:>5}'),\n",
    ").find_optimal_policy(1000)"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-06T19:21:52.946209Z",
     "start_time": "2024-04-06T19:21:52.943234Z"
    }
   },
   "id": "59d060a3b01355a7",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "nn.Conv2d"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7c593851a4f4f6a4"
  }
 ],
 "metadata": {
  "autoscrollcelloutput": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
