{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import inspect\n",
    "import os\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "from gymnasium import Env\n",
    "\n",
    "from src.datetime import get_current_timestamp\n",
    "from src.model_db import ModelDB\n",
    "from src.module_analysis import count_parameters, get_gradients_per_parameter\n",
    "from src.moving_averages import ExponentialMovingAverage\n",
    "from src.networks.core.tensor_shape import TensorShape\n",
    "from src.networks.core.torch_wrappers.torch_net import TorchNet\n",
    "from src.reinforcement_learning.core.generalized_advantage_estimate import compute_gae_and_returns\n",
    "from src.reinforcement_learning.core.policies.base_policy import BasePolicy\n",
    "from src.reinforcement_learning.gym.envs.normalize_reward_wrapper import NormalizeRewardWrapper\n",
    "from src.stopwatch import Stopwatch\n",
    "from src.summary_statistics import format_summary_statics\n",
    "from src.reinforcement_learning.core.policies.actor_critic_policy import ActorCriticPolicy\n",
    "from typing import Any, SupportsFloat, Optional\n",
    "from gymnasium.wrappers import RecordVideo, AutoResetWrapper, NormalizeReward, TransformReward, TransformObservation, \\\n",
    "    RescaleAction, ClipAction\n",
    "from src.reinforcement_learning.core.callback import Callback\n",
    "from src.reinforcement_learning.a2c.a2c import A2C\n",
    "from src.reinforcement_learning.ppo.ppo import PPO\n",
    "from src.reinforcement_learning.core.normalization import NormalizationType\n",
    "from src.reinforcement_learning.gym.envs.step_skip_wrapper import StepSkipWrapper\n",
    "from src.reinforcement_learning.core.rl_base import RLBase\n",
    "from src.torch_device import set_default_torch_device\n",
    "from src.reinforcement_learning.gym.envs.parallelize_env import parallelize_env_async\n",
    "from torch.distributions import Normal, Categorical\n",
    "\n",
    "import torch\n",
    "from torch import optim, nn\n",
    "import torch.distributions as dist\n",
    "from src.networks.core.seq_net import SeqNet\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T18:55:42.197997Z",
     "start_time": "2024-04-28T18:55:39.151671Z"
    }
   },
   "id": "ba8c59a3eba2f172"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device cuda:0\n",
      "count_parameters(policy) = 1639186\n",
      "env = <ClipAction<RescaleAction<AsyncVectorEnv instance>>>, num_envs = 64\n",
      "envs reset\n",
      "step =    2500, scores =   24.9 ±  8.1 [  -0.0,  77.8], score_ema =   24.9, advantages =  1.338 ± 1.0 [ -1.060,  6.480], abs_actor_obj =  1.496 ± 1.195, critic_obj = 108.896 ± 5.340, resets = 64.14 ≥ 57, time = 26.4\n",
      "step =    5000, scores =   22.9 ±  6.0 [   1.0,  70.3], score_ema =   24.7, advantages =  1.295 ± 1.0 [ -1.027,  7.081], abs_actor_obj =  1.523 ± 1.161, critic_obj = 78.081 ± 2.220, resets = 69.27 ≥ 63, time = 21.2\n",
      "step =    7500, scores =   25.0 ±  7.9 [   0.9,  74.1], score_ema =   24.7, advantages =  1.182 ± 1.0 [ -1.358,  6.040], abs_actor_obj =  1.511 ± 1.288, critic_obj = 94.225 ± 4.631, resets = 63.31 ≥ 57, time = 21.6\n",
      "step =   10000, scores =   36.8 ± 16.3 [   0.8,  92.7], score_ema =   25.9, advantages =  1.213 ± 1.0 [ -1.402,  4.444], abs_actor_obj =  1.520 ± 1.348, critic_obj = 240.866 ± 7.855, resets = 47.12 ≥ 39, time = 21.1\n",
      "step =   12500, scores =   48.5 ± 17.5 [   1.6,  95.3], score_ema =   28.2, advantages =  1.397 ± 1.0 [ -1.563,  4.042], abs_actor_obj =  1.765 ± 1.463, critic_obj = 343.979 ± 13.712, resets = 39.69 ≥ 34, time = 19.8\n",
      "step =   15000, scores =   57.2 ± 14.6 [   1.7, 129.2], score_ema =   31.1, advantages =  1.497 ± 1.0 [ -1.994,  4.678], abs_actor_obj =  1.930 ± 1.575, critic_obj = 384.902 ± 25.674, resets = 35.61 ≥ 33, time = 20.8\n",
      "step =   17500, scores =   62.3 ± 14.5 [   2.1, 118.0], score_ema =   34.2, advantages =  1.437 ± 1.0 [ -3.219,  4.217], abs_actor_obj =  2.002 ± 1.898, critic_obj = 410.441 ± 21.459, resets = 34.50 ≥ 32, time = 19.9\n",
      "step =   20000, scores =   65.6 ± 14.1 [   1.2,  99.2], score_ema =   37.4, advantages =  1.327 ± 1.0 [ -3.419,  3.740], abs_actor_obj =  2.067 ± 2.276, critic_obj = 408.944 ± 22.261, resets = 34.08 ≥ 32, time = 20.9\n",
      "step =   22500, scores =   63.1 ± 12.8 [   4.3,  94.0], score_ema =   39.9, advantages =  1.056 ± 1.0 [ -4.607,  3.543], abs_actor_obj =  2.349 ± 3.572, critic_obj = 331.155 ± 18.825, resets = 35.03 ≥ 32, time = 20.6\n",
      "step =   25000, scores =   62.6 ± 11.9 [   2.0, 118.6], score_ema =   42.2, advantages =  0.840 ± 1.0 [ -5.466,  3.778], abs_actor_obj =  2.794 ± 5.095, critic_obj = 292.660 ± 8.807, resets = 35.27 ≥ 33, time = 21.8\n",
      "step =   27500, scores =   61.8 ± 11.4 [   1.9,  89.4], score_ema =   44.2, advantages =  0.644 ± 1.0 [ -6.141,  5.776], abs_actor_obj =  3.309 ± 6.513, critic_obj = 271.582 ± 3.969, resets = 35.17 ≥ 33, time = 21.8\n",
      "step =   30000, scores =   64.9 ± 11.1 [   2.5,  96.0], score_ema =   46.2, advantages =  0.623 ± 1.0 [ -6.485,  3.111], abs_actor_obj =  3.442 ± 6.846, critic_obj = 288.719 ± 4.030, resets = 33.92 ≥ 32, time = 21.4\n",
      "step =   32500, scores =   64.2 ± 12.1 [   2.5, 102.4], score_ema =   48.0, advantages =  0.542 ± 1.0 [ -6.999,  3.271], abs_actor_obj =  3.764 ± 7.314, critic_obj = 285.121 ± 4.876, resets = 34.14 ≥ 32, time = 21.8\n",
      "step =   35000, scores =   63.9 ± 13.0 [   2.4, 106.3], score_ema =   49.6, advantages =  0.519 ± 1.0 [ -6.661,  3.129], abs_actor_obj =  3.840 ± 7.422, critic_obj = 281.944 ± 6.902, resets = 34.78 ≥ 33, time = 21.0\n",
      "step =   37500, scores =   65.0 ± 13.7 [  -0.5,  97.7], score_ema =   51.2, advantages =  0.499 ± 1.0 [ -6.972,  6.814], abs_actor_obj =  4.009 ± 7.411, critic_obj = 283.392 ± 4.813, resets = 33.33 ≥ 31, time = 21.2\n",
      "step =   40000, scores =   66.4 ± 13.8 [   2.0,  95.5], score_ema =   52.7, advantages =  0.506 ± 1.0 [ -7.297,  3.280], abs_actor_obj =  4.058 ± 7.347, critic_obj = 290.270 ± 2.855, resets = 32.53 ≥ 29, time = 21.0\n",
      "step =   42500, scores =   67.2 ± 15.0 [  -0.0, 108.1], score_ema =   54.1, advantages =  0.496 ± 1.0 [ -6.963,  3.774], abs_actor_obj =  4.146 ± 7.331, critic_obj = 292.548 ± 5.898, resets = 31.83 ≥ 30, time = 21.0\n",
      "step =   45000, scores =   67.9 ± 14.9 [   1.8, 107.8], score_ema =   55.5, advantages =  0.468 ± 1.0 [ -6.611,  4.229], abs_actor_obj =  4.294 ± 7.538, critic_obj = 290.608 ± 3.111, resets = 31.34 ≥ 29, time = 21.2\n",
      "step =   47500, scores =   66.7 ± 15.5 [   0.3, 104.5], score_ema =   56.6, advantages =  0.405 ± 1.0 [ -6.380,  3.286], abs_actor_obj =  4.581 ± 7.927, critic_obj = 276.561 ± 6.625, resets = 31.27 ≥ 29, time = 20.9\n",
      "step =   50000, scores =   64.2 ± 15.6 [   2.1, 102.8], score_ema =   57.4, advantages =  0.339 ± 1.0 [ -6.566,  5.471], abs_actor_obj =  4.906 ± 8.248, critic_obj = 254.334 ± 3.770, resets = 31.78 ≥ 29, time = 21.0\n",
      "step =   52500, scores =   63.9 ± 15.2 [   3.1, 106.7], score_ema =   58.0, advantages =  0.363 ± 1.0 [ -6.786,  4.304], abs_actor_obj =  4.801 ± 7.949, critic_obj = 246.491 ± 1.799, resets = 31.73 ≥ 30, time = 20.9\n",
      "step =   55000, scores =   64.2 ± 16.1 [   1.4, 116.6], score_ema =   58.6, advantages =  0.406 ± 1.0 [ -6.608,  4.006], abs_actor_obj =  4.622 ± 7.535, critic_obj = 245.432 ± 7.628, resets = 32.09 ≥ 30, time = 20.1\n",
      "step =   57500, scores =   69.4 ± 15.0 [   0.3, 122.3], score_ema =   59.7, advantages =  0.502 ± 1.0 [ -6.825,  3.280], abs_actor_obj =  4.233 ± 7.029, critic_obj = 269.740 ± 4.709, resets = 31.11 ≥ 29, time = 21.0\n",
      "step =   60000, scores =   70.5 ± 14.3 [   1.9, 106.2], score_ema =   60.8, advantages =  0.458 ± 1.0 [ -7.716,  3.328], abs_actor_obj =  4.394 ± 7.316, critic_obj = 265.742 ± 3.218, resets = 31.19 ≥ 29, time = 20.2\n",
      "step =   62500, scores =   70.5 ± 14.2 [   1.8, 112.1], score_ema =   61.8, advantages =  0.376 ± 1.0 [ -6.757,  3.779], abs_actor_obj =  4.763 ± 7.809, critic_obj = 260.129 ± 3.884, resets = 31.61 ≥ 30, time = 21.4\n",
      "step =   65000, scores =   70.2 ± 14.3 [   2.0, 114.4], score_ema =   62.6, advantages =  0.345 ± 1.0 [ -6.785,  4.684], abs_actor_obj =  4.920 ± 7.923, critic_obj = 251.588 ± 3.079, resets = 31.70 ≥ 29, time = 20.5\n",
      "step =   67500, scores =   70.5 ± 14.2 [   2.5, 126.1], score_ema =   63.4, advantages =  0.365 ± 1.0 [ -5.797,  3.146], abs_actor_obj =  4.836 ± 7.654, critic_obj = 242.354 ± 3.440, resets = 31.69 ≥ 29, time = 21.1\n",
      "step =   70000, scores =   70.0 ± 13.8 [   1.6, 109.6], score_ema =   64.1, advantages =  0.336 ± 1.0 [ -5.895,  3.100], abs_actor_obj =  4.997 ± 7.783, critic_obj = 231.505 ± 2.383, resets = 31.94 ≥ 29, time = 22.2\n",
      "step =   72500, scores =   69.9 ± 13.0 [   2.5, 113.2], score_ema =   64.7, advantages =  0.328 ± 1.0 [ -5.653,  2.995], abs_actor_obj =  5.034 ± 7.802, critic_obj = 221.945 ± 5.739, resets = 32.41 ≥ 30, time = 22.3\n",
      "step =   75000, scores =   69.6 ± 13.2 [   5.5, 121.1], score_ema =   65.2, advantages =  0.325 ± 1.0 [ -5.531,  3.159], abs_actor_obj =  5.062 ± 7.714, critic_obj = 210.985 ± 3.818, resets = 32.58 ≥ 30, time = 21.9\n",
      "step =   77500, scores =   68.9 ± 13.4 [   2.0, 109.3], score_ema =   65.5, advantages =  0.286 ± 1.0 [ -5.915,  4.953], abs_actor_obj =  5.284 ± 7.893, critic_obj = 201.822 ± 3.292, resets = 32.58 ≥ 30, time = 20.6\n",
      "step =   80000, scores =   68.9 ± 12.7 [   2.0, 107.7], score_ema =   65.9, advantages =  0.283 ± 1.0 [ -5.540,  3.177], abs_actor_obj =  5.305 ± 7.848, critic_obj = 191.182 ± 2.841, resets = 32.86 ≥ 31, time = 22.0\n",
      "step =   82500, scores =   69.7 ± 11.7 [   2.0,  99.8], score_ema =   66.2, advantages =  0.317 ± 1.0 [ -5.660,  3.215], abs_actor_obj =  5.104 ± 7.517, critic_obj = 179.178 ± 3.912, resets = 32.92 ≥ 31, time = 22.5\n",
      "step =   85000, scores =   70.1 ± 11.9 [   2.6, 110.7], score_ema =   66.6, advantages =  0.289 ± 1.0 [ -5.139,  3.087], abs_actor_obj =  5.269 ± 7.646, critic_obj = 173.151 ± 4.187, resets = 33.25 ≥ 31, time = 19.5\n",
      "step =   87500, scores =   70.6 ± 12.1 [   2.0, 108.6], score_ema =   67.0, advantages =  0.277 ± 1.0 [ -5.151,  3.409], abs_actor_obj =  5.345 ± 7.762, critic_obj = 166.776 ± 3.969, resets = 33.08 ≥ 31, time = 20.6\n",
      "step =   90000, scores =   70.5 ± 11.1 [   2.0, 102.1], score_ema =   67.4, advantages =  0.254 ± 1.0 [ -4.538,  3.507], abs_actor_obj =  5.471 ± 7.848, critic_obj = 151.279 ± 3.373, resets = 33.70 ≥ 31, time = 21.6\n",
      "step =   92500, scores =   70.8 ± 11.6 [   2.5, 111.7], score_ema =   67.7, advantages =  0.267 ± 1.0 [ -4.360,  3.275], abs_actor_obj =  5.380 ± 7.886, critic_obj = 141.043 ± 4.001, resets = 33.88 ≥ 31, time = 21.2\n",
      "step =   95000, scores =   71.0 ± 11.3 [   1.9, 109.2], score_ema =   68.0, advantages =  0.219 ± 1.0 [ -5.420,  3.476], abs_actor_obj =  5.630 ± 8.238, critic_obj = 130.377 ± 4.346, resets = 33.89 ≥ 31, time = 22.6\n",
      "step =   97500, scores =   71.8 ± 11.9 [   1.8, 110.2], score_ema =   68.4, advantages =  0.185 ± 1.0 [ -5.218,  3.723], abs_actor_obj =  5.770 ± 8.553, critic_obj = 124.478 ± 4.837, resets = 33.38 ≥ 31, time = 22.6\n",
      "step =  100000, scores =   72.3 ± 12.1 [   2.0, 103.6], score_ema =   68.8, advantages =  0.182 ± 1.0 [ -4.008,  3.469], abs_actor_obj =  5.686 ± 8.480, critic_obj = 112.674 ± 5.208, resets = 33.11 ≥ 31, time = 21.2\n",
      "step =  102500, scores =   72.9 ± 12.9 [   2.0, 119.3], score_ema =   69.2, advantages =  0.163 ± 1.0 [ -3.911,  3.665], abs_actor_obj =  5.810 ± 8.722, critic_obj = 109.431 ± 5.712, resets = 32.39 ≥ 30, time = 21.4\n",
      "step =  105000, scores =   73.5 ± 12.9 [   2.0, 118.6], score_ema =   69.7, advantages =  0.194 ± 1.0 [ -4.297,  4.036], abs_actor_obj =  5.671 ± 8.804, critic_obj = 106.389 ± 5.200, resets = 32.09 ≥ 30, time = 21.2\n",
      "step =  107500, scores =   73.2 ± 12.4 [   2.5, 119.8], score_ema =   70.0, advantages =  0.152 ± 1.0 [ -4.287,  4.055], abs_actor_obj =  5.895 ± 9.286, critic_obj = 94.132 ± 4.003, resets = 32.44 ≥ 30, time = 21.4\n",
      "step =  110000, scores =   71.7 ± 12.0 [   2.2, 112.6], score_ema =   70.2, advantages =  0.142 ± 1.0 [ -5.343,  4.515], abs_actor_obj =  5.883 ± 9.594, critic_obj = 80.223 ± 3.971, resets = 33.31 ≥ 31, time = 21.2\n",
      "step =  112500, scores =   71.4 ± 11.4 [   2.9, 112.1], score_ema =   70.3, advantages =  0.158 ± 1.0 [ -5.668,  5.349], abs_actor_obj =  5.693 ± 9.427, critic_obj = 65.803 ± 3.615, resets = 33.69 ≥ 32, time = 21.2\n",
      "step =  115000, scores =   71.7 ± 11.8 [   2.0, 118.6], score_ema =   70.4, advantages =  0.119 ± 1.0 [ -5.898,  5.376], abs_actor_obj =  5.756 ± 9.955, critic_obj = 61.728 ± 3.138, resets = 33.62 ≥ 31, time = 21.2\n",
      "step =  117500, scores =   70.7 ± 11.8 [   2.0, 118.1], score_ema =   70.5, advantages =  0.083 ± 1.0 [ -6.396,  6.348], abs_actor_obj =  5.807 ± 10.023, critic_obj = 51.504 ± 2.761, resets = 34.27 ≥ 31, time = 21.2\n",
      "step =  120000, scores =   72.1 ± 11.3 [   0.7, 140.3], score_ema =   70.6, advantages =  0.114 ± 1.0 [ -6.706,  6.284], abs_actor_obj =  5.416 ± 9.782, critic_obj = 47.221 ± 4.190, resets = 33.95 ≥ 31, time = 21.2\n",
      "step =  122500, scores =   73.4 ± 10.7 [   1.9, 117.0], score_ema =   70.9, advantages =  0.089 ± 1.0 [ -7.275,  6.465], abs_actor_obj =  5.468 ± 9.658, critic_obj = 43.024 ± 3.304, resets = 33.50 ≥ 32, time = 21.2\n",
      "step =  125000, scores =   74.6 ± 11.3 [   3.1, 107.5], score_ema =   71.3, advantages =  0.058 ± 1.0 [ -7.278,  7.100], abs_actor_obj =  5.605 ± 10.310, critic_obj = 47.111 ± 4.334, resets = 32.77 ≥ 31, time = 21.4\n",
      "step =  127500, scores =   75.5 ± 12.4 [   1.6, 109.3], score_ema =   71.7, advantages =  0.038 ± 1.0 [ -7.056,  6.298], abs_actor_obj =  5.611 ± 11.017, critic_obj = 53.504 ± 7.803, resets = 32.09 ≥ 29, time = 21.4\n",
      "step =  130000, scores =   75.9 ± 12.1 [   2.0, 112.5], score_ema =   72.1, advantages =  0.075 ± 1.0 [ -8.242,  6.787], abs_actor_obj =  5.341 ± 10.375, critic_obj = 48.163 ± 2.134, resets = 31.88 ≥ 30, time = 21.4\n",
      "step =  132500, scores =   75.5 ± 12.0 [   2.0, 128.3], score_ema =   72.5, advantages =  0.035 ± 1.0 [ -7.229,  6.776], abs_actor_obj =  5.550 ± 10.554, critic_obj = 47.334 ± 3.737, resets = 31.92 ≥ 29, time = 21.2\n",
      "step =  135000, scores =   75.7 ± 13.0 [   1.7, 121.6], score_ema =   72.8, advantages =  0.058 ± 1.0 [ -6.893,  6.059], abs_actor_obj =  5.256 ± 11.612, critic_obj = 59.964 ± 8.455, resets = 31.56 ≥ 29, time = 21.2\n",
      "step =  137500, scores =   76.4 ± 12.6 [   2.5, 117.4], score_ema =   73.1, advantages =  0.070 ± 1.0 [ -6.523,  6.171], abs_actor_obj =  5.274 ± 11.463, critic_obj = 57.928 ± 8.325, resets = 31.39 ≥ 30, time = 21.0\n",
      "step =  140000, scores =   75.3 ± 12.4 [   2.4, 110.4], score_ema =   73.4, advantages =  0.003 ± 1.0 [ -7.644,  7.163], abs_actor_obj =  5.541 ± 11.518, critic_obj = 52.625 ± 9.559, resets = 32.08 ≥ 30, time = 21.0\n",
      "step =  142500, scores =   75.1 ± 11.8 [   2.5, 116.3], score_ema =   73.5, advantages =  0.010 ± 1.0 [ -8.662,  6.940], abs_actor_obj =  5.455 ± 10.858, critic_obj = 44.560 ± 5.747, resets = 32.44 ≥ 31, time = 21.2\n",
      "step =  145000, scores =   75.0 ± 11.4 [   2.0, 113.3], score_ema =   73.7, advantages =  0.025 ± 1.0 [ -7.628,  7.487], abs_actor_obj =  5.304 ± 10.256, critic_obj = 40.190 ± 2.162, resets = 32.72 ≥ 30, time = 21.0\n",
      "step =  147500, scores =   75.1 ± 11.5 [   2.5, 122.8], score_ema =   73.8, advantages = -0.001 ± 1.0 [ -8.027,  7.603], abs_actor_obj =  5.394 ± 10.858, critic_obj = 43.090 ± 3.129, resets = 32.47 ≥ 31, time = 20.8\n",
      "step =  150000, scores =   75.6 ± 11.8 [   2.1, 129.0], score_ema =   74.0, advantages =  0.089 ± 1.0 [ -8.151,  8.180], abs_actor_obj =  4.921 ± 9.211, critic_obj = 36.171 ± 2.595, resets = 32.30 ≥ 30, time = 21.0\n",
      "step =  152500, scores =   76.1 ± 13.4 [   1.9, 147.0], score_ema =   74.2, advantages =  0.061 ± 1.0 [ -7.548,  6.859], abs_actor_obj =  4.977 ± 11.385, critic_obj = 52.957 ± 4.244, resets = 31.48 ≥ 29, time = 21.0\n",
      "step =  155000, scores =   77.2 ± 14.1 [   2.1, 120.2], score_ema =   74.5, advantages =  0.009 ± 1.0 [ -6.669,  6.332], abs_actor_obj =  5.617 ± 11.882, critic_obj = 61.949 ± 4.270, resets = 31.00 ≥ 29, time = 20.8\n",
      "step =  157500, scores =   76.1 ± 11.2 [   2.1, 125.8], score_ema =   74.7, advantages = -0.005 ± 1.0 [ -8.047,  7.967], abs_actor_obj =  5.413 ± 10.056, critic_obj = 38.090 ± 4.150, resets = 32.45 ≥ 30, time = 21.2\n",
      "step =  160000, scores =   75.2 ± 10.4 [   2.0, 110.3], score_ema =   74.7, advantages = -0.041 ± 1.0 [ -7.248,  8.027], abs_actor_obj =  5.861 ± 9.005, critic_obj = 32.959 ± 3.642, resets = 33.11 ≥ 31, time = 21.4\n",
      "step =  162500, scores =   75.9 ± 11.6 [   1.9, 125.8], score_ema =   74.8, advantages =  0.032 ± 1.0 [ -7.688,  9.159], abs_actor_obj =  5.195 ± 9.263, critic_obj = 35.791 ± 2.550, resets = 32.66 ≥ 31, time = 21.4\n",
      "step =  165000, scores =   76.9 ± 11.8 [   1.9, 120.4], score_ema =   75.0, advantages =  0.091 ± 1.0 [ -7.202,  7.768], abs_actor_obj =  4.785 ± 9.584, critic_obj = 38.023 ± 3.640, resets = 31.84 ≥ 29, time = 21.2\n",
      "step =  167500, scores =   77.7 ± 11.8 [   2.0, 114.0], score_ema =   75.3, advantages =  0.083 ± 1.0 [ -7.553,  7.579], abs_actor_obj =  4.858 ± 9.986, critic_obj = 40.287 ± 4.886, resets = 31.48 ≥ 30, time = 21.2\n",
      "step =  170000, scores =   77.5 ± 12.1 [   2.0, 118.0], score_ema =   75.5, advantages =  0.047 ± 1.0 [ -7.496,  7.686], abs_actor_obj =  5.027 ± 10.081, critic_obj = 39.634 ± 2.372, resets = 31.58 ≥ 30, time = 21.0\n",
      "step =  172500, scores =   78.9 ± 11.9 [   2.0, 117.2], score_ema =   75.9, advantages =  0.046 ± 1.0 [ -7.463,  8.202], abs_actor_obj =  5.128 ± 10.345, critic_obj = 42.855 ± 6.349, resets = 30.97 ≥ 29, time = 21.2\n",
      "step =  175000, scores =   80.1 ± 13.2 [   3.0, 124.7], score_ema =   76.3, advantages =  0.010 ± 1.0 [ -9.628,  6.967], abs_actor_obj =  5.345 ± 11.404, critic_obj = 53.521 ± 2.561, resets = 30.33 ≥ 28, time = 21.2\n",
      "step =  177500, scores =   80.3 ± 13.1 [   4.1, 130.5], score_ema =   76.7, advantages =  0.019 ± 1.0 [ -7.867,  7.376], abs_actor_obj =  5.323 ± 10.910, critic_obj = 49.286 ± 4.050, resets = 30.45 ≥ 28, time = 21.6\n",
      "step =  180000, scores =   80.3 ± 13.8 [   1.6, 126.7], score_ema =   77.1, advantages = -0.092 ± 1.0 [-10.466,  6.478], abs_actor_obj =  6.239 ± 12.280, critic_obj = 67.404 ± 8.565, resets = 29.92 ≥ 28, time = 21.0\n",
      "step =  182500, scores =   79.5 ± 14.3 [   3.3, 133.6], score_ema =   77.3, advantages =  0.007 ± 1.0 [ -7.420,  6.774], abs_actor_obj =  5.337 ± 11.736, critic_obj = 61.594 ± 9.632, resets = 30.19 ≥ 28, time = 21.6\n",
      "step =  185000, scores =   77.7 ± 13.1 [   1.7, 146.4], score_ema =   77.3, advantages = -0.022 ± 1.0 [ -6.517,  7.176], abs_actor_obj =  5.582 ± 11.344, critic_obj = 53.489 ± 4.025, resets = 31.05 ≥ 29, time = 21.4\n",
      "step =  187500, scores =   78.0 ± 14.1 [   1.0, 143.7], score_ema =   77.4, advantages = -0.077 ± 1.0 [ -5.976,  6.095], abs_actor_obj =  6.122 ± 12.287, critic_obj = 68.480 ± 7.333, resets = 30.16 ≥ 28, time = 21.2\n",
      "step =  190000, scores =   77.5 ± 12.9 [   2.0, 139.3], score_ema =   77.4, advantages =  0.026 ± 1.0 [ -6.233,  6.977], abs_actor_obj =  5.402 ± 10.726, critic_obj = 50.581 ± 8.495, resets = 31.33 ≥ 29, time = 21.0\n",
      "step =  192500, scores =   77.6 ± 13.0 [   2.0, 123.3], score_ema =   77.4, advantages = -0.022 ± 1.0 [ -8.140,  6.421], abs_actor_obj =  6.127 ± 11.147, critic_obj = 56.303 ± 4.890, resets = 31.58 ≥ 29, time = 21.0\n",
      "step =  195000, scores =   76.2 ± 11.6 [   2.0, 119.7], score_ema =   77.3, advantages =  0.055 ± 1.0 [ -7.209,  9.086], abs_actor_obj =  5.031 ± 8.675, critic_obj = 34.510 ± 1.982, resets = 33.02 ≥ 30, time = 21.2\n",
      "step =  197500, scores =   73.8 ± 10.4 [   2.5, 114.6], score_ema =   77.0, advantages = -0.115 ± 1.0 [ -7.502,  8.420], abs_actor_obj =  6.347 ± 8.286, critic_obj = 29.110 ± 1.289, resets = 34.31 ≥ 32, time = 20.8\n",
      "step =  200000, scores =   79.4 ± 12.9 [   1.9, 157.9], score_ema =   77.2, advantages =  0.188 ± 1.0 [ -6.741,  8.635], abs_actor_obj =  4.116 ± 9.251, critic_obj = 41.805 ± 3.297, resets = 31.25 ≥ 29, time = 21.2\n",
      "step =  202500, scores =   70.0 ± 19.3 [   2.6, 173.4], score_ema =   76.5, advantages = -0.451 ± 1.0 [ -6.649,  4.653], abs_actor_obj =  10.901 ± 13.483, critic_obj = 125.800 ± 7.489, resets = 31.69 ≥ 30, time = 20.8\n",
      "step =  205000, scores =   75.7 ± 10.0 [   2.6, 129.3], score_ema =   76.4, advantages =  0.735 ± 1.0 [ -6.660,  8.847], abs_actor_obj =  2.554 ± 5.290, critic_obj = 37.298 ± 6.187, resets = 33.19 ≥ 30, time = 21.2\n",
      "step =  207500, scores =   71.4 ± 10.1 [   1.9,  97.5], score_ema =   75.9, advantages = -0.128 ± 1.0 [ -5.227,  8.070], abs_actor_obj =  6.774 ± 8.603, critic_obj = 29.697 ± 1.140, resets = 36.03 ≥ 34, time = 21.2\n",
      "step =  210000, scores =   74.3 ±  9.9 [   2.5, 127.0], score_ema =   75.7, advantages = -0.019 ± 1.0 [ -7.489,  8.552], abs_actor_obj =  5.593 ± 8.776, critic_obj = 30.278 ± 0.918, resets = 34.16 ≥ 33, time = 21.2\n",
      "step =  212500, scores =   75.8 ± 11.8 [   1.5, 109.5], score_ema =   75.7, advantages =  0.033 ± 1.0 [ -7.160,  7.533], abs_actor_obj =  5.316 ± 10.161, critic_obj = 40.177 ± 2.480, resets = 32.30 ≥ 31, time = 22.0\n",
      "step =  215000, scores =   76.4 ± 10.5 [   2.9, 111.3], score_ema =   75.8, advantages =  0.083 ± 1.0 [ -7.351,  8.189], abs_actor_obj =  4.701 ± 9.425, critic_obj = 35.174 ± 3.938, resets = 31.95 ≥ 30, time = 21.2\n",
      "step =  217500, scores =   76.9 ± 11.6 [   2.5, 121.5], score_ema =   75.9, advantages =  0.057 ± 1.0 [ -8.219,  8.174], abs_actor_obj =  4.831 ± 9.086, critic_obj = 33.199 ± 1.881, resets = 32.02 ≥ 30, time = 21.4\n",
      "step =  220000, scores =   78.4 ± 12.0 [   2.1, 121.1], score_ema =   76.2, advantages =  0.079 ± 1.0 [ -6.540,  8.281], abs_actor_obj =  4.794 ± 9.453, critic_obj = 38.211 ± 1.913, resets = 31.41 ≥ 29, time = 21.2\n",
      "step =  222500, scores =   79.0 ± 12.4 [   3.1, 145.1], score_ema =   76.4, advantages =  0.009 ± 1.0 [ -6.574,  8.572], abs_actor_obj =  5.486 ± 10.167, critic_obj = 44.536 ± 3.761, resets = 31.08 ≥ 28, time = 21.4\n",
      "step =  225000, scores =   77.9 ± 11.5 [   2.6, 139.1], score_ema =   76.6, advantages = -0.020 ± 1.0 [ -7.935,  8.895], abs_actor_obj =  5.319 ± 9.621, critic_obj = 36.108 ± 4.047, resets = 31.91 ≥ 30, time = 21.2\n",
      "step =  227500, scores =   75.7 ± 10.9 [   2.0, 135.3], score_ema =   76.5, advantages = -0.092 ± 1.0 [ -7.181,  8.947], abs_actor_obj =  5.882 ± 8.383, critic_obj = 28.735 ± 0.850, resets = 33.22 ≥ 31, time = 21.4\n",
      "step =  230000, scores =   75.9 ± 11.0 [   2.1, 118.3], score_ema =   76.4, advantages =  0.037 ± 1.0 [ -6.559,  8.575], abs_actor_obj =  4.824 ± 8.457, critic_obj = 30.195 ± 2.116, resets = 32.92 ≥ 31, time = 21.2\n",
      "step =  232500, scores =   78.0 ± 11.0 [   4.6, 130.3], score_ema =   76.6, advantages =  0.166 ± 1.0 [ -8.610,  9.547], abs_actor_obj =  3.861 ± 7.608, critic_obj = 29.708 ± 2.368, resets = 32.20 ≥ 30, time = 21.4\n",
      "step =  235000, scores =   78.7 ± 11.6 [   2.0, 123.5], score_ema =   76.8, advantages =  0.037 ± 1.0 [ -8.181,  8.776], abs_actor_obj =  4.624 ± 9.700, critic_obj = 35.635 ± 5.239, resets = 31.44 ≥ 30, time = 21.4\n",
      "step =  237500, scores =   79.2 ± 12.4 [   2.0, 145.3], score_ema =   77.0, advantages =  0.043 ± 1.0 [ -8.136,  9.103], abs_actor_obj =  4.553 ± 9.184, critic_obj = 33.263 ± 4.315, resets = 31.25 ≥ 29, time = 21.6\n",
      "step =  240000, scores =   78.9 ± 12.7 [   3.1, 129.7], score_ema =   77.2, advantages = -0.129 ± 1.0 [ -7.273,  7.359], abs_actor_obj =  5.769 ± 12.505, critic_obj = 53.064 ± 9.731, resets = 30.34 ≥ 28, time = 21.4\n",
      "step =  242500, scores =   80.7 ± 13.0 [   2.1, 123.3], score_ema =   77.6, advantages =  0.125 ± 1.0 [ -7.053,  6.822], abs_actor_obj =  3.983 ± 11.821, critic_obj = 51.918 ± 9.744, resets = 29.83 ≥ 28, time = 21.6\n",
      "step =  245000, scores =   81.1 ± 13.2 [   2.5, 156.6], score_ema =   77.9, advantages =  0.047 ± 1.0 [ -6.680,  7.468], abs_actor_obj =  4.659 ± 11.538, critic_obj = 49.206 ± 4.071, resets = 29.61 ≥ 28, time = 21.6\n",
      "step =  247500, scores =   80.6 ± 14.3 [   2.5, 130.9], score_ema =   78.2, advantages = -0.049 ± 1.0 [ -6.278,  6.380], abs_actor_obj =  5.555 ± 12.365, critic_obj = 61.473 ± 5.725, resets = 29.27 ≥ 27, time = 21.6\n",
      "step =  250000, scores =   81.8 ± 15.3 [   2.5, 158.1], score_ema =   78.6, advantages =  0.104 ± 1.0 [ -5.862,  6.909], abs_actor_obj =  4.899 ± 11.178, critic_obj = 63.034 ± 5.299, resets = 28.75 ≥ 26, time = 21.8\n",
      "step =  252500, scores =   81.1 ± 13.9 [   1.9, 133.5], score_ema =   78.8, advantages =  0.006 ± 1.0 [ -5.781,  6.649], abs_actor_obj =  5.408 ± 11.339, critic_obj = 56.017 ± 8.891, resets = 29.48 ≥ 27, time = 21.8\n",
      "step =  255000, scores =   80.2 ± 11.9 [   4.0, 165.7], score_ema =   79.0, advantages = -0.079 ± 1.0 [ -6.759,  8.868], abs_actor_obj =  6.024 ± 10.066, critic_obj = 39.888 ± 4.690, resets = 31.17 ≥ 29, time = 22.6\n",
      "step =  257500, scores =   80.2 ± 11.6 [   3.0, 137.2], score_ema =   79.1, advantages =  0.043 ± 1.0 [ -7.531,  8.303], abs_actor_obj =  5.073 ± 8.699, critic_obj = 35.479 ± 4.112, resets = 32.12 ≥ 30, time = 21.6\n",
      "step =  260000, scores =   81.3 ± 12.0 [   2.5, 135.7], score_ema =   79.3, advantages =  0.085 ± 1.0 [ -7.422,  8.262], abs_actor_obj =  4.550 ± 9.418, critic_obj = 38.904 ± 6.871, resets = 31.83 ≥ 30, time = 21.6\n",
      "step =  262500, scores =   80.9 ± 12.8 [   2.1, 154.0], score_ema =   79.5, advantages = -0.028 ± 1.0 [ -6.909,  8.044], abs_actor_obj =  5.184 ± 10.718, critic_obj = 44.725 ± 4.494, resets = 31.55 ≥ 30, time = 21.6\n",
      "step =  265000, scores =   82.7 ± 12.8 [   1.9, 124.1], score_ema =   79.8, advantages =  0.090 ± 1.0 [ -7.353,  8.162], abs_actor_obj =  4.510 ± 9.024, critic_obj = 36.569 ± 1.431, resets = 31.27 ≥ 30, time = 21.6\n",
      "step =  267500, scores =   84.5 ± 13.5 [   2.0, 145.8], score_ema =   80.3, advantages =  0.083 ± 1.0 [ -7.325,  7.643], abs_actor_obj =  4.203 ± 10.878, critic_obj = 47.576 ± 10.439, resets = 29.89 ≥ 27, time = 21.6\n",
      "step =  270000, scores =   85.0 ± 16.2 [   1.9, 165.7], score_ema =   80.7, advantages =  0.011 ± 1.0 [ -5.539,  6.820], abs_actor_obj =  4.862 ± 12.167, critic_obj = 68.575 ± 8.262, resets = 28.41 ≥ 26, time = 21.4\n",
      "step =  272500, scores =   84.7 ± 18.3 [  -0.4, 146.5], score_ema =   81.1, advantages =  0.017 ± 1.0 [ -4.396,  5.362], abs_actor_obj =  5.757 ± 12.162, critic_obj = 98.461 ± 8.564, resets = 27.11 ≥ 24, time = 21.8\n",
      "step =  275000, scores =   84.9 ± 18.5 [   2.6, 148.3], score_ema =   81.5, advantages =  0.038 ± 1.0 [ -4.247,  5.378], abs_actor_obj =  5.851 ± 11.635, critic_obj = 96.352 ± 7.846, resets = 27.33 ≥ 24, time = 21.6\n",
      "step =  277500, scores =   82.8 ± 13.5 [   1.8, 152.5], score_ema =   81.6, advantages = -0.047 ± 1.0 [ -5.296,  7.205], abs_actor_obj =  6.003 ± 10.575, critic_obj = 53.181 ± 2.183, resets = 29.62 ≥ 28, time = 21.4\n",
      "step =  280000, scores =   81.0 ± 12.3 [   2.5, 152.8], score_ema =   81.6, advantages = -0.139 ± 1.0 [ -8.963,  8.248], abs_actor_obj =  6.758 ± 9.337, critic_obj = 36.566 ± 4.030, resets = 31.50 ≥ 29, time = 21.4\n",
      "step =  282500, scores =   79.7 ± 11.4 [  -0.3, 115.6], score_ema =   81.4, advantages = -0.188 ± 1.0 [ -8.335,  8.206], abs_actor_obj =  7.022 ± 8.910, critic_obj = 30.737 ± 2.794, resets = 32.42 ≥ 31, time = 21.4\n",
      "step =  285000, scores =   81.6 ± 11.9 [   2.0, 117.6], score_ema =   81.4, advantages =  0.034 ± 1.0 [ -7.772,  8.565], abs_actor_obj =  4.636 ± 8.844, critic_obj = 33.127 ± 3.598, resets = 31.20 ≥ 29, time = 21.4\n",
      "step =  287500, scores =   83.4 ± 14.4 [   2.0, 164.5], score_ema =   81.6, advantages =  0.072 ± 1.0 [ -6.713,  7.641], abs_actor_obj =  4.139 ± 11.180, critic_obj = 50.312 ± 6.111, resets = 29.52 ≥ 27, time = 21.6\n",
      "step =  290000, scores =   82.3 ± 12.9 [   1.9, 138.6], score_ema =   81.7, advantages = -0.054 ± 1.0 [ -7.289,  7.701], abs_actor_obj =  5.302 ± 10.993, critic_obj = 43.385 ± 2.190, resets = 29.94 ≥ 27, time = 21.8\n",
      "step =  292500, scores =   82.1 ± 12.3 [   3.0, 128.5], score_ema =   81.7, advantages = -0.002 ± 1.0 [ -7.471,  7.740], abs_actor_obj =  4.989 ± 9.980, critic_obj = 37.257 ± 3.642, resets = 30.20 ≥ 28, time = 22.2\n",
      "step =  295000, scores =   84.3 ± 15.8 [   3.1, 141.0], score_ema =   82.0, advantages =  0.062 ± 1.0 [ -5.347,  6.334], abs_actor_obj =  4.542 ± 12.159, critic_obj = 65.260 ± 8.255, resets = 28.30 ≥ 26, time = 21.2\n",
      "step =  297500, scores =   85.2 ± 16.3 [   1.4, 155.2], score_ema =   82.3, advantages =  0.042 ± 1.0 [ -5.287,  6.651], abs_actor_obj =  5.125 ± 11.926, critic_obj = 73.532 ± 10.744, resets = 27.27 ≥ 25, time = 22.0\n",
      "step =  300000, scores =   85.1 ± 15.8 [   2.1, 146.6], score_ema =   82.6, advantages =  0.007 ± 1.0 [ -5.366,  6.416], abs_actor_obj =  5.365 ± 11.544, critic_obj = 63.581 ± 11.241, resets = 27.66 ≥ 24, time = 22.2\n",
      "step =  302500, scores =   85.0 ± 14.1 [   2.1, 151.6], score_ema =   82.8, advantages = -0.015 ± 1.0 [ -6.168,  7.517], abs_actor_obj =  5.390 ± 10.931, critic_obj = 51.906 ± 3.324, resets = 28.27 ≥ 26, time = 22.4\n",
      "step =  305000, scores =   84.6 ± 14.4 [   2.0, 154.4], score_ema =   83.0, advantages = -0.026 ± 1.0 [ -6.338,  8.105], abs_actor_obj =  5.304 ± 10.568, critic_obj = 46.500 ± 3.055, resets = 28.88 ≥ 26, time = 21.6\n",
      "step =  307500, scores =   83.3 ± 14.3 [   1.8, 141.4], score_ema =   83.0, advantages = -0.124 ± 1.0 [ -6.528,  7.666], abs_actor_obj =  6.126 ± 11.021, critic_obj = 45.231 ± 5.508, resets = 29.39 ≥ 27, time = 22.0\n",
      "step =  310000, scores =   81.8 ± 13.4 [   2.5, 141.0], score_ema =   82.9, advantages = -0.154 ± 1.0 [ -6.360,  7.631], abs_actor_obj =  6.767 ± 11.276, critic_obj = 48.839 ± 8.468, resets = 29.97 ≥ 28, time = 21.4\n",
      "step =  312500, scores =   85.0 ± 13.6 [   2.1, 146.3], score_ema =   83.1, advantages =  0.182 ± 1.0 [ -6.709,  8.117], abs_actor_obj =  4.048 ± 9.479, critic_obj = 43.892 ± 3.685, resets = 29.80 ≥ 27, time = 20.8\n",
      "step =  315000, scores =   84.5 ± 13.7 [   3.5, 173.3], score_ema =   83.3, advantages =  0.085 ± 1.0 [ -6.757,  8.354], abs_actor_obj =  4.398 ± 9.140, critic_obj = 40.504 ± 4.525, resets = 29.78 ≥ 27, time = 21.4\n",
      "step =  317500, scores =   85.0 ± 12.5 [   4.0, 122.3], score_ema =   83.4, advantages =  0.039 ± 1.0 [ -7.135,  8.617], abs_actor_obj =  4.621 ± 9.259, critic_obj = 37.267 ± 5.271, resets = 29.69 ≥ 27, time = 21.8\n",
      "step =  320000, scores =   85.9 ± 13.3 [   2.1, 164.2], score_ema =   83.7, advantages =  0.069 ± 1.0 [ -7.115,  8.964], abs_actor_obj =  4.335 ± 9.786, critic_obj = 39.668 ± 4.288, resets = 29.73 ≥ 27, time = 21.6\n",
      "step =  322500, scores =   85.8 ± 13.4 [   0.7, 130.4], score_ema =   83.9, advantages = -0.003 ± 1.0 [ -6.755,  8.057], abs_actor_obj =  4.776 ± 10.459, critic_obj = 42.374 ± 7.781, resets = 29.52 ≥ 26, time = 21.6\n",
      "step =  325000, scores =   87.0 ± 13.3 [   2.0, 149.1], score_ema =   84.2, advantages =  0.076 ± 1.0 [ -6.641,  8.690], abs_actor_obj =  4.331 ± 9.875, critic_obj = 40.818 ± 3.787, resets = 29.08 ≥ 27, time = 21.6\n",
      "step =  327500, scores =   87.8 ± 14.7 [   2.0, 164.4], score_ema =   84.6, advantages =  0.077 ± 1.0 [ -6.454,  7.570], abs_actor_obj =  4.441 ± 10.665, critic_obj = 48.237 ± 5.652, resets = 28.47 ≥ 26, time = 21.6\n",
      "step =  330000, scores =   88.3 ± 15.9 [   1.9, 153.3], score_ema =   84.9, advantages =  0.041 ± 1.0 [ -6.033,  7.400], abs_actor_obj =  4.600 ± 11.480, critic_obj = 55.307 ± 7.878, resets = 28.20 ≥ 26, time = 21.6\n",
      "step =  332500, scores =   89.8 ± 14.8 [   3.1, 171.5], score_ema =   85.4, advantages =  0.045 ± 1.0 [ -6.098,  7.003], abs_actor_obj =  4.881 ± 11.273, critic_obj = 58.444 ± 9.030, resets = 27.66 ≥ 25, time = 21.6\n",
      "step =  335000, scores =   88.9 ± 16.2 [   2.3, 148.4], score_ema =   85.8, advantages =  0.013 ± 1.0 [ -5.939,  7.492], abs_actor_obj =  5.405 ± 10.656, critic_obj = 59.383 ± 2.740, resets = 27.78 ≥ 24, time = 21.4\n",
      "step =  337500, scores =   87.7 ± 15.5 [   2.1, 163.6], score_ema =   86.0, advantages = -0.083 ± 1.0 [ -5.653,  7.152], abs_actor_obj =  6.248 ± 10.930, critic_obj = 58.626 ± 2.747, resets = 27.91 ≥ 25, time = 22.0\n",
      "step =  340000, scores =   84.5 ± 14.2 [   4.1, 158.5], score_ema =   85.8, advantages = -0.165 ± 1.0 [ -5.506,  8.365], abs_actor_obj =  7.206 ± 10.306, critic_obj = 47.296 ± 4.464, resets = 29.50 ≥ 26, time = 21.8\n",
      "step =  342500, scores =   86.3 ± 13.6 [   2.0, 142.6], score_ema =   85.9, advantages =  0.103 ± 1.0 [ -6.055,  8.328], abs_actor_obj =  4.621 ± 9.128, critic_obj = 42.267 ± 4.254, resets = 29.05 ≥ 27, time = 21.6\n",
      "step =  345000, scores =   88.9 ± 15.0 [   2.0, 146.6], score_ema =   86.2, advantages =  0.193 ± 1.0 [ -5.882,  7.682], abs_actor_obj =  4.100 ± 9.720, critic_obj = 53.246 ± 1.616, resets = 27.98 ≥ 25, time = 21.6\n",
      "step =  347500, scores =   88.7 ± 15.8 [   1.8, 186.1], score_ema =   86.4, advantages =  0.059 ± 1.0 [ -5.301,  8.064], abs_actor_obj =  4.869 ± 10.273, critic_obj = 56.598 ± 3.358, resets = 27.95 ≥ 24, time = 21.6\n",
      "step =  350000, scores =   86.9 ± 13.0 [   2.0, 165.9], score_ema =   86.5, advantages = -0.017 ± 1.0 [ -6.751,  8.269], abs_actor_obj =  5.267 ± 9.204, critic_obj = 39.929 ± 1.996, resets = 29.25 ≥ 27, time = 21.6\n",
      "step =  352500, scores =   87.7 ± 13.0 [   2.9, 151.8], score_ema =   86.6, advantages =  0.097 ± 1.0 [ -6.672,  8.996], abs_actor_obj =  4.334 ± 9.044, critic_obj = 39.633 ± 4.284, resets = 29.59 ≥ 28, time = 21.3\n",
      "step =  355000, scores =   89.8 ± 14.6 [   1.9, 126.4], score_ema =   86.9, advantages =  0.124 ± 1.0 [ -7.239,  7.502], abs_actor_obj =  4.212 ± 10.054, critic_obj = 45.633 ± 6.844, resets = 28.77 ≥ 27, time = 20.9\n",
      "step =  357500, scores =   90.3 ± 13.8 [   2.1, 144.6], score_ema =   87.3, advantages =  0.102 ± 1.0 [ -7.588,  8.249], abs_actor_obj =  4.366 ± 9.533, critic_obj = 41.369 ± 6.928, resets = 29.22 ≥ 27, time = 21.8\n",
      "step =  360000, scores =   90.9 ± 13.8 [   2.0, 137.6], score_ema =   87.6, advantages =  0.069 ± 1.0 [ -7.240,  8.367], abs_actor_obj =  4.617 ± 9.993, critic_obj = 44.586 ± 5.237, resets = 29.02 ≥ 26, time = 21.6\n",
      "step =  362500, scores =   90.9 ± 14.6 [   4.2, 158.5], score_ema =   87.9, advantages =  0.071 ± 1.0 [ -7.294,  8.040], abs_actor_obj =  4.805 ± 9.588, critic_obj = 44.498 ± 4.180, resets = 29.69 ≥ 28, time = 21.2\n",
      "step =  365000, scores =   91.3 ± 13.2 [   2.0, 149.4], score_ema =   88.3, advantages =  0.059 ± 1.0 [ -6.652,  9.121], abs_actor_obj =  4.724 ± 8.291, critic_obj = 36.916 ± 2.572, resets = 29.44 ≥ 27, time = 21.4\n",
      "step =  367500, scores =   92.1 ± 14.6 [   3.4, 161.8], score_ema =   88.7, advantages =  0.022 ± 1.0 [ -6.178,  7.622], abs_actor_obj =  5.060 ± 9.881, critic_obj = 47.832 ± 5.434, resets = 28.73 ≥ 27, time = 21.6\n",
      "step =  370000, scores =   92.3 ± 15.6 [   2.7, 133.6], score_ema =   89.0, advantages = -0.012 ± 1.0 [ -6.663,  7.224], abs_actor_obj =  5.298 ± 11.160, critic_obj = 56.181 ± 3.892, resets = 28.75 ≥ 26, time = 21.2\n",
      "step =  372500, scores =   88.7 ± 16.4 [   1.7, 141.4], score_ema =   89.0, advantages = -0.201 ± 1.0 [ -6.052,  7.310], abs_actor_obj =  7.259 ± 12.177, critic_obj = 64.910 ± 4.760, resets = 29.34 ≥ 26, time = 21.4\n",
      "step =  375000, scores =   85.8 ± 13.6 [   2.1, 125.8], score_ema =   88.7, advantages = -0.101 ± 1.0 [ -6.584,  7.516], abs_actor_obj =  6.203 ± 11.060, critic_obj = 50.399 ± 5.770, resets = 31.47 ≥ 30, time = 21.4\n",
      "step =  377500, scores =   77.8 ± 11.2 [   2.2, 104.3], score_ema =   87.6, advantages = -0.340 ± 1.0 [ -6.209,  7.742], abs_actor_obj =  8.999 ± 9.746, critic_obj = 36.266 ± 2.167, resets = 35.53 ≥ 34, time = 22.6\n",
      "step =  380000, scores =   84.7 ± 13.0 [   2.7, 136.0], score_ema =   87.3, advantages =  0.116 ± 1.0 [ -6.576,  8.504], abs_actor_obj =  4.250 ± 8.361, critic_obj = 38.563 ± 2.915, resets = 31.03 ≥ 29, time = 22.6\n",
      "step =  382500, scores =   88.0 ± 19.1 [   2.2, 160.8], score_ema =   87.4, advantages =  0.032 ± 1.0 [ -4.979,  5.912], abs_actor_obj =  4.990 ± 12.425, critic_obj = 85.547 ± 10.381, resets = 26.94 ≥ 24, time = 23.6\n",
      "step =  385000, scores =   89.2 ± 16.1 [  -0.8, 149.3], score_ema =   87.5, advantages =  0.090 ± 1.0 [ -5.828,  6.471], abs_actor_obj =  4.738 ± 11.396, critic_obj = 66.267 ± 7.239, resets = 27.30 ≥ 26, time = 22.6\n",
      "step =  387500, scores =   87.7 ± 14.2 [   2.5, 142.8], score_ema =   87.6, advantages =  0.021 ± 1.0 [ -7.309,  7.632], abs_actor_obj =  5.139 ± 9.942, critic_obj = 45.541 ± 3.431, resets = 29.84 ≥ 28, time = 21.6\n",
      "step =  390000, scores =   88.0 ± 12.7 [   2.4, 136.7], score_ema =   87.6, advantages =  0.010 ± 1.0 [ -6.348,  8.733], abs_actor_obj =  5.252 ± 8.330, critic_obj = 36.710 ± 2.573, resets = 30.14 ≥ 28, time = 21.6\n",
      "step =  392500, scores =   89.5 ± 14.6 [   2.5, 150.5], score_ema =   87.8, advantages =  0.108 ± 1.0 [ -6.219,  7.841], abs_actor_obj =  4.393 ± 9.655, critic_obj = 45.976 ± 5.347, resets = 29.44 ≥ 27, time = 22.5\n",
      "step =  395000, scores =   90.2 ± 14.9 [   2.0, 162.1], score_ema =   88.0, advantages =  0.046 ± 1.0 [ -6.660,  7.615], abs_actor_obj =  4.554 ± 10.346, critic_obj = 46.617 ± 6.741, resets = 28.56 ≥ 27, time = 21.6\n",
      "step =  397500, scores =   88.8 ± 13.9 [   2.1, 144.0], score_ema =   88.1, advantages = -0.050 ± 1.0 [ -6.777,  7.742], abs_actor_obj =  5.378 ± 10.185, critic_obj = 42.759 ± 5.529, resets = 28.94 ≥ 26, time = 21.4\n",
      "step =  400000, scores =   90.1 ± 13.9 [   2.0, 135.3], score_ema =   88.3, advantages =  0.112 ± 1.0 [ -7.333,  8.633], abs_actor_obj =  4.211 ± 8.172, critic_obj = 36.652 ± 2.343, resets = 29.05 ≥ 27, time = 21.6\n",
      "step =  402500, scores =   91.3 ± 14.7 [   2.7, 154.6], score_ema =   88.6, advantages =  0.055 ± 1.0 [ -6.472,  8.209], abs_actor_obj =  4.574 ± 10.036, critic_obj = 45.622 ± 2.759, resets = 28.25 ≥ 26, time = 21.8\n",
      "step =  405000, scores =   91.8 ± 15.6 [   2.1, 160.3], score_ema =   88.9, advantages = -0.005 ± 1.0 [ -6.213,  7.591], abs_actor_obj =  4.889 ± 10.963, critic_obj = 52.500 ± 7.192, resets = 27.75 ≥ 26, time = 22.2\n",
      "step =  407500, scores =   91.6 ± 15.4 [   2.7, 144.2], score_ema =   89.2, advantages =  0.010 ± 1.0 [ -6.065,  7.660], abs_actor_obj =  4.796 ± 10.833, critic_obj = 51.302 ± 7.729, resets = 27.59 ≥ 26, time = 21.8\n",
      "step =  410000, scores =   91.0 ± 14.4 [   1.6, 157.8], score_ema =   89.4, advantages =  0.034 ± 1.0 [ -6.434,  8.617], abs_actor_obj =  4.665 ± 9.193, critic_obj = 41.557 ± 5.759, resets = 28.38 ≥ 26, time = 22.8\n",
      "step =  412500, scores =   90.2 ± 14.5 [   3.0, 138.6], score_ema =   89.5, advantages = -0.025 ± 1.0 [ -6.916,  8.549], abs_actor_obj =  5.083 ± 9.873, critic_obj = 41.078 ± 3.273, resets = 28.53 ≥ 26, time = 21.0\n",
      "step =  415000, scores =   90.1 ± 13.7 [   2.0, 153.9], score_ema =   89.5, advantages = -0.014 ± 1.0 [ -6.591,  8.593], abs_actor_obj =  4.961 ± 9.326, critic_obj = 37.647 ± 5.394, resets = 28.95 ≥ 27, time = 22.6\n",
      "step =  417500, scores =   89.4 ± 13.1 [   2.0, 143.0], score_ema =   89.5, advantages = -0.033 ± 1.0 [ -7.436,  8.577], abs_actor_obj =  4.988 ± 9.182, critic_obj = 35.654 ± 2.867, resets = 29.75 ≥ 27, time = 21.7\n",
      "step =  420000, scores =   90.1 ± 13.6 [   2.5, 144.9], score_ema =   89.6, advantages =  0.047 ± 1.0 [ -7.334,  8.730], abs_actor_obj =  4.248 ± 9.160, critic_obj = 36.920 ± 3.842, resets = 29.03 ≥ 26, time = 21.9\n",
      "step =  422500, scores =   88.6 ± 14.0 [   2.0, 140.9], score_ema =   89.5, advantages = -0.095 ± 1.0 [ -6.563,  7.813], abs_actor_obj =  5.531 ± 10.779, critic_obj = 44.523 ± 4.442, resets = 28.45 ≥ 26, time = 22.1\n",
      "step =  425000, scores =   88.2 ± 14.0 [   3.4, 140.1], score_ema =   89.4, advantages =  0.010 ± 1.0 [ -6.288,  8.353], abs_actor_obj =  4.741 ± 9.666, critic_obj = 39.947 ± 3.555, resets = 28.75 ≥ 27, time = 22.5\n",
      "step =  427500, scores =   87.5 ± 13.4 [   1.8, 134.8], score_ema =   89.2, advantages =  0.027 ± 1.0 [ -6.850,  8.631], abs_actor_obj =  4.438 ± 9.713, critic_obj = 39.003 ± 2.338, resets = 29.33 ≥ 28, time = 22.3\n",
      "step =  430000, scores =   87.7 ± 12.8 [   2.2, 142.4], score_ema =   89.0, advantages =  0.048 ± 1.0 [ -6.006,  9.250], abs_actor_obj =  4.259 ± 8.572, critic_obj = 33.967 ± 2.503, resets = 29.56 ≥ 27, time = 21.8\n",
      "step =  432500, scores =   88.3 ± 13.7 [   2.5, 175.5], score_ema =   89.0, advantages = -0.017 ± 1.0 [ -7.167,  8.299], abs_actor_obj =  4.728 ± 10.574, critic_obj = 42.965 ± 2.265, resets = 28.88 ≥ 27, time = 22.5\n",
      "step =  435000, scores =   88.8 ± 13.5 [   2.0, 126.1], score_ema =   88.9, advantages =  0.040 ± 1.0 [ -7.063,  8.378], abs_actor_obj =  4.377 ± 9.740, critic_obj = 38.709 ± 5.940, resets = 29.09 ≥ 27, time = 20.6\n",
      "step =  437500, scores =   88.0 ± 12.7 [   2.5, 132.5], score_ema =   88.8, advantages =  0.005 ± 1.0 [ -7.086,  9.027], abs_actor_obj =  4.535 ± 8.858, critic_obj = 33.883 ± 4.159, resets = 29.70 ≥ 27, time = 21.9\n",
      "step =  440000, scores =   88.0 ± 13.6 [   6.0, 163.7], score_ema =   88.8, advantages =  0.034 ± 1.0 [ -7.188,  8.385], abs_actor_obj =  4.306 ± 9.514, critic_obj = 40.476 ± 4.703, resets = 29.28 ≥ 27, time = 22.6\n",
      "step =  442500, scores =   88.9 ± 14.5 [   2.4, 135.5], score_ema =   88.8, advantages =  0.014 ± 1.0 [ -6.632,  8.734], abs_actor_obj =  4.571 ± 10.241, critic_obj = 42.195 ± 8.049, resets = 28.48 ≥ 25, time = 23.4\n",
      "step =  445000, scores =   90.1 ± 14.8 [   2.9, 155.2], score_ema =   88.9, advantages =  0.019 ± 1.0 [ -6.259,  7.918], abs_actor_obj =  4.671 ± 10.401, critic_obj = 46.639 ± 3.040, resets = 27.44 ≥ 25, time = 23.0\n",
      "step =  447500, scores =   88.6 ± 13.5 [   3.0, 148.2], score_ema =   88.9, advantages = -0.046 ± 1.0 [ -6.834,  8.695], abs_actor_obj =  5.069 ± 9.632, critic_obj = 37.863 ± 3.574, resets = 28.81 ≥ 26, time = 22.0\n",
      "step =  450000, scores =   87.9 ± 13.4 [   2.9, 149.0], score_ema =   88.8, advantages = -0.031 ± 1.0 [ -6.595,  9.044], abs_actor_obj =  4.906 ± 8.994, critic_obj = 35.195 ± 1.433, resets = 29.39 ≥ 27, time = 22.0\n",
      "step =  452500, scores =   87.2 ± 12.1 [   2.6, 126.4], score_ema =   88.6, advantages = -0.006 ± 1.0 [ -6.925,  9.811], abs_actor_obj =  4.514 ± 7.362, critic_obj = 28.505 ± 1.107, resets = 30.73 ≥ 29, time = 20.8\n",
      "step =  455000, scores =   88.6 ± 13.1 [   1.9, 125.7], score_ema =   88.6, advantages =  0.021 ± 1.0 [ -7.218,  9.116], abs_actor_obj =  4.387 ± 8.890, critic_obj = 32.736 ± 2.395, resets = 29.78 ≥ 28, time = 21.3\n",
      "step =  457500, scores =   91.3 ± 14.5 [   2.0, 149.4], score_ema =   88.9, advantages =  0.088 ± 1.0 [ -6.909,  8.349], abs_actor_obj =  3.978 ± 10.509, critic_obj = 44.515 ± 3.704, resets = 28.00 ≥ 25, time = 22.8\n",
      "step =  460000, scores =   91.6 ± 13.6 [   0.8, 149.0], score_ema =   89.2, advantages =  0.026 ± 1.0 [ -6.239,  8.974], abs_actor_obj =  4.455 ± 9.889, critic_obj = 39.488 ± 5.156, resets = 27.94 ≥ 26, time = 20.9\n",
      "step =  462500, scores =   91.9 ± 15.1 [   3.4, 157.1], score_ema =   89.4, advantages = -0.011 ± 1.0 [ -6.834,  8.922], abs_actor_obj =  4.752 ± 10.132, critic_obj = 40.334 ± 5.563, resets = 27.78 ≥ 25, time = 22.6\n",
      "step =  465000, scores =   88.5 ± 14.5 [   1.9, 142.9], score_ema =   89.3, advantages = -0.268 ± 1.0 [ -6.497,  8.429], abs_actor_obj =  7.877 ± 10.748, critic_obj = 41.588 ± 3.915, resets = 28.81 ≥ 26, time = 22.8\n",
      "step =  467500, scores =   91.2 ± 14.5 [   1.9, 151.6], score_ema =   89.5, advantages =  0.143 ± 1.0 [ -6.770,  8.466], abs_actor_obj =  4.008 ± 9.285, critic_obj = 41.534 ± 1.906, resets = 28.58 ≥ 26, time = 22.4\n",
      "step =  470000, scores =   91.6 ± 14.6 [   2.4, 204.8], score_ema =   89.7, advantages =  0.084 ± 1.0 [ -6.881,  9.314], abs_actor_obj =  4.090 ± 9.231, critic_obj = 39.310 ± 5.568, resets = 28.48 ≥ 27, time = 20.8\n",
      "step =  472500, scores =   90.5 ± 13.2 [   2.0, 144.5], score_ema =   89.8, advantages = -0.056 ± 1.0 [ -6.786,  9.426], abs_actor_obj =  5.092 ± 8.193, critic_obj = 31.393 ± 1.423, resets = 28.94 ≥ 26, time = 21.8\n",
      "step =  475000, scores =   90.6 ± 14.9 [   2.9, 141.8], score_ema =   89.9, advantages = -0.048 ± 1.0 [ -6.466,  8.755], abs_actor_obj =  4.956 ± 10.041, critic_obj = 38.916 ± 2.447, resets = 27.95 ≥ 26, time = 23.0\n",
      "step =  477500, scores =   93.2 ± 15.8 [   1.8, 161.8], score_ema =   90.2, advantages =  0.125 ± 1.0 [ -6.244,  8.030], abs_actor_obj =  3.829 ± 10.544, critic_obj = 49.712 ± 4.497, resets = 26.89 ≥ 25, time = 22.6\n",
      "step =  480000, scores =   90.7 ± 13.6 [   1.9, 140.7], score_ema =   90.3, advantages = -0.105 ± 1.0 [ -7.364,  9.275], abs_actor_obj =  5.561 ± 9.373, critic_obj = 35.378 ± 1.765, resets = 28.83 ≥ 26, time = 21.8\n",
      "step =  482500, scores =   90.7 ± 13.7 [   2.0, 152.0], score_ema =   90.3, advantages =  0.021 ± 1.0 [ -7.314,  9.512], abs_actor_obj =  4.293 ± 8.941, critic_obj = 33.995 ± 2.081, resets = 29.28 ≥ 27, time = 20.6\n",
      "step =  485000, scores =   91.4 ± 13.4 [   3.4, 135.4], score_ema =   90.4, advantages =  0.077 ± 1.0 [ -7.643,  9.652], abs_actor_obj =  4.001 ± 8.759, critic_obj = 34.323 ± 4.446, resets = 29.25 ≥ 27, time = 21.8\n",
      "step =  487500, scores =   94.2 ± 15.5 [   2.6, 161.6], score_ema =   90.8, advantages =  0.084 ± 1.0 [ -6.615,  8.782], abs_actor_obj =  4.136 ± 10.019, critic_obj = 44.565 ± 6.276, resets = 27.19 ≥ 23, time = 22.1\n",
      "step =  490000, scores =   94.0 ± 15.6 [   1.7, 142.1], score_ema =   91.1, advantages =  0.000 ± 1.0 [ -6.009,  8.832], abs_actor_obj =  4.874 ± 10.299, critic_obj = 46.517 ± 6.504, resets = 26.80 ≥ 24, time = 22.6\n",
      "step =  492500, scores =   92.7 ± 14.5 [   1.9, 156.3], score_ema =   91.3, advantages = -0.068 ± 1.0 [ -5.834,  9.066], abs_actor_obj =  5.538 ± 10.046, critic_obj = 43.370 ± 3.770, resets = 27.47 ≥ 25, time = 21.0\n",
      "step =  495000, scores =   93.2 ± 15.1 [   2.9, 136.4], score_ema =   91.5, advantages =  0.025 ± 1.0 [ -5.930,  9.447], abs_actor_obj =  4.613 ± 9.478, critic_obj = 41.532 ± 2.918, resets = 27.69 ≥ 24, time = 21.6\n",
      "step =  497500, scores =   92.6 ± 14.5 [   1.6, 138.8], score_ema =   91.6, advantages =  0.002 ± 1.0 [ -6.570,  9.800], abs_actor_obj =  4.707 ± 8.656, critic_obj = 36.344 ± 2.053, resets = 28.34 ≥ 25, time = 21.8\n",
      "step =  500000, scores =   92.7 ± 12.9 [   1.8, 158.7], score_ema =   91.7, advantages = -0.021 ± 1.0 [ -6.452, 10.111], abs_actor_obj =  4.883 ± 8.473, critic_obj = 35.175 ± 1.866, resets = 28.44 ≥ 25, time = 20.7\n",
      "step =  502500, scores =   93.8 ± 14.9 [  -0.2, 152.0], score_ema =   91.9, advantages =  0.024 ± 1.0 [ -6.553,  9.261], abs_actor_obj =  4.556 ± 9.355, critic_obj = 42.085 ± 4.248, resets = 28.06 ≥ 26, time = 21.8\n",
      "step =  505000, scores =   94.3 ± 15.8 [   1.7, 164.2], score_ema =   92.1, advantages = -0.031 ± 1.0 [ -5.816,  8.338], abs_actor_obj =  5.222 ± 10.660, critic_obj = 52.154 ± 3.254, resets = 26.88 ≥ 25, time = 21.5\n",
      "step =  507500, scores =   93.1 ± 14.5 [   1.5, 149.9], score_ema =   92.2, advantages =  0.001 ± 1.0 [ -6.223,  9.163], abs_actor_obj =  4.805 ± 9.556, critic_obj = 40.743 ± 2.903, resets = 28.17 ≥ 26, time = 22.3\n",
      "step =  510000, scores =   94.2 ± 15.6 [   2.3, 149.1], score_ema =   92.4, advantages =  0.034 ± 1.0 [ -6.379, 10.212], abs_actor_obj =  4.757 ± 9.284, critic_obj = 42.573 ± 1.717, resets = 27.39 ≥ 25, time = 22.0\n",
      "step =  512500, scores =   94.8 ± 17.3 [   1.6, 162.9], score_ema =   92.7, advantages =  0.008 ± 1.0 [ -6.100,  8.836], abs_actor_obj =  4.966 ± 10.431, critic_obj = 55.305 ± 3.066, resets = 26.16 ≥ 24, time = 21.3\n",
      "step =  515000, scores =   93.4 ± 14.1 [   1.7, 146.2], score_ema =   92.7, advantages =  0.004 ± 1.0 [ -6.549,  9.413], abs_actor_obj =  4.670 ± 9.167, critic_obj = 39.838 ± 3.919, resets = 28.20 ≥ 26, time = 22.3\n",
      "step =  517500, scores =   90.5 ± 13.3 [   1.6, 152.5], score_ema =   92.5, advantages = -0.049 ± 1.0 [ -7.100, 10.347], abs_actor_obj =  5.121 ± 8.012, critic_obj = 32.814 ± 2.839, resets = 30.53 ≥ 27, time = 20.6\n",
      "step =  520000, scores =   92.8 ± 13.4 [   1.8, 153.7], score_ema =   92.6, advantages =  0.092 ± 1.0 [ -6.238,  9.721], abs_actor_obj =  3.894 ± 8.349, critic_obj = 34.855 ± 2.737, resets = 28.45 ≥ 26, time = 20.1\n",
      "step =  522500, scores =   94.0 ± 15.6 [   2.5, 143.9], score_ema =   92.7, advantages =  0.018 ± 1.0 [ -5.967,  9.792], abs_actor_obj =  4.567 ± 10.296, critic_obj = 44.629 ± 5.946, resets = 26.66 ≥ 25, time = 21.9\n",
      "step =  525000, scores =   93.6 ± 15.0 [   1.9, 144.7], score_ema =   92.8, advantages =  0.003 ± 1.0 [ -6.491,  9.603], abs_actor_obj =  4.693 ± 9.314, critic_obj = 37.733 ± 1.664, resets = 27.44 ≥ 26, time = 21.8\n",
      "step =  527500, scores =   94.1 ± 14.7 [   3.5, 154.2], score_ema =   92.9, advantages = -0.003 ± 1.0 [ -6.239,  9.369], abs_actor_obj =  4.723 ± 9.808, critic_obj = 39.331 ± 2.519, resets = 27.55 ≥ 26, time = 21.4\n",
      "step =  530000, scores =   93.4 ± 14.5 [   1.7, 151.1], score_ema =   93.0, advantages = -0.024 ± 1.0 [ -6.223,  9.391], abs_actor_obj =  4.774 ± 9.980, critic_obj = 40.400 ± 2.618, resets = 27.83 ≥ 25, time = 21.4\n",
      "step =  532500, scores =   93.0 ± 13.2 [   1.9, 177.8], score_ema =   93.0, advantages = -0.006 ± 1.0 [ -6.822,  9.781], abs_actor_obj =  4.535 ± 8.718, critic_obj = 35.171 ± 5.452, resets = 28.22 ≥ 26, time = 21.4\n",
      "step =  535000, scores =   93.9 ± 13.4 [   4.2, 156.2], score_ema =   93.1, advantages = -0.015 ± 1.0 [ -6.336, 10.866], abs_actor_obj =  4.666 ± 9.070, critic_obj = 36.470 ± 4.517, resets = 27.78 ≥ 26, time = 21.2\n",
      "step =  537500, scores =   94.6 ± 15.9 [   2.7, 143.2], score_ema =   93.2, advantages = -0.038 ± 1.0 [ -6.190,  9.031], abs_actor_obj =  5.115 ± 11.077, critic_obj = 49.445 ± 7.528, resets = 26.88 ≥ 25, time = 21.2\n",
      "step =  540000, scores =   90.7 ± 16.9 [   2.6, 145.6], score_ema =   93.0, advantages = -0.206 ± 1.0 [ -5.695,  7.681], abs_actor_obj =  7.357 ± 11.845, critic_obj = 60.250 ± 4.415, resets = 27.97 ≥ 26, time = 21.6\n",
      "step =  542500, scores =   93.5 ± 16.1 [   1.9, 198.8], score_ema =   93.0, advantages =  0.184 ± 1.0 [ -6.092,  9.131], abs_actor_obj =  4.063 ± 9.917, critic_obj = 53.185 ± 4.872, resets = 27.98 ≥ 25, time = 21.2\n",
      "step =  545000, scores =   94.3 ± 14.2 [   3.3, 140.6], score_ema =   93.2, advantages =  0.161 ± 1.0 [ -6.393,  9.923], abs_actor_obj =  3.958 ± 9.380, critic_obj = 45.375 ± 2.514, resets = 28.45 ≥ 26, time = 21.0\n",
      "step =  547500, scores =   92.0 ± 13.6 [   2.2, 130.9], score_ema =   93.0, advantages = -0.061 ± 1.0 [ -6.785,  9.601], abs_actor_obj =  5.528 ± 8.935, critic_obj = 37.784 ± 3.247, resets = 30.06 ≥ 28, time = 21.0\n",
      "step =  550000, scores =   93.0 ± 14.1 [   2.2, 135.0], score_ema =   93.0, advantages =  0.001 ± 1.0 [ -6.358,  9.797], abs_actor_obj =  4.996 ± 8.792, critic_obj = 36.945 ± 2.553, resets = 29.33 ≥ 28, time = 21.0\n",
      "step =  552500, scores =   95.0 ± 15.6 [   2.3, 162.0], score_ema =   93.2, advantages =  0.098 ± 1.0 [ -5.652,  9.114], abs_actor_obj =  4.557 ± 8.675, critic_obj = 48.157 ± 3.287, resets = 27.78 ≥ 25, time = 21.0\n",
      "step =  555000, scores =   96.1 ± 15.3 [   3.2, 158.6], score_ema =   93.5, advantages =  0.003 ± 1.0 [ -6.245, 10.001], abs_actor_obj =  4.923 ± 9.597, critic_obj = 44.963 ± 1.992, resets = 26.77 ≥ 25, time = 21.0\n",
      "step =  557500, scores =   93.1 ± 15.0 [   2.3, 142.0], score_ema =   93.5, advantages = -0.147 ± 1.0 [ -6.880,  8.641], abs_actor_obj =  5.997 ± 10.522, critic_obj = 43.791 ± 2.547, resets = 27.94 ≥ 25, time = 21.2\n",
      "step =  560000, scores =   92.5 ± 12.8 [   1.9, 143.9], score_ema =   93.4, advantages = -0.013 ± 1.0 [ -6.771,  9.952], abs_actor_obj =  5.001 ± 8.327, critic_obj = 33.873 ± 0.657, resets = 28.67 ≥ 27, time = 21.2\n",
      "step =  562500, scores =   94.0 ± 15.6 [   1.8, 158.1], score_ema =   93.4, advantages =  0.080 ± 1.0 [ -6.239,  8.334], abs_actor_obj =  4.200 ± 10.166, critic_obj = 48.027 ± 2.247, resets = 27.81 ≥ 26, time = 21.2\n",
      "step =  565000, scores =   93.4 ± 15.2 [   1.7, 144.4], score_ema =   93.4, advantages = -0.007 ± 1.0 [ -6.373,  9.284], abs_actor_obj =  4.852 ± 9.760, critic_obj = 41.410 ± 2.958, resets = 28.31 ≥ 26, time = 21.2\n",
      "step =  567500, scores =   92.7 ± 13.7 [   4.5, 142.9], score_ema =   93.4, advantages = -0.031 ± 1.0 [ -6.893,  9.367], abs_actor_obj =  4.992 ± 9.482, critic_obj = 39.034 ± 3.538, resets = 29.14 ≥ 27, time = 21.2\n",
      "step =  570000, scores =   95.1 ± 15.7 [   2.6, 150.6], score_ema =   93.5, advantages =  0.125 ± 1.0 [ -6.105, 10.143], abs_actor_obj =  4.024 ± 9.175, critic_obj = 45.437 ± 3.172, resets = 28.03 ≥ 25, time = 21.0\n",
      "step =  572500, scores =   95.2 ± 16.6 [   3.1, 177.2], score_ema =   93.7, advantages =  0.069 ± 1.0 [ -5.664,  8.876], abs_actor_obj =  4.609 ± 9.304, critic_obj = 50.566 ± 4.345, resets = 27.81 ≥ 26, time = 21.0\n",
      "step =  575000, scores =   94.7 ± 14.6 [   4.3, 168.5], score_ema =   93.8, advantages = -0.083 ± 1.0 [ -6.924,  9.689], abs_actor_obj =  5.420 ± 9.872, critic_obj = 39.807 ± 3.470, resets = 28.50 ≥ 27, time = 21.0\n",
      "step =  577500, scores =   94.6 ± 14.7 [   1.7, 136.6], score_ema =   93.9, advantages =  0.025 ± 1.0 [ -6.936,  9.703], abs_actor_obj =  4.462 ± 8.757, critic_obj = 37.250 ± 3.543, resets = 28.67 ≥ 27, time = 21.4\n",
      "step =  580000, scores =   76.8 ± 15.7 [   2.3, 134.7], score_ema =   92.2, advantages = -0.877 ± 1.0 [ -4.429,  6.385], abs_actor_obj =  16.445 ± 20.396, critic_obj = 94.143 ± 21.064, resets = 32.83 ≥ 30, time = 21.2\n",
      "step =  582500, scores =   77.0 ±  9.6 [   2.1,  99.3], score_ema =   90.7, advantages =  0.087 ± 1.0 [ -4.959,  6.525], abs_actor_obj =  6.193 ± 9.119, critic_obj = 41.620 ± 6.041, resets = 37.53 ≥ 36, time = 20.3\n",
      "step =  585000, scores =   70.9 ± 10.8 [   1.9,  96.0], score_ema =   88.7, advantages = -0.192 ± 1.0 [ -4.900,  7.374], abs_actor_obj =  7.576 ± 10.198, critic_obj = 41.254 ± 2.585, resets = 40.81 ≥ 40, time = 21.1\n",
      "step =  587500, scores =   76.2 ± 10.0 [   2.3, 106.7], score_ema =   87.4, advantages =  0.245 ± 1.0 [ -5.232,  9.033], abs_actor_obj =  3.633 ± 6.353, critic_obj = 31.583 ± 0.941, resets = 38.42 ≥ 37, time = 21.2\n",
      "step =  590000, scores =   79.2 ± 11.0 [   1.9, 108.3], score_ema =   86.6, advantages =  0.134 ± 1.0 [ -5.979,  8.225], abs_actor_obj =  4.201 ± 7.226, critic_obj = 30.892 ± 1.171, resets = 36.19 ≥ 34, time = 21.0\n",
      "step =  592500, scores =   80.9 ± 11.3 [   3.6, 116.6], score_ema =   86.0, advantages =  0.055 ± 1.0 [ -5.937,  8.502], abs_actor_obj =  4.607 ± 7.857, critic_obj = 29.384 ± 0.964, resets = 34.98 ≥ 33, time = 21.2\n",
      "step =  595000, scores =   82.1 ± 12.0 [   2.6, 117.0], score_ema =   85.6, advantages =  0.113 ± 1.0 [ -6.992,  9.142], abs_actor_obj =  3.881 ± 7.908, critic_obj = 30.033 ± 0.779, resets = 34.70 ≥ 33, time = 21.4\n",
      "step =  597500, scores =   83.5 ± 11.2 [   2.4, 140.1], score_ema =   85.4, advantages =  0.120 ± 1.0 [ -6.623,  9.798], abs_actor_obj =  3.714 ± 7.157, critic_obj = 27.538 ± 0.440, resets = 33.56 ≥ 32, time = 21.2\n",
      "step =  600000, scores =   85.3 ± 12.3 [   2.0, 131.6], score_ema =   85.4, advantages =  0.094 ± 1.0 [ -6.480,  9.463], abs_actor_obj =  3.861 ± 7.674, critic_obj = 27.874 ± 0.530, resets = 32.38 ≥ 31, time = 21.2\n",
      "step =  602500, scores =   87.5 ± 12.5 [   2.1, 135.8], score_ema =   85.6, advantages =  0.081 ± 1.0 [ -7.220,  9.332], abs_actor_obj =  4.000 ± 8.625, critic_obj = 31.759 ± 1.355, resets = 30.98 ≥ 28, time = 21.2\n",
      "step =  605000, scores =   89.0 ± 13.3 [   2.0, 136.0], score_ema =   86.0, advantages =  0.058 ± 1.0 [ -7.350,  8.888], abs_actor_obj =  4.060 ± 9.561, critic_obj = 35.774 ± 3.292, resets = 29.92 ≥ 28, time = 21.2\n",
      "step =  607500, scores =   89.2 ± 13.4 [   1.8, 134.2], score_ema =   86.3, advantages =  0.003 ± 1.0 [ -7.188,  8.570], abs_actor_obj =  4.326 ± 10.450, critic_obj = 38.806 ± 2.443, resets = 29.48 ≥ 26, time = 21.6\n",
      "step =  610000, scores =   88.6 ± 14.1 [   1.8, 136.3], score_ema =   86.5, advantages = -0.025 ± 1.0 [ -7.131,  8.464], abs_actor_obj =  4.565 ± 10.561, critic_obj = 39.340 ± 3.328, resets = 29.48 ≥ 27, time = 21.6\n",
      "step =  612500, scores =   90.1 ± 14.2 [   3.0, 137.7], score_ema =   86.9, advantages =  0.034 ± 1.0 [ -6.676,  8.918], abs_actor_obj =  4.267 ± 10.173, critic_obj = 40.480 ± 3.225, resets = 28.91 ≥ 27, time = 21.6\n",
      "step =  615000, scores =   90.2 ± 15.1 [   2.5, 158.5], score_ema =   87.2, advantages = -0.003 ± 1.0 [ -6.169,  8.643], abs_actor_obj =  4.560 ± 10.768, critic_obj = 44.781 ± 3.821, resets = 28.70 ≥ 26, time = 21.6\n",
      "step =  617500, scores =   90.4 ± 14.1 [   1.8, 160.3], score_ema =   87.5, advantages =  0.036 ± 1.0 [ -6.785,  9.199], abs_actor_obj =  4.268 ± 9.605, critic_obj = 38.445 ± 4.508, resets = 28.81 ≥ 26, time = 21.6\n",
      "step =  620000, scores =   90.0 ± 15.1 [   1.7, 142.6], score_ema =   87.8, advantages = -0.001 ± 1.0 [ -7.047,  8.975], abs_actor_obj =  4.526 ± 10.328, critic_obj = 41.744 ± 3.915, resets = 29.08 ≥ 25, time = 21.8\n",
      "step =  622500, scores =   90.7 ± 14.8 [   2.0, 185.1], score_ema =   88.1, advantages =  0.035 ± 1.0 [ -6.988, 10.052], abs_actor_obj =  4.301 ± 9.546, critic_obj = 38.690 ± 3.014, resets = 29.16 ≥ 27, time = 21.4\n",
      "step =  625000, scores =   91.3 ± 13.9 [   4.7, 184.0], score_ema =   88.4, advantages =  0.001 ± 1.0 [ -6.684,  9.795], abs_actor_obj =  4.624 ± 9.514, critic_obj = 38.288 ± 3.231, resets = 28.47 ≥ 25, time = 21.6\n",
      "step =  627500, scores =   91.9 ± 15.2 [   1.1, 155.5], score_ema =   88.8, advantages =  0.016 ± 1.0 [ -6.207,  9.387], abs_actor_obj =  4.564 ± 9.952, critic_obj = 41.442 ± 2.239, resets = 28.16 ≥ 25, time = 21.4\n",
      "step =  630000, scores =   91.8 ± 16.3 [   1.9, 147.7], score_ema =   89.1, advantages = -0.028 ± 1.0 [ -6.187,  8.379], abs_actor_obj =  4.994 ± 11.323, critic_obj = 51.071 ± 6.136, resets = 28.11 ≥ 26, time = 21.2\n",
      "step =  632500, scores =   89.6 ± 13.4 [   1.7, 177.0], score_ema =   89.1, advantages = -0.073 ± 1.0 [ -7.396, 10.583], abs_actor_obj =  5.229 ± 9.499, critic_obj = 36.706 ± 2.472, resets = 30.08 ≥ 28, time = 21.4\n",
      "step =  635000, scores =   89.1 ± 13.3 [   1.9, 142.9], score_ema =   89.1, advantages = -0.063 ± 1.0 [ -6.770,  9.781], abs_actor_obj =  5.310 ± 8.515, critic_obj = 32.340 ± 1.265, resets = 30.22 ≥ 28, time = 21.2\n",
      "step =  637500, scores =   91.8 ± 18.0 [   1.8, 153.8], score_ema =   89.4, advantages =  0.045 ± 1.0 [ -6.177,  8.881], abs_actor_obj =  4.551 ± 11.311, critic_obj = 56.323 ± 3.598, resets = 27.47 ≥ 25, time = 21.4\n",
      "step =  640000, scores =   91.1 ± 16.5 [   1.2, 155.1], score_ema =   89.6, advantages = -0.015 ± 1.0 [ -6.186,  8.504], abs_actor_obj =  4.881 ± 11.310, critic_obj = 49.240 ± 3.338, resets = 27.72 ≥ 25, time = 21.4\n",
      "step =  642500, scores =   87.4 ± 12.3 [   2.0, 146.8], score_ema =   89.3, advantages = -0.063 ± 1.0 [ -6.826, 10.670], abs_actor_obj =  5.393 ± 8.154, critic_obj = 31.138 ± 1.974, resets = 30.80 ≥ 29, time = 21.4\n",
      "step =  645000, scores =   86.8 ± 12.4 [   2.3, 130.1], score_ema =   89.1, advantages = -0.062 ± 1.0 [ -6.755, 10.586], abs_actor_obj =  5.364 ± 7.947, critic_obj = 30.163 ± 1.769, resets = 31.09 ≥ 29, time = 21.4\n",
      "step =  647500, scores =   91.8 ± 17.3 [   2.3, 156.4], score_ema =   89.3, advantages =  0.056 ± 1.0 [ -6.162,  7.870], abs_actor_obj =  4.628 ± 11.506, critic_obj = 56.804 ± 2.624, resets = 27.61 ≥ 25, time = 21.2\n",
      "step =  650000, scores =   90.1 ± 17.7 [   1.7, 144.8], score_ema =   89.4, advantages = -0.051 ± 1.0 [ -6.324,  7.741], abs_actor_obj =  5.576 ± 11.662, critic_obj = 57.956 ± 4.660, resets = 28.06 ≥ 25, time = 21.4\n",
      "step =  652500, scores =   88.0 ± 12.7 [   2.3, 138.9], score_ema =   89.3, advantages = -0.042 ± 1.0 [ -6.685, 10.044], abs_actor_obj =  5.228 ± 7.665, critic_obj = 32.021 ± 0.975, resets = 31.67 ≥ 29, time = 21.4\n",
      "step =  655000, scores =   87.4 ± 12.4 [   3.4, 139.5], score_ema =   89.1, advantages = -0.022 ± 1.0 [ -6.497,  9.957], abs_actor_obj =  4.990 ± 7.430, critic_obj = 31.090 ± 2.715, resets = 31.66 ≥ 30, time = 21.4\n",
      "step =  657500, scores =   91.3 ± 14.3 [   1.8, 149.3], score_ema =   89.3, advantages =  0.095 ± 1.0 [ -6.369,  9.889], abs_actor_obj =  4.108 ± 9.340, critic_obj = 38.430 ± 3.923, resets = 28.55 ≥ 27, time = 21.6\n",
      "step =  660000, scores =   93.0 ± 14.5 [   4.4, 153.9], score_ema =   89.7, advantages =  0.123 ± 1.0 [ -6.524, 10.019], abs_actor_obj =  3.750 ± 9.118, critic_obj = 36.721 ± 3.243, resets = 28.44 ≥ 27, time = 21.4\n",
      "step =  662500, scores =   92.4 ± 13.4 [   4.7, 164.2], score_ema =   90.0, advantages =  0.012 ± 1.0 [ -7.585, 10.329], abs_actor_obj =  4.353 ± 9.222, critic_obj = 36.672 ± 2.441, resets = 29.23 ≥ 27, time = 21.2\n",
      "step =  665000, scores =   90.3 ± 12.4 [   1.7, 126.8], score_ema =   90.0, advantages = -0.038 ± 1.0 [ -6.869, 10.258], abs_actor_obj =  4.735 ± 8.655, critic_obj = 34.018 ± 1.282, resets = 31.08 ≥ 29, time = 21.4\n",
      "step =  667500, scores =   88.1 ± 12.3 [   1.6, 135.7], score_ema =   89.8, advantages = -0.295 ± 1.0 [ -7.825,  8.811], abs_actor_obj =  7.820 ± 10.450, critic_obj = 43.197 ± 2.540, resets = 31.03 ≥ 29, time = 21.4\n",
      "step =  670000, scores =   95.0 ± 15.5 [   1.6, 150.5], score_ema =   90.3, advantages =  0.212 ± 1.0 [ -5.685,  8.265], abs_actor_obj =  3.886 ± 9.460, critic_obj = 51.824 ± 3.278, resets = 27.09 ≥ 25, time = 21.4\n",
      "step =  672500, scores =   95.1 ± 15.9 [   2.0, 158.5], score_ema =   90.8, advantages =  0.176 ± 1.0 [ -5.750,  9.056], abs_actor_obj =  3.884 ± 9.324, critic_obj = 49.876 ± 3.007, resets = 27.22 ≥ 25, time = 21.8\n",
      "step =  675000, scores =   93.4 ± 16.7 [   2.4, 173.4], score_ema =   91.1, advantages =  0.025 ± 1.0 [ -5.756,  8.969], abs_actor_obj =  4.729 ± 10.077, critic_obj = 49.882 ± 3.144, resets = 27.52 ≥ 25, time = 22.0\n",
      "step =  677500, scores =   95.5 ± 18.1 [   2.4, 183.0], score_ema =   91.5, advantages = -0.023 ± 1.0 [ -7.035,  8.299], abs_actor_obj =  5.206 ± 11.325, critic_obj = 62.803 ± 5.941, resets = 25.73 ≥ 23, time = 21.4\n",
      "step =  680000, scores =   94.5 ± 18.4 [  -0.2, 148.2], score_ema =   91.8, advantages = -0.171 ± 1.0 [ -6.206,  7.373], abs_actor_obj =  6.648 ± 12.627, critic_obj = 75.296 ± 6.451, resets = 26.23 ≥ 24, time = 21.2\n",
      "step =  682500, scores =   91.5 ± 14.1 [   1.4, 144.7], score_ema =   91.8, advantages =  0.004 ± 1.0 [ -6.579, 10.461], abs_actor_obj =  4.993 ± 9.164, critic_obj = 41.371 ± 3.099, resets = 29.78 ≥ 28, time = 21.4\n",
      "step =  685000, scores =   91.1 ± 12.6 [   1.8, 136.3], score_ema =   91.7, advantages =  0.095 ± 1.0 [ -6.756,  9.905], abs_actor_obj =  4.126 ± 7.421, critic_obj = 33.963 ± 1.144, resets = 30.88 ≥ 29, time = 21.2\n",
      "step =  687500, scores =   94.6 ± 15.1 [   1.6, 151.7], score_ema =   92.0, advantages =  0.069 ± 1.0 [ -6.757,  9.003], abs_actor_obj =  4.569 ± 9.914, critic_obj = 48.726 ± 4.908, resets = 28.00 ≥ 26, time = 21.4\n",
      "step =  690000, scores =   94.1 ± 15.0 [   1.9, 138.7], score_ema =   92.2, advantages =  0.000 ± 1.0 [ -6.059,  9.475], abs_actor_obj =  5.185 ± 9.608, critic_obj = 49.435 ± 4.212, resets = 27.73 ≥ 25, time = 21.2\n",
      "step =  692500, scores =   93.1 ± 14.3 [   1.8, 162.0], score_ema =   92.3, advantages =  0.052 ± 1.0 [ -6.203, 10.096], abs_actor_obj =  4.574 ± 8.261, critic_obj = 39.299 ± 2.270, resets = 29.12 ≥ 27, time = 21.2\n",
      "step =  695000, scores =   93.2 ± 14.5 [   1.9, 162.8], score_ema =   92.4, advantages = -0.006 ± 1.0 [ -6.699,  9.945], abs_actor_obj =  4.926 ± 8.793, critic_obj = 37.410 ± 2.167, resets = 29.05 ≥ 27, time = 21.6\n",
      "step =  697500, scores =   94.5 ± 15.8 [   1.9, 162.3], score_ema =   92.6, advantages = -0.028 ± 1.0 [ -6.413,  8.417], abs_actor_obj =  5.254 ± 10.949, critic_obj = 50.935 ± 3.377, resets = 27.59 ≥ 25, time = 22.0\n",
      "step =  700000, scores =   95.0 ± 15.3 [   2.0, 165.1], score_ema =   92.8, advantages =  0.025 ± 1.0 [ -6.779,  8.913], abs_actor_obj =  4.798 ± 10.021, critic_obj = 47.789 ± 2.236, resets = 27.55 ≥ 24, time = 21.2\n",
      "step =  702500, scores =   93.2 ± 13.4 [   2.4, 171.5], score_ema =   92.9, advantages = -0.033 ± 1.0 [ -7.429, 10.086], abs_actor_obj =  5.012 ± 8.979, critic_obj = 36.700 ± 2.238, resets = 28.70 ≥ 26, time = 21.4\n",
      "step =  705000, scores =   93.0 ± 13.3 [   2.4, 143.2], score_ema =   92.9, advantages = -0.013 ± 1.0 [ -7.335,  9.539], abs_actor_obj =  4.965 ± 8.413, critic_obj = 37.798 ± 1.713, resets = 29.41 ≥ 27, time = 21.4\n",
      "step =  707500, scores =   94.2 ± 13.3 [   1.9, 152.1], score_ema =   93.0, advantages =  0.108 ± 1.0 [ -6.956, 10.465], abs_actor_obj =  3.898 ± 8.254, critic_obj = 36.924 ± 3.593, resets = 29.69 ≥ 27, time = 21.2\n",
      "step =  710000, scores =   93.5 ± 14.4 [   2.4, 161.9], score_ema =   93.1, advantages = -0.062 ± 1.0 [ -6.643,  9.571], abs_actor_obj =  5.250 ± 9.472, critic_obj = 37.836 ± 1.890, resets = 29.17 ≥ 27, time = 22.4\n",
      "step =  712500, scores =   94.6 ± 14.1 [   1.9, 132.8], score_ema =   93.2, advantages =  0.025 ± 1.0 [ -7.665,  9.939], abs_actor_obj =  4.526 ± 8.899, critic_obj = 35.595 ± 1.172, resets = 28.61 ≥ 27, time = 22.0\n",
      "step =  715000, scores =   93.1 ± 13.5 [   2.8, 127.0], score_ema =   93.2, advantages = -0.074 ± 1.0 [ -6.201,  9.755], abs_actor_obj =  5.423 ± 9.143, critic_obj = 35.857 ± 2.402, resets = 28.83 ≥ 26, time = 21.6\n",
      "step =  717500, scores =   93.6 ± 13.3 [   1.8, 143.1], score_ema =   93.2, advantages =  0.005 ± 1.0 [ -7.421,  9.691], abs_actor_obj =  4.555 ± 9.482, critic_obj = 36.754 ± 1.092, resets = 28.41 ≥ 26, time = 21.6\n",
      "step =  720000, scores =   94.3 ± 13.8 [   2.1, 157.7], score_ema =   93.4, advantages =  0.030 ± 1.0 [ -6.917,  9.976], abs_actor_obj =  4.453 ± 9.803, critic_obj = 42.808 ± 2.354, resets = 28.28 ≥ 25, time = 21.6\n",
      "step =  722500, scores =   93.0 ± 13.3 [   2.3, 138.2], score_ema =   93.3, advantages =  0.010 ± 1.0 [ -7.648,  9.778], abs_actor_obj =  4.651 ± 8.614, critic_obj = 36.484 ± 1.572, resets = 29.53 ≥ 28, time = 21.6\n",
      "step =  725000, scores =   93.5 ± 14.1 [   3.3, 148.4], score_ema =   93.3, advantages =  0.009 ± 1.0 [ -7.086,  9.977], abs_actor_obj =  4.587 ± 9.186, critic_obj = 39.378 ± 2.431, resets = 28.45 ≥ 26, time = 21.6\n",
      "step =  727500, scores =   95.6 ± 14.2 [   2.3, 165.6], score_ema =   93.6, advantages =  0.060 ± 1.0 [ -6.778,  9.636], abs_actor_obj =  4.281 ± 9.313, critic_obj = 40.583 ± 2.667, resets = 27.50 ≥ 25, time = 21.6\n",
      "step =  730000, scores =   94.5 ± 16.2 [   2.8, 142.2], score_ema =   93.7, advantages = -0.115 ± 1.0 [ -6.676,  8.127], abs_actor_obj =  6.187 ± 10.634, critic_obj = 53.954 ± 1.120, resets = 27.34 ≥ 25, time = 21.4\n",
      "step =  732500, scores =   94.7 ± 14.2 [   2.9, 137.9], score_ema =   93.8, advantages =  0.076 ± 1.0 [ -7.289,  9.137], abs_actor_obj =  4.269 ± 9.189, critic_obj = 40.118 ± 1.735, resets = 27.67 ≥ 25, time = 21.4\n",
      "step =  735000, scores =   93.6 ± 13.2 [   1.8, 138.5], score_ema =   93.7, advantages = -0.030 ± 1.0 [ -6.745,  9.928], abs_actor_obj =  4.974 ± 8.713, critic_obj = 35.226 ± 0.962, resets = 28.31 ≥ 26, time = 21.4\n",
      "step =  737500, scores =   95.3 ± 13.8 [   2.0, 143.6], score_ema =   93.9, advantages =  0.110 ± 1.0 [ -6.932, 10.425], abs_actor_obj =  3.819 ± 8.416, critic_obj = 35.750 ± 2.780, resets = 28.41 ≥ 27, time = 21.4\n",
      "step =  740000, scores =   92.7 ± 14.7 [   1.8, 137.3], score_ema =   93.8, advantages = -0.137 ± 1.0 [ -7.047,  9.656], abs_actor_obj =  6.415 ± 8.611, critic_obj = 42.605 ± 0.815, resets = 29.41 ≥ 27, time = 21.2\n",
      "step =  742500, scores =   94.2 ± 14.9 [   1.7, 158.1], score_ema =   93.8, advantages =  0.147 ± 1.0 [ -6.245,  9.624], abs_actor_obj =  3.697 ± 8.288, critic_obj = 37.158 ± 1.029, resets = 29.39 ≥ 27, time = 21.4\n",
      "step =  745000, scores =   92.2 ± 13.1 [   2.3, 154.1], score_ema =   93.7, advantages = -0.129 ± 1.0 [ -6.749, 10.579], abs_actor_obj =  5.870 ± 9.006, critic_obj = 33.912 ± 2.232, resets = 29.58 ≥ 27, time = 21.2\n",
      "step =  747500, scores =   95.6 ± 15.9 [   2.0, 150.4], score_ema =   93.9, advantages =  0.034 ± 1.0 [ -6.327,  8.328], abs_actor_obj =  4.938 ± 10.441, critic_obj = 50.946 ± 2.648, resets = 27.67 ≥ 25, time = 21.2\n",
      "step =  750000, scores =   94.7 ± 15.1 [   1.8, 186.6], score_ema =   93.9, advantages =  0.033 ± 1.0 [ -6.040,  9.640], abs_actor_obj =  5.124 ± 8.181, critic_obj = 46.237 ± 0.464, resets = 28.84 ≥ 27, time = 21.0\n",
      "step =  752500, scores =   92.8 ± 13.9 [   3.1, 133.7], score_ema =   93.8, advantages = -0.053 ± 1.0 [ -6.600,  9.518], abs_actor_obj =  5.256 ± 8.751, critic_obj = 34.267 ± 1.338, resets = 29.67 ≥ 28, time = 21.2\n",
      "step =  755000, scores =   95.3 ± 13.9 [   2.0, 162.5], score_ema =   94.0, advantages =  0.052 ± 1.0 [ -6.892,  9.464], abs_actor_obj =  4.356 ± 9.036, critic_obj = 37.640 ± 3.049, resets = 28.17 ≥ 26, time = 21.2\n",
      "step =  757500, scores =   92.5 ± 18.9 [   4.0, 162.0], score_ema =   93.8, advantages = -0.162 ± 1.0 [ -6.838,  7.233], abs_actor_obj =  7.780 ± 10.079, critic_obj = 78.699 ± 4.285, resets = 28.41 ≥ 26, time = 20.6\n",
      "step =  760000, scores =   97.7 ± 20.6 [   2.1, 169.0], score_ema =   94.2, advantages =  0.290 ± 1.0 [ -5.760,  7.726], abs_actor_obj =  4.151 ± 7.903, critic_obj = 86.785 ± 4.002, resets = 28.02 ≥ 25, time = 21.0\n",
      "step =  762500, scores =   82.6 ± 14.7 [   2.0, 146.8], score_ema =   93.1, advantages = -0.389 ± 1.0 [ -5.632,  8.217], abs_actor_obj =  9.887 ± 10.957, critic_obj = 54.462 ± 6.678, resets = 31.75 ≥ 27, time = 21.2\n",
      "step =  765000, scores =   92.9 ± 18.3 [   2.1, 159.9], score_ema =   93.0, advantages =  0.072 ± 1.0 [ -4.734,  8.686], abs_actor_obj =  5.171 ± 9.947, critic_obj = 65.357 ± 2.593, resets = 26.00 ≥ 22, time = 23.5\n",
      "step =  767500, scores =   93.8 ± 16.7 [   2.7, 171.1], score_ema =   93.1, advantages =  0.194 ± 1.0 [ -5.847,  8.509], abs_actor_obj =  4.112 ± 9.282, critic_obj = 55.393 ± 5.617, resets = 26.89 ≥ 24, time = 22.4\n",
      "step =  770000, scores =   88.9 ± 13.2 [   2.0, 156.5], score_ema =   92.7, advantages = -0.150 ± 1.0 [ -7.552,  9.941], abs_actor_obj =  6.522 ± 8.552, critic_obj = 35.480 ± 2.302, resets = 30.92 ≥ 29, time = 22.9\n",
      "step =  772500, scores =   95.7 ± 15.1 [   2.4, 146.6], score_ema =   93.0, advantages =  0.307 ± 1.0 [ -7.759,  9.132], abs_actor_obj =  3.324 ± 7.326, critic_obj = 45.197 ± 1.935, resets = 28.86 ≥ 26, time = 22.0\n",
      "step =  775000, scores =  104.4 ± 20.9 [   2.1, 165.3], score_ema =   94.1, advantages =  0.350 ± 1.0 [ -5.584,  7.768], abs_actor_obj =  3.931 ± 8.516, critic_obj = 86.378 ± 4.370, resets = 25.69 ≥ 23, time = 21.4\n",
      "step =  777500, scores =  105.0 ± 22.8 [   1.2, 175.3], score_ema =   95.2, advantages =  0.071 ± 1.0 [ -5.866,  7.106], abs_actor_obj =  5.428 ± 10.564, critic_obj = 96.662 ± 6.772, resets = 24.78 ≥ 21, time = 21.7\n"
     ]
    }
   ],
   "source": [
    "policy_id: str\n",
    "policy: Optional[BasePolicy]\n",
    "def get_policy(create_new_if_exists: bool):\n",
    "    \n",
    "    global policy_id, policy\n",
    "    \n",
    "    policy_in_ram = 'policy' in globals()\n",
    "    if not policy_in_ram or create_new_if_exists:\n",
    "        if not policy_in_ram:\n",
    "            print('No policy in RAM, creating a new one')\n",
    "        \n",
    "        policy_id = get_current_timestamp()\n",
    "        policy = init_policy()\n",
    "        print(f'New policy {policy_id} created')\n",
    "    \n",
    "    if parent_policy_id is not None:\n",
    "        policy_db.load_model_state_dict(policy, parent_policy_id)\n",
    "        print(f'Loading state dict from policy {parent_policy_id}')\n",
    "    \n",
    "    return policy_id, policy\n",
    "\n",
    "def init_policy():\n",
    "    class A2CNetwork(nn.Module):\n",
    "\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "            \n",
    "            in_size = 376\n",
    "            shared_out_sizes = []\n",
    "            actor_out_sizes = [512, 512, 256, 256, 256, 256, 256, 256, 17]\n",
    "            critic_out_sizes = [512, 512, 256, 256, 256, 1]\n",
    "            \n",
    "            hidden_activation_function = nn.ELU()\n",
    "            actor_out_activation_function = nn.Tanh()\n",
    "            critic_out_activation_function = nn.Identity()\n",
    "            \n",
    "            self.has_shared = len(shared_out_sizes) > 0\n",
    "            \n",
    "            if self.has_shared:\n",
    "                self.shared = SeqNet.from_layer_provider(\n",
    "                    layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n",
    "                        nn.Linear(in_features, out_features),\n",
    "                        hidden_activation_function\n",
    "                    ),\n",
    "                    in_size=in_size,\n",
    "                    out_sizes=shared_out_sizes\n",
    "                )\n",
    "            else:\n",
    "                self.shared = TorchNet(nn.Identity(), in_shape=TensorShape(features=in_size), out_shape=TensorShape(features=in_size))\n",
    "\n",
    "            self.actor = SeqNet.from_layer_provider(\n",
    "                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n",
    "                    nn.Linear(in_features, out_features),\n",
    "                    actor_out_activation_function if is_last_layer else hidden_activation_function\n",
    "                ),\n",
    "                in_size=self.shared.out_shape.get_definite_features(),\n",
    "                out_sizes=actor_out_sizes\n",
    "            )\n",
    "\n",
    "            self.critic = SeqNet.from_layer_provider(\n",
    "                layer_provider=lambda layer_nr, is_last_layer, in_features, out_features: nn.Sequential(\n",
    "                    nn.Linear(in_features, out_features),\n",
    "                    critic_out_activation_function if is_last_layer else hidden_activation_function\n",
    "                ),\n",
    "                in_size=self.shared.out_shape.get_definite_features(),\n",
    "                out_sizes=critic_out_sizes\n",
    "            )\n",
    "\n",
    "        def forward(self, x: torch.Tensor):\n",
    "            if self.has_shared:\n",
    "                shared_out = self.shared(x)\n",
    "            else:\n",
    "                shared_out = x\n",
    "\n",
    "            return self.actor(shared_out), self.critic(shared_out)\n",
    "\n",
    "    return ActorCriticPolicy(A2CNetwork(), lambda action_logits: dist.Normal(loc=action_logits, scale=policy_action_std))\n",
    "\n",
    "score_mean_ema = ExponentialMovingAverage(alpha=0.1)\n",
    "stopwatch = Stopwatch()\n",
    "best_iteration_score = -1e6\n",
    "\n",
    "def on_rollout_done(rl: PPO, step: int, info: dict[str, Any]):    \n",
    "    if 'unnormalized_rewards' in info['rollout']:\n",
    "        unnormalized_rewards = info['rollout']['unnormalized_rewards']\n",
    "        _, gamma_1_returns = compute_gae_and_returns(\n",
    "            value_estimates=np.zeros_like(rl.buffer.rewards[:len(unnormalized_rewards)]),\n",
    "            rewards=unnormalized_rewards,\n",
    "            episode_starts=rl.buffer.episode_starts[:len(unnormalized_rewards)],\n",
    "            last_values=np.zeros_like(rl.buffer.rewards[0], dtype=float),\n",
    "            last_dones=np.zeros_like(rl.buffer.episode_starts[0], dtype=bool),\n",
    "            gamma=1.0,\n",
    "            gae_lambda=1.0,\n",
    "            normalize_rewards=None,\n",
    "            normalize_advantages=None,\n",
    "        )\n",
    "    else:\n",
    "        _, gamma_1_returns = rl.buffer.compute_gae_and_returns(\n",
    "            last_values=torch.zeros_like(rl.buffer.value_estimates[0]),\n",
    "            last_dones=np.zeros_like(rl.buffer.episode_starts[0], dtype=bool),\n",
    "            gamma=1.0,\n",
    "            gae_lambda=1.0,\n",
    "            normalize_advantages=None,\n",
    "            normalize_rewards=None,\n",
    "        )\n",
    "    \n",
    "    episode_scores = gamma_1_returns[\n",
    "        rl.buffer.episode_starts[:rl.buffer.pos]\n",
    "    ]\n",
    "    \n",
    "    iteration_score = episode_scores.mean()\n",
    "    score_moving_average = score_mean_ema.update(iteration_score)\n",
    "    global best_iteration_score\n",
    "    if iteration_score >= best_iteration_score:\n",
    "        best_iteration_score = iteration_score\n",
    "        policy_db.save_model_state_dict(\n",
    "            model=policy,\n",
    "            model_id=policy_id,\n",
    "            parent_model_id=parent_policy_id,\n",
    "            model_info={'score': iteration_score.item()},\n",
    "            init_function=init_policy\n",
    "        )\n",
    "        \n",
    "    info['episode_scores'] = episode_scores\n",
    "    info['score_moving_average'] = score_moving_average\n",
    "\n",
    "def on_optimization_done(rl: PPO, step: int, info: dict[str, Any]):\n",
    "    time_taken = stopwatch.reset()\n",
    "    \n",
    "    episode_scores = info['episode_scores']\n",
    "    score_moving_average = info['score_moving_average']\n",
    "        \n",
    "    \n",
    "    scores = format_summary_statics(\n",
    "        episode_scores, \n",
    "        mean_format=' 6.1f',\n",
    "        std_format='4.1f',\n",
    "        min_value_format=' 6.1f',\n",
    "        max_value_format='5.1f',\n",
    "    )\n",
    "    advantages = format_summary_statics(\n",
    "        info['advantages'], \n",
    "        mean_format=' 6.3f',\n",
    "        std_format='.1f',\n",
    "        min_value_format=' 7.3f',\n",
    "        max_value_format='6.3f',\n",
    "    )\n",
    "    abs_actor_obj = format_summary_statics(\n",
    "        rl.weigh_actor_objective(info['actor_objective_unreduced']),  \n",
    "        mean_format=' 5.3f',\n",
    "        std_format='5.3f',\n",
    "        min_value_format=None,\n",
    "        max_value_format=None,\n",
    "    )\n",
    "    critic_obj = format_summary_statics(\n",
    "        info['weighted_critic_objective'], \n",
    "        mean_format='5.3f',\n",
    "        std_format='5.3f',\n",
    "        min_value_format=None,\n",
    "        max_value_format=None,\n",
    "    )\n",
    "    resets = format_summary_statics(\n",
    "        rl.buffer.episode_starts.astype(int).sum(axis=0), \n",
    "        mean_format='.2f',\n",
    "        std_format=None,\n",
    "        min_value_format='1d',\n",
    "        max_value_format=None,\n",
    "    )\n",
    "    print(f\"{step = : >7}, \"\n",
    "          f'{scores = :s}, '\n",
    "          f'score_ema = {score_moving_average: 6.1f}, '\n",
    "          f\"{advantages = :s}, \"\n",
    "          f\"{abs_actor_obj = :s}, \"\n",
    "          f\"{critic_obj = :s}, \"\n",
    "          f\"{resets = :s}, \"\n",
    "          f\"time = {time_taken:4.1f}\")\n",
    "    \n",
    "    # for param_name, param_grad in get_gradients_per_parameter(rl.policy, param_type='weight'):\n",
    "    #     print(f'{param_name + \".grad\":<50}: ' + format_summary_statics(\n",
    "    #         param_grad,\n",
    "    #         mean_format=' 8.5f',\n",
    "    #         std_format='.5f',\n",
    "    #         min_value_format=' 8.5f',\n",
    "    #         max_value_format='7.5f',\n",
    "    #     ))\n",
    "    # \n",
    "    # print('\\n')\n",
    "\n",
    "device = set_default_torch_device(\"cuda:0\") if True else set_default_torch_device('cpu')\n",
    "print(f'using device {device}')\n",
    "\n",
    "def create_env(render_mode: str | None):\n",
    "    return gym.make(env_name, render_mode=render_mode, **env_kwargs)\n",
    "\n",
    "def wrap_env(_env: Env):\n",
    "    # _env = NormalizeRewardWrapper(_env, gamma=gamma)\n",
    "    # _env = TransformObservation(_env, lambda _obs: _obs / 255)\n",
    "    # _env = TransformReward(_env, lambda _reward: 0.01 * _reward) \n",
    "    _env = RescaleAction(_env, min_action=-1.0, max_action=1.0)\n",
    "    _env = ClipAction(_env)\n",
    "    return _env\n",
    "\n",
    "env_name = 'Humanoid-v4'\n",
    "env_kwargs = {'forward_reward_weight': 1.25, 'healthy_reward': 0.5, 'ctrl_cost_weight': 0.001 }\n",
    "num_envs = 64\n",
    "    \n",
    "policy_db = ModelDB(base_path=f'saved_models/rl/{env_name}')\n",
    "\n",
    "parent_policy_id=None\n",
    "policy_action_std=0.15\n",
    "\n",
    "policy_id, policy = get_policy(create_new_if_exists=False)\n",
    "print(f'{count_parameters(policy) = }')\n",
    "\n",
    "gamma = 0.995\n",
    "\n",
    "env = parallelize_env_async(lambda: create_env(render_mode=None), num_envs)\n",
    "try:\n",
    "    env = wrap_env(env)\n",
    "    print(f'{env = }, {num_envs = }')\n",
    "    \n",
    "    PPO(\n",
    "        env=env,\n",
    "        policy=policy.to(device),\n",
    "        policy_optimizer=lambda pol: optim.Adam(pol.parameters(), lr=1e-5),\n",
    "        buffer_size=2500,\n",
    "        gamma=gamma,\n",
    "        gae_lambda=1.0,\n",
    "        normalize_rewards=None,\n",
    "        normalize_advantages=NormalizationType.Std,\n",
    "        weigh_actor_objective=lambda obj: 1.0 * obj,\n",
    "        weigh_critic_objective=lambda obj: 0.5 * obj,\n",
    "        ppo_epochs=3,\n",
    "        ppo_batch_size=500,\n",
    "        action_ratio_clip_range=0.01,\n",
    "        log_unreduced=True,\n",
    "        callback=Callback(on_rollout_done=on_rollout_done, on_optimization_done=on_optimization_done)\n",
    "    ).train(5_000_000)\n",
    "except KeyboardInterrupt:\n",
    "    print('keyboard interrupt')\n",
    "finally:\n",
    "    print('closing envs')\n",
    "    time.sleep(5.0)\n",
    "    env.close()\n",
    "    print('envs closed')\n",
    "    policy_db.close()\n",
    "    print('model db closed')\n",
    "\n",
    "print('done')"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-04-28T19:06:52.577424Z"
    }
   },
   "id": "f71efe062771e81b"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video C:\\Users\\domin\\Videos\\rl\\2024-04-28_14.27.40\\rl-video-episode-0.mp4.\n",
      "Moviepy - Writing video C:\\Users\\domin\\Videos\\rl\\2024-04-28_14.27.40\\rl-video-episode-0.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready C:\\Users\\domin\\Videos\\rl\\2024-04-28_14.27.40\\rl-video-episode-0.mp4\n",
      "Moviepy - Building video C:\\Users\\domin\\Videos\\rl\\2024-04-28_14.27.40\\rl-video-episode-1.mp4.\n",
      "Moviepy - Writing video C:\\Users\\domin\\Videos\\rl\\2024-04-28_14.27.40\\rl-video-episode-1.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready C:\\Users\\domin\\Videos\\rl\\2024-04-28_14.27.40\\rl-video-episode-1.mp4\n",
      "Moviepy - Building video C:\\Users\\domin\\Videos\\rl\\2024-04-28_14.27.40\\rl-video-episode-2.mp4.\n",
      "Moviepy - Writing video C:\\Users\\domin\\Videos\\rl\\2024-04-28_14.27.40\\rl-video-episode-2.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready C:\\Users\\domin\\Videos\\rl\\2024-04-28_14.27.40\\rl-video-episode-2.mp4\n",
      "Moviepy - Building video C:\\Users\\domin\\Videos\\rl\\2024-04-28_14.27.40\\rl-video-episode-3.mp4.\n",
      "Moviepy - Writing video C:\\Users\\domin\\Videos\\rl\\2024-04-28_14.27.40\\rl-video-episode-3.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready C:\\Users\\domin\\Videos\\rl\\2024-04-28_14.27.40\\rl-video-episode-3.mp4\n",
      "Moviepy - Building video C:\\Users\\domin\\Videos\\rl\\2024-04-28_14.27.40\\rl-video-episode-4.mp4.\n",
      "Moviepy - Writing video C:\\Users\\domin\\Videos\\rl\\2024-04-28_14.27.40\\rl-video-episode-4.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready C:\\Users\\domin\\Videos\\rl\\2024-04-28_14.27.40\\rl-video-episode-4.mp4\n",
      "Moviepy - Building video C:\\Users\\domin\\Videos\\rl\\2024-04-28_14.27.40\\rl-video-episode-5.mp4.\n",
      "Moviepy - Writing video C:\\Users\\domin\\Videos\\rl\\2024-04-28_14.27.40\\rl-video-episode-5.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready C:\\Users\\domin\\Videos\\rl\\2024-04-28_14.27.40\\rl-video-episode-5.mp4\n",
      "Moviepy - Building video C:\\Users\\domin\\Videos\\rl\\2024-04-28_14.27.40\\rl-video-episode-6.mp4.\n",
      "Moviepy - Writing video C:\\Users\\domin\\Videos\\rl\\2024-04-28_14.27.40\\rl-video-episode-6.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyboard interrupt\n",
      "closing record_env\n",
      "Moviepy - Building video C:\\Users\\domin\\Videos\\rl\\2024-04-28_14.27.40\\rl-video-episode-6.mp4.\n",
      "Moviepy - Writing video C:\\Users\\domin\\Videos\\rl\\2024-04-28_14.27.40\\rl-video-episode-6.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready C:\\Users\\domin\\Videos\\rl\\2024-04-28_14.27.40\\rl-video-episode-6.mp4\n",
      "record_env closed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "record_env: gym.Env = create_env(render_mode='rgb_array')\n",
    "try:\n",
    "    if 'render_fps' not in record_env.metadata:\n",
    "        record_env.metadata['render_fps'] = 30\n",
    "    record_env = wrap_env(record_env)\n",
    "    record_env = AutoResetWrapper(\n",
    "        RecordVideo(record_env, video_folder=rf'C:\\Users\\domin\\Videos\\rl\\{get_current_timestamp()}', episode_trigger=lambda ep_nr: True)\n",
    "    )\n",
    "    def record(max_steps: int):\n",
    "        obs, info = record_env.reset()\n",
    "        for step in range(max_steps):\n",
    "            actions_dist = policy.predict_actions(obs)\n",
    "            actions = actions_dist.sample().detach().cpu().numpy()\n",
    "            obs, reward, terminated, truncated, info = record_env.step(actions)\n",
    "    \n",
    "    record(10000)\n",
    "except KeyboardInterrupt:\n",
    "    print('keyboard interrupt')\n",
    "finally:\n",
    "    print('closing record_env')\n",
    "    record_env.close()\n",
    "    print('record_env closed')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T12:27:46.929424Z",
     "start_time": "2024-04-28T12:27:39.289650Z"
    }
   },
   "id": "d1ae8571d73535c6",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "torch.save(policy.state_dict(), f'saved_models/rl/{env_name}/{get_current_timestamp()}---6x96_6x64-elu--state_dict.pth')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-27T01:34:57.846923Z",
     "start_time": "2024-04-27T01:34:57.746930Z"
    }
   },
   "id": "459d7865a53e3600",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from stable_baselines3 import A2C\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "import gymnasium as gym\n",
    "\n",
    "# Parallel environments\n",
    "vec_env = make_vec_env(lambda: gym.make('CartPole-v1', render_mode='rgb_array'), n_envs=4)\n",
    "\n",
    "model = A2C(\"MlpPolicy\", vec_env, verbose=2)\n",
    "model.learn(total_timesteps=25000)\n",
    "model.save(\"a2c_cartpole\")\n",
    "\n",
    "del model # remove to demonstrate saving and loading\n",
    "\n",
    "model = A2C.load(\"a2c_cartpole\")\n",
    "\n",
    "obs = vec_env.reset()\n",
    "for _ in range(100_000):\n",
    "    action, _states = model.predict(obs)\n",
    "    obs, rewards, dones, info = vec_env.step(action)\n",
    "    vec_env.render(\"human\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "266d91aeee84c4cd",
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video C:\\Users\\domin\\Videos\\rl\\2024-04-24.1\\rl-video-episode-0.mp4.\n",
      "Moviepy - Writing video C:\\Users\\domin\\Videos\\rl\\2024-04-24.1\\rl-video-episode-0.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready C:\\Users\\domin\\Videos\\rl\\2024-04-24.1\\rl-video-episode-0.mp4\n",
      "closing record_env\n",
      "Moviepy - Building video C:\\Users\\domin\\Videos\\rl\\2024-04-24.1\\rl-video-episode-1.mp4.\n",
      "Moviepy - Writing video C:\\Users\\domin\\Videos\\rl\\2024-04-24.1\\rl-video-episode-1.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready C:\\Users\\domin\\Videos\\rl\\2024-04-24.1\\rl-video-episode-1.mp4\n",
      "record_env closed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "import gymnasium\n",
    "record_env = gymnasium.make(\"ALE/Pacman-ram-v5\", render_mode='rgb_array')\n",
    "try:\n",
    "    record_env = AutoResetWrapper(\n",
    "        RecordVideo(record_env, video_folder=r'C:\\Users\\domin\\Videos\\rl\\2024-04-24.1', episode_trigger=lambda ep_nr: True)\n",
    "    )\n",
    "    def record(max_steps: int):\n",
    "        obs, info = record_env.reset()\n",
    "        for step in range(max_steps):\n",
    "            # actions_dist = policy.predict_actions(obs)\n",
    "            # actions = actions_dist.sample().detach().cpu().numpy()\n",
    "            \n",
    "            actions = 2\n",
    "            \n",
    "            obs, reward, terminated, truncated, info = record_env.step(actions)\n",
    "            \n",
    "            if terminated or truncated:\n",
    "                break\n",
    "    \n",
    "    record(10000)\n",
    "except KeyboardInterrupt:\n",
    "    print('keyboard interrupt')\n",
    "finally:\n",
    "    print('closing record_env')\n",
    "    record_env.close()\n",
    "    print('record_env closed')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T15:57:07.218154Z",
     "start_time": "2024-04-24T15:57:06.685399Z"
    }
   },
   "id": "1a6d8096efe48ca3",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<OrderEnforcing<PassiveEnvChecker<AtariEnv<ALE/Pacman-ram-v5>>>>\n"
     ]
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T16:29:07.007390Z",
     "start_time": "2024-04-24T16:29:06.925013Z"
    }
   },
   "id": "bba6ab51a61dd845",
   "execution_count": 10
  }
 ],
 "metadata": {
  "autoscrollcelloutput": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
