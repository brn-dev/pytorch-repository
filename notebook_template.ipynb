{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4de06880-6b03-4d58-9afc-5bd1d6263d6c",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-03-15T00:04:19.110918Z",
     "start_time": "2024-03-15T00:04:17.268862Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import dataclasses\n",
    "\n",
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4c2f3051-d357-447d-87b5-a4cdd1caa627",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-15T00:13:37.154011Z",
     "start_time": "2024-03-15T00:13:35.563621Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67239936\n",
      "AdditiveSkipNet(\n",
      "  (layers): NetList(\n",
      "    (0-255): 256 x TorchNet(\n",
      "      (torch_module): Sequential(\n",
      "        (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (1): CELU(alpha=1.0)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": "tensor([-2.4459e-02, -1.6072e-02,  9.7477e-04,  4.3461e-02, -4.0533e-03,\n         6.5953e-02, -4.7980e-02,  5.0557e-02, -1.9582e-02,  2.7958e-02,\n        -1.3671e-02,  1.2019e-02,  1.5130e-02,  1.4208e-02, -3.2068e-03,\n        -3.4776e-02, -3.3296e-02,  2.4347e-02,  4.0360e-02,  3.7785e-02,\n        -8.7982e-03,  2.6627e-02, -9.5907e-03,  3.2516e-02, -9.1851e-03,\n        -5.4405e-02,  4.9836e-03, -6.2159e-02,  2.8282e-03, -3.2337e-02,\n         9.6193e-03,  2.6433e-02,  4.6095e-02,  1.1417e-02, -3.7447e-02,\n         1.7427e-02, -1.1938e-02,  2.8570e-02,  1.1151e-02, -4.9988e-02,\n         4.5225e-03, -8.7485e-04,  3.8626e-04, -2.0135e-02,  2.5093e-02,\n        -1.3513e-02,  1.8518e-02,  3.5196e-03,  3.1535e-02,  1.3996e-03,\n         1.3780e-02, -2.1670e-02, -5.2225e-03,  2.5584e-02,  4.2089e-03,\n         3.8124e-02,  2.6356e-02,  6.5364e-03, -2.6392e-02,  2.5153e-02,\n         3.8956e-03, -2.3723e-03,  1.1107e-02, -1.0164e-02, -2.1589e-02,\n         4.2959e-04, -5.3201e-03, -7.1018e-03,  3.8354e-02, -3.1566e-02,\n        -5.4392e-02, -6.9081e-03, -2.0118e-02,  3.9108e-02,  5.2898e-02,\n        -2.9806e-02,  2.9153e-03, -2.0809e-02, -5.0453e-03,  5.6375e-02,\n         3.0187e-02,  1.8004e-02, -4.2141e-02, -1.3734e-02, -5.1492e-02,\n         1.5902e-02, -1.4882e-02, -1.8903e-02, -1.7953e-02, -1.3936e-02,\n        -7.1016e-02,  2.8691e-02, -2.0724e-02,  5.5857e-02, -2.4585e-03,\n         7.3313e-02,  5.2563e-03,  4.2594e-02,  5.3725e-02,  1.8441e-02,\n         1.6917e-03,  3.6303e-02,  2.3945e-02, -3.2344e-02,  3.2553e-03,\n        -1.9167e-02, -4.4334e-02,  3.9803e-02, -1.9151e-02, -6.4997e-03,\n        -1.6137e-02, -1.5707e-02, -2.9232e-02, -1.5439e-02,  2.9270e-02,\n        -3.4386e-02, -2.3832e-02, -2.3655e-02, -3.1289e-02, -2.0325e-03,\n         2.8216e-02, -1.8466e-02, -6.4867e-02,  1.7630e-02, -1.1404e-02,\n         9.8349e-03, -3.2882e-02,  4.0311e-02, -2.3014e-02, -6.3402e-02,\n         2.3763e-02,  4.3423e-02,  1.8633e-02,  4.9515e-02, -1.0803e-02,\n         3.9881e-03, -3.3340e-03, -3.3554e-02, -3.5826e-03, -7.3466e-03,\n        -3.6185e-02,  3.0759e-02,  3.2033e-02,  4.8816e-03,  2.9372e-03,\n         2.4598e-02,  6.3836e-02, -5.5318e-02, -1.8839e-03, -2.2939e-02,\n        -2.4446e-02, -4.0971e-02, -1.2349e-02, -1.4514e-02,  4.3253e-02,\n        -3.2355e-02, -1.4892e-02,  1.6562e-02,  6.9631e-03, -1.5455e-03,\n         2.9432e-02,  3.9622e-02, -1.0088e-02,  4.1018e-02,  1.7982e-02,\n        -2.7261e-02, -1.8590e-02, -2.0049e-02, -1.2700e-02, -1.7333e-02,\n         7.4103e-03, -2.1999e-02, -9.7317e-03, -2.1245e-02, -1.5038e-02,\n        -3.9707e-02,  7.3319e-03,  3.2563e-03,  2.4064e-02,  3.2273e-02,\n        -4.8896e-02, -1.8710e-02,  4.3756e-02,  5.4508e-02,  1.7032e-02,\n        -1.6547e-02,  1.9985e-02,  1.8401e-02,  7.8026e-03,  3.2205e-02,\n        -4.4261e-02,  1.9250e-02, -6.1391e-05,  1.9695e-02,  3.0884e-02,\n        -3.7116e-02, -1.8625e-02,  2.2501e-04, -4.9301e-03, -4.1436e-03,\n         2.5902e-02, -4.0282e-03, -1.1720e-02,  3.8302e-03,  3.9821e-02,\n        -4.9551e-02,  2.7475e-02,  3.0709e-02,  1.7595e-02,  3.8964e-02,\n        -9.7549e-03,  1.5379e-03,  3.3634e-02, -1.1166e-02,  3.5440e-02,\n         2.1290e-02, -4.5897e-02, -3.1546e-03, -6.4353e-03,  1.1563e-02,\n        -1.2121e-02,  1.9742e-02, -2.5141e-02,  9.6644e-03,  4.7279e-03,\n        -1.5185e-02, -4.2401e-02, -3.5363e-02, -2.4696e-02,  2.7743e-02,\n         1.7791e-02, -4.2941e-03,  7.9650e-02, -1.8909e-02, -6.8849e-02,\n         1.6532e-02, -5.1533e-02,  4.6417e-02, -5.0641e-02,  4.4021e-03,\n         5.5228e-02,  3.5608e-02,  2.1866e-02,  1.1616e-02,  1.0231e-02,\n         3.5425e-02, -6.5255e-03, -3.8505e-02, -1.6462e-02, -1.3195e-02,\n         1.7093e-03, -4.4674e-02,  3.1638e-02, -4.2032e-03, -3.6664e-02,\n        -1.6861e-03,  1.9975e-02, -3.4789e-03,  1.2030e-03,  3.8017e-02,\n        -4.1901e-02, -2.8788e-02, -1.7662e-02,  6.0864e-03,  4.1293e-02,\n        -3.0686e-02, -2.8795e-02, -1.4041e-02, -2.6309e-02,  2.4461e-02,\n         4.7914e-02, -4.1671e-02,  6.7554e-03, -3.2115e-02,  1.2002e-02,\n         2.7440e-02, -1.1739e-02,  3.9808e-02, -2.3246e-02, -3.4203e-02,\n         1.2475e-02, -2.7068e-02,  3.1780e-03, -4.8388e-02,  1.1949e-02,\n         6.4224e-03,  2.1366e-02,  3.6450e-02, -1.9239e-02, -1.5970e-02,\n         2.1541e-02, -4.6215e-02,  5.5982e-02,  3.1539e-02,  3.7270e-02,\n        -1.7429e-02, -2.1533e-02, -2.1888e-02,  4.8549e-03, -3.3962e-02,\n         8.6748e-03,  2.3321e-02,  2.4407e-03, -9.7443e-03,  2.5593e-02,\n         8.5039e-02,  1.4389e-02, -5.1795e-02, -4.1282e-02, -4.2452e-02,\n        -1.0868e-03,  2.0946e-02,  6.6731e-03, -2.9915e-02, -4.0494e-02,\n         6.5891e-06,  2.2894e-02,  3.2235e-02,  6.7736e-03,  4.1591e-02,\n        -1.6306e-02,  3.1592e-02,  8.7277e-03, -7.1795e-02, -6.2773e-02,\n        -1.7885e-02, -1.3388e-02, -4.9008e-02,  1.2854e-02, -9.7705e-03,\n         2.5678e-02,  5.9443e-02, -1.0576e-02, -6.4409e-03,  1.4764e-02,\n         1.1457e-02,  1.2296e-02, -2.3408e-03,  4.6962e-02,  3.0773e-02,\n         2.5980e-02,  6.9821e-03, -3.4007e-03,  2.8049e-02, -5.9131e-02,\n         9.1472e-03,  2.9532e-02,  1.6776e-02,  7.9528e-04, -2.2810e-03,\n         2.4195e-02,  7.6681e-03,  4.7351e-02, -1.3194e-02,  3.3120e-02,\n         5.2170e-02, -5.1744e-02,  2.1149e-02, -4.3069e-02, -7.1468e-03,\n         5.1380e-02,  2.2538e-02,  7.2674e-02,  3.3932e-02, -9.7106e-03,\n        -4.1814e-02, -6.6706e-02, -4.4842e-02, -1.8795e-02, -2.3453e-02,\n        -1.5713e-02,  3.9117e-02,  1.6532e-02,  4.9258e-02, -1.7738e-02,\n        -3.4397e-02,  1.4257e-02, -6.9226e-02,  7.2988e-03, -2.2353e-03,\n         2.7215e-02,  4.5418e-04, -5.5413e-03, -8.8816e-03,  5.0825e-02,\n        -5.1394e-02, -7.8356e-03,  5.4895e-02, -6.3182e-02,  7.8520e-03,\n         2.4969e-02, -1.8521e-02,  3.2755e-02,  3.1697e-03, -5.1278e-03,\n         8.3151e-04, -1.9937e-02, -1.1711e-02, -6.7088e-03,  5.0560e-03,\n        -7.6986e-02,  1.7715e-02,  3.7020e-02, -1.2592e-02, -1.7903e-02,\n        -4.1251e-02,  1.8015e-02, -1.2835e-02, -3.2818e-02, -4.0190e-02,\n         3.7402e-03, -2.9695e-02, -4.8587e-02, -1.5524e-02, -4.9107e-03,\n         3.5758e-03, -2.0782e-02,  1.2017e-02, -2.4392e-02,  1.4292e-02,\n        -3.7692e-02, -3.3561e-02,  1.7345e-02, -3.1682e-02,  4.4869e-03,\n        -1.9243e-03, -3.6827e-02, -1.5922e-02, -2.4342e-02,  2.6449e-02,\n        -1.5103e-02, -2.6972e-02, -3.1471e-02, -6.2291e-03,  8.5631e-03,\n        -3.5383e-02,  1.6009e-02, -5.4442e-02, -4.7372e-03,  3.5776e-02,\n        -4.3964e-02,  4.1963e-02, -5.2468e-03,  4.6858e-02, -5.3066e-02,\n         4.4797e-03, -2.5859e-02, -4.2804e-02,  4.1824e-03, -6.5898e-03,\n         6.1486e-06, -4.1330e-02,  5.6652e-02,  2.4818e-02, -2.5542e-02,\n         1.1009e-02, -4.6585e-02,  5.9552e-02, -1.2657e-03, -6.8601e-03,\n         2.3884e-03, -8.7499e-03,  1.0809e-03,  2.5891e-02, -5.9846e-03,\n        -5.9949e-03,  1.9207e-02,  3.6267e-02, -1.4507e-02,  4.0101e-02,\n        -8.9881e-03,  3.3039e-02,  3.0556e-02, -3.8921e-02, -3.1528e-04,\n        -1.8981e-02,  1.2414e-02,  6.7135e-02,  2.6214e-02,  7.5510e-03,\n         4.8992e-03,  3.7507e-02,  3.0166e-02,  1.0858e-02,  3.3014e-02,\n        -1.4618e-02,  2.5819e-02, -1.9128e-03,  4.2443e-02,  1.0894e-02,\n         2.7081e-02,  8.1226e-03,  2.3095e-02, -1.1285e-02, -2.5196e-02,\n         4.5187e-02, -2.6855e-02, -3.0506e-02, -2.6663e-02,  1.5108e-02,\n         2.4811e-02,  6.0866e-02, -2.8868e-02,  6.1158e-02, -6.4629e-03,\n         1.7970e-02, -3.1961e-02, -8.4662e-03,  4.6212e-03,  3.4618e-02,\n         6.3437e-02, -2.2518e-03], grad_fn=<SumBackward1>)"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.network_analysis import count_parameters\n",
    "from src.networks.skip_nets.dense_skip_net import DenseSkipNet\n",
    "from src.networks.core.torch_net import TorchNet\n",
    "from src.networks.core.layer_connections import LayerConnections\n",
    "from src.networks.skip_nets.additive_skip_net import AdditiveSkipNet\n",
    "\n",
    "def create_layer(i, last, in_features, out_features):\n",
    "    l = nn.Linear(in_features, out_features)\n",
    "    # l.weight.data[:] = 0.1\n",
    "    # l.bias.data[:] = 0.0\n",
    "    return nn.Sequential(\n",
    "        l,\n",
    "        nn.CELU(),\n",
    "    )\n",
    "\n",
    "net = AdditiveSkipNet.from_layer_provider(\n",
    "    layer_provider=create_layer,\n",
    "    num_layers=256,\n",
    "    num_features=512,\n",
    "    layer_connections='full',\n",
    "    initial_direct_connection_weight=1.0,\n",
    "    initial_skip_connection_weight=0.01,\n",
    "    return_dense=False,\n",
    "    weights_trainable=False,\n",
    ")\n",
    "# net = DenseSkipNet.from_layer_provider(\n",
    "#     layer_provider=create_layer,\n",
    "#     num_layers=4,\n",
    "#     num_features=1,\n",
    "# )\n",
    "print(count_parameters(net))\n",
    "print(net)\n",
    "\n",
    "net(torch.ones(512) * 0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "2.0500000000000003"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1.61 + 0.1 * (1.3 + 1 + 1 + 1.1)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c5a5e3e1d339c766"
  }
 ],
 "metadata": {
  "autoscrollcelloutput": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
